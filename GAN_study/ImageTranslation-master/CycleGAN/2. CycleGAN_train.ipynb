{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ncp/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torchvision import transforms\n",
    "from dataset import DatasetFromFolder\n",
    "from model import Generator, Discriminator\n",
    "\n",
    "import utils\n",
    "import argparse\n",
    "import os, itertools\n",
    "from logger import Logger\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Setting Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(batch_size=1, beta1=0.5, beta2=0.999, crop_size=256, dataset='horse2zebra', decay_epoch=100, fliplr=True, input_size=256, lambdaA=10, lambdaB=10, lrD=0.0002, lrG=0.0002, ndf=64, ngf=32, num_epochs=200, num_resnet=6, resize_scale=286)\n"
     ]
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "#Data Set Parameter\n",
    "parser.add_argument('--dataset', required=False, default='horse2zebra', help='input dataset')\n",
    "parser.add_argument('--batch_size', type=int, default=1, help='train batch size')\n",
    "parser.add_argument('--input_size', type=int, default=256, help='input size')\n",
    "parser.add_argument('--resize_scale', type=int, default=286, help='resize scale (0 is false)')\n",
    "parser.add_argument('--crop_size', type=int, default=256, help='crop size (0 is false)')\n",
    "parser.add_argument('--fliplr', type=bool, default=True, help='random fliplr True of False')\n",
    "\n",
    "#Model Parameters \n",
    "parser.add_argument('--ngf', type=int, default=32) # number of generator filters\n",
    "parser.add_argument('--ndf', type=int, default=64) # number of discriminator filters\n",
    "parser.add_argument('--num_resnet', type=int, default=6, help='number of resnet blocks in generator')\n",
    "\n",
    "#Learning Parameters\n",
    "parser.add_argument('--num_epochs', type=int, default=200, help='number of train epochs')\n",
    "parser.add_argument('--decay_epoch', type=int, default=100, help='start decaying learning rate after this number')\n",
    "parser.add_argument('--lrG', type=float, default=0.0002, help='learning rate for generator, default=0.0002')\n",
    "parser.add_argument('--lrD', type=float, default=0.0002, help='learning rate for discriminator, default=0.0002')\n",
    "parser.add_argument('--beta1', type=float, default=0.5, help='beta1 for Adam optimizer')\n",
    "parser.add_argument('--beta2', type=float, default=0.999, help='beta2 for Adam optimizer')\n",
    "parser.add_argument('--lambdaA', type=float, default=10, help='lambdaA for cycle loss')\n",
    "parser.add_argument('--lambdaB', type=float, default=10, help='lambdaB for cycle loss')\n",
    "params = parser.parse_args([])\n",
    "print(params)\n",
    "\n",
    "# Directories for loading data and saving results\n",
    "data_dir = 'data/' + params.dataset + '/'\n",
    "save_dir = params.dataset + '_results/'\n",
    "model_dir = params.dataset + '_model/'\n",
    "\n",
    "# Set the logger\n",
    "D_A_log_dir = save_dir + 'D_A_logs'\n",
    "D_B_log_dir = save_dir + 'D_B_logs'\n",
    "D_A_logger = Logger(D_A_log_dir)\n",
    "D_B_logger = Logger(D_B_log_dir)\n",
    "\n",
    "G_A_log_dir = save_dir + 'G_A_logs'\n",
    "G_B_log_dir = save_dir + 'G_B_logs'\n",
    "\n",
    "G_A_logger = Logger(G_A_log_dir)\n",
    "G_B_logger = Logger(G_B_log_dir)\n",
    "\n",
    "cycle_A_log_dir = save_dir + 'cycle_A_logs'\n",
    "cycle_B_log_dir = save_dir + 'cycle_B_logs'\n",
    "\n",
    "cycle_A_logger = Logger(cycle_A_log_dir)\n",
    "cycle_B_logger = Logger(cycle_B_log_dir)\n",
    "\n",
    "img_log_dir = save_dir + 'img_logs'\n",
    "img_logger = Logger(img_log_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load Dataset\n",
    "### 3.2 Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Scale((params.input_size,params.input_size)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Load Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_A = DatasetFromFolder(data_dir, subfolder='trainA', transform=transform,\n",
    "                                resize_scale=params.resize_scale, crop_size=params.crop_size, fliplr=params.fliplr)\n",
    "\n",
    "train_data_loader_A = torch.utils.data.DataLoader(dataset=train_data_A, batch_size=params.batch_size, shuffle=True)\n",
    "\n",
    "train_data_B = DatasetFromFolder(data_dir, subfolder='trainB', transform=transform,\n",
    "                                resize_scale=params.resize_scale, crop_size=params.crop_size, fliplr=params.fliplr)\n",
    "\n",
    "train_data_loader_B = torch.utils.data.DataLoader(dataset=train_data_B, batch_size=params.batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Load Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "( 0 , 0 ,.,.) = \n",
      "  0.3490  0.2784  0.3333  ...   0.5686  0.5529  0.4902\n",
      "  0.3412  0.3412  0.3569  ...   0.4510  0.4510  0.3725\n",
      "  0.3176  0.3176  0.2314  ...   0.3961  0.3804  0.2941\n",
      "           ...             ⋱             ...          \n",
      " -0.3098 -0.5451 -0.5216  ...  -0.1922 -0.2392 -0.1137\n",
      " -0.2314 -0.4196 -0.4980  ...  -0.0353 -0.0353 -0.0275\n",
      " -0.3176 -0.3412 -0.3882  ...  -0.0588  0.0902  0.0902\n",
      "\n",
      "( 0 , 1 ,.,.) = \n",
      "  0.2627  0.1843  0.2471  ...   0.4980  0.4667  0.4196\n",
      "  0.2471  0.2549  0.2784  ...   0.3961  0.3804  0.3020\n",
      "  0.2157  0.2314  0.1686  ...   0.3490  0.3333  0.2471\n",
      "           ...             ⋱             ...          \n",
      " -0.1843 -0.4353 -0.4196  ...  -0.1608 -0.1137  0.0118\n",
      " -0.1216 -0.3569 -0.4745  ...  -0.0118  0.0510  0.0196\n",
      " -0.2078 -0.2863 -0.4039  ...  -0.0275  0.1137  0.0039\n",
      "\n",
      "( 0 , 2 ,.,.) = \n",
      "  0.0353  0.0196  0.1059  ...   0.0667  0.0510 -0.0118\n",
      "  0.0431  0.0902  0.1373  ...  -0.0667 -0.0667 -0.1294\n",
      "  0.0431  0.0902  0.0431  ...  -0.1373 -0.1451 -0.2078\n",
      "           ...             ⋱             ...          \n",
      " -0.6392 -0.7804 -0.8118  ...  -0.5843 -0.5451 -0.4824\n",
      " -0.6000 -0.6706 -0.7647  ...  -0.4745 -0.4275 -0.4980\n",
      " -0.6627 -0.6314 -0.6549  ...  -0.5137 -0.4118 -0.4980\n",
      "[torch.FloatTensor of size 1x3x256x256]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_data_A = DatasetFromFolder(data_dir, subfolder='testA', transform=transform)\n",
    "\n",
    "test_data_loader_A = torch.utils.data.DataLoader(dataset=test_data_A, batch_size=params.batch_size, shuffle=False)\n",
    "\n",
    "test_data_B = DatasetFromFolder(data_dir, subfolder='testB', transform=transform)\n",
    "\n",
    "test_data_loader_B = torch.utils.data.DataLoader(dataset=test_data_B, batch_size=params.batch_size, shuffle=False)\n",
    "\n",
    "\n",
    "# Get specific test images\n",
    "test_real_A_data = train_data_A.__getitem__(11).unsqueeze(0) # Convert to 4d tensor (BxNxHxW)\n",
    "test_real_B_data = train_data_B.__getitem__(91).unsqueeze(0)\n",
    "print(test_real_A_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Build Model & Optimizers & Criterions\n",
    "### 4.1 Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generator(\n",
      "  (pad): ReflectionPad2d((3, 3, 3, 3))\n",
      "  (conv1): ConvBlock(\n",
      "    (conv): Conv2d(3, 32, kernel_size=(7, 7), stride=(1, 1))\n",
      "    (bn): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=False)\n",
      "    (relu): ReLU(inplace)\n",
      "    (lrelu): LeakyReLU(0.2, inplace)\n",
      "    (tanh): Tanh()\n",
      "  )\n",
      "  (conv2): ConvBlock(\n",
      "    (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (bn): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False)\n",
      "    (relu): ReLU(inplace)\n",
      "    (lrelu): LeakyReLU(0.2, inplace)\n",
      "    (tanh): Tanh()\n",
      "  )\n",
      "  (conv3): ConvBlock(\n",
      "    (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (bn): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False)\n",
      "    (relu): ReLU(inplace)\n",
      "    (lrelu): LeakyReLU(0.2, inplace)\n",
      "    (tanh): Tanh()\n",
      "  )\n",
      "  (resnet_blocks): Sequential(\n",
      "    (0): ResnetBlock(\n",
      "      (resnet_block): Sequential(\n",
      "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False)\n",
      "        (3): ReLU(inplace)\n",
      "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (5): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (6): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False)\n",
      "      )\n",
      "    )\n",
      "    (1): ResnetBlock(\n",
      "      (resnet_block): Sequential(\n",
      "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False)\n",
      "        (3): ReLU(inplace)\n",
      "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (5): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (6): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False)\n",
      "      )\n",
      "    )\n",
      "    (2): ResnetBlock(\n",
      "      (resnet_block): Sequential(\n",
      "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False)\n",
      "        (3): ReLU(inplace)\n",
      "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (5): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (6): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False)\n",
      "      )\n",
      "    )\n",
      "    (3): ResnetBlock(\n",
      "      (resnet_block): Sequential(\n",
      "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False)\n",
      "        (3): ReLU(inplace)\n",
      "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (5): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (6): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False)\n",
      "      )\n",
      "    )\n",
      "    (4): ResnetBlock(\n",
      "      (resnet_block): Sequential(\n",
      "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False)\n",
      "        (3): ReLU(inplace)\n",
      "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (5): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (6): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False)\n",
      "      )\n",
      "    )\n",
      "    (5): ResnetBlock(\n",
      "      (resnet_block): Sequential(\n",
      "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False)\n",
      "        (3): ReLU(inplace)\n",
      "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (5): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (6): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (deconv1): DeconvBlock(\n",
      "    (deconv): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "    (bn): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False)\n",
      "    (relu): ReLU(inplace)\n",
      "  )\n",
      "  (deconv2): DeconvBlock(\n",
      "    (deconv): ConvTranspose2d(64, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "    (bn): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=False)\n",
      "    (relu): ReLU(inplace)\n",
      "  )\n",
      "  (deconv3): ConvBlock(\n",
      "    (conv): Conv2d(32, 3, kernel_size=(7, 7), stride=(1, 1))\n",
      "    (bn): InstanceNorm2d(3, eps=1e-05, momentum=0.1, affine=False)\n",
      "    (relu): ReLU(inplace)\n",
      "    (lrelu): LeakyReLU(0.2, inplace)\n",
      "    (tanh): Tanh()\n",
      "  )\n",
      ")\n",
      "Generator(\n",
      "  (pad): ReflectionPad2d((3, 3, 3, 3))\n",
      "  (conv1): ConvBlock(\n",
      "    (conv): Conv2d(3, 32, kernel_size=(7, 7), stride=(1, 1))\n",
      "    (bn): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=False)\n",
      "    (relu): ReLU(inplace)\n",
      "    (lrelu): LeakyReLU(0.2, inplace)\n",
      "    (tanh): Tanh()\n",
      "  )\n",
      "  (conv2): ConvBlock(\n",
      "    (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (bn): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False)\n",
      "    (relu): ReLU(inplace)\n",
      "    (lrelu): LeakyReLU(0.2, inplace)\n",
      "    (tanh): Tanh()\n",
      "  )\n",
      "  (conv3): ConvBlock(\n",
      "    (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (bn): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False)\n",
      "    (relu): ReLU(inplace)\n",
      "    (lrelu): LeakyReLU(0.2, inplace)\n",
      "    (tanh): Tanh()\n",
      "  )\n",
      "  (resnet_blocks): Sequential(\n",
      "    (0): ResnetBlock(\n",
      "      (resnet_block): Sequential(\n",
      "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False)\n",
      "        (3): ReLU(inplace)\n",
      "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (5): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (6): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False)\n",
      "      )\n",
      "    )\n",
      "    (1): ResnetBlock(\n",
      "      (resnet_block): Sequential(\n",
      "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False)\n",
      "        (3): ReLU(inplace)\n",
      "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (5): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (6): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False)\n",
      "      )\n",
      "    )\n",
      "    (2): ResnetBlock(\n",
      "      (resnet_block): Sequential(\n",
      "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False)\n",
      "        (3): ReLU(inplace)\n",
      "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (5): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (6): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False)\n",
      "      )\n",
      "    )\n",
      "    (3): ResnetBlock(\n",
      "      (resnet_block): Sequential(\n",
      "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False)\n",
      "        (3): ReLU(inplace)\n",
      "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (5): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (6): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False)\n",
      "      )\n",
      "    )\n",
      "    (4): ResnetBlock(\n",
      "      (resnet_block): Sequential(\n",
      "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False)\n",
      "        (3): ReLU(inplace)\n",
      "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (5): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (6): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False)\n",
      "      )\n",
      "    )\n",
      "    (5): ResnetBlock(\n",
      "      (resnet_block): Sequential(\n",
      "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False)\n",
      "        (3): ReLU(inplace)\n",
      "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (5): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (6): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (deconv1): DeconvBlock(\n",
      "    (deconv): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "    (bn): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False)\n",
      "    (relu): ReLU(inplace)\n",
      "  )\n",
      "  (deconv2): DeconvBlock(\n",
      "    (deconv): ConvTranspose2d(64, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "    (bn): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=False)\n",
      "    (relu): ReLU(inplace)\n",
      "  )\n",
      "  (deconv3): ConvBlock(\n",
      "    (conv): Conv2d(32, 3, kernel_size=(7, 7), stride=(1, 1))\n",
      "    (bn): InstanceNorm2d(3, eps=1e-05, momentum=0.1, affine=False)\n",
      "    (relu): ReLU(inplace)\n",
      "    (lrelu): LeakyReLU(0.2, inplace)\n",
      "    (tanh): Tanh()\n",
      "  )\n",
      ")\n",
      "Discriminator(\n",
      "  (conv_blocks): Sequential(\n",
      "    (0): ConvBlock(\n",
      "      (conv): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "      (bn): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False)\n",
      "      (relu): ReLU(inplace)\n",
      "      (lrelu): LeakyReLU(0.2, inplace)\n",
      "      (tanh): Tanh()\n",
      "    )\n",
      "    (1): ConvBlock(\n",
      "      (conv): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "      (bn): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False)\n",
      "      (relu): ReLU(inplace)\n",
      "      (lrelu): LeakyReLU(0.2, inplace)\n",
      "      (tanh): Tanh()\n",
      "    )\n",
      "    (2): ConvBlock(\n",
      "      (conv): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "      (bn): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False)\n",
      "      (relu): ReLU(inplace)\n",
      "      (lrelu): LeakyReLU(0.2, inplace)\n",
      "      (tanh): Tanh()\n",
      "    )\n",
      "    (3): ConvBlock(\n",
      "      (conv): Conv2d(256, 512, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1))\n",
      "      (bn): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False)\n",
      "      (relu): ReLU(inplace)\n",
      "      (lrelu): LeakyReLU(0.2, inplace)\n",
      "      (tanh): Tanh()\n",
      "    )\n",
      "    (4): ConvBlock(\n",
      "      (conv): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1))\n",
      "      (bn): InstanceNorm2d(1, eps=1e-05, momentum=0.1, affine=False)\n",
      "      (relu): ReLU(inplace)\n",
      "      (lrelu): LeakyReLU(0.2, inplace)\n",
      "      (tanh): Tanh()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Discriminator(\n",
      "  (conv_blocks): Sequential(\n",
      "    (0): ConvBlock(\n",
      "      (conv): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "      (bn): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False)\n",
      "      (relu): ReLU(inplace)\n",
      "      (lrelu): LeakyReLU(0.2, inplace)\n",
      "      (tanh): Tanh()\n",
      "    )\n",
      "    (1): ConvBlock(\n",
      "      (conv): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "      (bn): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False)\n",
      "      (relu): ReLU(inplace)\n",
      "      (lrelu): LeakyReLU(0.2, inplace)\n",
      "      (tanh): Tanh()\n",
      "    )\n",
      "    (2): ConvBlock(\n",
      "      (conv): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "      (bn): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False)\n",
      "      (relu): ReLU(inplace)\n",
      "      (lrelu): LeakyReLU(0.2, inplace)\n",
      "      (tanh): Tanh()\n",
      "    )\n",
      "    (3): ConvBlock(\n",
      "      (conv): Conv2d(256, 512, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1))\n",
      "      (bn): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False)\n",
      "      (relu): ReLU(inplace)\n",
      "      (lrelu): LeakyReLU(0.2, inplace)\n",
      "      (tanh): Tanh()\n",
      "    )\n",
      "    (4): ConvBlock(\n",
      "      (conv): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1))\n",
      "      (bn): InstanceNorm2d(1, eps=1e-05, momentum=0.1, affine=False)\n",
      "      (relu): ReLU(inplace)\n",
      "      (lrelu): LeakyReLU(0.2, inplace)\n",
      "      (tanh): Tanh()\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "G_A = Generator(3, params.ngf, 3, params.num_resnet) # input_dim, num_filter, output_dim, num_resnet\n",
    "G_B = Generator(3, params.ngf, 3, params.num_resnet)\n",
    "\n",
    "D_A = Discriminator(3, params.ndf, 1) # input_dim, num_filter, output_dim\n",
    "D_B = Discriminator(3, params.ndf, 1)\n",
    "\n",
    "G_A.normal_weight_init(mean=0.0, std=0.02)\n",
    "G_B.normal_weight_init(mean=0.0, std=0.02)\n",
    "D_A.normal_weight_init(mean=0.0, std=0.02)\n",
    "D_B.normal_weight_init(mean=0.0, std=0.02)\n",
    "\n",
    "print(G_A.cuda())\n",
    "print(G_B.cuda())\n",
    "print(D_A.cuda())\n",
    "print(D_B.cuda())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_optimizer = torch.optim.Adam(itertools.chain(G_A.parameters(), G_B.parameters()), lr=params.lrG, betas=(params.beta1, params.beta2))\n",
    "D_A_optimizer = torch.optim.Adam(D_A.parameters(), lr=params.lrD, betas=(params.beta1, params.beta2))\n",
    "D_B_optimizer = torch.optim.Adam(D_B.parameters(), lr=params.lrD, betas=(params.beta1, params.beta2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Loss Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "MSE_Loss = torch.nn.MSELoss().cuda()\n",
    "L1_Loss = torch.nn.L1Loss().cuda()\n",
    "\n",
    "# # Training GAN\n",
    "D_A_avg_losses = []\n",
    "D_B_avg_losses = []\n",
    "G_A_avg_losses = []\n",
    "G_B_avg_losses = []\n",
    "cycle_A_avg_losses = []\n",
    "cycle_B_avg_losses = []\n",
    "\n",
    "# Generated image pool\n",
    "num_pool = 50\n",
    "fake_A_pool = utils.ImagePool(num_pool)\n",
    "fake_B_pool = utils.ImagePool(num_pool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Training Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/200], Step [1/1067], D_A_loss: 0.5368, D_B_loss: 0.5034, G_A_loss: 0.8002, G_B_loss: 0.9582\n",
      "Epoch [1/200], Step [11/1067], D_A_loss: 0.3148, D_B_loss: 0.3428, G_A_loss: 0.3399, G_B_loss: 0.2891\n",
      "Epoch [1/200], Step [21/1067], D_A_loss: 0.2535, D_B_loss: 0.2348, G_A_loss: 0.3818, G_B_loss: 0.2847\n",
      "Epoch [1/200], Step [31/1067], D_A_loss: 0.3186, D_B_loss: 0.3931, G_A_loss: 0.7738, G_B_loss: 0.3859\n",
      "Epoch [1/200], Step [41/1067], D_A_loss: 0.3415, D_B_loss: 0.2320, G_A_loss: 0.3605, G_B_loss: 0.4218\n",
      "Epoch [1/200], Step [51/1067], D_A_loss: 0.2629, D_B_loss: 0.2178, G_A_loss: 0.5693, G_B_loss: 0.4091\n",
      "Epoch [1/200], Step [61/1067], D_A_loss: 0.2171, D_B_loss: 0.3190, G_A_loss: 0.4678, G_B_loss: 0.2745\n",
      "Epoch [1/200], Step [71/1067], D_A_loss: 0.2923, D_B_loss: 0.2944, G_A_loss: 0.2868, G_B_loss: 0.4338\n",
      "Epoch [1/200], Step [81/1067], D_A_loss: 0.2180, D_B_loss: 0.2870, G_A_loss: 0.3484, G_B_loss: 0.3156\n",
      "Epoch [1/200], Step [91/1067], D_A_loss: 0.2218, D_B_loss: 0.1730, G_A_loss: 0.2867, G_B_loss: 0.2754\n",
      "Epoch [1/200], Step [101/1067], D_A_loss: 0.3277, D_B_loss: 0.1960, G_A_loss: 0.3455, G_B_loss: 0.3887\n",
      "Epoch [1/200], Step [111/1067], D_A_loss: 0.2244, D_B_loss: 0.2326, G_A_loss: 0.5070, G_B_loss: 0.3867\n",
      "Epoch [1/200], Step [121/1067], D_A_loss: 0.2578, D_B_loss: 0.2800, G_A_loss: 0.3682, G_B_loss: 0.4839\n",
      "Epoch [1/200], Step [131/1067], D_A_loss: 0.1811, D_B_loss: 0.2267, G_A_loss: 0.4064, G_B_loss: 0.3830\n",
      "Epoch [1/200], Step [141/1067], D_A_loss: 0.2384, D_B_loss: 0.2249, G_A_loss: 0.4377, G_B_loss: 0.4209\n",
      "Epoch [1/200], Step [151/1067], D_A_loss: 0.2495, D_B_loss: 0.4635, G_A_loss: 0.4559, G_B_loss: 0.6621\n",
      "Epoch [1/200], Step [161/1067], D_A_loss: 0.2426, D_B_loss: 0.2189, G_A_loss: 0.3156, G_B_loss: 0.3047\n",
      "Epoch [1/200], Step [171/1067], D_A_loss: 0.1643, D_B_loss: 0.2530, G_A_loss: 0.3299, G_B_loss: 0.3797\n",
      "Epoch [1/200], Step [181/1067], D_A_loss: 0.2289, D_B_loss: 0.1970, G_A_loss: 0.5121, G_B_loss: 0.1270\n",
      "Epoch [1/200], Step [191/1067], D_A_loss: 0.2329, D_B_loss: 0.1963, G_A_loss: 0.5222, G_B_loss: 0.4411\n",
      "Epoch [1/200], Step [201/1067], D_A_loss: 0.3316, D_B_loss: 0.2982, G_A_loss: 0.5309, G_B_loss: 0.2306\n",
      "Epoch [1/200], Step [211/1067], D_A_loss: 0.1377, D_B_loss: 0.1292, G_A_loss: 0.3867, G_B_loss: 0.5149\n",
      "Epoch [1/200], Step [221/1067], D_A_loss: 0.1985, D_B_loss: 0.2414, G_A_loss: 0.5780, G_B_loss: 0.4044\n",
      "Epoch [1/200], Step [231/1067], D_A_loss: 0.1815, D_B_loss: 0.2740, G_A_loss: 0.2160, G_B_loss: 0.5047\n",
      "Epoch [1/200], Step [241/1067], D_A_loss: 0.1538, D_B_loss: 0.2201, G_A_loss: 0.2234, G_B_loss: 0.6415\n",
      "Epoch [1/200], Step [251/1067], D_A_loss: 0.1126, D_B_loss: 0.4471, G_A_loss: 0.1747, G_B_loss: 0.6849\n",
      "Epoch [1/200], Step [261/1067], D_A_loss: 0.1042, D_B_loss: 0.1788, G_A_loss: 0.2780, G_B_loss: 0.2576\n",
      "Epoch [1/200], Step [271/1067], D_A_loss: 0.1614, D_B_loss: 0.1393, G_A_loss: 0.4766, G_B_loss: 0.4534\n",
      "Epoch [1/200], Step [281/1067], D_A_loss: 0.3797, D_B_loss: 0.3381, G_A_loss: 0.3126, G_B_loss: 0.6559\n",
      "Epoch [1/200], Step [291/1067], D_A_loss: 0.1703, D_B_loss: 0.3127, G_A_loss: 0.9033, G_B_loss: 0.2239\n",
      "Epoch [1/200], Step [301/1067], D_A_loss: 0.2217, D_B_loss: 0.0982, G_A_loss: 0.3775, G_B_loss: 0.2185\n",
      "Epoch [1/200], Step [311/1067], D_A_loss: 0.2907, D_B_loss: 0.1690, G_A_loss: 0.5537, G_B_loss: 0.5895\n",
      "Epoch [1/200], Step [321/1067], D_A_loss: 0.1847, D_B_loss: 0.2897, G_A_loss: 0.3259, G_B_loss: 0.3533\n",
      "Epoch [1/200], Step [331/1067], D_A_loss: 0.3140, D_B_loss: 0.1215, G_A_loss: 0.6463, G_B_loss: 0.2365\n",
      "Epoch [1/200], Step [341/1067], D_A_loss: 0.2512, D_B_loss: 0.2222, G_A_loss: 0.2537, G_B_loss: 0.5529\n",
      "Epoch [1/200], Step [351/1067], D_A_loss: 0.1151, D_B_loss: 0.1358, G_A_loss: 0.3505, G_B_loss: 0.8194\n",
      "Epoch [1/200], Step [361/1067], D_A_loss: 0.3901, D_B_loss: 0.1593, G_A_loss: 0.5302, G_B_loss: 0.2042\n",
      "Epoch [1/200], Step [371/1067], D_A_loss: 0.2780, D_B_loss: 0.0985, G_A_loss: 0.3275, G_B_loss: 0.2856\n",
      "Epoch [1/200], Step [381/1067], D_A_loss: 0.2786, D_B_loss: 0.2082, G_A_loss: 0.4268, G_B_loss: 0.2187\n",
      "Epoch [1/200], Step [391/1067], D_A_loss: 0.4567, D_B_loss: 0.1989, G_A_loss: 0.2307, G_B_loss: 0.8076\n",
      "Epoch [1/200], Step [401/1067], D_A_loss: 0.1482, D_B_loss: 0.2510, G_A_loss: 0.7446, G_B_loss: 0.2089\n",
      "Epoch [1/200], Step [411/1067], D_A_loss: 0.2812, D_B_loss: 0.2290, G_A_loss: 0.1462, G_B_loss: 0.1200\n",
      "Epoch [1/200], Step [421/1067], D_A_loss: 0.2152, D_B_loss: 0.1848, G_A_loss: 0.8060, G_B_loss: 0.7615\n",
      "Epoch [1/200], Step [431/1067], D_A_loss: 0.0747, D_B_loss: 0.2720, G_A_loss: 0.7194, G_B_loss: 0.5281\n",
      "Epoch [1/200], Step [441/1067], D_A_loss: 0.1818, D_B_loss: 0.1747, G_A_loss: 0.5633, G_B_loss: 0.3293\n",
      "Epoch [1/200], Step [451/1067], D_A_loss: 0.2514, D_B_loss: 0.1494, G_A_loss: 0.5734, G_B_loss: 0.2633\n",
      "Epoch [1/200], Step [461/1067], D_A_loss: 0.1814, D_B_loss: 0.2209, G_A_loss: 0.3697, G_B_loss: 0.3207\n",
      "Epoch [1/200], Step [471/1067], D_A_loss: 0.1168, D_B_loss: 0.1417, G_A_loss: 0.7385, G_B_loss: 0.5508\n",
      "Epoch [1/200], Step [481/1067], D_A_loss: 0.2784, D_B_loss: 0.0807, G_A_loss: 0.4599, G_B_loss: 0.1344\n",
      "Epoch [1/200], Step [491/1067], D_A_loss: 0.2691, D_B_loss: 0.1692, G_A_loss: 0.2319, G_B_loss: 0.5992\n",
      "Epoch [1/200], Step [501/1067], D_A_loss: 0.3092, D_B_loss: 0.2099, G_A_loss: 0.6432, G_B_loss: 0.7722\n",
      "Epoch [1/200], Step [511/1067], D_A_loss: 0.1458, D_B_loss: 0.1830, G_A_loss: 0.5271, G_B_loss: 0.3704\n",
      "Epoch [1/200], Step [521/1067], D_A_loss: 0.2646, D_B_loss: 0.1020, G_A_loss: 0.3733, G_B_loss: 0.1663\n",
      "Epoch [1/200], Step [531/1067], D_A_loss: 0.1540, D_B_loss: 0.2486, G_A_loss: 0.1903, G_B_loss: 0.5206\n",
      "Epoch [1/200], Step [541/1067], D_A_loss: 0.1125, D_B_loss: 0.2829, G_A_loss: 0.2461, G_B_loss: 0.3857\n",
      "Epoch [1/200], Step [551/1067], D_A_loss: 0.2700, D_B_loss: 0.1228, G_A_loss: 0.4735, G_B_loss: 0.1385\n",
      "Epoch [1/200], Step [561/1067], D_A_loss: 0.5171, D_B_loss: 0.0981, G_A_loss: 0.2141, G_B_loss: 0.8154\n",
      "Epoch [1/200], Step [571/1067], D_A_loss: 0.2044, D_B_loss: 0.1736, G_A_loss: 0.2494, G_B_loss: 0.4672\n",
      "Epoch [1/200], Step [581/1067], D_A_loss: 0.0883, D_B_loss: 0.1953, G_A_loss: 0.3418, G_B_loss: 0.2801\n",
      "Epoch [1/200], Step [591/1067], D_A_loss: 0.1596, D_B_loss: 0.0918, G_A_loss: 0.4991, G_B_loss: 0.5877\n",
      "Epoch [1/200], Step [601/1067], D_A_loss: 0.2063, D_B_loss: 0.1846, G_A_loss: 0.9052, G_B_loss: 0.6394\n",
      "Epoch [1/200], Step [611/1067], D_A_loss: 0.2219, D_B_loss: 0.0765, G_A_loss: 0.0912, G_B_loss: 0.3891\n",
      "Epoch [1/200], Step [621/1067], D_A_loss: 0.0963, D_B_loss: 0.1672, G_A_loss: 0.3700, G_B_loss: 0.2787\n",
      "Epoch [1/200], Step [631/1067], D_A_loss: 0.0837, D_B_loss: 0.1368, G_A_loss: 0.2083, G_B_loss: 0.1347\n",
      "Epoch [1/200], Step [641/1067], D_A_loss: 0.2182, D_B_loss: 0.2110, G_A_loss: 0.2798, G_B_loss: 0.3510\n",
      "Epoch [1/200], Step [651/1067], D_A_loss: 0.0461, D_B_loss: 0.0873, G_A_loss: 0.4645, G_B_loss: 0.2620\n",
      "Epoch [1/200], Step [661/1067], D_A_loss: 0.1462, D_B_loss: 0.1015, G_A_loss: 0.3928, G_B_loss: 0.0994\n",
      "Epoch [1/200], Step [671/1067], D_A_loss: 0.1291, D_B_loss: 0.0945, G_A_loss: 0.5823, G_B_loss: 0.3680\n",
      "Epoch [1/200], Step [681/1067], D_A_loss: 0.1039, D_B_loss: 0.2253, G_A_loss: 0.2969, G_B_loss: 0.4542\n",
      "Epoch [1/200], Step [691/1067], D_A_loss: 0.4227, D_B_loss: 0.2199, G_A_loss: 0.4536, G_B_loss: 0.5230\n",
      "Epoch [1/200], Step [701/1067], D_A_loss: 0.1793, D_B_loss: 0.1365, G_A_loss: 0.1486, G_B_loss: 0.3130\n",
      "Epoch [1/200], Step [711/1067], D_A_loss: 0.2230, D_B_loss: 0.3629, G_A_loss: 0.1273, G_B_loss: 0.1585\n",
      "Epoch [1/200], Step [721/1067], D_A_loss: 0.0932, D_B_loss: 0.2666, G_A_loss: 0.3705, G_B_loss: 0.0738\n",
      "Epoch [1/200], Step [731/1067], D_A_loss: 0.2632, D_B_loss: 0.0960, G_A_loss: 0.4557, G_B_loss: 0.1067\n",
      "Epoch [1/200], Step [741/1067], D_A_loss: 0.1402, D_B_loss: 0.2674, G_A_loss: 0.5333, G_B_loss: 0.2453\n",
      "Epoch [1/200], Step [751/1067], D_A_loss: 0.1961, D_B_loss: 0.2685, G_A_loss: 0.2323, G_B_loss: 0.4541\n",
      "Epoch [1/200], Step [761/1067], D_A_loss: 0.0704, D_B_loss: 0.2965, G_A_loss: 0.3230, G_B_loss: 0.2653\n",
      "Epoch [1/200], Step [771/1067], D_A_loss: 0.2799, D_B_loss: 0.1353, G_A_loss: 0.3516, G_B_loss: 0.1560\n",
      "Epoch [1/200], Step [781/1067], D_A_loss: 0.2059, D_B_loss: 0.2002, G_A_loss: 0.2196, G_B_loss: 0.1886\n",
      "Epoch [1/200], Step [791/1067], D_A_loss: 0.1043, D_B_loss: 0.2984, G_A_loss: 0.0929, G_B_loss: 0.3608\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/200], Step [801/1067], D_A_loss: 0.2576, D_B_loss: 0.2407, G_A_loss: 0.2695, G_B_loss: 0.6254\n",
      "Epoch [1/200], Step [811/1067], D_A_loss: 0.3679, D_B_loss: 0.0984, G_A_loss: 0.3395, G_B_loss: 0.0524\n",
      "Epoch [1/200], Step [821/1067], D_A_loss: 0.3162, D_B_loss: 0.2332, G_A_loss: 0.2801, G_B_loss: 0.4361\n",
      "Epoch [1/200], Step [831/1067], D_A_loss: 0.0776, D_B_loss: 0.0477, G_A_loss: 0.7011, G_B_loss: 0.3523\n",
      "Epoch [1/200], Step [841/1067], D_A_loss: 0.1131, D_B_loss: 0.2342, G_A_loss: 0.8285, G_B_loss: 0.5045\n",
      "Epoch [1/200], Step [851/1067], D_A_loss: 0.1211, D_B_loss: 0.1155, G_A_loss: 0.3278, G_B_loss: 0.1160\n",
      "Epoch [1/200], Step [861/1067], D_A_loss: 0.1899, D_B_loss: 0.4503, G_A_loss: 0.0608, G_B_loss: 0.1965\n",
      "Epoch [1/200], Step [871/1067], D_A_loss: 0.0961, D_B_loss: 0.2628, G_A_loss: 0.1353, G_B_loss: 0.5472\n",
      "Epoch [1/200], Step [881/1067], D_A_loss: 0.1340, D_B_loss: 0.2116, G_A_loss: 0.3309, G_B_loss: 0.0975\n",
      "Epoch [1/200], Step [891/1067], D_A_loss: 0.3133, D_B_loss: 0.1637, G_A_loss: 0.4101, G_B_loss: 0.6913\n",
      "Epoch [1/200], Step [901/1067], D_A_loss: 0.1455, D_B_loss: 0.3079, G_A_loss: 0.3408, G_B_loss: 0.3144\n",
      "Epoch [1/200], Step [911/1067], D_A_loss: 0.3004, D_B_loss: 0.1573, G_A_loss: 0.2942, G_B_loss: 0.1206\n",
      "Epoch [1/200], Step [921/1067], D_A_loss: 0.1022, D_B_loss: 0.1729, G_A_loss: 0.6088, G_B_loss: 0.3612\n",
      "Epoch [1/200], Step [931/1067], D_A_loss: 0.2361, D_B_loss: 0.0647, G_A_loss: 0.0727, G_B_loss: 0.1660\n",
      "Epoch [1/200], Step [941/1067], D_A_loss: 0.1908, D_B_loss: 0.1047, G_A_loss: 0.5247, G_B_loss: 0.2338\n",
      "Epoch [1/200], Step [951/1067], D_A_loss: 0.2382, D_B_loss: 0.0759, G_A_loss: 0.4252, G_B_loss: 0.2049\n",
      "Epoch [1/200], Step [961/1067], D_A_loss: 0.0874, D_B_loss: 0.1338, G_A_loss: 0.4425, G_B_loss: 0.3876\n",
      "Epoch [1/200], Step [971/1067], D_A_loss: 0.0575, D_B_loss: 0.3395, G_A_loss: 0.1033, G_B_loss: 0.6146\n",
      "Epoch [1/200], Step [981/1067], D_A_loss: 0.1000, D_B_loss: 0.0782, G_A_loss: 0.1469, G_B_loss: 0.5057\n",
      "Epoch [1/200], Step [991/1067], D_A_loss: 0.3291, D_B_loss: 0.3436, G_A_loss: 0.0796, G_B_loss: 0.1102\n",
      "Epoch [1/200], Step [1001/1067], D_A_loss: 0.0506, D_B_loss: 0.3789, G_A_loss: 0.0675, G_B_loss: 0.1960\n",
      "Epoch [1/200], Step [1011/1067], D_A_loss: 0.1843, D_B_loss: 0.1020, G_A_loss: 1.0857, G_B_loss: 0.5033\n",
      "Epoch [1/200], Step [1021/1067], D_A_loss: 0.1196, D_B_loss: 0.2071, G_A_loss: 0.3075, G_B_loss: 0.9862\n",
      "Epoch [1/200], Step [1031/1067], D_A_loss: 0.0710, D_B_loss: 0.0305, G_A_loss: 0.5013, G_B_loss: 0.1711\n",
      "Epoch [1/200], Step [1041/1067], D_A_loss: 0.5385, D_B_loss: 0.1360, G_A_loss: 0.0349, G_B_loss: 0.0626\n",
      "Epoch [1/200], Step [1051/1067], D_A_loss: 0.1461, D_B_loss: 0.1481, G_A_loss: 0.9167, G_B_loss: 0.4791\n",
      "Epoch [1/200], Step [1061/1067], D_A_loss: 0.1926, D_B_loss: 0.3812, G_A_loss: 0.0546, G_B_loss: 0.1862\n",
      "Epoch [2/200], Step [1/1067], D_A_loss: 0.0615, D_B_loss: 0.1225, G_A_loss: 0.3935, G_B_loss: 0.2042\n",
      "Epoch [2/200], Step [11/1067], D_A_loss: 0.2484, D_B_loss: 0.2788, G_A_loss: 0.4726, G_B_loss: 0.2592\n",
      "Epoch [2/200], Step [21/1067], D_A_loss: 0.1556, D_B_loss: 0.1363, G_A_loss: 0.2047, G_B_loss: 0.2603\n",
      "Epoch [2/200], Step [31/1067], D_A_loss: 0.1605, D_B_loss: 0.0457, G_A_loss: 0.8899, G_B_loss: 0.2819\n",
      "Epoch [2/200], Step [41/1067], D_A_loss: 0.1872, D_B_loss: 0.4353, G_A_loss: 0.9092, G_B_loss: 0.2220\n",
      "Epoch [2/200], Step [51/1067], D_A_loss: 0.0652, D_B_loss: 0.1459, G_A_loss: 0.8317, G_B_loss: 0.6933\n",
      "Epoch [2/200], Step [61/1067], D_A_loss: 0.2096, D_B_loss: 0.2552, G_A_loss: 0.4344, G_B_loss: 0.0340\n",
      "Epoch [2/200], Step [71/1067], D_A_loss: 0.1080, D_B_loss: 0.1345, G_A_loss: 0.8385, G_B_loss: 0.3402\n",
      "Epoch [2/200], Step [81/1067], D_A_loss: 0.2410, D_B_loss: 0.1545, G_A_loss: 0.4617, G_B_loss: 0.8369\n",
      "Epoch [2/200], Step [91/1067], D_A_loss: 0.0637, D_B_loss: 0.1147, G_A_loss: 0.1554, G_B_loss: 0.1627\n",
      "Epoch [2/200], Step [101/1067], D_A_loss: 0.0930, D_B_loss: 0.1096, G_A_loss: 0.8599, G_B_loss: 0.6545\n",
      "Epoch [2/200], Step [111/1067], D_A_loss: 0.0424, D_B_loss: 0.0310, G_A_loss: 0.5387, G_B_loss: 0.6772\n",
      "Epoch [2/200], Step [121/1067], D_A_loss: 0.2424, D_B_loss: 0.2675, G_A_loss: 0.7670, G_B_loss: 0.3685\n",
      "Epoch [2/200], Step [131/1067], D_A_loss: 0.1957, D_B_loss: 0.1474, G_A_loss: 0.2839, G_B_loss: 0.1962\n",
      "Epoch [2/200], Step [141/1067], D_A_loss: 0.1496, D_B_loss: 0.5786, G_A_loss: 0.0287, G_B_loss: 0.3947\n",
      "Epoch [2/200], Step [151/1067], D_A_loss: 0.1640, D_B_loss: 0.2308, G_A_loss: 0.8850, G_B_loss: 0.2374\n",
      "Epoch [2/200], Step [161/1067], D_A_loss: 0.1717, D_B_loss: 0.2382, G_A_loss: 0.2719, G_B_loss: 0.5872\n",
      "Epoch [2/200], Step [171/1067], D_A_loss: 0.0929, D_B_loss: 0.2573, G_A_loss: 0.0958, G_B_loss: 0.0647\n",
      "Epoch [2/200], Step [181/1067], D_A_loss: 0.2127, D_B_loss: 0.2224, G_A_loss: 0.2950, G_B_loss: 0.4385\n",
      "Epoch [2/200], Step [191/1067], D_A_loss: 0.2086, D_B_loss: 0.0578, G_A_loss: 0.6565, G_B_loss: 0.7640\n",
      "Epoch [2/200], Step [201/1067], D_A_loss: 0.1007, D_B_loss: 0.1773, G_A_loss: 0.2427, G_B_loss: 0.4777\n",
      "Epoch [2/200], Step [211/1067], D_A_loss: 0.0481, D_B_loss: 0.1446, G_A_loss: 0.3157, G_B_loss: 0.3835\n",
      "Epoch [2/200], Step [221/1067], D_A_loss: 0.5253, D_B_loss: 0.0533, G_A_loss: 0.2028, G_B_loss: 1.3092\n",
      "Epoch [2/200], Step [231/1067], D_A_loss: 0.1361, D_B_loss: 0.2357, G_A_loss: 0.1409, G_B_loss: 0.4854\n",
      "Epoch [2/200], Step [241/1067], D_A_loss: 0.0527, D_B_loss: 0.0983, G_A_loss: 0.4371, G_B_loss: 0.4165\n",
      "Epoch [2/200], Step [251/1067], D_A_loss: 0.1549, D_B_loss: 0.1133, G_A_loss: 1.2240, G_B_loss: 0.3085\n",
      "Epoch [2/200], Step [261/1067], D_A_loss: 0.1510, D_B_loss: 0.3918, G_A_loss: 0.0642, G_B_loss: 0.5802\n",
      "Epoch [2/200], Step [271/1067], D_A_loss: 0.1109, D_B_loss: 0.4401, G_A_loss: 0.1950, G_B_loss: 0.2629\n",
      "Epoch [2/200], Step [281/1067], D_A_loss: 0.2074, D_B_loss: 0.1766, G_A_loss: 0.7303, G_B_loss: 0.4211\n",
      "Epoch [2/200], Step [291/1067], D_A_loss: 0.1851, D_B_loss: 0.1014, G_A_loss: 0.2874, G_B_loss: 0.0553\n",
      "Epoch [2/200], Step [301/1067], D_A_loss: 0.0418, D_B_loss: 0.3663, G_A_loss: 0.8816, G_B_loss: 0.1945\n",
      "Epoch [2/200], Step [311/1067], D_A_loss: 0.0730, D_B_loss: 0.1735, G_A_loss: 0.2129, G_B_loss: 0.2051\n",
      "Epoch [2/200], Step [321/1067], D_A_loss: 0.0950, D_B_loss: 0.1065, G_A_loss: 0.5778, G_B_loss: 0.3797\n",
      "Epoch [2/200], Step [331/1067], D_A_loss: 0.0507, D_B_loss: 0.0825, G_A_loss: 0.4851, G_B_loss: 0.5412\n",
      "Epoch [2/200], Step [341/1067], D_A_loss: 0.1320, D_B_loss: 0.2747, G_A_loss: 0.8763, G_B_loss: 0.6140\n",
      "Epoch [2/200], Step [351/1067], D_A_loss: 0.2820, D_B_loss: 0.1700, G_A_loss: 0.2560, G_B_loss: 0.1129\n",
      "Epoch [2/200], Step [361/1067], D_A_loss: 0.1954, D_B_loss: 0.0776, G_A_loss: 0.3158, G_B_loss: 0.5535\n",
      "Epoch [2/200], Step [371/1067], D_A_loss: 0.1260, D_B_loss: 0.2204, G_A_loss: 0.1804, G_B_loss: 0.3899\n",
      "Epoch [2/200], Step [381/1067], D_A_loss: 0.1520, D_B_loss: 0.0827, G_A_loss: 0.7187, G_B_loss: 0.4501\n",
      "Epoch [2/200], Step [391/1067], D_A_loss: 0.0522, D_B_loss: 0.1876, G_A_loss: 0.1922, G_B_loss: 0.4626\n",
      "Epoch [2/200], Step [401/1067], D_A_loss: 0.3705, D_B_loss: 0.1651, G_A_loss: 1.1949, G_B_loss: 0.1723\n",
      "Epoch [2/200], Step [411/1067], D_A_loss: 0.1996, D_B_loss: 0.1388, G_A_loss: 0.2980, G_B_loss: 0.1773\n",
      "Epoch [2/200], Step [421/1067], D_A_loss: 0.0591, D_B_loss: 0.2890, G_A_loss: 0.1252, G_B_loss: 0.5808\n",
      "Epoch [2/200], Step [431/1067], D_A_loss: 0.1842, D_B_loss: 0.0735, G_A_loss: 0.7335, G_B_loss: 0.4131\n",
      "Epoch [2/200], Step [441/1067], D_A_loss: 0.0327, D_B_loss: 0.2597, G_A_loss: 0.1554, G_B_loss: 0.2583\n",
      "Epoch [2/200], Step [451/1067], D_A_loss: 0.1452, D_B_loss: 0.1755, G_A_loss: 0.9648, G_B_loss: 0.4201\n",
      "Epoch [2/200], Step [461/1067], D_A_loss: 0.6235, D_B_loss: 0.1647, G_A_loss: 1.1075, G_B_loss: 0.0203\n",
      "Epoch [2/200], Step [471/1067], D_A_loss: 0.0983, D_B_loss: 0.1277, G_A_loss: 0.8102, G_B_loss: 0.2278\n",
      "Epoch [2/200], Step [481/1067], D_A_loss: 0.1918, D_B_loss: 0.2387, G_A_loss: 0.1505, G_B_loss: 0.2035\n",
      "Epoch [2/200], Step [491/1067], D_A_loss: 0.2339, D_B_loss: 0.1642, G_A_loss: 0.8739, G_B_loss: 0.4114\n",
      "Epoch [2/200], Step [501/1067], D_A_loss: 0.1297, D_B_loss: 0.2144, G_A_loss: 0.1780, G_B_loss: 0.1492\n",
      "Epoch [2/200], Step [511/1067], D_A_loss: 0.0917, D_B_loss: 0.1023, G_A_loss: 0.6435, G_B_loss: 0.4985\n",
      "Epoch [2/200], Step [521/1067], D_A_loss: 0.2033, D_B_loss: 0.1249, G_A_loss: 0.2566, G_B_loss: 0.2599\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/200], Step [531/1067], D_A_loss: 0.1811, D_B_loss: 0.0679, G_A_loss: 0.2855, G_B_loss: 0.2382\n",
      "Epoch [2/200], Step [541/1067], D_A_loss: 0.2169, D_B_loss: 0.1103, G_A_loss: 0.3301, G_B_loss: 0.4837\n",
      "Epoch [2/200], Step [551/1067], D_A_loss: 0.2472, D_B_loss: 0.3207, G_A_loss: 0.2495, G_B_loss: 0.2731\n",
      "Epoch [2/200], Step [561/1067], D_A_loss: 0.2281, D_B_loss: 0.1734, G_A_loss: 0.2960, G_B_loss: 0.1675\n",
      "Epoch [2/200], Step [571/1067], D_A_loss: 0.3891, D_B_loss: 0.1097, G_A_loss: 0.5749, G_B_loss: 0.2196\n",
      "Epoch [2/200], Step [581/1067], D_A_loss: 0.2510, D_B_loss: 0.3126, G_A_loss: 0.1026, G_B_loss: 0.4337\n",
      "Epoch [2/200], Step [591/1067], D_A_loss: 0.1212, D_B_loss: 0.1727, G_A_loss: 0.9362, G_B_loss: 0.0894\n",
      "Epoch [2/200], Step [601/1067], D_A_loss: 0.1481, D_B_loss: 0.3422, G_A_loss: 0.7425, G_B_loss: 0.2566\n",
      "Epoch [2/200], Step [611/1067], D_A_loss: 0.1064, D_B_loss: 0.1659, G_A_loss: 0.3530, G_B_loss: 0.5818\n",
      "Epoch [2/200], Step [621/1067], D_A_loss: 0.2669, D_B_loss: 0.1555, G_A_loss: 0.2620, G_B_loss: 0.6449\n",
      "Epoch [2/200], Step [631/1067], D_A_loss: 0.1430, D_B_loss: 0.0645, G_A_loss: 0.4917, G_B_loss: 0.1913\n",
      "Epoch [2/200], Step [641/1067], D_A_loss: 0.2385, D_B_loss: 0.0439, G_A_loss: 0.1798, G_B_loss: 0.4549\n",
      "Epoch [2/200], Step [651/1067], D_A_loss: 0.0957, D_B_loss: 0.1195, G_A_loss: 0.1034, G_B_loss: 0.4134\n",
      "Epoch [2/200], Step [661/1067], D_A_loss: 0.0848, D_B_loss: 0.2057, G_A_loss: 0.8581, G_B_loss: 0.6733\n",
      "Epoch [2/200], Step [671/1067], D_A_loss: 0.1730, D_B_loss: 0.2993, G_A_loss: 0.7679, G_B_loss: 0.2281\n",
      "Epoch [2/200], Step [681/1067], D_A_loss: 0.3276, D_B_loss: 0.0678, G_A_loss: 0.3467, G_B_loss: 0.7884\n",
      "Epoch [2/200], Step [691/1067], D_A_loss: 0.2420, D_B_loss: 0.0828, G_A_loss: 0.7181, G_B_loss: 0.1867\n",
      "Epoch [2/200], Step [701/1067], D_A_loss: 0.1662, D_B_loss: 0.2968, G_A_loss: 0.8192, G_B_loss: 0.4897\n",
      "Epoch [2/200], Step [711/1067], D_A_loss: 0.1781, D_B_loss: 0.1106, G_A_loss: 0.3710, G_B_loss: 0.5128\n",
      "Epoch [2/200], Step [721/1067], D_A_loss: 0.2002, D_B_loss: 0.0279, G_A_loss: 0.5865, G_B_loss: 0.7183\n",
      "Epoch [2/200], Step [731/1067], D_A_loss: 0.1672, D_B_loss: 0.0941, G_A_loss: 0.4948, G_B_loss: 0.7631\n",
      "Epoch [2/200], Step [741/1067], D_A_loss: 0.1941, D_B_loss: 0.0544, G_A_loss: 0.5258, G_B_loss: 0.2907\n",
      "Epoch [2/200], Step [751/1067], D_A_loss: 0.3002, D_B_loss: 0.0935, G_A_loss: 0.4265, G_B_loss: 0.7713\n",
      "Epoch [2/200], Step [761/1067], D_A_loss: 0.2978, D_B_loss: 0.0630, G_A_loss: 0.1575, G_B_loss: 0.4311\n",
      "Epoch [2/200], Step [771/1067], D_A_loss: 0.1156, D_B_loss: 0.1759, G_A_loss: 0.3690, G_B_loss: 0.3157\n",
      "Epoch [2/200], Step [781/1067], D_A_loss: 0.0994, D_B_loss: 0.1326, G_A_loss: 0.7812, G_B_loss: 0.4399\n",
      "Epoch [2/200], Step [791/1067], D_A_loss: 0.0988, D_B_loss: 0.2124, G_A_loss: 0.1493, G_B_loss: 0.4555\n",
      "Epoch [2/200], Step [801/1067], D_A_loss: 0.0277, D_B_loss: 0.0266, G_A_loss: 0.7706, G_B_loss: 1.2930\n",
      "Epoch [2/200], Step [811/1067], D_A_loss: 0.2994, D_B_loss: 0.1172, G_A_loss: 0.4387, G_B_loss: 0.5087\n",
      "Epoch [2/200], Step [821/1067], D_A_loss: 0.1423, D_B_loss: 0.0732, G_A_loss: 0.4083, G_B_loss: 0.3085\n",
      "Epoch [2/200], Step [831/1067], D_A_loss: 0.2283, D_B_loss: 0.1347, G_A_loss: 0.4966, G_B_loss: 0.9157\n",
      "Epoch [2/200], Step [841/1067], D_A_loss: 0.0756, D_B_loss: 0.0564, G_A_loss: 0.4457, G_B_loss: 0.3501\n",
      "Epoch [2/200], Step [851/1067], D_A_loss: 0.1025, D_B_loss: 0.0349, G_A_loss: 0.4409, G_B_loss: 0.7596\n",
      "Epoch [2/200], Step [861/1067], D_A_loss: 0.0504, D_B_loss: 0.0837, G_A_loss: 0.5046, G_B_loss: 0.3271\n",
      "Epoch [2/200], Step [871/1067], D_A_loss: 0.0502, D_B_loss: 0.0624, G_A_loss: 0.7807, G_B_loss: 0.5102\n",
      "Epoch [2/200], Step [881/1067], D_A_loss: 0.1506, D_B_loss: 0.0871, G_A_loss: 0.4715, G_B_loss: 0.4363\n",
      "Epoch [2/200], Step [891/1067], D_A_loss: 0.1476, D_B_loss: 0.2641, G_A_loss: 0.4082, G_B_loss: 0.9535\n",
      "Epoch [2/200], Step [901/1067], D_A_loss: 0.0737, D_B_loss: 0.1263, G_A_loss: 0.4080, G_B_loss: 0.3163\n",
      "Epoch [2/200], Step [911/1067], D_A_loss: 0.1185, D_B_loss: 0.2342, G_A_loss: 0.1515, G_B_loss: 0.4472\n",
      "Epoch [2/200], Step [921/1067], D_A_loss: 0.1615, D_B_loss: 0.1391, G_A_loss: 0.5440, G_B_loss: 0.3417\n",
      "Epoch [2/200], Step [931/1067], D_A_loss: 0.0646, D_B_loss: 0.1374, G_A_loss: 0.0851, G_B_loss: 0.5227\n",
      "Epoch [2/200], Step [941/1067], D_A_loss: 0.1277, D_B_loss: 0.0884, G_A_loss: 0.2931, G_B_loss: 0.6365\n",
      "Epoch [2/200], Step [951/1067], D_A_loss: 0.0960, D_B_loss: 0.1631, G_A_loss: 0.6014, G_B_loss: 0.3858\n",
      "Epoch [2/200], Step [961/1067], D_A_loss: 0.1900, D_B_loss: 0.0603, G_A_loss: 0.9301, G_B_loss: 0.2335\n",
      "Epoch [2/200], Step [971/1067], D_A_loss: 0.1626, D_B_loss: 0.1426, G_A_loss: 0.2479, G_B_loss: 0.6666\n",
      "Epoch [2/200], Step [981/1067], D_A_loss: 0.1317, D_B_loss: 0.0763, G_A_loss: 0.2972, G_B_loss: 0.3802\n",
      "Epoch [2/200], Step [991/1067], D_A_loss: 0.1865, D_B_loss: 0.1953, G_A_loss: 0.5439, G_B_loss: 0.2766\n",
      "Epoch [2/200], Step [1001/1067], D_A_loss: 0.2147, D_B_loss: 0.3678, G_A_loss: 0.6270, G_B_loss: 0.1865\n",
      "Epoch [2/200], Step [1011/1067], D_A_loss: 0.2177, D_B_loss: 0.2225, G_A_loss: 0.2365, G_B_loss: 0.2819\n",
      "Epoch [2/200], Step [1021/1067], D_A_loss: 0.1536, D_B_loss: 0.0939, G_A_loss: 0.5039, G_B_loss: 0.3378\n",
      "Epoch [2/200], Step [1031/1067], D_A_loss: 0.1437, D_B_loss: 0.1404, G_A_loss: 0.3214, G_B_loss: 0.6825\n",
      "Epoch [2/200], Step [1041/1067], D_A_loss: 0.0862, D_B_loss: 0.3797, G_A_loss: 0.0415, G_B_loss: 0.0185\n",
      "Epoch [2/200], Step [1051/1067], D_A_loss: 0.0520, D_B_loss: 0.2473, G_A_loss: 0.8063, G_B_loss: 0.1672\n",
      "Epoch [2/200], Step [1061/1067], D_A_loss: 0.1207, D_B_loss: 0.1097, G_A_loss: 0.4072, G_B_loss: 0.5056\n",
      "Epoch [3/200], Step [1/1067], D_A_loss: 0.0547, D_B_loss: 0.1069, G_A_loss: 0.5675, G_B_loss: 0.2431\n",
      "Epoch [3/200], Step [11/1067], D_A_loss: 0.3052, D_B_loss: 0.0712, G_A_loss: 0.1833, G_B_loss: 0.0828\n",
      "Epoch [3/200], Step [21/1067], D_A_loss: 0.0723, D_B_loss: 0.0734, G_A_loss: 0.7268, G_B_loss: 0.4764\n",
      "Epoch [3/200], Step [31/1067], D_A_loss: 0.1804, D_B_loss: 0.0887, G_A_loss: 0.5849, G_B_loss: 0.4994\n",
      "Epoch [3/200], Step [41/1067], D_A_loss: 0.2920, D_B_loss: 0.1994, G_A_loss: 0.8208, G_B_loss: 0.2758\n",
      "Epoch [3/200], Step [51/1067], D_A_loss: 0.2092, D_B_loss: 0.1603, G_A_loss: 0.4410, G_B_loss: 0.4160\n",
      "Epoch [3/200], Step [61/1067], D_A_loss: 0.1408, D_B_loss: 0.0698, G_A_loss: 0.4205, G_B_loss: 0.5563\n",
      "Epoch [3/200], Step [71/1067], D_A_loss: 0.1694, D_B_loss: 0.0916, G_A_loss: 0.9769, G_B_loss: 0.0783\n",
      "Epoch [3/200], Step [81/1067], D_A_loss: 0.1973, D_B_loss: 0.0918, G_A_loss: 0.4019, G_B_loss: 0.2178\n",
      "Epoch [3/200], Step [91/1067], D_A_loss: 0.1347, D_B_loss: 0.2106, G_A_loss: 0.5875, G_B_loss: 0.7008\n",
      "Epoch [3/200], Step [101/1067], D_A_loss: 0.1926, D_B_loss: 0.0546, G_A_loss: 0.0629, G_B_loss: 0.2490\n",
      "Epoch [3/200], Step [111/1067], D_A_loss: 0.2649, D_B_loss: 0.0846, G_A_loss: 0.4706, G_B_loss: 0.6431\n",
      "Epoch [3/200], Step [121/1067], D_A_loss: 0.2128, D_B_loss: 0.2967, G_A_loss: 0.3144, G_B_loss: 0.1913\n",
      "Epoch [3/200], Step [131/1067], D_A_loss: 0.2420, D_B_loss: 0.2199, G_A_loss: 0.7314, G_B_loss: 0.4217\n",
      "Epoch [3/200], Step [141/1067], D_A_loss: 0.2361, D_B_loss: 0.1007, G_A_loss: 0.1586, G_B_loss: 0.1281\n",
      "Epoch [3/200], Step [151/1067], D_A_loss: 0.1286, D_B_loss: 0.1410, G_A_loss: 0.3508, G_B_loss: 0.3852\n",
      "Epoch [3/200], Step [161/1067], D_A_loss: 0.1210, D_B_loss: 0.0892, G_A_loss: 0.6465, G_B_loss: 0.1402\n",
      "Epoch [3/200], Step [171/1067], D_A_loss: 0.0713, D_B_loss: 0.1311, G_A_loss: 0.2973, G_B_loss: 0.5685\n",
      "Epoch [3/200], Step [181/1067], D_A_loss: 0.1417, D_B_loss: 0.1810, G_A_loss: 0.3900, G_B_loss: 0.2811\n",
      "Epoch [3/200], Step [191/1067], D_A_loss: 0.0875, D_B_loss: 0.2349, G_A_loss: 0.7439, G_B_loss: 0.4910\n",
      "Epoch [3/200], Step [201/1067], D_A_loss: 0.1235, D_B_loss: 0.0655, G_A_loss: 0.7892, G_B_loss: 0.4083\n",
      "Epoch [3/200], Step [211/1067], D_A_loss: 0.0540, D_B_loss: 0.0228, G_A_loss: 0.7018, G_B_loss: 0.4914\n",
      "Epoch [3/200], Step [221/1067], D_A_loss: 0.2982, D_B_loss: 0.2360, G_A_loss: 0.7273, G_B_loss: 0.0792\n",
      "Epoch [3/200], Step [231/1067], D_A_loss: 0.1016, D_B_loss: 0.1278, G_A_loss: 0.1093, G_B_loss: 0.2956\n",
      "Epoch [3/200], Step [241/1067], D_A_loss: 0.0975, D_B_loss: 0.2212, G_A_loss: 0.7168, G_B_loss: 0.7313\n",
      "Epoch [3/200], Step [251/1067], D_A_loss: 0.2803, D_B_loss: 0.1053, G_A_loss: 0.4560, G_B_loss: 0.7867\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/200], Step [261/1067], D_A_loss: 0.1258, D_B_loss: 0.0542, G_A_loss: 0.5719, G_B_loss: 0.4203\n",
      "Epoch [3/200], Step [271/1067], D_A_loss: 0.2538, D_B_loss: 0.0348, G_A_loss: 0.4580, G_B_loss: 0.2119\n",
      "Epoch [3/200], Step [281/1067], D_A_loss: 0.1325, D_B_loss: 0.0548, G_A_loss: 0.2847, G_B_loss: 0.5619\n",
      "Epoch [3/200], Step [291/1067], D_A_loss: 0.3002, D_B_loss: 0.0688, G_A_loss: 0.4878, G_B_loss: 0.7302\n",
      "Epoch [3/200], Step [301/1067], D_A_loss: 0.1945, D_B_loss: 0.2908, G_A_loss: 0.4179, G_B_loss: 0.3472\n",
      "Epoch [3/200], Step [311/1067], D_A_loss: 0.2231, D_B_loss: 0.1046, G_A_loss: 0.4470, G_B_loss: 0.1326\n",
      "Epoch [3/200], Step [321/1067], D_A_loss: 0.2135, D_B_loss: 0.0741, G_A_loss: 0.9215, G_B_loss: 0.3426\n",
      "Epoch [3/200], Step [331/1067], D_A_loss: 0.2176, D_B_loss: 0.2348, G_A_loss: 0.1915, G_B_loss: 0.3162\n",
      "Epoch [3/200], Step [341/1067], D_A_loss: 0.0736, D_B_loss: 0.3289, G_A_loss: 0.0835, G_B_loss: 0.1437\n",
      "Epoch [3/200], Step [351/1067], D_A_loss: 0.1825, D_B_loss: 0.0749, G_A_loss: 0.3798, G_B_loss: 0.2256\n",
      "Epoch [3/200], Step [361/1067], D_A_loss: 0.2192, D_B_loss: 0.1622, G_A_loss: 1.0747, G_B_loss: 0.1852\n",
      "Epoch [3/200], Step [371/1067], D_A_loss: 0.0501, D_B_loss: 0.3039, G_A_loss: 0.7829, G_B_loss: 0.2026\n",
      "Epoch [3/200], Step [381/1067], D_A_loss: 0.2518, D_B_loss: 0.0536, G_A_loss: 0.7560, G_B_loss: 0.9980\n",
      "Epoch [3/200], Step [391/1067], D_A_loss: 0.1231, D_B_loss: 0.1971, G_A_loss: 0.1940, G_B_loss: 0.2967\n",
      "Epoch [3/200], Step [401/1067], D_A_loss: 0.1404, D_B_loss: 0.0515, G_A_loss: 0.5866, G_B_loss: 0.0975\n",
      "Epoch [3/200], Step [411/1067], D_A_loss: 0.2217, D_B_loss: 0.2073, G_A_loss: 0.4268, G_B_loss: 0.2963\n",
      "Epoch [3/200], Step [421/1067], D_A_loss: 0.1464, D_B_loss: 0.1004, G_A_loss: 0.6033, G_B_loss: 0.1017\n",
      "Epoch [3/200], Step [431/1067], D_A_loss: 0.1875, D_B_loss: 0.1459, G_A_loss: 0.1831, G_B_loss: 0.2924\n",
      "Epoch [3/200], Step [441/1067], D_A_loss: 0.6096, D_B_loss: 0.3332, G_A_loss: 0.6229, G_B_loss: 0.0207\n",
      "Epoch [3/200], Step [451/1067], D_A_loss: 0.0282, D_B_loss: 0.1958, G_A_loss: 0.3378, G_B_loss: 0.4736\n",
      "Epoch [3/200], Step [461/1067], D_A_loss: 0.0812, D_B_loss: 0.0656, G_A_loss: 0.2568, G_B_loss: 0.2939\n",
      "Epoch [3/200], Step [471/1067], D_A_loss: 0.0764, D_B_loss: 0.2204, G_A_loss: 0.6661, G_B_loss: 0.3566\n",
      "Epoch [3/200], Step [481/1067], D_A_loss: 0.0887, D_B_loss: 0.2615, G_A_loss: 1.0400, G_B_loss: 0.3091\n",
      "Epoch [3/200], Step [491/1067], D_A_loss: 0.1844, D_B_loss: 0.1748, G_A_loss: 0.3369, G_B_loss: 0.2295\n",
      "Epoch [3/200], Step [501/1067], D_A_loss: 0.2070, D_B_loss: 0.1760, G_A_loss: 0.5114, G_B_loss: 0.4132\n",
      "Epoch [3/200], Step [511/1067], D_A_loss: 0.2885, D_B_loss: 0.1003, G_A_loss: 0.5083, G_B_loss: 0.1687\n",
      "Epoch [3/200], Step [521/1067], D_A_loss: 0.2176, D_B_loss: 0.1337, G_A_loss: 0.4858, G_B_loss: 0.6313\n",
      "Epoch [3/200], Step [531/1067], D_A_loss: 0.2049, D_B_loss: 0.0902, G_A_loss: 0.4771, G_B_loss: 0.4964\n",
      "Epoch [3/200], Step [541/1067], D_A_loss: 0.1457, D_B_loss: 0.2447, G_A_loss: 0.4716, G_B_loss: 0.1942\n",
      "Epoch [3/200], Step [551/1067], D_A_loss: 0.4500, D_B_loss: 0.4079, G_A_loss: 0.8626, G_B_loss: 0.4442\n",
      "Epoch [3/200], Step [561/1067], D_A_loss: 0.2400, D_B_loss: 0.1867, G_A_loss: 0.4140, G_B_loss: 0.2707\n",
      "Epoch [3/200], Step [571/1067], D_A_loss: 0.2004, D_B_loss: 0.1500, G_A_loss: 0.2908, G_B_loss: 0.6173\n",
      "Epoch [3/200], Step [581/1067], D_A_loss: 0.1041, D_B_loss: 0.0542, G_A_loss: 0.6049, G_B_loss: 0.2602\n",
      "Epoch [3/200], Step [591/1067], D_A_loss: 0.1031, D_B_loss: 0.0402, G_A_loss: 0.6340, G_B_loss: 0.5650\n",
      "Epoch [3/200], Step [601/1067], D_A_loss: 0.0354, D_B_loss: 0.0830, G_A_loss: 0.5818, G_B_loss: 0.5143\n",
      "Epoch [3/200], Step [611/1067], D_A_loss: 0.2592, D_B_loss: 0.0374, G_A_loss: 0.4500, G_B_loss: 0.3460\n",
      "Epoch [3/200], Step [621/1067], D_A_loss: 0.0751, D_B_loss: 0.0639, G_A_loss: 0.4859, G_B_loss: 0.5789\n",
      "Epoch [3/200], Step [631/1067], D_A_loss: 0.1193, D_B_loss: 0.1426, G_A_loss: 0.4463, G_B_loss: 0.3516\n",
      "Epoch [3/200], Step [641/1067], D_A_loss: 0.1456, D_B_loss: 0.2276, G_A_loss: 0.2185, G_B_loss: 0.3617\n",
      "Epoch [3/200], Step [651/1067], D_A_loss: 0.0980, D_B_loss: 0.0705, G_A_loss: 0.3240, G_B_loss: 0.5928\n",
      "Epoch [3/200], Step [661/1067], D_A_loss: 0.0465, D_B_loss: 0.0721, G_A_loss: 0.9675, G_B_loss: 0.3186\n",
      "Epoch [3/200], Step [671/1067], D_A_loss: 0.0433, D_B_loss: 0.2479, G_A_loss: 0.1646, G_B_loss: 0.5892\n",
      "Epoch [3/200], Step [681/1067], D_A_loss: 0.2493, D_B_loss: 0.0494, G_A_loss: 0.5942, G_B_loss: 0.5423\n",
      "Epoch [3/200], Step [691/1067], D_A_loss: 0.0461, D_B_loss: 0.1045, G_A_loss: 0.3670, G_B_loss: 0.1040\n",
      "Epoch [3/200], Step [701/1067], D_A_loss: 0.1963, D_B_loss: 0.2360, G_A_loss: 0.2059, G_B_loss: 0.2719\n",
      "Epoch [3/200], Step [711/1067], D_A_loss: 0.2227, D_B_loss: 0.0376, G_A_loss: 0.2975, G_B_loss: 0.2548\n",
      "Epoch [3/200], Step [721/1067], D_A_loss: 0.2653, D_B_loss: 0.0212, G_A_loss: 0.0820, G_B_loss: 0.5727\n",
      "Epoch [3/200], Step [731/1067], D_A_loss: 0.4146, D_B_loss: 0.0132, G_A_loss: 0.2020, G_B_loss: 0.4236\n",
      "Epoch [3/200], Step [741/1067], D_A_loss: 0.2282, D_B_loss: 0.0520, G_A_loss: 0.2004, G_B_loss: 0.1635\n",
      "Epoch [3/200], Step [751/1067], D_A_loss: 0.4637, D_B_loss: 0.1812, G_A_loss: 0.5669, G_B_loss: 0.4937\n",
      "Epoch [3/200], Step [761/1067], D_A_loss: 0.1245, D_B_loss: 0.1571, G_A_loss: 0.2777, G_B_loss: 0.3862\n",
      "Epoch [3/200], Step [771/1067], D_A_loss: 0.3420, D_B_loss: 0.1330, G_A_loss: 0.2598, G_B_loss: 0.3157\n",
      "Epoch [3/200], Step [781/1067], D_A_loss: 0.1446, D_B_loss: 0.2649, G_A_loss: 0.5234, G_B_loss: 0.3718\n",
      "Epoch [3/200], Step [791/1067], D_A_loss: 0.2250, D_B_loss: 0.0616, G_A_loss: 0.4963, G_B_loss: 0.6260\n",
      "Epoch [3/200], Step [801/1067], D_A_loss: 0.0817, D_B_loss: 0.0313, G_A_loss: 0.4905, G_B_loss: 0.0734\n",
      "Epoch [3/200], Step [811/1067], D_A_loss: 0.1240, D_B_loss: 0.1250, G_A_loss: 0.4450, G_B_loss: 0.7227\n",
      "Epoch [3/200], Step [821/1067], D_A_loss: 0.2713, D_B_loss: 0.0697, G_A_loss: 0.5745, G_B_loss: 0.4001\n",
      "Epoch [3/200], Step [831/1067], D_A_loss: 0.0399, D_B_loss: 0.2537, G_A_loss: 0.9806, G_B_loss: 0.5434\n",
      "Epoch [3/200], Step [841/1067], D_A_loss: 0.1565, D_B_loss: 0.4440, G_A_loss: 0.5245, G_B_loss: 0.0989\n",
      "Epoch [3/200], Step [851/1067], D_A_loss: 0.0496, D_B_loss: 0.2224, G_A_loss: 0.2507, G_B_loss: 0.7745\n",
      "Epoch [3/200], Step [861/1067], D_A_loss: 0.3276, D_B_loss: 0.0974, G_A_loss: 0.3388, G_B_loss: 0.0612\n",
      "Epoch [3/200], Step [871/1067], D_A_loss: 0.0641, D_B_loss: 0.0929, G_A_loss: 0.5130, G_B_loss: 0.5653\n",
      "Epoch [3/200], Step [881/1067], D_A_loss: 0.1249, D_B_loss: 0.1724, G_A_loss: 0.8091, G_B_loss: 0.3474\n",
      "Epoch [3/200], Step [891/1067], D_A_loss: 0.1186, D_B_loss: 0.0228, G_A_loss: 1.0621, G_B_loss: 0.2051\n",
      "Epoch [3/200], Step [901/1067], D_A_loss: 0.1758, D_B_loss: 0.0887, G_A_loss: 0.5820, G_B_loss: 0.1870\n",
      "Epoch [3/200], Step [911/1067], D_A_loss: 0.3579, D_B_loss: 0.2408, G_A_loss: 0.5708, G_B_loss: 0.1056\n",
      "Epoch [3/200], Step [921/1067], D_A_loss: 0.0829, D_B_loss: 0.1199, G_A_loss: 0.1912, G_B_loss: 0.4037\n",
      "Epoch [3/200], Step [931/1067], D_A_loss: 0.1045, D_B_loss: 0.2694, G_A_loss: 0.1170, G_B_loss: 0.5233\n",
      "Epoch [3/200], Step [941/1067], D_A_loss: 0.0857, D_B_loss: 0.0510, G_A_loss: 0.7327, G_B_loss: 0.5782\n",
      "Epoch [3/200], Step [951/1067], D_A_loss: 0.0381, D_B_loss: 0.1824, G_A_loss: 0.1898, G_B_loss: 0.2631\n",
      "Epoch [3/200], Step [961/1067], D_A_loss: 0.0568, D_B_loss: 0.1166, G_A_loss: 0.3375, G_B_loss: 0.4850\n",
      "Epoch [3/200], Step [971/1067], D_A_loss: 0.1568, D_B_loss: 0.2550, G_A_loss: 0.1760, G_B_loss: 0.5532\n",
      "Epoch [3/200], Step [981/1067], D_A_loss: 0.1020, D_B_loss: 0.1209, G_A_loss: 0.6671, G_B_loss: 0.3635\n",
      "Epoch [3/200], Step [991/1067], D_A_loss: 0.2653, D_B_loss: 0.0534, G_A_loss: 0.7579, G_B_loss: 0.7199\n",
      "Epoch [3/200], Step [1001/1067], D_A_loss: 0.1445, D_B_loss: 0.1966, G_A_loss: 0.8414, G_B_loss: 0.1942\n",
      "Epoch [3/200], Step [1011/1067], D_A_loss: 0.1203, D_B_loss: 0.3243, G_A_loss: 0.1093, G_B_loss: 0.5422\n",
      "Epoch [3/200], Step [1021/1067], D_A_loss: 0.2277, D_B_loss: 0.2054, G_A_loss: 0.2578, G_B_loss: 0.1717\n",
      "Epoch [3/200], Step [1031/1067], D_A_loss: 0.0661, D_B_loss: 0.0515, G_A_loss: 0.2776, G_B_loss: 0.3972\n",
      "Epoch [3/200], Step [1041/1067], D_A_loss: 0.1680, D_B_loss: 0.2025, G_A_loss: 0.2227, G_B_loss: 0.4466\n",
      "Epoch [3/200], Step [1051/1067], D_A_loss: 0.1429, D_B_loss: 0.0844, G_A_loss: 0.5355, G_B_loss: 0.4659\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/200], Step [1061/1067], D_A_loss: 0.0760, D_B_loss: 0.2432, G_A_loss: 0.1990, G_B_loss: 0.2257\n",
      "Epoch [4/200], Step [1/1067], D_A_loss: 0.0624, D_B_loss: 0.1940, G_A_loss: 0.1750, G_B_loss: 0.3348\n",
      "Epoch [4/200], Step [11/1067], D_A_loss: 0.2529, D_B_loss: 0.1560, G_A_loss: 0.2617, G_B_loss: 0.4699\n",
      "Epoch [4/200], Step [21/1067], D_A_loss: 0.2491, D_B_loss: 0.2081, G_A_loss: 0.1731, G_B_loss: 0.3381\n",
      "Epoch [4/200], Step [31/1067], D_A_loss: 0.2041, D_B_loss: 0.1404, G_A_loss: 0.5391, G_B_loss: 0.3988\n",
      "Epoch [4/200], Step [41/1067], D_A_loss: 0.2115, D_B_loss: 0.3499, G_A_loss: 0.0703, G_B_loss: 0.5230\n",
      "Epoch [4/200], Step [51/1067], D_A_loss: 0.1759, D_B_loss: 0.1154, G_A_loss: 0.4827, G_B_loss: 0.7560\n",
      "Epoch [4/200], Step [61/1067], D_A_loss: 0.1046, D_B_loss: 0.0959, G_A_loss: 0.4855, G_B_loss: 0.3076\n",
      "Epoch [4/200], Step [71/1067], D_A_loss: 0.1765, D_B_loss: 0.2665, G_A_loss: 0.9343, G_B_loss: 0.2352\n",
      "Epoch [4/200], Step [81/1067], D_A_loss: 0.2820, D_B_loss: 0.0911, G_A_loss: 0.5773, G_B_loss: 0.1192\n",
      "Epoch [4/200], Step [91/1067], D_A_loss: 0.2155, D_B_loss: 0.2994, G_A_loss: 0.9506, G_B_loss: 0.4465\n",
      "Epoch [4/200], Step [101/1067], D_A_loss: 0.2225, D_B_loss: 0.0497, G_A_loss: 0.5906, G_B_loss: 0.3782\n",
      "Epoch [4/200], Step [111/1067], D_A_loss: 0.0743, D_B_loss: 0.0600, G_A_loss: 0.3909, G_B_loss: 0.3814\n",
      "Epoch [4/200], Step [121/1067], D_A_loss: 0.2138, D_B_loss: 0.2947, G_A_loss: 0.3996, G_B_loss: 0.6250\n",
      "Epoch [4/200], Step [131/1067], D_A_loss: 0.2440, D_B_loss: 0.1976, G_A_loss: 0.8336, G_B_loss: 0.1760\n",
      "Epoch [4/200], Step [141/1067], D_A_loss: 0.2106, D_B_loss: 0.0850, G_A_loss: 0.7768, G_B_loss: 0.2705\n",
      "Epoch [4/200], Step [151/1067], D_A_loss: 0.1578, D_B_loss: 0.0912, G_A_loss: 0.4143, G_B_loss: 0.2720\n",
      "Epoch [4/200], Step [161/1067], D_A_loss: 0.1610, D_B_loss: 0.1341, G_A_loss: 0.3179, G_B_loss: 0.3011\n",
      "Epoch [4/200], Step [171/1067], D_A_loss: 0.0984, D_B_loss: 0.1124, G_A_loss: 0.2113, G_B_loss: 0.0844\n",
      "Epoch [4/200], Step [181/1067], D_A_loss: 0.0892, D_B_loss: 0.1033, G_A_loss: 0.3529, G_B_loss: 0.5081\n",
      "Epoch [4/200], Step [191/1067], D_A_loss: 0.0270, D_B_loss: 0.0951, G_A_loss: 0.3861, G_B_loss: 0.2442\n",
      "Epoch [4/200], Step [201/1067], D_A_loss: 0.0712, D_B_loss: 0.4641, G_A_loss: 0.0481, G_B_loss: 0.4823\n",
      "Epoch [4/200], Step [211/1067], D_A_loss: 0.0981, D_B_loss: 0.4136, G_A_loss: 0.0679, G_B_loss: 0.3507\n",
      "Epoch [4/200], Step [221/1067], D_A_loss: 0.1909, D_B_loss: 0.2104, G_A_loss: 0.1916, G_B_loss: 0.2309\n",
      "Epoch [4/200], Step [231/1067], D_A_loss: 0.1836, D_B_loss: 0.0164, G_A_loss: 0.2313, G_B_loss: 0.4479\n",
      "Epoch [4/200], Step [241/1067], D_A_loss: 0.1799, D_B_loss: 0.0859, G_A_loss: 0.1814, G_B_loss: 0.4375\n",
      "Epoch [4/200], Step [251/1067], D_A_loss: 0.1601, D_B_loss: 0.0967, G_A_loss: 0.5236, G_B_loss: 0.4683\n",
      "Epoch [4/200], Step [261/1067], D_A_loss: 0.0784, D_B_loss: 0.1041, G_A_loss: 0.4051, G_B_loss: 0.5722\n",
      "Epoch [4/200], Step [271/1067], D_A_loss: 0.1061, D_B_loss: 0.1910, G_A_loss: 0.1966, G_B_loss: 0.4277\n",
      "Epoch [4/200], Step [281/1067], D_A_loss: 0.0879, D_B_loss: 0.1008, G_A_loss: 0.5207, G_B_loss: 0.4444\n",
      "Epoch [4/200], Step [291/1067], D_A_loss: 0.1806, D_B_loss: 0.0367, G_A_loss: 0.2826, G_B_loss: 0.5661\n",
      "Epoch [4/200], Step [301/1067], D_A_loss: 0.1941, D_B_loss: 0.1198, G_A_loss: 0.5961, G_B_loss: 0.1862\n",
      "Epoch [4/200], Step [311/1067], D_A_loss: 0.0729, D_B_loss: 0.0789, G_A_loss: 0.4220, G_B_loss: 0.6532\n",
      "Epoch [4/200], Step [321/1067], D_A_loss: 0.0931, D_B_loss: 0.1701, G_A_loss: 0.6119, G_B_loss: 0.5404\n",
      "Epoch [4/200], Step [331/1067], D_A_loss: 0.1579, D_B_loss: 0.0996, G_A_loss: 0.5869, G_B_loss: 0.5212\n",
      "Epoch [4/200], Step [341/1067], D_A_loss: 0.2000, D_B_loss: 0.0419, G_A_loss: 0.4350, G_B_loss: 0.2102\n",
      "Epoch [4/200], Step [351/1067], D_A_loss: 0.4466, D_B_loss: 0.0762, G_A_loss: 0.4892, G_B_loss: 0.0362\n",
      "Epoch [4/200], Step [361/1067], D_A_loss: 0.1337, D_B_loss: 0.1639, G_A_loss: 0.2466, G_B_loss: 0.3690\n",
      "Epoch [4/200], Step [371/1067], D_A_loss: 0.2226, D_B_loss: 0.0875, G_A_loss: 0.7703, G_B_loss: 0.5610\n",
      "Epoch [4/200], Step [381/1067], D_A_loss: 0.1797, D_B_loss: 0.1345, G_A_loss: 0.8256, G_B_loss: 0.4301\n",
      "Epoch [4/200], Step [391/1067], D_A_loss: 0.0524, D_B_loss: 0.0648, G_A_loss: 0.8800, G_B_loss: 0.5796\n",
      "Epoch [4/200], Step [401/1067], D_A_loss: 0.0883, D_B_loss: 0.1948, G_A_loss: 1.3393, G_B_loss: 0.4834\n",
      "Epoch [4/200], Step [411/1067], D_A_loss: 0.2880, D_B_loss: 0.0727, G_A_loss: 0.3085, G_B_loss: 0.8431\n",
      "Epoch [4/200], Step [421/1067], D_A_loss: 0.1076, D_B_loss: 0.0466, G_A_loss: 0.5407, G_B_loss: 0.4214\n",
      "Epoch [4/200], Step [431/1067], D_A_loss: 0.1444, D_B_loss: 0.1347, G_A_loss: 0.2088, G_B_loss: 0.3114\n",
      "Epoch [4/200], Step [441/1067], D_A_loss: 0.0983, D_B_loss: 0.2327, G_A_loss: 0.1440, G_B_loss: 0.2458\n",
      "Epoch [4/200], Step [451/1067], D_A_loss: 0.0319, D_B_loss: 0.0293, G_A_loss: 0.5398, G_B_loss: 0.1930\n",
      "Epoch [4/200], Step [461/1067], D_A_loss: 0.0861, D_B_loss: 0.0169, G_A_loss: 0.4169, G_B_loss: 0.4587\n",
      "Epoch [4/200], Step [471/1067], D_A_loss: 0.1640, D_B_loss: 0.2213, G_A_loss: 0.9890, G_B_loss: 0.4015\n",
      "Epoch [4/200], Step [481/1067], D_A_loss: 0.0687, D_B_loss: 0.0229, G_A_loss: 0.6901, G_B_loss: 0.4666\n",
      "Epoch [4/200], Step [491/1067], D_A_loss: 0.1525, D_B_loss: 0.0388, G_A_loss: 0.5859, G_B_loss: 0.2831\n",
      "Epoch [4/200], Step [501/1067], D_A_loss: 0.1453, D_B_loss: 0.0409, G_A_loss: 0.2678, G_B_loss: 0.2573\n",
      "Epoch [4/200], Step [511/1067], D_A_loss: 0.0846, D_B_loss: 0.2164, G_A_loss: 0.2374, G_B_loss: 0.6535\n",
      "Epoch [4/200], Step [521/1067], D_A_loss: 0.1662, D_B_loss: 0.2664, G_A_loss: 0.4221, G_B_loss: 0.4148\n",
      "Epoch [4/200], Step [531/1067], D_A_loss: 0.1818, D_B_loss: 0.1167, G_A_loss: 0.3297, G_B_loss: 0.2678\n",
      "Epoch [4/200], Step [541/1067], D_A_loss: 0.1589, D_B_loss: 0.0284, G_A_loss: 0.5368, G_B_loss: 0.2596\n",
      "Epoch [4/200], Step [551/1067], D_A_loss: 0.0500, D_B_loss: 0.0252, G_A_loss: 0.7637, G_B_loss: 0.3937\n",
      "Epoch [4/200], Step [561/1067], D_A_loss: 0.0951, D_B_loss: 0.1573, G_A_loss: 0.4204, G_B_loss: 0.4284\n",
      "Epoch [4/200], Step [571/1067], D_A_loss: 0.4116, D_B_loss: 0.1599, G_A_loss: 0.2425, G_B_loss: 0.0809\n",
      "Epoch [4/200], Step [581/1067], D_A_loss: 0.2961, D_B_loss: 0.0392, G_A_loss: 0.5021, G_B_loss: 0.0981\n",
      "Epoch [4/200], Step [591/1067], D_A_loss: 0.2113, D_B_loss: 0.2355, G_A_loss: 0.8249, G_B_loss: 0.3257\n",
      "Epoch [4/200], Step [601/1067], D_A_loss: 0.0612, D_B_loss: 0.0713, G_A_loss: 0.2692, G_B_loss: 0.4738\n",
      "Epoch [4/200], Step [611/1067], D_A_loss: 0.2353, D_B_loss: 0.1477, G_A_loss: 0.2614, G_B_loss: 0.1588\n",
      "Epoch [4/200], Step [621/1067], D_A_loss: 0.2670, D_B_loss: 0.0344, G_A_loss: 0.8480, G_B_loss: 0.2931\n",
      "Epoch [4/200], Step [631/1067], D_A_loss: 0.2837, D_B_loss: 0.0370, G_A_loss: 0.3873, G_B_loss: 0.0960\n",
      "Epoch [4/200], Step [641/1067], D_A_loss: 0.1510, D_B_loss: 0.0766, G_A_loss: 0.5415, G_B_loss: 0.2522\n",
      "Epoch [4/200], Step [651/1067], D_A_loss: 0.1411, D_B_loss: 0.4279, G_A_loss: 0.0351, G_B_loss: 0.0280\n",
      "Epoch [4/200], Step [661/1067], D_A_loss: 0.2327, D_B_loss: 0.2825, G_A_loss: 0.0778, G_B_loss: 0.5378\n",
      "Epoch [4/200], Step [671/1067], D_A_loss: 0.2597, D_B_loss: 0.1561, G_A_loss: 0.3037, G_B_loss: 0.2159\n",
      "Epoch [4/200], Step [681/1067], D_A_loss: 0.1829, D_B_loss: 0.3063, G_A_loss: 0.1027, G_B_loss: 0.2329\n",
      "Epoch [4/200], Step [691/1067], D_A_loss: 0.1551, D_B_loss: 0.0979, G_A_loss: 0.4004, G_B_loss: 0.3616\n",
      "Epoch [4/200], Step [701/1067], D_A_loss: 0.0567, D_B_loss: 0.0662, G_A_loss: 0.4264, G_B_loss: 0.3922\n",
      "Epoch [4/200], Step [711/1067], D_A_loss: 0.0729, D_B_loss: 0.1148, G_A_loss: 0.1660, G_B_loss: 0.4488\n",
      "Epoch [4/200], Step [721/1067], D_A_loss: 0.0639, D_B_loss: 0.1090, G_A_loss: 0.9206, G_B_loss: 0.7302\n",
      "Epoch [4/200], Step [731/1067], D_A_loss: 0.1400, D_B_loss: 0.0983, G_A_loss: 0.2329, G_B_loss: 0.2149\n",
      "Epoch [4/200], Step [741/1067], D_A_loss: 0.0396, D_B_loss: 0.1348, G_A_loss: 0.6035, G_B_loss: 0.6322\n",
      "Epoch [4/200], Step [751/1067], D_A_loss: 0.2731, D_B_loss: 0.1543, G_A_loss: 0.8689, G_B_loss: 0.0817\n",
      "Epoch [4/200], Step [761/1067], D_A_loss: 0.1374, D_B_loss: 0.0465, G_A_loss: 0.3221, G_B_loss: 0.2231\n",
      "Epoch [4/200], Step [771/1067], D_A_loss: 0.0921, D_B_loss: 0.1527, G_A_loss: 0.3590, G_B_loss: 0.2830\n",
      "Epoch [4/200], Step [781/1067], D_A_loss: 0.0688, D_B_loss: 0.1328, G_A_loss: 0.3759, G_B_loss: 0.5152\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/200], Step [791/1067], D_A_loss: 0.1462, D_B_loss: 0.0641, G_A_loss: 0.7850, G_B_loss: 1.1272\n",
      "Epoch [4/200], Step [801/1067], D_A_loss: 0.0489, D_B_loss: 0.1553, G_A_loss: 0.7967, G_B_loss: 0.3804\n",
      "Epoch [4/200], Step [811/1067], D_A_loss: 0.1837, D_B_loss: 0.0597, G_A_loss: 0.6535, G_B_loss: 0.4464\n",
      "Epoch [4/200], Step [821/1067], D_A_loss: 0.1350, D_B_loss: 0.0541, G_A_loss: 0.3729, G_B_loss: 0.5011\n",
      "Epoch [4/200], Step [831/1067], D_A_loss: 0.0602, D_B_loss: 0.0304, G_A_loss: 0.2141, G_B_loss: 0.3385\n",
      "Epoch [4/200], Step [841/1067], D_A_loss: 0.1224, D_B_loss: 0.0858, G_A_loss: 1.0191, G_B_loss: 0.3886\n",
      "Epoch [4/200], Step [851/1067], D_A_loss: 0.2854, D_B_loss: 0.1587, G_A_loss: 0.3424, G_B_loss: 0.1325\n",
      "Epoch [4/200], Step [861/1067], D_A_loss: 0.0680, D_B_loss: 0.1133, G_A_loss: 0.5164, G_B_loss: 0.5237\n",
      "Epoch [4/200], Step [871/1067], D_A_loss: 0.3241, D_B_loss: 0.0852, G_A_loss: 0.4432, G_B_loss: 0.0633\n",
      "Epoch [4/200], Step [881/1067], D_A_loss: 0.1967, D_B_loss: 0.0862, G_A_loss: 0.4099, G_B_loss: 0.3981\n",
      "Epoch [4/200], Step [891/1067], D_A_loss: 0.1946, D_B_loss: 0.0360, G_A_loss: 0.5121, G_B_loss: 0.6550\n",
      "Epoch [4/200], Step [901/1067], D_A_loss: 0.1687, D_B_loss: 0.1457, G_A_loss: 0.2777, G_B_loss: 0.4132\n",
      "Epoch [4/200], Step [911/1067], D_A_loss: 0.1781, D_B_loss: 0.1292, G_A_loss: 0.3531, G_B_loss: 0.5841\n",
      "Epoch [4/200], Step [921/1067], D_A_loss: 0.2440, D_B_loss: 0.1705, G_A_loss: 0.2221, G_B_loss: 0.4867\n",
      "Epoch [4/200], Step [931/1067], D_A_loss: 0.1559, D_B_loss: 0.0285, G_A_loss: 0.3105, G_B_loss: 0.3980\n",
      "Epoch [4/200], Step [941/1067], D_A_loss: 0.0444, D_B_loss: 0.0755, G_A_loss: 0.1271, G_B_loss: 0.7732\n",
      "Epoch [4/200], Step [951/1067], D_A_loss: 0.3087, D_B_loss: 0.2132, G_A_loss: 0.2288, G_B_loss: 0.1238\n",
      "Epoch [4/200], Step [961/1067], D_A_loss: 0.0945, D_B_loss: 0.0854, G_A_loss: 0.4836, G_B_loss: 0.5584\n",
      "Epoch [4/200], Step [971/1067], D_A_loss: 0.1161, D_B_loss: 0.1898, G_A_loss: 0.4708, G_B_loss: 0.6613\n",
      "Epoch [4/200], Step [981/1067], D_A_loss: 0.1600, D_B_loss: 0.0786, G_A_loss: 0.6404, G_B_loss: 0.2231\n",
      "Epoch [4/200], Step [991/1067], D_A_loss: 0.0708, D_B_loss: 0.0630, G_A_loss: 0.3616, G_B_loss: 0.5704\n",
      "Epoch [4/200], Step [1001/1067], D_A_loss: 0.0915, D_B_loss: 0.0985, G_A_loss: 0.1024, G_B_loss: 0.2080\n",
      "Epoch [4/200], Step [1011/1067], D_A_loss: 0.0955, D_B_loss: 0.1150, G_A_loss: 0.4293, G_B_loss: 0.3564\n",
      "Epoch [4/200], Step [1021/1067], D_A_loss: 0.0706, D_B_loss: 0.0311, G_A_loss: 1.0556, G_B_loss: 0.4814\n",
      "Epoch [4/200], Step [1031/1067], D_A_loss: 0.2461, D_B_loss: 0.2187, G_A_loss: 0.6243, G_B_loss: 0.7251\n",
      "Epoch [4/200], Step [1041/1067], D_A_loss: 0.2623, D_B_loss: 0.0482, G_A_loss: 0.4232, G_B_loss: 0.1758\n",
      "Epoch [4/200], Step [1051/1067], D_A_loss: 0.0883, D_B_loss: 0.0323, G_A_loss: 0.1126, G_B_loss: 0.4191\n",
      "Epoch [4/200], Step [1061/1067], D_A_loss: 0.0728, D_B_loss: 0.0548, G_A_loss: 0.4048, G_B_loss: 0.3121\n",
      "Epoch [5/200], Step [1/1067], D_A_loss: 0.1864, D_B_loss: 0.0680, G_A_loss: 0.5745, G_B_loss: 0.2405\n",
      "Epoch [5/200], Step [11/1067], D_A_loss: 0.1344, D_B_loss: 0.1062, G_A_loss: 0.5629, G_B_loss: 0.3522\n",
      "Epoch [5/200], Step [21/1067], D_A_loss: 0.1160, D_B_loss: 0.1212, G_A_loss: 0.4384, G_B_loss: 0.7131\n",
      "Epoch [5/200], Step [31/1067], D_A_loss: 0.2788, D_B_loss: 0.0900, G_A_loss: 0.1123, G_B_loss: 0.6600\n",
      "Epoch [5/200], Step [41/1067], D_A_loss: 0.1902, D_B_loss: 0.4627, G_A_loss: 0.0227, G_B_loss: 0.6876\n",
      "Epoch [5/200], Step [51/1067], D_A_loss: 0.0677, D_B_loss: 0.2303, G_A_loss: 0.1362, G_B_loss: 0.3282\n",
      "Epoch [5/200], Step [61/1067], D_A_loss: 0.1413, D_B_loss: 0.1867, G_A_loss: 0.3362, G_B_loss: 0.3001\n",
      "Epoch [5/200], Step [71/1067], D_A_loss: 0.0886, D_B_loss: 0.0780, G_A_loss: 0.2818, G_B_loss: 0.3756\n",
      "Epoch [5/200], Step [81/1067], D_A_loss: 0.2424, D_B_loss: 0.3927, G_A_loss: 0.0566, G_B_loss: 0.9928\n",
      "Epoch [5/200], Step [91/1067], D_A_loss: 0.3157, D_B_loss: 0.2232, G_A_loss: 0.6970, G_B_loss: 0.1151\n",
      "Epoch [5/200], Step [101/1067], D_A_loss: 0.1350, D_B_loss: 0.0672, G_A_loss: 0.9586, G_B_loss: 0.2760\n",
      "Epoch [5/200], Step [111/1067], D_A_loss: 0.2595, D_B_loss: 0.1581, G_A_loss: 0.2355, G_B_loss: 0.7957\n",
      "Epoch [5/200], Step [121/1067], D_A_loss: 0.3431, D_B_loss: 0.0892, G_A_loss: 0.6529, G_B_loss: 0.4812\n",
      "Epoch [5/200], Step [131/1067], D_A_loss: 0.1338, D_B_loss: 0.3155, G_A_loss: 1.3742, G_B_loss: 0.7725\n",
      "Epoch [5/200], Step [141/1067], D_A_loss: 0.0737, D_B_loss: 0.1420, G_A_loss: 0.8707, G_B_loss: 0.4685\n",
      "Epoch [5/200], Step [151/1067], D_A_loss: 0.0482, D_B_loss: 0.0449, G_A_loss: 0.6228, G_B_loss: 0.5594\n",
      "Epoch [5/200], Step [161/1067], D_A_loss: 0.1373, D_B_loss: 0.1010, G_A_loss: 0.5403, G_B_loss: 0.2719\n",
      "Epoch [5/200], Step [171/1067], D_A_loss: 0.1412, D_B_loss: 0.2793, G_A_loss: 0.1253, G_B_loss: 0.3155\n",
      "Epoch [5/200], Step [181/1067], D_A_loss: 0.1243, D_B_loss: 0.0724, G_A_loss: 0.2600, G_B_loss: 0.3058\n",
      "Epoch [5/200], Step [191/1067], D_A_loss: 0.4013, D_B_loss: 0.0948, G_A_loss: 0.4100, G_B_loss: 0.6187\n",
      "Epoch [5/200], Step [201/1067], D_A_loss: 0.0190, D_B_loss: 0.0465, G_A_loss: 0.7875, G_B_loss: 0.5992\n",
      "Epoch [5/200], Step [211/1067], D_A_loss: 0.2296, D_B_loss: 0.0885, G_A_loss: 0.6437, G_B_loss: 0.2572\n",
      "Epoch [5/200], Step [221/1067], D_A_loss: 0.1218, D_B_loss: 0.1583, G_A_loss: 1.1160, G_B_loss: 0.4191\n",
      "Epoch [5/200], Step [231/1067], D_A_loss: 0.0857, D_B_loss: 0.0323, G_A_loss: 0.7598, G_B_loss: 0.1782\n",
      "Epoch [5/200], Step [241/1067], D_A_loss: 0.4459, D_B_loss: 0.1049, G_A_loss: 0.3368, G_B_loss: 1.3516\n",
      "Epoch [5/200], Step [251/1067], D_A_loss: 0.0951, D_B_loss: 0.0660, G_A_loss: 0.6115, G_B_loss: 0.3681\n",
      "Epoch [5/200], Step [261/1067], D_A_loss: 0.1941, D_B_loss: 0.1080, G_A_loss: 0.6498, G_B_loss: 0.2370\n",
      "Epoch [5/200], Step [271/1067], D_A_loss: 0.1790, D_B_loss: 0.0832, G_A_loss: 0.1637, G_B_loss: 0.1425\n",
      "Epoch [5/200], Step [281/1067], D_A_loss: 0.1648, D_B_loss: 0.1752, G_A_loss: 0.3687, G_B_loss: 0.0629\n",
      "Epoch [5/200], Step [291/1067], D_A_loss: 0.2336, D_B_loss: 0.0501, G_A_loss: 0.5532, G_B_loss: 0.4637\n",
      "Epoch [5/200], Step [301/1067], D_A_loss: 0.0620, D_B_loss: 0.2746, G_A_loss: 0.1349, G_B_loss: 0.3663\n",
      "Epoch [5/200], Step [311/1067], D_A_loss: 0.3038, D_B_loss: 0.0592, G_A_loss: 0.6006, G_B_loss: 0.1874\n",
      "Epoch [5/200], Step [321/1067], D_A_loss: 0.0588, D_B_loss: 0.0308, G_A_loss: 0.7008, G_B_loss: 0.3914\n",
      "Epoch [5/200], Step [331/1067], D_A_loss: 0.1109, D_B_loss: 0.2609, G_A_loss: 0.7686, G_B_loss: 1.1640\n",
      "Epoch [5/200], Step [341/1067], D_A_loss: 0.0795, D_B_loss: 0.1651, G_A_loss: 0.3579, G_B_loss: 0.4121\n",
      "Epoch [5/200], Step [351/1067], D_A_loss: 0.0904, D_B_loss: 0.0414, G_A_loss: 0.9603, G_B_loss: 0.2938\n",
      "Epoch [5/200], Step [361/1067], D_A_loss: 0.1702, D_B_loss: 0.0844, G_A_loss: 0.4494, G_B_loss: 0.1925\n",
      "Epoch [5/200], Step [371/1067], D_A_loss: 0.1312, D_B_loss: 0.0507, G_A_loss: 0.5896, G_B_loss: 0.4399\n",
      "Epoch [5/200], Step [381/1067], D_A_loss: 0.0334, D_B_loss: 0.1046, G_A_loss: 0.7961, G_B_loss: 0.5241\n",
      "Epoch [5/200], Step [391/1067], D_A_loss: 0.0523, D_B_loss: 0.1968, G_A_loss: 0.2166, G_B_loss: 0.7479\n",
      "Epoch [5/200], Step [401/1067], D_A_loss: 0.1629, D_B_loss: 0.0930, G_A_loss: 0.4407, G_B_loss: 0.2247\n",
      "Epoch [5/200], Step [411/1067], D_A_loss: 0.0580, D_B_loss: 0.1268, G_A_loss: 0.1567, G_B_loss: 0.2576\n",
      "Epoch [5/200], Step [421/1067], D_A_loss: 0.0610, D_B_loss: 0.0671, G_A_loss: 0.8854, G_B_loss: 0.2781\n",
      "Epoch [5/200], Step [431/1067], D_A_loss: 0.0641, D_B_loss: 0.1356, G_A_loss: 0.8566, G_B_loss: 0.5775\n",
      "Epoch [5/200], Step [441/1067], D_A_loss: 0.0552, D_B_loss: 0.2052, G_A_loss: 0.9298, G_B_loss: 0.2170\n",
      "Epoch [5/200], Step [451/1067], D_A_loss: 0.0771, D_B_loss: 0.1354, G_A_loss: 0.5109, G_B_loss: 0.4063\n",
      "Epoch [5/200], Step [461/1067], D_A_loss: 0.1677, D_B_loss: 0.2943, G_A_loss: 0.3252, G_B_loss: 0.2426\n",
      "Epoch [5/200], Step [471/1067], D_A_loss: 0.1009, D_B_loss: 0.0220, G_A_loss: 0.6797, G_B_loss: 0.5021\n",
      "Epoch [5/200], Step [481/1067], D_A_loss: 0.1583, D_B_loss: 0.1488, G_A_loss: 0.2202, G_B_loss: 0.2326\n",
      "Epoch [5/200], Step [491/1067], D_A_loss: 0.1980, D_B_loss: 0.0262, G_A_loss: 0.3586, G_B_loss: 0.7107\n",
      "Epoch [5/200], Step [501/1067], D_A_loss: 0.1334, D_B_loss: 0.1523, G_A_loss: 1.2746, G_B_loss: 0.4180\n",
      "Epoch [5/200], Step [511/1067], D_A_loss: 0.0327, D_B_loss: 0.0213, G_A_loss: 0.8426, G_B_loss: 0.6767\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/200], Step [521/1067], D_A_loss: 0.0322, D_B_loss: 0.1899, G_A_loss: 0.8614, G_B_loss: 0.1325\n",
      "Epoch [5/200], Step [531/1067], D_A_loss: 0.0926, D_B_loss: 0.0376, G_A_loss: 0.1461, G_B_loss: 0.1479\n",
      "Epoch [5/200], Step [541/1067], D_A_loss: 0.2753, D_B_loss: 0.1087, G_A_loss: 0.9297, G_B_loss: 0.2256\n",
      "Epoch [5/200], Step [551/1067], D_A_loss: 0.0730, D_B_loss: 0.0371, G_A_loss: 0.8535, G_B_loss: 0.3655\n",
      "Epoch [5/200], Step [561/1067], D_A_loss: 0.1246, D_B_loss: 0.1327, G_A_loss: 0.4241, G_B_loss: 0.1366\n",
      "Epoch [5/200], Step [571/1067], D_A_loss: 0.2092, D_B_loss: 0.1371, G_A_loss: 0.4725, G_B_loss: 0.7674\n",
      "Epoch [5/200], Step [581/1067], D_A_loss: 0.0859, D_B_loss: 0.1160, G_A_loss: 0.5726, G_B_loss: 0.4660\n",
      "Epoch [5/200], Step [591/1067], D_A_loss: 0.2212, D_B_loss: 0.1268, G_A_loss: 0.3511, G_B_loss: 0.9604\n",
      "Epoch [5/200], Step [601/1067], D_A_loss: 0.2569, D_B_loss: 0.1132, G_A_loss: 0.8576, G_B_loss: 0.1280\n",
      "Epoch [5/200], Step [611/1067], D_A_loss: 0.2353, D_B_loss: 0.2016, G_A_loss: 0.2119, G_B_loss: 0.1592\n",
      "Epoch [5/200], Step [621/1067], D_A_loss: 0.0879, D_B_loss: 0.2864, G_A_loss: 0.5730, G_B_loss: 0.3863\n",
      "Epoch [5/200], Step [631/1067], D_A_loss: 0.1642, D_B_loss: 0.0251, G_A_loss: 0.1489, G_B_loss: 0.4057\n",
      "Epoch [5/200], Step [641/1067], D_A_loss: 0.3347, D_B_loss: 0.2499, G_A_loss: 0.1296, G_B_loss: 0.1597\n",
      "Epoch [5/200], Step [651/1067], D_A_loss: 0.0298, D_B_loss: 0.1290, G_A_loss: 0.5447, G_B_loss: 0.5259\n",
      "Epoch [5/200], Step [661/1067], D_A_loss: 0.1334, D_B_loss: 0.0621, G_A_loss: 0.6776, G_B_loss: 0.4118\n",
      "Epoch [5/200], Step [671/1067], D_A_loss: 0.1385, D_B_loss: 0.1188, G_A_loss: 0.3170, G_B_loss: 0.2593\n",
      "Epoch [5/200], Step [681/1067], D_A_loss: 0.2291, D_B_loss: 0.0535, G_A_loss: 0.4251, G_B_loss: 0.4026\n",
      "Epoch [5/200], Step [691/1067], D_A_loss: 0.1464, D_B_loss: 0.2038, G_A_loss: 0.1736, G_B_loss: 0.5949\n",
      "Epoch [5/200], Step [701/1067], D_A_loss: 0.1081, D_B_loss: 0.1218, G_A_loss: 0.4038, G_B_loss: 0.3166\n",
      "Epoch [5/200], Step [711/1067], D_A_loss: 0.1525, D_B_loss: 0.1381, G_A_loss: 0.8634, G_B_loss: 0.3264\n",
      "Epoch [5/200], Step [721/1067], D_A_loss: 0.0808, D_B_loss: 0.2612, G_A_loss: 1.8214, G_B_loss: 0.4185\n",
      "Epoch [5/200], Step [731/1067], D_A_loss: 0.1499, D_B_loss: 0.2106, G_A_loss: 0.1609, G_B_loss: 0.3446\n",
      "Epoch [5/200], Step [741/1067], D_A_loss: 0.1031, D_B_loss: 0.0892, G_A_loss: 0.3818, G_B_loss: 0.2887\n",
      "Epoch [5/200], Step [751/1067], D_A_loss: 0.0546, D_B_loss: 0.0959, G_A_loss: 0.3981, G_B_loss: 0.4440\n",
      "Epoch [5/200], Step [761/1067], D_A_loss: 0.2749, D_B_loss: 0.0971, G_A_loss: 0.8637, G_B_loss: 0.8577\n",
      "Epoch [5/200], Step [771/1067], D_A_loss: 0.1944, D_B_loss: 0.0830, G_A_loss: 0.6394, G_B_loss: 0.1669\n",
      "Epoch [5/200], Step [781/1067], D_A_loss: 0.1054, D_B_loss: 0.1813, G_A_loss: 0.4747, G_B_loss: 0.3553\n",
      "Epoch [5/200], Step [791/1067], D_A_loss: 0.1011, D_B_loss: 0.0403, G_A_loss: 0.4537, G_B_loss: 0.4149\n",
      "Epoch [5/200], Step [801/1067], D_A_loss: 0.2280, D_B_loss: 0.0283, G_A_loss: 0.3398, G_B_loss: 0.1997\n",
      "Epoch [5/200], Step [811/1067], D_A_loss: 0.1130, D_B_loss: 0.0202, G_A_loss: 0.5797, G_B_loss: 0.3514\n",
      "Epoch [5/200], Step [821/1067], D_A_loss: 0.4263, D_B_loss: 0.0443, G_A_loss: 0.6445, G_B_loss: 0.0728\n",
      "Epoch [5/200], Step [831/1067], D_A_loss: 0.0935, D_B_loss: 0.0770, G_A_loss: 0.7446, G_B_loss: 0.2975\n",
      "Epoch [5/200], Step [841/1067], D_A_loss: 0.0489, D_B_loss: 0.1886, G_A_loss: 0.1886, G_B_loss: 0.4786\n",
      "Epoch [5/200], Step [851/1067], D_A_loss: 0.0907, D_B_loss: 0.0525, G_A_loss: 0.7001, G_B_loss: 0.8502\n",
      "Epoch [5/200], Step [861/1067], D_A_loss: 0.0242, D_B_loss: 0.0690, G_A_loss: 0.2032, G_B_loss: 0.4807\n",
      "Epoch [5/200], Step [871/1067], D_A_loss: 0.1350, D_B_loss: 0.0947, G_A_loss: 0.4181, G_B_loss: 0.5538\n",
      "Epoch [5/200], Step [881/1067], D_A_loss: 0.1491, D_B_loss: 0.2100, G_A_loss: 0.1848, G_B_loss: 0.2898\n",
      "Epoch [5/200], Step [891/1067], D_A_loss: 0.0891, D_B_loss: 0.0301, G_A_loss: 0.6763, G_B_loss: 0.3915\n",
      "Epoch [5/200], Step [901/1067], D_A_loss: 0.3167, D_B_loss: 0.0221, G_A_loss: 0.3530, G_B_loss: 0.8079\n",
      "Epoch [5/200], Step [911/1067], D_A_loss: 0.1765, D_B_loss: 0.1234, G_A_loss: 0.3661, G_B_loss: 0.3605\n",
      "Epoch [5/200], Step [921/1067], D_A_loss: 0.0888, D_B_loss: 0.0915, G_A_loss: 0.8690, G_B_loss: 0.4254\n",
      "Epoch [5/200], Step [931/1067], D_A_loss: 0.0545, D_B_loss: 0.0432, G_A_loss: 0.8219, G_B_loss: 0.5055\n",
      "Epoch [5/200], Step [941/1067], D_A_loss: 0.0834, D_B_loss: 0.3183, G_A_loss: 0.8059, G_B_loss: 0.4571\n",
      "Epoch [5/200], Step [951/1067], D_A_loss: 0.0436, D_B_loss: 0.1004, G_A_loss: 0.7499, G_B_loss: 0.3974\n",
      "Epoch [5/200], Step [961/1067], D_A_loss: 0.2387, D_B_loss: 0.1270, G_A_loss: 0.5185, G_B_loss: 0.8857\n",
      "Epoch [5/200], Step [971/1067], D_A_loss: 0.4378, D_B_loss: 0.1646, G_A_loss: 0.2942, G_B_loss: 0.4062\n",
      "Epoch [5/200], Step [981/1067], D_A_loss: 0.2157, D_B_loss: 0.1155, G_A_loss: 0.4430, G_B_loss: 0.1601\n",
      "Epoch [5/200], Step [991/1067], D_A_loss: 0.2109, D_B_loss: 0.1852, G_A_loss: 0.8171, G_B_loss: 0.6782\n",
      "Epoch [5/200], Step [1001/1067], D_A_loss: 0.1617, D_B_loss: 0.2082, G_A_loss: 0.2060, G_B_loss: 0.5926\n",
      "Epoch [5/200], Step [1011/1067], D_A_loss: 0.0439, D_B_loss: 0.1055, G_A_loss: 0.7220, G_B_loss: 0.9498\n",
      "Epoch [5/200], Step [1021/1067], D_A_loss: 0.4391, D_B_loss: 0.0721, G_A_loss: 0.4364, G_B_loss: 0.5570\n",
      "Epoch [5/200], Step [1031/1067], D_A_loss: 0.0570, D_B_loss: 0.1480, G_A_loss: 0.8204, G_B_loss: 0.4870\n",
      "Epoch [5/200], Step [1041/1067], D_A_loss: 0.1362, D_B_loss: 0.0978, G_A_loss: 0.4847, G_B_loss: 0.1402\n",
      "Epoch [5/200], Step [1051/1067], D_A_loss: 0.0594, D_B_loss: 0.0798, G_A_loss: 0.2899, G_B_loss: 0.2417\n",
      "Epoch [5/200], Step [1061/1067], D_A_loss: 0.2456, D_B_loss: 0.1157, G_A_loss: 0.3261, G_B_loss: 0.3936\n",
      "Epoch [6/200], Step [1/1067], D_A_loss: 0.1221, D_B_loss: 0.2908, G_A_loss: 1.2441, G_B_loss: 0.3331\n",
      "Epoch [6/200], Step [11/1067], D_A_loss: 0.0471, D_B_loss: 0.0961, G_A_loss: 0.4070, G_B_loss: 0.6938\n",
      "Epoch [6/200], Step [21/1067], D_A_loss: 0.1101, D_B_loss: 0.1846, G_A_loss: 0.6963, G_B_loss: 0.0710\n",
      "Epoch [6/200], Step [31/1067], D_A_loss: 0.1501, D_B_loss: 0.0708, G_A_loss: 0.4381, G_B_loss: 0.4593\n",
      "Epoch [6/200], Step [41/1067], D_A_loss: 0.1325, D_B_loss: 0.1668, G_A_loss: 0.3963, G_B_loss: 0.3888\n",
      "Epoch [6/200], Step [51/1067], D_A_loss: 0.2034, D_B_loss: 0.3747, G_A_loss: 0.7681, G_B_loss: 0.4241\n",
      "Epoch [6/200], Step [61/1067], D_A_loss: 0.1125, D_B_loss: 0.1613, G_A_loss: 0.6162, G_B_loss: 0.4268\n",
      "Epoch [6/200], Step [71/1067], D_A_loss: 0.1626, D_B_loss: 0.1087, G_A_loss: 0.3621, G_B_loss: 0.6634\n",
      "Epoch [6/200], Step [81/1067], D_A_loss: 0.1141, D_B_loss: 0.2369, G_A_loss: 0.6393, G_B_loss: 0.3742\n",
      "Epoch [6/200], Step [91/1067], D_A_loss: 0.2553, D_B_loss: 0.1225, G_A_loss: 0.7036, G_B_loss: 0.8355\n",
      "Epoch [6/200], Step [101/1067], D_A_loss: 0.1439, D_B_loss: 0.0374, G_A_loss: 0.6395, G_B_loss: 1.1908\n",
      "Epoch [6/200], Step [111/1067], D_A_loss: 0.1835, D_B_loss: 0.2691, G_A_loss: 1.2537, G_B_loss: 0.3554\n",
      "Epoch [6/200], Step [121/1067], D_A_loss: 0.1296, D_B_loss: 0.4478, G_A_loss: 0.3608, G_B_loss: 0.3323\n",
      "Epoch [6/200], Step [131/1067], D_A_loss: 0.2401, D_B_loss: 0.1122, G_A_loss: 0.5912, G_B_loss: 0.1378\n",
      "Epoch [6/200], Step [141/1067], D_A_loss: 0.1945, D_B_loss: 0.0678, G_A_loss: 0.3762, G_B_loss: 0.2094\n",
      "Epoch [6/200], Step [151/1067], D_A_loss: 0.3141, D_B_loss: 0.0445, G_A_loss: 0.5524, G_B_loss: 0.6437\n",
      "Epoch [6/200], Step [161/1067], D_A_loss: 0.1315, D_B_loss: 0.1926, G_A_loss: 0.1338, G_B_loss: 0.3491\n",
      "Epoch [6/200], Step [171/1067], D_A_loss: 0.0504, D_B_loss: 0.0551, G_A_loss: 0.2885, G_B_loss: 0.3538\n",
      "Epoch [6/200], Step [181/1067], D_A_loss: 0.1206, D_B_loss: 0.1839, G_A_loss: 0.2182, G_B_loss: 0.3877\n",
      "Epoch [6/200], Step [191/1067], D_A_loss: 0.0709, D_B_loss: 0.1442, G_A_loss: 0.3124, G_B_loss: 0.5839\n",
      "Epoch [6/200], Step [201/1067], D_A_loss: 0.0572, D_B_loss: 0.0593, G_A_loss: 0.6304, G_B_loss: 0.6931\n",
      "Epoch [6/200], Step [211/1067], D_A_loss: 0.0751, D_B_loss: 0.0499, G_A_loss: 0.4373, G_B_loss: 1.0183\n",
      "Epoch [6/200], Step [221/1067], D_A_loss: 0.0721, D_B_loss: 0.2080, G_A_loss: 0.8941, G_B_loss: 0.4624\n",
      "Epoch [6/200], Step [231/1067], D_A_loss: 0.1522, D_B_loss: 0.1352, G_A_loss: 0.6081, G_B_loss: 0.2815\n",
      "Epoch [6/200], Step [241/1067], D_A_loss: 0.3207, D_B_loss: 0.1449, G_A_loss: 0.4795, G_B_loss: 0.5062\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/200], Step [791/1067], D_A_loss: 0.2454, D_B_loss: 0.0566, G_A_loss: 0.5431, G_B_loss: 0.9878\n",
      "Epoch [6/200], Step [801/1067], D_A_loss: 0.0946, D_B_loss: 0.0390, G_A_loss: 0.8386, G_B_loss: 0.7988\n",
      "Epoch [6/200], Step [811/1067], D_A_loss: 0.4098, D_B_loss: 0.0698, G_A_loss: 0.4742, G_B_loss: 0.1020\n",
      "Epoch [6/200], Step [821/1067], D_A_loss: 0.2421, D_B_loss: 0.0404, G_A_loss: 0.3846, G_B_loss: 0.2405\n",
      "Epoch [6/200], Step [831/1067], D_A_loss: 0.0902, D_B_loss: 0.0870, G_A_loss: 0.6126, G_B_loss: 0.7033\n",
      "Epoch [6/200], Step [841/1067], D_A_loss: 0.1062, D_B_loss: 0.0996, G_A_loss: 0.3398, G_B_loss: 0.4689\n",
      "Epoch [6/200], Step [851/1067], D_A_loss: 0.1936, D_B_loss: 0.1747, G_A_loss: 0.3131, G_B_loss: 0.2940\n",
      "Epoch [6/200], Step [861/1067], D_A_loss: 0.2341, D_B_loss: 0.1538, G_A_loss: 0.4227, G_B_loss: 0.2043\n",
      "Epoch [6/200], Step [871/1067], D_A_loss: 0.2809, D_B_loss: 0.1301, G_A_loss: 0.2935, G_B_loss: 0.8958\n",
      "Epoch [6/200], Step [881/1067], D_A_loss: 0.1499, D_B_loss: 0.0664, G_A_loss: 0.9058, G_B_loss: 0.2341\n",
      "Epoch [6/200], Step [891/1067], D_A_loss: 0.1665, D_B_loss: 0.0186, G_A_loss: 0.4269, G_B_loss: 0.3356\n",
      "Epoch [6/200], Step [901/1067], D_A_loss: 0.1432, D_B_loss: 0.1017, G_A_loss: 0.4227, G_B_loss: 0.4845\n",
      "Epoch [6/200], Step [911/1067], D_A_loss: 0.1524, D_B_loss: 0.0326, G_A_loss: 0.3356, G_B_loss: 0.3874\n",
      "Epoch [6/200], Step [921/1067], D_A_loss: 0.0925, D_B_loss: 0.0743, G_A_loss: 0.5304, G_B_loss: 0.5366\n",
      "Epoch [6/200], Step [931/1067], D_A_loss: 0.1215, D_B_loss: 0.0766, G_A_loss: 0.5484, G_B_loss: 0.3574\n",
      "Epoch [6/200], Step [941/1067], D_A_loss: 0.1815, D_B_loss: 0.0919, G_A_loss: 0.2778, G_B_loss: 0.3913\n",
      "Epoch [6/200], Step [951/1067], D_A_loss: 0.1125, D_B_loss: 0.0282, G_A_loss: 0.3606, G_B_loss: 0.5143\n",
      "Epoch [6/200], Step [961/1067], D_A_loss: 0.1901, D_B_loss: 0.5359, G_A_loss: 1.1301, G_B_loss: 0.3178\n",
      "Epoch [6/200], Step [971/1067], D_A_loss: 0.0782, D_B_loss: 0.1014, G_A_loss: 0.3966, G_B_loss: 0.6752\n",
      "Epoch [6/200], Step [981/1067], D_A_loss: 0.0838, D_B_loss: 0.3652, G_A_loss: 1.0152, G_B_loss: 0.2547\n",
      "Epoch [6/200], Step [991/1067], D_A_loss: 0.1243, D_B_loss: 0.1328, G_A_loss: 0.4113, G_B_loss: 0.1195\n",
      "Epoch [6/200], Step [1001/1067], D_A_loss: 0.1709, D_B_loss: 0.1815, G_A_loss: 0.2611, G_B_loss: 0.4321\n",
      "Epoch [6/200], Step [1011/1067], D_A_loss: 0.1573, D_B_loss: 0.1077, G_A_loss: 0.4195, G_B_loss: 0.4270\n",
      "Epoch [6/200], Step [1021/1067], D_A_loss: 0.0332, D_B_loss: 0.1758, G_A_loss: 0.8807, G_B_loss: 0.1156\n",
      "Epoch [6/200], Step [1031/1067], D_A_loss: 0.1348, D_B_loss: 0.0746, G_A_loss: 0.4523, G_B_loss: 0.5147\n",
      "Epoch [6/200], Step [1041/1067], D_A_loss: 0.0987, D_B_loss: 0.0917, G_A_loss: 0.5387, G_B_loss: 0.3754\n",
      "Epoch [6/200], Step [1051/1067], D_A_loss: 0.0380, D_B_loss: 0.3130, G_A_loss: 0.8690, G_B_loss: 0.1389\n",
      "Epoch [6/200], Step [1061/1067], D_A_loss: 0.2721, D_B_loss: 0.0517, G_A_loss: 0.2773, G_B_loss: 0.8526\n",
      "Epoch [7/200], Step [1/1067], D_A_loss: 0.0628, D_B_loss: 0.1985, G_A_loss: 0.5445, G_B_loss: 0.1726\n",
      "Epoch [7/200], Step [11/1067], D_A_loss: 0.0693, D_B_loss: 0.0954, G_A_loss: 0.4442, G_B_loss: 0.1927\n",
      "Epoch [7/200], Step [21/1067], D_A_loss: 0.0528, D_B_loss: 0.1565, G_A_loss: 0.6671, G_B_loss: 0.5382\n",
      "Epoch [7/200], Step [31/1067], D_A_loss: 0.2011, D_B_loss: 0.0520, G_A_loss: 0.7471, G_B_loss: 0.2624\n",
      "Epoch [7/200], Step [41/1067], D_A_loss: 0.0977, D_B_loss: 0.1165, G_A_loss: 0.3795, G_B_loss: 0.9683\n",
      "Epoch [7/200], Step [51/1067], D_A_loss: 0.1896, D_B_loss: 0.0811, G_A_loss: 0.4784, G_B_loss: 0.6851\n",
      "Epoch [7/200], Step [61/1067], D_A_loss: 0.2675, D_B_loss: 0.0391, G_A_loss: 0.6588, G_B_loss: 0.2795\n",
      "Epoch [7/200], Step [71/1067], D_A_loss: 0.0743, D_B_loss: 0.0505, G_A_loss: 0.5849, G_B_loss: 0.4574\n",
      "Epoch [7/200], Step [81/1067], D_A_loss: 0.1449, D_B_loss: 0.0709, G_A_loss: 0.5122, G_B_loss: 0.2516\n",
      "Epoch [7/200], Step [91/1067], D_A_loss: 0.0470, D_B_loss: 0.1142, G_A_loss: 0.1425, G_B_loss: 0.0952\n",
      "Epoch [7/200], Step [101/1067], D_A_loss: 0.2342, D_B_loss: 0.1185, G_A_loss: 0.7908, G_B_loss: 0.5001\n",
      "Epoch [7/200], Step [111/1067], D_A_loss: 0.1962, D_B_loss: 0.0498, G_A_loss: 0.1530, G_B_loss: 0.5435\n",
      "Epoch [7/200], Step [121/1067], D_A_loss: 0.1447, D_B_loss: 0.0968, G_A_loss: 0.2538, G_B_loss: 0.1641\n",
      "Epoch [7/200], Step [131/1067], D_A_loss: 0.1469, D_B_loss: 0.1056, G_A_loss: 0.6918, G_B_loss: 0.7086\n",
      "Epoch [7/200], Step [141/1067], D_A_loss: 0.2360, D_B_loss: 0.1610, G_A_loss: 0.6760, G_B_loss: 0.3492\n",
      "Epoch [7/200], Step [151/1067], D_A_loss: 0.1942, D_B_loss: 0.0679, G_A_loss: 0.4871, G_B_loss: 0.1961\n",
      "Epoch [7/200], Step [161/1067], D_A_loss: 0.1554, D_B_loss: 0.0848, G_A_loss: 0.7954, G_B_loss: 0.2051\n",
      "Epoch [7/200], Step [171/1067], D_A_loss: 0.2825, D_B_loss: 0.1083, G_A_loss: 0.3107, G_B_loss: 0.0913\n",
      "Epoch [7/200], Step [181/1067], D_A_loss: 0.1992, D_B_loss: 0.2014, G_A_loss: 0.4956, G_B_loss: 0.6632\n",
      "Epoch [7/200], Step [191/1067], D_A_loss: 0.2601, D_B_loss: 0.2165, G_A_loss: 0.2716, G_B_loss: 0.1453\n",
      "Epoch [7/200], Step [201/1067], D_A_loss: 0.2334, D_B_loss: 0.0739, G_A_loss: 0.5981, G_B_loss: 0.4614\n",
      "Epoch [7/200], Step [211/1067], D_A_loss: 0.1208, D_B_loss: 0.0219, G_A_loss: 0.8879, G_B_loss: 0.5082\n",
      "Epoch [7/200], Step [221/1067], D_A_loss: 0.1662, D_B_loss: 0.2832, G_A_loss: 1.0292, G_B_loss: 0.2477\n",
      "Epoch [7/200], Step [231/1067], D_A_loss: 0.1571, D_B_loss: 0.0964, G_A_loss: 0.5988, G_B_loss: 0.1902\n",
      "Epoch [7/200], Step [241/1067], D_A_loss: 0.1276, D_B_loss: 0.1734, G_A_loss: 0.4127, G_B_loss: 0.6577\n",
      "Epoch [7/200], Step [251/1067], D_A_loss: 0.2298, D_B_loss: 0.1027, G_A_loss: 0.5636, G_B_loss: 0.7637\n",
      "Epoch [7/200], Step [261/1067], D_A_loss: 0.0850, D_B_loss: 0.0840, G_A_loss: 0.4858, G_B_loss: 0.4508\n",
      "Epoch [7/200], Step [271/1067], D_A_loss: 0.0332, D_B_loss: 0.0400, G_A_loss: 0.6502, G_B_loss: 0.4149\n",
      "Epoch [7/200], Step [281/1067], D_A_loss: 0.0701, D_B_loss: 0.1670, G_A_loss: 1.2260, G_B_loss: 0.3334\n",
      "Epoch [7/200], Step [291/1067], D_A_loss: 0.7483, D_B_loss: 0.0406, G_A_loss: 0.7171, G_B_loss: 1.2749\n",
      "Epoch [7/200], Step [301/1067], D_A_loss: 0.0976, D_B_loss: 0.0853, G_A_loss: 0.2053, G_B_loss: 0.9648\n",
      "Epoch [7/200], Step [311/1067], D_A_loss: 0.0655, D_B_loss: 0.0634, G_A_loss: 0.8683, G_B_loss: 0.5521\n",
      "Epoch [7/200], Step [321/1067], D_A_loss: 0.1330, D_B_loss: 0.1349, G_A_loss: 0.7224, G_B_loss: 0.2880\n",
      "Epoch [7/200], Step [331/1067], D_A_loss: 0.0798, D_B_loss: 0.1298, G_A_loss: 0.3039, G_B_loss: 0.9058\n",
      "Epoch [7/200], Step [341/1067], D_A_loss: 0.2281, D_B_loss: 0.2081, G_A_loss: 0.3308, G_B_loss: 0.3412\n",
      "Epoch [7/200], Step [351/1067], D_A_loss: 0.2526, D_B_loss: 0.2069, G_A_loss: 0.7506, G_B_loss: 0.2163\n",
      "Epoch [7/200], Step [361/1067], D_A_loss: 0.1863, D_B_loss: 0.1224, G_A_loss: 0.3878, G_B_loss: 0.4110\n",
      "Epoch [7/200], Step [371/1067], D_A_loss: 0.2311, D_B_loss: 0.0315, G_A_loss: 0.2129, G_B_loss: 0.4360\n",
      "Epoch [7/200], Step [381/1067], D_A_loss: 0.1910, D_B_loss: 0.0646, G_A_loss: 0.9283, G_B_loss: 0.4472\n",
      "Epoch [7/200], Step [391/1067], D_A_loss: 0.1353, D_B_loss: 0.6970, G_A_loss: 0.0386, G_B_loss: 0.6282\n",
      "Epoch [7/200], Step [401/1067], D_A_loss: 0.1390, D_B_loss: 0.1647, G_A_loss: 0.4938, G_B_loss: 0.5264\n",
      "Epoch [7/200], Step [411/1067], D_A_loss: 0.0428, D_B_loss: 0.0990, G_A_loss: 0.2798, G_B_loss: 0.4690\n",
      "Epoch [7/200], Step [421/1067], D_A_loss: 0.0679, D_B_loss: 0.2116, G_A_loss: 0.1854, G_B_loss: 0.6041\n",
      "Epoch [7/200], Step [431/1067], D_A_loss: 0.0947, D_B_loss: 0.0543, G_A_loss: 0.5336, G_B_loss: 0.8801\n",
      "Epoch [7/200], Step [441/1067], D_A_loss: 0.1485, D_B_loss: 0.0615, G_A_loss: 0.4433, G_B_loss: 1.1575\n",
      "Epoch [7/200], Step [451/1067], D_A_loss: 0.0286, D_B_loss: 0.0751, G_A_loss: 1.0086, G_B_loss: 0.3745\n",
      "Epoch [7/200], Step [461/1067], D_A_loss: 0.1365, D_B_loss: 0.0869, G_A_loss: 0.5996, G_B_loss: 0.4378\n",
      "Epoch [7/200], Step [471/1067], D_A_loss: 0.0635, D_B_loss: 0.1149, G_A_loss: 0.4052, G_B_loss: 0.4494\n",
      "Epoch [7/200], Step [481/1067], D_A_loss: 0.1964, D_B_loss: 0.1308, G_A_loss: 0.5285, G_B_loss: 0.6161\n",
      "Epoch [7/200], Step [491/1067], D_A_loss: 0.0961, D_B_loss: 0.1355, G_A_loss: 0.4808, G_B_loss: 0.5600\n",
      "Epoch [7/200], Step [501/1067], D_A_loss: 0.2140, D_B_loss: 0.0546, G_A_loss: 0.1667, G_B_loss: 0.3632\n",
      "Epoch [7/200], Step [511/1067], D_A_loss: 0.0815, D_B_loss: 0.2037, G_A_loss: 0.6123, G_B_loss: 0.4418\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/200], Step [521/1067], D_A_loss: 0.1243, D_B_loss: 0.1075, G_A_loss: 0.6559, G_B_loss: 0.4021\n",
      "Epoch [7/200], Step [531/1067], D_A_loss: 0.0819, D_B_loss: 0.2538, G_A_loss: 0.1309, G_B_loss: 0.8477\n",
      "Epoch [7/200], Step [541/1067], D_A_loss: 0.0895, D_B_loss: 0.4010, G_A_loss: 0.5119, G_B_loss: 0.4182\n",
      "Epoch [7/200], Step [551/1067], D_A_loss: 0.1522, D_B_loss: 0.1121, G_A_loss: 0.2292, G_B_loss: 0.3056\n",
      "Epoch [7/200], Step [561/1067], D_A_loss: 0.2206, D_B_loss: 0.1527, G_A_loss: 0.7840, G_B_loss: 0.5097\n",
      "Epoch [7/200], Step [571/1067], D_A_loss: 0.2456, D_B_loss: 0.0663, G_A_loss: 0.6739, G_B_loss: 0.3498\n",
      "Epoch [7/200], Step [581/1067], D_A_loss: 0.1179, D_B_loss: 0.2317, G_A_loss: 0.0390, G_B_loss: 0.5550\n",
      "Epoch [7/200], Step [591/1067], D_A_loss: 0.0934, D_B_loss: 0.1742, G_A_loss: 0.2199, G_B_loss: 0.6235\n",
      "Epoch [7/200], Step [601/1067], D_A_loss: 0.1479, D_B_loss: 0.1459, G_A_loss: 0.2835, G_B_loss: 0.4580\n",
      "Epoch [7/200], Step [611/1067], D_A_loss: 0.0545, D_B_loss: 0.1177, G_A_loss: 0.3525, G_B_loss: 0.2990\n",
      "Epoch [7/200], Step [621/1067], D_A_loss: 0.2316, D_B_loss: 0.0709, G_A_loss: 0.6383, G_B_loss: 0.2355\n",
      "Epoch [7/200], Step [631/1067], D_A_loss: 0.0515, D_B_loss: 0.1288, G_A_loss: 0.3435, G_B_loss: 0.3488\n",
      "Epoch [7/200], Step [641/1067], D_A_loss: 0.0281, D_B_loss: 0.0389, G_A_loss: 0.2051, G_B_loss: 0.3837\n",
      "Epoch [7/200], Step [651/1067], D_A_loss: 0.2821, D_B_loss: 0.0645, G_A_loss: 0.4554, G_B_loss: 0.2876\n",
      "Epoch [7/200], Step [661/1067], D_A_loss: 0.3278, D_B_loss: 0.1584, G_A_loss: 0.2540, G_B_loss: 0.6214\n",
      "Epoch [7/200], Step [671/1067], D_A_loss: 0.0879, D_B_loss: 0.1205, G_A_loss: 0.3429, G_B_loss: 0.4147\n",
      "Epoch [7/200], Step [681/1067], D_A_loss: 0.3382, D_B_loss: 0.0841, G_A_loss: 0.2822, G_B_loss: 0.1533\n",
      "Epoch [7/200], Step [691/1067], D_A_loss: 0.1485, D_B_loss: 0.0695, G_A_loss: 0.4072, G_B_loss: 0.8065\n",
      "Epoch [7/200], Step [701/1067], D_A_loss: 0.2061, D_B_loss: 0.1919, G_A_loss: 0.1899, G_B_loss: 0.3937\n",
      "Epoch [7/200], Step [711/1067], D_A_loss: 0.0587, D_B_loss: 0.1344, G_A_loss: 0.6605, G_B_loss: 0.0978\n",
      "Epoch [7/200], Step [721/1067], D_A_loss: 0.0869, D_B_loss: 0.0147, G_A_loss: 0.9365, G_B_loss: 0.4269\n",
      "Epoch [7/200], Step [731/1067], D_A_loss: 0.1508, D_B_loss: 0.0255, G_A_loss: 0.5873, G_B_loss: 0.3987\n",
      "Epoch [7/200], Step [741/1067], D_A_loss: 0.0300, D_B_loss: 0.0563, G_A_loss: 0.1687, G_B_loss: 0.7485\n",
      "Epoch [7/200], Step [751/1067], D_A_loss: 0.2224, D_B_loss: 0.1116, G_A_loss: 0.3421, G_B_loss: 0.6671\n",
      "Epoch [7/200], Step [761/1067], D_A_loss: 0.0808, D_B_loss: 0.1209, G_A_loss: 0.3026, G_B_loss: 0.4705\n",
      "Epoch [7/200], Step [771/1067], D_A_loss: 0.2514, D_B_loss: 0.2108, G_A_loss: 0.2949, G_B_loss: 0.2437\n",
      "Epoch [7/200], Step [781/1067], D_A_loss: 0.2018, D_B_loss: 0.1303, G_A_loss: 0.3452, G_B_loss: 0.2505\n",
      "Epoch [7/200], Step [791/1067], D_A_loss: 0.1174, D_B_loss: 0.0371, G_A_loss: 0.3463, G_B_loss: 0.4179\n",
      "Epoch [7/200], Step [801/1067], D_A_loss: 0.2248, D_B_loss: 0.0925, G_A_loss: 0.6613, G_B_loss: 0.4218\n",
      "Epoch [7/200], Step [811/1067], D_A_loss: 0.1128, D_B_loss: 0.1895, G_A_loss: 0.2967, G_B_loss: 0.6377\n",
      "Epoch [7/200], Step [821/1067], D_A_loss: 0.2081, D_B_loss: 0.1086, G_A_loss: 0.4131, G_B_loss: 0.1742\n",
      "Epoch [7/200], Step [831/1067], D_A_loss: 0.3613, D_B_loss: 0.1167, G_A_loss: 0.6503, G_B_loss: 0.3957\n",
      "Epoch [7/200], Step [841/1067], D_A_loss: 0.2328, D_B_loss: 0.0570, G_A_loss: 0.7212, G_B_loss: 0.1964\n",
      "Epoch [7/200], Step [851/1067], D_A_loss: 0.1982, D_B_loss: 0.1515, G_A_loss: 0.7697, G_B_loss: 0.2643\n",
      "Epoch [7/200], Step [861/1067], D_A_loss: 0.0658, D_B_loss: 0.0411, G_A_loss: 0.7223, G_B_loss: 0.5800\n",
      "Epoch [7/200], Step [871/1067], D_A_loss: 0.0748, D_B_loss: 0.1377, G_A_loss: 0.3293, G_B_loss: 0.4378\n",
      "Epoch [7/200], Step [881/1067], D_A_loss: 0.0640, D_B_loss: 0.2003, G_A_loss: 0.1910, G_B_loss: 0.4611\n",
      "Epoch [7/200], Step [891/1067], D_A_loss: 0.0164, D_B_loss: 0.1375, G_A_loss: 0.3527, G_B_loss: 0.7388\n",
      "Epoch [7/200], Step [901/1067], D_A_loss: 0.2568, D_B_loss: 0.3860, G_A_loss: 1.2492, G_B_loss: 0.2158\n",
      "Epoch [7/200], Step [911/1067], D_A_loss: 0.2077, D_B_loss: 0.1660, G_A_loss: 0.3324, G_B_loss: 0.4516\n",
      "Epoch [7/200], Step [921/1067], D_A_loss: 0.0332, D_B_loss: 0.1547, G_A_loss: 0.2567, G_B_loss: 0.4148\n",
      "Epoch [7/200], Step [931/1067], D_A_loss: 0.2263, D_B_loss: 0.0345, G_A_loss: 0.6927, G_B_loss: 0.5663\n",
      "Epoch [7/200], Step [941/1067], D_A_loss: 0.1128, D_B_loss: 0.1642, G_A_loss: 0.3997, G_B_loss: 0.3543\n",
      "Epoch [7/200], Step [951/1067], D_A_loss: 0.2389, D_B_loss: 0.0430, G_A_loss: 0.6704, G_B_loss: 0.8617\n",
      "Epoch [7/200], Step [961/1067], D_A_loss: 0.1272, D_B_loss: 0.0551, G_A_loss: 0.7262, G_B_loss: 0.0729\n",
      "Epoch [7/200], Step [971/1067], D_A_loss: 0.0724, D_B_loss: 0.0689, G_A_loss: 0.4604, G_B_loss: 0.6355\n",
      "Epoch [7/200], Step [981/1067], D_A_loss: 0.1110, D_B_loss: 0.0889, G_A_loss: 0.3920, G_B_loss: 0.4333\n",
      "Epoch [7/200], Step [991/1067], D_A_loss: 0.2278, D_B_loss: 0.1461, G_A_loss: 0.6594, G_B_loss: 0.1469\n",
      "Epoch [7/200], Step [1001/1067], D_A_loss: 0.2330, D_B_loss: 0.0829, G_A_loss: 0.5494, G_B_loss: 0.4962\n",
      "Epoch [7/200], Step [1011/1067], D_A_loss: 0.0859, D_B_loss: 0.0602, G_A_loss: 0.7076, G_B_loss: 0.3060\n",
      "Epoch [7/200], Step [1021/1067], D_A_loss: 0.1185, D_B_loss: 0.0821, G_A_loss: 0.5595, G_B_loss: 0.5213\n",
      "Epoch [7/200], Step [1031/1067], D_A_loss: 0.4829, D_B_loss: 0.0383, G_A_loss: 0.2882, G_B_loss: 0.4422\n",
      "Epoch [7/200], Step [1041/1067], D_A_loss: 0.0751, D_B_loss: 0.0896, G_A_loss: 0.2633, G_B_loss: 0.4458\n",
      "Epoch [7/200], Step [1051/1067], D_A_loss: 0.2137, D_B_loss: 0.0326, G_A_loss: 0.6508, G_B_loss: 0.1642\n",
      "Epoch [7/200], Step [1061/1067], D_A_loss: 0.0613, D_B_loss: 0.0590, G_A_loss: 0.3456, G_B_loss: 0.6145\n",
      "Epoch [8/200], Step [1/1067], D_A_loss: 0.0936, D_B_loss: 0.2166, G_A_loss: 0.7698, G_B_loss: 0.6780\n",
      "Epoch [8/200], Step [11/1067], D_A_loss: 0.1542, D_B_loss: 0.1628, G_A_loss: 0.2626, G_B_loss: 0.6706\n",
      "Epoch [8/200], Step [21/1067], D_A_loss: 0.0947, D_B_loss: 0.0425, G_A_loss: 0.6425, G_B_loss: 0.3619\n",
      "Epoch [8/200], Step [31/1067], D_A_loss: 0.0794, D_B_loss: 0.0742, G_A_loss: 0.5851, G_B_loss: 0.4965\n",
      "Epoch [8/200], Step [41/1067], D_A_loss: 0.1613, D_B_loss: 0.0722, G_A_loss: 0.4536, G_B_loss: 1.4677\n",
      "Epoch [8/200], Step [51/1067], D_A_loss: 0.0546, D_B_loss: 0.0434, G_A_loss: 0.6130, G_B_loss: 0.1873\n",
      "Epoch [8/200], Step [61/1067], D_A_loss: 0.1450, D_B_loss: 0.0464, G_A_loss: 0.3449, G_B_loss: 0.5009\n",
      "Epoch [8/200], Step [71/1067], D_A_loss: 0.0450, D_B_loss: 0.0378, G_A_loss: 0.9493, G_B_loss: 0.6504\n",
      "Epoch [8/200], Step [81/1067], D_A_loss: 0.3580, D_B_loss: 0.1534, G_A_loss: 0.7798, G_B_loss: 0.5154\n",
      "Epoch [8/200], Step [91/1067], D_A_loss: 0.2153, D_B_loss: 0.0502, G_A_loss: 0.3854, G_B_loss: 0.4656\n",
      "Epoch [8/200], Step [101/1067], D_A_loss: 0.2524, D_B_loss: 0.0610, G_A_loss: 0.0965, G_B_loss: 0.1454\n",
      "Epoch [8/200], Step [111/1067], D_A_loss: 0.2803, D_B_loss: 0.2389, G_A_loss: 0.4530, G_B_loss: 0.4651\n",
      "Epoch [8/200], Step [121/1067], D_A_loss: 0.1257, D_B_loss: 0.0966, G_A_loss: 0.1881, G_B_loss: 0.6325\n",
      "Epoch [8/200], Step [131/1067], D_A_loss: 0.1321, D_B_loss: 0.0366, G_A_loss: 0.3019, G_B_loss: 0.5470\n",
      "Epoch [8/200], Step [141/1067], D_A_loss: 0.1794, D_B_loss: 0.1899, G_A_loss: 0.1658, G_B_loss: 0.4027\n",
      "Epoch [8/200], Step [151/1067], D_A_loss: 0.2944, D_B_loss: 0.0191, G_A_loss: 0.3560, G_B_loss: 0.2559\n",
      "Epoch [8/200], Step [161/1067], D_A_loss: 0.1253, D_B_loss: 0.1529, G_A_loss: 0.5410, G_B_loss: 0.5425\n",
      "Epoch [8/200], Step [171/1067], D_A_loss: 0.2416, D_B_loss: 0.1299, G_A_loss: 0.2925, G_B_loss: 0.3949\n",
      "Epoch [8/200], Step [181/1067], D_A_loss: 0.1865, D_B_loss: 0.4095, G_A_loss: 0.7377, G_B_loss: 0.1736\n",
      "Epoch [8/200], Step [191/1067], D_A_loss: 0.0548, D_B_loss: 0.0817, G_A_loss: 0.4490, G_B_loss: 0.5390\n",
      "Epoch [8/200], Step [201/1067], D_A_loss: 0.1859, D_B_loss: 0.1115, G_A_loss: 0.4588, G_B_loss: 0.3308\n",
      "Epoch [8/200], Step [211/1067], D_A_loss: 0.0378, D_B_loss: 0.2132, G_A_loss: 0.2934, G_B_loss: 0.1742\n",
      "Epoch [8/200], Step [221/1067], D_A_loss: 0.0348, D_B_loss: 0.1290, G_A_loss: 0.3166, G_B_loss: 0.2453\n",
      "Epoch [8/200], Step [231/1067], D_A_loss: 0.1653, D_B_loss: 0.1014, G_A_loss: 0.4066, G_B_loss: 0.3429\n",
      "Epoch [8/200], Step [241/1067], D_A_loss: 0.0588, D_B_loss: 0.0583, G_A_loss: 0.5498, G_B_loss: 0.7083\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/200], Step [251/1067], D_A_loss: 0.2421, D_B_loss: 0.0696, G_A_loss: 0.2053, G_B_loss: 0.1549\n",
      "Epoch [8/200], Step [261/1067], D_A_loss: 0.2048, D_B_loss: 0.1523, G_A_loss: 0.4165, G_B_loss: 1.0950\n",
      "Epoch [8/200], Step [271/1067], D_A_loss: 0.2404, D_B_loss: 0.0822, G_A_loss: 0.8850, G_B_loss: 0.2098\n",
      "Epoch [8/200], Step [281/1067], D_A_loss: 0.1037, D_B_loss: 0.0290, G_A_loss: 1.0908, G_B_loss: 0.4144\n",
      "Epoch [8/200], Step [291/1067], D_A_loss: 0.1089, D_B_loss: 0.0551, G_A_loss: 0.6054, G_B_loss: 0.4146\n",
      "Epoch [8/200], Step [301/1067], D_A_loss: 0.0380, D_B_loss: 0.0391, G_A_loss: 0.8108, G_B_loss: 0.4674\n",
      "Epoch [8/200], Step [311/1067], D_A_loss: 0.0851, D_B_loss: 0.0234, G_A_loss: 0.9945, G_B_loss: 0.6121\n",
      "Epoch [8/200], Step [321/1067], D_A_loss: 0.1428, D_B_loss: 0.1188, G_A_loss: 1.0031, G_B_loss: 0.2875\n",
      "Epoch [8/200], Step [331/1067], D_A_loss: 0.4138, D_B_loss: 0.0582, G_A_loss: 0.4972, G_B_loss: 0.2534\n",
      "Epoch [8/200], Step [341/1067], D_A_loss: 0.1276, D_B_loss: 0.0757, G_A_loss: 0.6042, G_B_loss: 0.3844\n",
      "Epoch [8/200], Step [351/1067], D_A_loss: 0.2731, D_B_loss: 0.1228, G_A_loss: 0.3990, G_B_loss: 0.6458\n",
      "Epoch [8/200], Step [361/1067], D_A_loss: 0.2204, D_B_loss: 0.0595, G_A_loss: 0.5124, G_B_loss: 0.3214\n",
      "Epoch [8/200], Step [371/1067], D_A_loss: 0.3109, D_B_loss: 0.1498, G_A_loss: 0.7928, G_B_loss: 1.4380\n",
      "Epoch [8/200], Step [381/1067], D_A_loss: 0.1563, D_B_loss: 0.4434, G_A_loss: 0.9652, G_B_loss: 0.2903\n",
      "Epoch [8/200], Step [391/1067], D_A_loss: 0.1362, D_B_loss: 0.0501, G_A_loss: 0.6847, G_B_loss: 0.7502\n",
      "Epoch [8/200], Step [401/1067], D_A_loss: 0.0500, D_B_loss: 0.0704, G_A_loss: 0.3923, G_B_loss: 0.7215\n",
      "Epoch [8/200], Step [411/1067], D_A_loss: 0.0735, D_B_loss: 0.0524, G_A_loss: 0.6030, G_B_loss: 0.1016\n",
      "Epoch [8/200], Step [421/1067], D_A_loss: 0.0953, D_B_loss: 0.0406, G_A_loss: 0.6624, G_B_loss: 0.3677\n",
      "Epoch [8/200], Step [431/1067], D_A_loss: 0.1035, D_B_loss: 0.1122, G_A_loss: 0.3868, G_B_loss: 0.0518\n",
      "Epoch [8/200], Step [441/1067], D_A_loss: 0.0635, D_B_loss: 0.0513, G_A_loss: 0.4758, G_B_loss: 0.7101\n",
      "Epoch [8/200], Step [451/1067], D_A_loss: 0.0722, D_B_loss: 0.1138, G_A_loss: 0.5571, G_B_loss: 0.0904\n",
      "Epoch [8/200], Step [461/1067], D_A_loss: 0.0344, D_B_loss: 0.0677, G_A_loss: 0.7557, G_B_loss: 0.7040\n",
      "Epoch [8/200], Step [471/1067], D_A_loss: 0.0832, D_B_loss: 0.0223, G_A_loss: 0.3820, G_B_loss: 0.5228\n",
      "Epoch [8/200], Step [481/1067], D_A_loss: 0.2437, D_B_loss: 0.1076, G_A_loss: 0.4984, G_B_loss: 0.5229\n",
      "Epoch [8/200], Step [491/1067], D_A_loss: 0.1207, D_B_loss: 0.1984, G_A_loss: 0.2287, G_B_loss: 0.3457\n",
      "Epoch [8/200], Step [501/1067], D_A_loss: 0.1245, D_B_loss: 0.1329, G_A_loss: 0.6863, G_B_loss: 0.3728\n",
      "Epoch [8/200], Step [511/1067], D_A_loss: 0.0428, D_B_loss: 0.1524, G_A_loss: 1.0184, G_B_loss: 0.2761\n",
      "Epoch [8/200], Step [521/1067], D_A_loss: 0.0978, D_B_loss: 0.0874, G_A_loss: 0.4474, G_B_loss: 0.4698\n",
      "Epoch [8/200], Step [531/1067], D_A_loss: 0.4948, D_B_loss: 0.1180, G_A_loss: 0.4074, G_B_loss: 0.1019\n",
      "Epoch [8/200], Step [541/1067], D_A_loss: 0.0787, D_B_loss: 0.0336, G_A_loss: 0.2151, G_B_loss: 0.6872\n",
      "Epoch [8/200], Step [551/1067], D_A_loss: 0.2045, D_B_loss: 0.0518, G_A_loss: 0.2120, G_B_loss: 0.4334\n",
      "Epoch [8/200], Step [561/1067], D_A_loss: 0.1881, D_B_loss: 0.0640, G_A_loss: 0.7062, G_B_loss: 0.3633\n",
      "Epoch [8/200], Step [571/1067], D_A_loss: 0.0883, D_B_loss: 0.0774, G_A_loss: 0.7303, G_B_loss: 0.4575\n",
      "Epoch [8/200], Step [581/1067], D_A_loss: 0.2050, D_B_loss: 0.1360, G_A_loss: 0.4960, G_B_loss: 0.5131\n",
      "Epoch [8/200], Step [591/1067], D_A_loss: 0.1104, D_B_loss: 0.0871, G_A_loss: 0.4090, G_B_loss: 0.6097\n",
      "Epoch [8/200], Step [601/1067], D_A_loss: 0.0687, D_B_loss: 0.0750, G_A_loss: 0.5160, G_B_loss: 0.3442\n",
      "Epoch [8/200], Step [611/1067], D_A_loss: 0.2289, D_B_loss: 0.0129, G_A_loss: 0.3195, G_B_loss: 0.3999\n",
      "Epoch [8/200], Step [621/1067], D_A_loss: 0.0251, D_B_loss: 0.1534, G_A_loss: 0.2545, G_B_loss: 0.7742\n",
      "Epoch [8/200], Step [631/1067], D_A_loss: 0.0946, D_B_loss: 0.0854, G_A_loss: 0.7863, G_B_loss: 0.3535\n",
      "Epoch [8/200], Step [641/1067], D_A_loss: 0.1423, D_B_loss: 0.1428, G_A_loss: 0.1668, G_B_loss: 0.2827\n",
      "Epoch [8/200], Step [651/1067], D_A_loss: 0.2149, D_B_loss: 0.0281, G_A_loss: 0.7744, G_B_loss: 0.3722\n",
      "Epoch [8/200], Step [661/1067], D_A_loss: 0.2191, D_B_loss: 0.1228, G_A_loss: 0.7206, G_B_loss: 0.1837\n",
      "Epoch [8/200], Step [671/1067], D_A_loss: 0.2120, D_B_loss: 0.0709, G_A_loss: 0.2733, G_B_loss: 0.8703\n",
      "Epoch [8/200], Step [681/1067], D_A_loss: 0.3023, D_B_loss: 0.1419, G_A_loss: 0.4410, G_B_loss: 0.7437\n",
      "Epoch [8/200], Step [691/1067], D_A_loss: 0.0896, D_B_loss: 0.0526, G_A_loss: 0.6029, G_B_loss: 0.7414\n",
      "Epoch [8/200], Step [701/1067], D_A_loss: 0.2286, D_B_loss: 0.1005, G_A_loss: 0.5857, G_B_loss: 0.1797\n",
      "Epoch [8/200], Step [711/1067], D_A_loss: 0.1451, D_B_loss: 0.0643, G_A_loss: 0.8510, G_B_loss: 0.4778\n",
      "Epoch [8/200], Step [721/1067], D_A_loss: 0.2509, D_B_loss: 0.0281, G_A_loss: 0.7468, G_B_loss: 0.1364\n",
      "Epoch [8/200], Step [731/1067], D_A_loss: 0.1383, D_B_loss: 0.0562, G_A_loss: 0.3214, G_B_loss: 0.3590\n",
      "Epoch [8/200], Step [741/1067], D_A_loss: 0.1967, D_B_loss: 0.1256, G_A_loss: 0.4731, G_B_loss: 1.1913\n",
      "Epoch [8/200], Step [751/1067], D_A_loss: 0.0896, D_B_loss: 0.0825, G_A_loss: 1.4265, G_B_loss: 0.2576\n",
      "Epoch [8/200], Step [761/1067], D_A_loss: 0.1279, D_B_loss: 0.0166, G_A_loss: 0.4180, G_B_loss: 0.6319\n",
      "Epoch [8/200], Step [771/1067], D_A_loss: 0.4571, D_B_loss: 0.0705, G_A_loss: 0.8790, G_B_loss: 0.0474\n",
      "Epoch [8/200], Step [781/1067], D_A_loss: 0.1221, D_B_loss: 0.0483, G_A_loss: 0.2978, G_B_loss: 0.7344\n",
      "Epoch [8/200], Step [791/1067], D_A_loss: 0.1218, D_B_loss: 0.1580, G_A_loss: 0.3117, G_B_loss: 0.8198\n",
      "Epoch [8/200], Step [801/1067], D_A_loss: 0.1819, D_B_loss: 0.0920, G_A_loss: 0.5672, G_B_loss: 0.3336\n",
      "Epoch [8/200], Step [811/1067], D_A_loss: 0.1328, D_B_loss: 0.2078, G_A_loss: 0.8768, G_B_loss: 0.6569\n",
      "Epoch [8/200], Step [821/1067], D_A_loss: 0.0145, D_B_loss: 0.1711, G_A_loss: 0.7953, G_B_loss: 0.6339\n",
      "Epoch [8/200], Step [831/1067], D_A_loss: 0.1807, D_B_loss: 0.0398, G_A_loss: 0.4811, G_B_loss: 0.4486\n",
      "Epoch [8/200], Step [841/1067], D_A_loss: 0.3725, D_B_loss: 0.1444, G_A_loss: 0.2091, G_B_loss: 0.2011\n",
      "Epoch [8/200], Step [851/1067], D_A_loss: 0.0366, D_B_loss: 0.2856, G_A_loss: 0.9010, G_B_loss: 0.6563\n",
      "Epoch [8/200], Step [861/1067], D_A_loss: 0.1827, D_B_loss: 0.0747, G_A_loss: 0.4412, G_B_loss: 0.7133\n",
      "Epoch [8/200], Step [871/1067], D_A_loss: 0.1192, D_B_loss: 0.0385, G_A_loss: 0.7352, G_B_loss: 0.1247\n",
      "Epoch [8/200], Step [881/1067], D_A_loss: 0.1885, D_B_loss: 0.1327, G_A_loss: 0.8796, G_B_loss: 0.2138\n",
      "Epoch [8/200], Step [891/1067], D_A_loss: 0.0805, D_B_loss: 0.2722, G_A_loss: 0.8984, G_B_loss: 0.8494\n",
      "Epoch [8/200], Step [901/1067], D_A_loss: 0.0984, D_B_loss: 0.1226, G_A_loss: 0.9662, G_B_loss: 0.3800\n",
      "Epoch [8/200], Step [911/1067], D_A_loss: 0.2235, D_B_loss: 0.1844, G_A_loss: 0.2051, G_B_loss: 0.3879\n",
      "Epoch [8/200], Step [921/1067], D_A_loss: 0.1932, D_B_loss: 0.0606, G_A_loss: 0.6052, G_B_loss: 0.3618\n",
      "Epoch [8/200], Step [931/1067], D_A_loss: 0.0795, D_B_loss: 0.1092, G_A_loss: 0.3575, G_B_loss: 0.4038\n",
      "Epoch [8/200], Step [941/1067], D_A_loss: 0.0210, D_B_loss: 0.0653, G_A_loss: 0.8225, G_B_loss: 1.0168\n",
      "Epoch [8/200], Step [951/1067], D_A_loss: 0.0814, D_B_loss: 0.0460, G_A_loss: 0.2381, G_B_loss: 0.4846\n",
      "Epoch [8/200], Step [961/1067], D_A_loss: 0.0880, D_B_loss: 0.2569, G_A_loss: 0.3670, G_B_loss: 0.4531\n",
      "Epoch [8/200], Step [971/1067], D_A_loss: 0.2740, D_B_loss: 0.0797, G_A_loss: 0.6959, G_B_loss: 0.3574\n",
      "Epoch [8/200], Step [981/1067], D_A_loss: 0.1501, D_B_loss: 0.2509, G_A_loss: 0.1536, G_B_loss: 0.4034\n",
      "Epoch [8/200], Step [991/1067], D_A_loss: 0.1744, D_B_loss: 0.2588, G_A_loss: 1.2525, G_B_loss: 0.4008\n",
      "Epoch [8/200], Step [1001/1067], D_A_loss: 0.0996, D_B_loss: 0.0689, G_A_loss: 0.7213, G_B_loss: 1.1084\n",
      "Epoch [8/200], Step [1011/1067], D_A_loss: 0.1510, D_B_loss: 0.2622, G_A_loss: 0.4974, G_B_loss: 0.3612\n",
      "Epoch [8/200], Step [1021/1067], D_A_loss: 0.2865, D_B_loss: 0.1515, G_A_loss: 0.8036, G_B_loss: 0.1983\n",
      "Epoch [8/200], Step [1031/1067], D_A_loss: 0.3294, D_B_loss: 0.1103, G_A_loss: 0.3782, G_B_loss: 0.2827\n",
      "Epoch [8/200], Step [1041/1067], D_A_loss: 0.2716, D_B_loss: 0.0517, G_A_loss: 0.6443, G_B_loss: 0.5876\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/200], Step [1051/1067], D_A_loss: 0.1256, D_B_loss: 0.1308, G_A_loss: 0.3162, G_B_loss: 0.3129\n",
      "Epoch [8/200], Step [1061/1067], D_A_loss: 0.2486, D_B_loss: 0.0230, G_A_loss: 0.0554, G_B_loss: 0.2637\n",
      "Epoch [9/200], Step [1/1067], D_A_loss: 0.2342, D_B_loss: 0.3149, G_A_loss: 0.9524, G_B_loss: 0.1529\n",
      "Epoch [9/200], Step [11/1067], D_A_loss: 0.3255, D_B_loss: 0.0948, G_A_loss: 0.4783, G_B_loss: 0.1117\n",
      "Epoch [9/200], Step [21/1067], D_A_loss: 0.1282, D_B_loss: 0.1647, G_A_loss: 0.2438, G_B_loss: 0.3413\n",
      "Epoch [9/200], Step [31/1067], D_A_loss: 0.1992, D_B_loss: 0.0717, G_A_loss: 0.6251, G_B_loss: 0.2046\n",
      "Epoch [9/200], Step [41/1067], D_A_loss: 0.1045, D_B_loss: 0.0792, G_A_loss: 0.4885, G_B_loss: 0.3782\n",
      "Epoch [9/200], Step [51/1067], D_A_loss: 0.1032, D_B_loss: 0.1820, G_A_loss: 0.2559, G_B_loss: 0.8265\n",
      "Epoch [9/200], Step [61/1067], D_A_loss: 0.1572, D_B_loss: 0.0672, G_A_loss: 0.6413, G_B_loss: 0.5309\n",
      "Epoch [9/200], Step [71/1067], D_A_loss: 0.2328, D_B_loss: 0.2158, G_A_loss: 0.3854, G_B_loss: 0.1795\n",
      "Epoch [9/200], Step [81/1067], D_A_loss: 0.1091, D_B_loss: 0.0670, G_A_loss: 1.0188, G_B_loss: 0.4606\n",
      "Epoch [9/200], Step [91/1067], D_A_loss: 0.2148, D_B_loss: 0.1281, G_A_loss: 0.2218, G_B_loss: 1.0544\n",
      "Epoch [9/200], Step [101/1067], D_A_loss: 0.1430, D_B_loss: 0.0128, G_A_loss: 0.5404, G_B_loss: 0.3484\n",
      "Epoch [9/200], Step [111/1067], D_A_loss: 0.1476, D_B_loss: 0.2687, G_A_loss: 0.1488, G_B_loss: 0.2734\n",
      "Epoch [9/200], Step [121/1067], D_A_loss: 0.0415, D_B_loss: 0.0568, G_A_loss: 0.4424, G_B_loss: 0.4956\n",
      "Epoch [9/200], Step [131/1067], D_A_loss: 0.1289, D_B_loss: 0.1675, G_A_loss: 0.2214, G_B_loss: 0.2990\n",
      "Epoch [9/200], Step [141/1067], D_A_loss: 0.0404, D_B_loss: 0.0754, G_A_loss: 0.2192, G_B_loss: 0.6862\n",
      "Epoch [9/200], Step [151/1067], D_A_loss: 0.2510, D_B_loss: 0.0983, G_A_loss: 0.3878, G_B_loss: 0.5691\n",
      "Epoch [9/200], Step [161/1067], D_A_loss: 0.0500, D_B_loss: 0.1616, G_A_loss: 0.4251, G_B_loss: 0.7177\n",
      "Epoch [9/200], Step [171/1067], D_A_loss: 0.1309, D_B_loss: 0.0850, G_A_loss: 0.5180, G_B_loss: 0.3917\n",
      "Epoch [9/200], Step [181/1067], D_A_loss: 0.1469, D_B_loss: 0.0647, G_A_loss: 0.5058, G_B_loss: 0.3460\n",
      "Epoch [9/200], Step [191/1067], D_A_loss: 0.0993, D_B_loss: 0.2103, G_A_loss: 0.5514, G_B_loss: 0.2017\n",
      "Epoch [9/200], Step [201/1067], D_A_loss: 0.1511, D_B_loss: 0.1319, G_A_loss: 0.9880, G_B_loss: 0.9017\n",
      "Epoch [9/200], Step [211/1067], D_A_loss: 0.2064, D_B_loss: 0.1942, G_A_loss: 0.8999, G_B_loss: 0.4403\n",
      "Epoch [9/200], Step [221/1067], D_A_loss: 0.0555, D_B_loss: 0.1215, G_A_loss: 0.4859, G_B_loss: 0.5547\n",
      "Epoch [9/200], Step [231/1067], D_A_loss: 0.0370, D_B_loss: 0.1561, G_A_loss: 0.3994, G_B_loss: 0.2664\n",
      "Epoch [9/200], Step [241/1067], D_A_loss: 0.1952, D_B_loss: 0.1464, G_A_loss: 0.3588, G_B_loss: 0.5382\n",
      "Epoch [9/200], Step [251/1067], D_A_loss: 0.1686, D_B_loss: 0.0646, G_A_loss: 0.3763, G_B_loss: 0.4415\n",
      "Epoch [9/200], Step [261/1067], D_A_loss: 0.1285, D_B_loss: 0.0637, G_A_loss: 0.5296, G_B_loss: 0.4796\n",
      "Epoch [9/200], Step [271/1067], D_A_loss: 0.1901, D_B_loss: 0.0745, G_A_loss: 0.5993, G_B_loss: 0.1988\n",
      "Epoch [9/200], Step [281/1067], D_A_loss: 0.1378, D_B_loss: 0.0687, G_A_loss: 0.6996, G_B_loss: 0.4080\n",
      "Epoch [9/200], Step [291/1067], D_A_loss: 0.0474, D_B_loss: 0.0772, G_A_loss: 1.0947, G_B_loss: 0.5667\n",
      "Epoch [9/200], Step [301/1067], D_A_loss: 0.2107, D_B_loss: 0.0646, G_A_loss: 1.1381, G_B_loss: 0.2627\n",
      "Epoch [9/200], Step [311/1067], D_A_loss: 0.0235, D_B_loss: 0.0965, G_A_loss: 0.5677, G_B_loss: 0.9071\n",
      "Epoch [9/200], Step [321/1067], D_A_loss: 0.1540, D_B_loss: 0.2574, G_A_loss: 0.2012, G_B_loss: 0.4390\n",
      "Epoch [9/200], Step [331/1067], D_A_loss: 0.0580, D_B_loss: 0.0932, G_A_loss: 0.7145, G_B_loss: 0.3247\n",
      "Epoch [9/200], Step [341/1067], D_A_loss: 0.1366, D_B_loss: 0.0689, G_A_loss: 1.1999, G_B_loss: 0.5266\n",
      "Epoch [9/200], Step [351/1067], D_A_loss: 0.1705, D_B_loss: 0.0424, G_A_loss: 0.2407, G_B_loss: 0.5773\n",
      "Epoch [9/200], Step [361/1067], D_A_loss: 0.2250, D_B_loss: 0.1232, G_A_loss: 0.3726, G_B_loss: 0.4133\n",
      "Epoch [9/200], Step [371/1067], D_A_loss: 0.2857, D_B_loss: 0.1995, G_A_loss: 0.3999, G_B_loss: 0.3822\n",
      "Epoch [9/200], Step [381/1067], D_A_loss: 0.0907, D_B_loss: 0.0327, G_A_loss: 1.0259, G_B_loss: 0.4700\n",
      "Epoch [9/200], Step [391/1067], D_A_loss: 0.1529, D_B_loss: 0.0625, G_A_loss: 0.4074, G_B_loss: 0.6398\n",
      "Epoch [9/200], Step [401/1067], D_A_loss: 0.1242, D_B_loss: 0.0767, G_A_loss: 0.5061, G_B_loss: 0.1605\n",
      "Epoch [9/200], Step [411/1067], D_A_loss: 0.2379, D_B_loss: 0.1401, G_A_loss: 0.5400, G_B_loss: 0.1322\n",
      "Epoch [9/200], Step [421/1067], D_A_loss: 0.2561, D_B_loss: 0.1834, G_A_loss: 0.2695, G_B_loss: 1.0405\n",
      "Epoch [9/200], Step [431/1067], D_A_loss: 0.3138, D_B_loss: 0.1732, G_A_loss: 0.1429, G_B_loss: 0.9185\n",
      "Epoch [9/200], Step [441/1067], D_A_loss: 0.3349, D_B_loss: 0.0335, G_A_loss: 0.1860, G_B_loss: 0.4979\n",
      "Epoch [9/200], Step [451/1067], D_A_loss: 0.2356, D_B_loss: 0.1504, G_A_loss: 0.4057, G_B_loss: 0.9010\n",
      "Epoch [9/200], Step [461/1067], D_A_loss: 0.1993, D_B_loss: 0.1430, G_A_loss: 0.4218, G_B_loss: 0.6151\n",
      "Epoch [9/200], Step [471/1067], D_A_loss: 0.1989, D_B_loss: 0.1339, G_A_loss: 0.2835, G_B_loss: 0.3251\n",
      "Epoch [9/200], Step [481/1067], D_A_loss: 0.0789, D_B_loss: 0.1071, G_A_loss: 0.5304, G_B_loss: 0.0981\n",
      "Epoch [9/200], Step [491/1067], D_A_loss: 0.1063, D_B_loss: 0.0246, G_A_loss: 0.3611, G_B_loss: 0.4362\n",
      "Epoch [9/200], Step [501/1067], D_A_loss: 0.0855, D_B_loss: 0.0905, G_A_loss: 0.3648, G_B_loss: 0.3094\n",
      "Epoch [9/200], Step [511/1067], D_A_loss: 0.1690, D_B_loss: 0.1556, G_A_loss: 0.2802, G_B_loss: 0.7930\n",
      "Epoch [9/200], Step [521/1067], D_A_loss: 0.1121, D_B_loss: 0.0388, G_A_loss: 0.5247, G_B_loss: 0.3061\n",
      "Epoch [9/200], Step [531/1067], D_A_loss: 0.2030, D_B_loss: 0.3579, G_A_loss: 0.2187, G_B_loss: 0.5682\n",
      "Epoch [9/200], Step [541/1067], D_A_loss: 0.1401, D_B_loss: 0.1308, G_A_loss: 0.8333, G_B_loss: 0.2559\n",
      "Epoch [9/200], Step [551/1067], D_A_loss: 0.2408, D_B_loss: 0.2042, G_A_loss: 0.2408, G_B_loss: 0.4419\n",
      "Epoch [9/200], Step [561/1067], D_A_loss: 0.0872, D_B_loss: 0.0301, G_A_loss: 0.7891, G_B_loss: 0.4509\n",
      "Epoch [9/200], Step [571/1067], D_A_loss: 0.1170, D_B_loss: 0.0743, G_A_loss: 0.8003, G_B_loss: 0.3139\n",
      "Epoch [9/200], Step [581/1067], D_A_loss: 0.0813, D_B_loss: 0.0949, G_A_loss: 1.2610, G_B_loss: 0.6048\n",
      "Epoch [9/200], Step [591/1067], D_A_loss: 0.0690, D_B_loss: 0.0405, G_A_loss: 0.6627, G_B_loss: 0.4797\n",
      "Epoch [9/200], Step [601/1067], D_A_loss: 0.2184, D_B_loss: 0.0301, G_A_loss: 0.0653, G_B_loss: 0.4728\n",
      "Epoch [9/200], Step [611/1067], D_A_loss: 0.0851, D_B_loss: 0.1858, G_A_loss: 0.7336, G_B_loss: 0.2415\n",
      "Epoch [9/200], Step [621/1067], D_A_loss: 0.0520, D_B_loss: 0.1047, G_A_loss: 0.3361, G_B_loss: 0.6547\n",
      "Epoch [9/200], Step [631/1067], D_A_loss: 0.1796, D_B_loss: 0.1003, G_A_loss: 0.7092, G_B_loss: 0.7430\n",
      "Epoch [9/200], Step [641/1067], D_A_loss: 0.1192, D_B_loss: 0.0499, G_A_loss: 0.3445, G_B_loss: 0.3064\n",
      "Epoch [9/200], Step [651/1067], D_A_loss: 0.0748, D_B_loss: 0.0465, G_A_loss: 0.7793, G_B_loss: 0.3211\n",
      "Epoch [9/200], Step [661/1067], D_A_loss: 0.1735, D_B_loss: 0.0972, G_A_loss: 0.9994, G_B_loss: 0.2014\n",
      "Epoch [9/200], Step [671/1067], D_A_loss: 0.2576, D_B_loss: 0.0589, G_A_loss: 0.5412, G_B_loss: 0.1331\n",
      "Epoch [9/200], Step [681/1067], D_A_loss: 0.0720, D_B_loss: 0.1393, G_A_loss: 0.7369, G_B_loss: 0.5222\n",
      "Epoch [9/200], Step [691/1067], D_A_loss: 0.1046, D_B_loss: 0.0996, G_A_loss: 0.3396, G_B_loss: 0.4345\n",
      "Epoch [9/200], Step [701/1067], D_A_loss: 0.5434, D_B_loss: 0.1211, G_A_loss: 0.4817, G_B_loss: 0.0301\n",
      "Epoch [9/200], Step [711/1067], D_A_loss: 0.2222, D_B_loss: 0.1088, G_A_loss: 0.3259, G_B_loss: 0.2470\n",
      "Epoch [9/200], Step [721/1067], D_A_loss: 0.2369, D_B_loss: 0.1460, G_A_loss: 0.2729, G_B_loss: 0.4418\n",
      "Epoch [9/200], Step [731/1067], D_A_loss: 0.1705, D_B_loss: 0.1816, G_A_loss: 0.1681, G_B_loss: 0.3545\n",
      "Epoch [9/200], Step [741/1067], D_A_loss: 0.1509, D_B_loss: 0.1251, G_A_loss: 0.3377, G_B_loss: 0.4752\n",
      "Epoch [9/200], Step [751/1067], D_A_loss: 0.0681, D_B_loss: 0.1005, G_A_loss: 0.4911, G_B_loss: 0.5088\n",
      "Epoch [9/200], Step [761/1067], D_A_loss: 0.2744, D_B_loss: 0.0392, G_A_loss: 0.9094, G_B_loss: 0.3372\n",
      "Epoch [9/200], Step [771/1067], D_A_loss: 0.1888, D_B_loss: 0.0428, G_A_loss: 0.4568, G_B_loss: 0.4005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/200], Step [781/1067], D_A_loss: 0.1734, D_B_loss: 0.1060, G_A_loss: 0.1059, G_B_loss: 0.2940\n",
      "Epoch [9/200], Step [791/1067], D_A_loss: 0.0802, D_B_loss: 0.0752, G_A_loss: 0.4345, G_B_loss: 0.7322\n",
      "Epoch [9/200], Step [801/1067], D_A_loss: 0.0372, D_B_loss: 0.1104, G_A_loss: 0.5539, G_B_loss: 0.1718\n",
      "Epoch [9/200], Step [811/1067], D_A_loss: 0.3303, D_B_loss: 0.0638, G_A_loss: 0.5669, G_B_loss: 0.4117\n",
      "Epoch [9/200], Step [821/1067], D_A_loss: 0.0396, D_B_loss: 0.1337, G_A_loss: 0.2862, G_B_loss: 0.4075\n",
      "Epoch [9/200], Step [831/1067], D_A_loss: 0.1327, D_B_loss: 0.0661, G_A_loss: 0.4978, G_B_loss: 0.4391\n",
      "Epoch [9/200], Step [841/1067], D_A_loss: 0.1603, D_B_loss: 0.0890, G_A_loss: 0.4176, G_B_loss: 0.5697\n",
      "Epoch [9/200], Step [851/1067], D_A_loss: 0.1881, D_B_loss: 0.0758, G_A_loss: 0.5932, G_B_loss: 0.4475\n",
      "Epoch [9/200], Step [861/1067], D_A_loss: 0.1540, D_B_loss: 0.1735, G_A_loss: 0.2340, G_B_loss: 0.4760\n",
      "Epoch [9/200], Step [871/1067], D_A_loss: 0.2926, D_B_loss: 0.0418, G_A_loss: 0.3971, G_B_loss: 0.4923\n",
      "Epoch [9/200], Step [881/1067], D_A_loss: 0.1729, D_B_loss: 0.0826, G_A_loss: 0.7257, G_B_loss: 0.5106\n",
      "Epoch [9/200], Step [891/1067], D_A_loss: 0.1175, D_B_loss: 0.1350, G_A_loss: 0.2580, G_B_loss: 0.5344\n",
      "Epoch [9/200], Step [901/1067], D_A_loss: 0.1793, D_B_loss: 0.0315, G_A_loss: 0.6559, G_B_loss: 0.2841\n",
      "Epoch [9/200], Step [911/1067], D_A_loss: 0.1262, D_B_loss: 0.1318, G_A_loss: 0.6770, G_B_loss: 0.2929\n",
      "Epoch [9/200], Step [921/1067], D_A_loss: 0.0181, D_B_loss: 0.0758, G_A_loss: 0.2051, G_B_loss: 0.2736\n",
      "Epoch [9/200], Step [931/1067], D_A_loss: 0.0445, D_B_loss: 0.1334, G_A_loss: 0.2761, G_B_loss: 0.9505\n",
      "Epoch [9/200], Step [941/1067], D_A_loss: 0.1321, D_B_loss: 0.0317, G_A_loss: 0.6127, G_B_loss: 0.4151\n",
      "Epoch [9/200], Step [951/1067], D_A_loss: 0.1771, D_B_loss: 0.0466, G_A_loss: 0.6583, G_B_loss: 0.3931\n",
      "Epoch [9/200], Step [961/1067], D_A_loss: 0.1729, D_B_loss: 0.0561, G_A_loss: 0.5431, G_B_loss: 0.0869\n",
      "Epoch [9/200], Step [971/1067], D_A_loss: 0.1269, D_B_loss: 0.0636, G_A_loss: 0.9934, G_B_loss: 0.3275\n",
      "Epoch [9/200], Step [981/1067], D_A_loss: 0.1302, D_B_loss: 0.0156, G_A_loss: 0.5143, G_B_loss: 0.8711\n",
      "Epoch [9/200], Step [991/1067], D_A_loss: 0.1273, D_B_loss: 0.1402, G_A_loss: 1.0122, G_B_loss: 0.2961\n",
      "Epoch [9/200], Step [1001/1067], D_A_loss: 0.0561, D_B_loss: 0.0975, G_A_loss: 0.4905, G_B_loss: 0.6570\n",
      "Epoch [9/200], Step [1011/1067], D_A_loss: 0.1257, D_B_loss: 0.0922, G_A_loss: 0.6185, G_B_loss: 0.1301\n",
      "Epoch [9/200], Step [1021/1067], D_A_loss: 0.5046, D_B_loss: 0.1607, G_A_loss: 0.5318, G_B_loss: 0.8407\n",
      "Epoch [9/200], Step [1031/1067], D_A_loss: 0.0784, D_B_loss: 0.0574, G_A_loss: 0.2843, G_B_loss: 0.4822\n",
      "Epoch [9/200], Step [1041/1067], D_A_loss: 0.0426, D_B_loss: 0.0925, G_A_loss: 0.1396, G_B_loss: 0.6541\n",
      "Epoch [9/200], Step [1051/1067], D_A_loss: 0.0792, D_B_loss: 0.1684, G_A_loss: 0.2340, G_B_loss: 0.2563\n",
      "Epoch [9/200], Step [1061/1067], D_A_loss: 0.2334, D_B_loss: 0.0342, G_A_loss: 0.5256, G_B_loss: 0.9635\n",
      "Epoch [10/200], Step [1/1067], D_A_loss: 0.0941, D_B_loss: 0.1389, G_A_loss: 0.2873, G_B_loss: 0.3831\n",
      "Epoch [10/200], Step [11/1067], D_A_loss: 0.0684, D_B_loss: 0.0454, G_A_loss: 0.7491, G_B_loss: 0.5314\n",
      "Epoch [10/200], Step [21/1067], D_A_loss: 0.0974, D_B_loss: 0.4171, G_A_loss: 0.0773, G_B_loss: 0.7072\n",
      "Epoch [10/200], Step [31/1067], D_A_loss: 0.0930, D_B_loss: 0.0432, G_A_loss: 1.0226, G_B_loss: 0.4963\n",
      "Epoch [10/200], Step [41/1067], D_A_loss: 0.1103, D_B_loss: 0.0596, G_A_loss: 0.2642, G_B_loss: 0.5141\n",
      "Epoch [10/200], Step [51/1067], D_A_loss: 0.1473, D_B_loss: 0.0264, G_A_loss: 0.7918, G_B_loss: 0.8017\n",
      "Epoch [10/200], Step [61/1067], D_A_loss: 0.0275, D_B_loss: 0.0477, G_A_loss: 0.1956, G_B_loss: 0.4394\n",
      "Epoch [10/200], Step [71/1067], D_A_loss: 0.1960, D_B_loss: 0.0876, G_A_loss: 0.5174, G_B_loss: 0.5240\n",
      "Epoch [10/200], Step [81/1067], D_A_loss: 0.0421, D_B_loss: 0.2254, G_A_loss: 0.3482, G_B_loss: 0.9208\n",
      "Epoch [10/200], Step [91/1067], D_A_loss: 0.1252, D_B_loss: 0.0242, G_A_loss: 0.3495, G_B_loss: 0.1557\n",
      "Epoch [10/200], Step [101/1067], D_A_loss: 0.2926, D_B_loss: 0.0554, G_A_loss: 0.8293, G_B_loss: 0.8834\n",
      "Epoch [10/200], Step [111/1067], D_A_loss: 0.2857, D_B_loss: 0.0573, G_A_loss: 1.0129, G_B_loss: 0.2289\n",
      "Epoch [10/200], Step [121/1067], D_A_loss: 0.1099, D_B_loss: 0.0516, G_A_loss: 0.2928, G_B_loss: 0.3302\n",
      "Epoch [10/200], Step [131/1067], D_A_loss: 0.0752, D_B_loss: 0.0283, G_A_loss: 0.6264, G_B_loss: 0.5283\n",
      "Epoch [10/200], Step [141/1067], D_A_loss: 0.0675, D_B_loss: 0.1707, G_A_loss: 0.1383, G_B_loss: 0.8829\n",
      "Epoch [10/200], Step [151/1067], D_A_loss: 0.2578, D_B_loss: 0.0469, G_A_loss: 0.7568, G_B_loss: 0.3053\n",
      "Epoch [10/200], Step [161/1067], D_A_loss: 0.0626, D_B_loss: 0.1197, G_A_loss: 0.3105, G_B_loss: 0.2509\n",
      "Epoch [10/200], Step [171/1067], D_A_loss: 0.0200, D_B_loss: 0.1297, G_A_loss: 0.5391, G_B_loss: 0.2580\n",
      "Epoch [10/200], Step [181/1067], D_A_loss: 0.1833, D_B_loss: 0.0466, G_A_loss: 0.2604, G_B_loss: 0.4834\n",
      "Epoch [10/200], Step [191/1067], D_A_loss: 0.1651, D_B_loss: 0.1155, G_A_loss: 0.6603, G_B_loss: 0.2615\n",
      "Epoch [10/200], Step [201/1067], D_A_loss: 0.1382, D_B_loss: 0.0708, G_A_loss: 0.9228, G_B_loss: 0.8920\n",
      "Epoch [10/200], Step [211/1067], D_A_loss: 0.1135, D_B_loss: 0.1238, G_A_loss: 0.3329, G_B_loss: 0.3605\n",
      "Epoch [10/200], Step [221/1067], D_A_loss: 0.0556, D_B_loss: 0.1579, G_A_loss: 0.5887, G_B_loss: 0.5004\n",
      "Epoch [10/200], Step [231/1067], D_A_loss: 0.0793, D_B_loss: 0.1571, G_A_loss: 0.3986, G_B_loss: 0.4450\n",
      "Epoch [10/200], Step [241/1067], D_A_loss: 0.1444, D_B_loss: 0.1691, G_A_loss: 0.4960, G_B_loss: 0.1654\n",
      "Epoch [10/200], Step [251/1067], D_A_loss: 0.0545, D_B_loss: 0.0733, G_A_loss: 0.3788, G_B_loss: 0.5597\n",
      "Epoch [10/200], Step [261/1067], D_A_loss: 0.1202, D_B_loss: 0.0398, G_A_loss: 0.8021, G_B_loss: 0.4221\n",
      "Epoch [10/200], Step [271/1067], D_A_loss: 0.1261, D_B_loss: 0.0273, G_A_loss: 0.5684, G_B_loss: 0.3783\n",
      "Epoch [10/200], Step [281/1067], D_A_loss: 0.1387, D_B_loss: 0.3167, G_A_loss: 0.9899, G_B_loss: 0.1785\n",
      "Epoch [10/200], Step [291/1067], D_A_loss: 0.0812, D_B_loss: 0.0902, G_A_loss: 0.5993, G_B_loss: 0.7688\n",
      "Epoch [10/200], Step [301/1067], D_A_loss: 0.3040, D_B_loss: 0.2726, G_A_loss: 0.2749, G_B_loss: 0.5493\n",
      "Epoch [10/200], Step [311/1067], D_A_loss: 0.0212, D_B_loss: 0.1271, G_A_loss: 0.3066, G_B_loss: 0.5861\n",
      "Epoch [10/200], Step [321/1067], D_A_loss: 0.1048, D_B_loss: 0.0813, G_A_loss: 0.4403, G_B_loss: 0.9225\n",
      "Epoch [10/200], Step [331/1067], D_A_loss: 0.0493, D_B_loss: 0.0365, G_A_loss: 0.3609, G_B_loss: 0.5724\n",
      "Epoch [10/200], Step [341/1067], D_A_loss: 0.3222, D_B_loss: 0.0999, G_A_loss: 0.3940, G_B_loss: 0.0814\n",
      "Epoch [10/200], Step [351/1067], D_A_loss: 0.0478, D_B_loss: 0.1105, G_A_loss: 0.3432, G_B_loss: 0.3300\n",
      "Epoch [10/200], Step [361/1067], D_A_loss: 0.0835, D_B_loss: 0.0723, G_A_loss: 0.8847, G_B_loss: 0.3314\n",
      "Epoch [10/200], Step [371/1067], D_A_loss: 0.1392, D_B_loss: 0.0619, G_A_loss: 0.9904, G_B_loss: 0.3037\n",
      "Epoch [10/200], Step [381/1067], D_A_loss: 0.2383, D_B_loss: 0.0610, G_A_loss: 0.4117, G_B_loss: 0.5749\n",
      "Epoch [10/200], Step [391/1067], D_A_loss: 0.0848, D_B_loss: 0.2323, G_A_loss: 0.1932, G_B_loss: 0.4200\n",
      "Epoch [10/200], Step [401/1067], D_A_loss: 0.3251, D_B_loss: 0.1361, G_A_loss: 0.2976, G_B_loss: 0.4589\n",
      "Epoch [10/200], Step [411/1067], D_A_loss: 0.0383, D_B_loss: 0.0691, G_A_loss: 0.7407, G_B_loss: 0.6701\n",
      "Epoch [10/200], Step [421/1067], D_A_loss: 0.1438, D_B_loss: 0.1095, G_A_loss: 0.7436, G_B_loss: 0.4395\n",
      "Epoch [10/200], Step [431/1067], D_A_loss: 0.0940, D_B_loss: 0.0595, G_A_loss: 0.1487, G_B_loss: 0.1485\n",
      "Epoch [10/200], Step [441/1067], D_A_loss: 0.0309, D_B_loss: 0.0657, G_A_loss: 1.4524, G_B_loss: 0.3567\n",
      "Epoch [10/200], Step [451/1067], D_A_loss: 0.0832, D_B_loss: 0.3432, G_A_loss: 0.7034, G_B_loss: 0.0595\n",
      "Epoch [10/200], Step [461/1067], D_A_loss: 0.0573, D_B_loss: 0.2699, G_A_loss: 0.4486, G_B_loss: 0.1643\n",
      "Epoch [10/200], Step [471/1067], D_A_loss: 0.2148, D_B_loss: 0.0924, G_A_loss: 0.4357, G_B_loss: 0.3616\n",
      "Epoch [10/200], Step [481/1067], D_A_loss: 0.1043, D_B_loss: 0.0274, G_A_loss: 0.6170, G_B_loss: 0.8621\n",
      "Epoch [10/200], Step [491/1067], D_A_loss: 0.4391, D_B_loss: 0.3541, G_A_loss: 0.0759, G_B_loss: 0.0897\n",
      "Epoch [10/200], Step [501/1067], D_A_loss: 0.0828, D_B_loss: 0.0801, G_A_loss: 0.5123, G_B_loss: 0.4636\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/200], Step [511/1067], D_A_loss: 0.0893, D_B_loss: 0.1105, G_A_loss: 0.3775, G_B_loss: 0.4739\n",
      "Epoch [10/200], Step [521/1067], D_A_loss: 0.1078, D_B_loss: 0.0682, G_A_loss: 1.0210, G_B_loss: 0.5780\n",
      "Epoch [10/200], Step [531/1067], D_A_loss: 0.3482, D_B_loss: 0.0215, G_A_loss: 0.5225, G_B_loss: 0.2264\n",
      "Epoch [10/200], Step [541/1067], D_A_loss: 0.0805, D_B_loss: 0.1819, G_A_loss: 0.1894, G_B_loss: 0.6261\n",
      "Epoch [10/200], Step [551/1067], D_A_loss: 0.2456, D_B_loss: 0.0692, G_A_loss: 0.7260, G_B_loss: 0.2443\n",
      "Epoch [10/200], Step [561/1067], D_A_loss: 0.0397, D_B_loss: 0.0410, G_A_loss: 0.5020, G_B_loss: 0.7759\n",
      "Epoch [10/200], Step [571/1067], D_A_loss: 0.3967, D_B_loss: 0.0743, G_A_loss: 0.6330, G_B_loss: 0.1624\n",
      "Epoch [10/200], Step [581/1067], D_A_loss: 0.3232, D_B_loss: 0.0466, G_A_loss: 0.3825, G_B_loss: 0.3932\n",
      "Epoch [10/200], Step [591/1067], D_A_loss: 0.2479, D_B_loss: 0.0261, G_A_loss: 0.3324, G_B_loss: 0.7701\n",
      "Epoch [10/200], Step [601/1067], D_A_loss: 0.1178, D_B_loss: 0.1745, G_A_loss: 0.8288, G_B_loss: 0.3526\n",
      "Epoch [10/200], Step [611/1067], D_A_loss: 0.0894, D_B_loss: 0.2582, G_A_loss: 0.5567, G_B_loss: 0.0339\n",
      "Epoch [10/200], Step [621/1067], D_A_loss: 0.1699, D_B_loss: 0.2000, G_A_loss: 0.5765, G_B_loss: 0.4445\n",
      "Epoch [10/200], Step [631/1067], D_A_loss: 0.0858, D_B_loss: 0.1431, G_A_loss: 0.2817, G_B_loss: 0.8659\n",
      "Epoch [10/200], Step [641/1067], D_A_loss: 0.1594, D_B_loss: 0.1190, G_A_loss: 0.5896, G_B_loss: 0.4646\n",
      "Epoch [10/200], Step [651/1067], D_A_loss: 0.0588, D_B_loss: 0.2187, G_A_loss: 0.7218, G_B_loss: 0.4158\n",
      "Epoch [10/200], Step [661/1067], D_A_loss: 0.0528, D_B_loss: 0.0354, G_A_loss: 0.4820, G_B_loss: 0.4742\n",
      "Epoch [10/200], Step [671/1067], D_A_loss: 0.2775, D_B_loss: 0.1447, G_A_loss: 0.2893, G_B_loss: 0.2056\n",
      "Epoch [10/200], Step [681/1067], D_A_loss: 0.2744, D_B_loss: 0.0286, G_A_loss: 0.2391, G_B_loss: 0.2723\n",
      "Epoch [10/200], Step [691/1067], D_A_loss: 0.1182, D_B_loss: 0.0330, G_A_loss: 0.6973, G_B_loss: 0.3986\n",
      "Epoch [10/200], Step [701/1067], D_A_loss: 0.0391, D_B_loss: 0.0635, G_A_loss: 0.6363, G_B_loss: 0.6557\n",
      "Epoch [10/200], Step [711/1067], D_A_loss: 0.1019, D_B_loss: 0.0343, G_A_loss: 0.3617, G_B_loss: 0.5423\n",
      "Epoch [10/200], Step [721/1067], D_A_loss: 0.0954, D_B_loss: 0.0514, G_A_loss: 0.5949, G_B_loss: 0.3772\n",
      "Epoch [10/200], Step [731/1067], D_A_loss: 0.0356, D_B_loss: 0.0796, G_A_loss: 0.9345, G_B_loss: 0.6638\n",
      "Epoch [10/200], Step [741/1067], D_A_loss: 0.1596, D_B_loss: 0.0718, G_A_loss: 0.5541, G_B_loss: 0.2429\n",
      "Epoch [10/200], Step [751/1067], D_A_loss: 0.1282, D_B_loss: 0.0592, G_A_loss: 0.4860, G_B_loss: 0.8327\n",
      "Epoch [10/200], Step [761/1067], D_A_loss: 0.0370, D_B_loss: 0.0138, G_A_loss: 0.6977, G_B_loss: 0.2461\n",
      "Epoch [10/200], Step [771/1067], D_A_loss: 0.0951, D_B_loss: 0.0903, G_A_loss: 0.3872, G_B_loss: 0.5548\n",
      "Epoch [10/200], Step [781/1067], D_A_loss: 0.0797, D_B_loss: 0.0546, G_A_loss: 0.7743, G_B_loss: 0.4792\n",
      "Epoch [10/200], Step [791/1067], D_A_loss: 0.0821, D_B_loss: 0.0625, G_A_loss: 0.7723, G_B_loss: 0.4714\n",
      "Epoch [10/200], Step [801/1067], D_A_loss: 0.1199, D_B_loss: 0.2902, G_A_loss: 0.1853, G_B_loss: 1.2802\n",
      "Epoch [10/200], Step [811/1067], D_A_loss: 0.0456, D_B_loss: 0.0831, G_A_loss: 0.8042, G_B_loss: 0.6347\n",
      "Epoch [10/200], Step [821/1067], D_A_loss: 0.1991, D_B_loss: 0.0710, G_A_loss: 0.5092, G_B_loss: 0.1077\n",
      "Epoch [10/200], Step [831/1067], D_A_loss: 0.2354, D_B_loss: 0.0618, G_A_loss: 0.7204, G_B_loss: 0.1741\n",
      "Epoch [10/200], Step [841/1067], D_A_loss: 0.1409, D_B_loss: 0.2164, G_A_loss: 0.2089, G_B_loss: 0.2741\n",
      "Epoch [10/200], Step [851/1067], D_A_loss: 0.2799, D_B_loss: 0.0612, G_A_loss: 0.6408, G_B_loss: 0.3884\n",
      "Epoch [10/200], Step [861/1067], D_A_loss: 0.0295, D_B_loss: 0.0941, G_A_loss: 0.8420, G_B_loss: 0.5477\n",
      "Epoch [10/200], Step [871/1067], D_A_loss: 0.1323, D_B_loss: 0.0728, G_A_loss: 0.9665, G_B_loss: 0.7387\n",
      "Epoch [10/200], Step [881/1067], D_A_loss: 0.1945, D_B_loss: 0.0278, G_A_loss: 0.6149, G_B_loss: 0.4153\n",
      "Epoch [10/200], Step [891/1067], D_A_loss: 0.3079, D_B_loss: 0.0713, G_A_loss: 0.4393, G_B_loss: 0.8278\n",
      "Epoch [10/200], Step [901/1067], D_A_loss: 0.0977, D_B_loss: 0.0111, G_A_loss: 0.2881, G_B_loss: 0.4908\n",
      "Epoch [10/200], Step [911/1067], D_A_loss: 0.1333, D_B_loss: 0.1130, G_A_loss: 0.6198, G_B_loss: 0.4007\n",
      "Epoch [10/200], Step [921/1067], D_A_loss: 0.0803, D_B_loss: 0.0213, G_A_loss: 0.8750, G_B_loss: 0.2475\n",
      "Epoch [10/200], Step [931/1067], D_A_loss: 0.0670, D_B_loss: 0.0579, G_A_loss: 0.4795, G_B_loss: 0.6099\n",
      "Epoch [10/200], Step [941/1067], D_A_loss: 0.1785, D_B_loss: 0.0361, G_A_loss: 0.6669, G_B_loss: 0.1807\n",
      "Epoch [10/200], Step [951/1067], D_A_loss: 0.1519, D_B_loss: 0.0823, G_A_loss: 0.6358, G_B_loss: 0.6518\n",
      "Epoch [10/200], Step [961/1067], D_A_loss: 0.1177, D_B_loss: 0.2588, G_A_loss: 0.1927, G_B_loss: 0.2954\n",
      "Epoch [10/200], Step [971/1067], D_A_loss: 0.0573, D_B_loss: 0.0806, G_A_loss: 0.2076, G_B_loss: 0.4411\n",
      "Epoch [10/200], Step [981/1067], D_A_loss: 0.1461, D_B_loss: 0.2894, G_A_loss: 0.5595, G_B_loss: 0.2834\n",
      "Epoch [10/200], Step [991/1067], D_A_loss: 0.2188, D_B_loss: 0.0934, G_A_loss: 0.5268, G_B_loss: 0.2147\n",
      "Epoch [10/200], Step [1001/1067], D_A_loss: 0.1885, D_B_loss: 0.1525, G_A_loss: 0.7683, G_B_loss: 0.4162\n",
      "Epoch [10/200], Step [1011/1067], D_A_loss: 0.1331, D_B_loss: 0.0263, G_A_loss: 0.7552, G_B_loss: 0.8942\n",
      "Epoch [10/200], Step [1021/1067], D_A_loss: 0.1299, D_B_loss: 0.1256, G_A_loss: 0.4805, G_B_loss: 0.3509\n",
      "Epoch [10/200], Step [1031/1067], D_A_loss: 0.1943, D_B_loss: 0.0936, G_A_loss: 0.7069, G_B_loss: 0.2218\n",
      "Epoch [10/200], Step [1041/1067], D_A_loss: 0.1979, D_B_loss: 0.0989, G_A_loss: 0.3942, G_B_loss: 0.4362\n",
      "Epoch [10/200], Step [1051/1067], D_A_loss: 0.3053, D_B_loss: 0.0449, G_A_loss: 0.6824, G_B_loss: 0.1008\n",
      "Epoch [10/200], Step [1061/1067], D_A_loss: 0.0208, D_B_loss: 0.0906, G_A_loss: 0.6138, G_B_loss: 0.2297\n",
      "Epoch [11/200], Step [1/1067], D_A_loss: 0.0558, D_B_loss: 0.0209, G_A_loss: 0.5274, G_B_loss: 0.5306\n",
      "Epoch [11/200], Step [11/1067], D_A_loss: 0.0696, D_B_loss: 0.1404, G_A_loss: 1.1613, G_B_loss: 0.2573\n",
      "Epoch [11/200], Step [21/1067], D_A_loss: 0.2073, D_B_loss: 0.1144, G_A_loss: 0.3159, G_B_loss: 0.2555\n",
      "Epoch [11/200], Step [31/1067], D_A_loss: 0.0703, D_B_loss: 0.1008, G_A_loss: 1.0535, G_B_loss: 0.4427\n",
      "Epoch [11/200], Step [41/1067], D_A_loss: 0.1536, D_B_loss: 0.2247, G_A_loss: 0.1641, G_B_loss: 0.5071\n",
      "Epoch [11/200], Step [51/1067], D_A_loss: 0.4524, D_B_loss: 0.0260, G_A_loss: 0.7231, G_B_loss: 0.0512\n",
      "Epoch [11/200], Step [61/1067], D_A_loss: 0.1624, D_B_loss: 0.0217, G_A_loss: 0.2442, G_B_loss: 0.2856\n",
      "Epoch [11/200], Step [71/1067], D_A_loss: 0.1518, D_B_loss: 0.0356, G_A_loss: 0.3027, G_B_loss: 0.6439\n",
      "Epoch [11/200], Step [81/1067], D_A_loss: 0.0281, D_B_loss: 0.0950, G_A_loss: 0.3807, G_B_loss: 0.9592\n",
      "Epoch [11/200], Step [91/1067], D_A_loss: 0.0308, D_B_loss: 0.1194, G_A_loss: 0.7615, G_B_loss: 0.8648\n",
      "Epoch [11/200], Step [101/1067], D_A_loss: 0.0791, D_B_loss: 0.0203, G_A_loss: 0.4053, G_B_loss: 0.6179\n",
      "Epoch [11/200], Step [111/1067], D_A_loss: 0.1588, D_B_loss: 0.1356, G_A_loss: 0.3269, G_B_loss: 0.4636\n",
      "Epoch [11/200], Step [121/1067], D_A_loss: 0.1476, D_B_loss: 0.0641, G_A_loss: 0.6692, G_B_loss: 0.4964\n",
      "Epoch [11/200], Step [131/1067], D_A_loss: 0.0516, D_B_loss: 0.0424, G_A_loss: 0.8985, G_B_loss: 0.5949\n",
      "Epoch [11/200], Step [141/1067], D_A_loss: 0.1614, D_B_loss: 0.1320, G_A_loss: 0.4886, G_B_loss: 0.3054\n",
      "Epoch [11/200], Step [151/1067], D_A_loss: 0.1751, D_B_loss: 0.2288, G_A_loss: 0.4062, G_B_loss: 0.6060\n",
      "Epoch [11/200], Step [161/1067], D_A_loss: 0.0549, D_B_loss: 0.1667, G_A_loss: 0.5923, G_B_loss: 0.3161\n",
      "Epoch [11/200], Step [171/1067], D_A_loss: 0.1184, D_B_loss: 0.0690, G_A_loss: 0.5823, G_B_loss: 0.4172\n",
      "Epoch [11/200], Step [181/1067], D_A_loss: 0.1975, D_B_loss: 0.1244, G_A_loss: 0.3384, G_B_loss: 0.2216\n",
      "Epoch [11/200], Step [191/1067], D_A_loss: 0.2648, D_B_loss: 0.2070, G_A_loss: 0.5086, G_B_loss: 0.3503\n",
      "Epoch [11/200], Step [201/1067], D_A_loss: 0.1610, D_B_loss: 0.0521, G_A_loss: 0.3316, G_B_loss: 0.3252\n",
      "Epoch [11/200], Step [211/1067], D_A_loss: 0.1378, D_B_loss: 0.0628, G_A_loss: 0.5283, G_B_loss: 0.8620\n",
      "Epoch [11/200], Step [221/1067], D_A_loss: 0.1499, D_B_loss: 0.0469, G_A_loss: 0.1927, G_B_loss: 0.3072\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/200], Step [231/1067], D_A_loss: 0.1271, D_B_loss: 0.0341, G_A_loss: 0.5612, G_B_loss: 0.5838\n",
      "Epoch [11/200], Step [241/1067], D_A_loss: 0.1184, D_B_loss: 0.1431, G_A_loss: 0.6009, G_B_loss: 0.5256\n",
      "Epoch [11/200], Step [251/1067], D_A_loss: 0.1306, D_B_loss: 0.0633, G_A_loss: 0.7473, G_B_loss: 0.3781\n",
      "Epoch [11/200], Step [261/1067], D_A_loss: 0.1510, D_B_loss: 0.0359, G_A_loss: 1.1463, G_B_loss: 0.4331\n",
      "Epoch [11/200], Step [271/1067], D_A_loss: 0.1783, D_B_loss: 0.0424, G_A_loss: 0.6631, G_B_loss: 0.2436\n",
      "Epoch [11/200], Step [281/1067], D_A_loss: 0.0271, D_B_loss: 0.1809, G_A_loss: 0.2306, G_B_loss: 0.4432\n",
      "Epoch [11/200], Step [291/1067], D_A_loss: 0.1191, D_B_loss: 0.1204, G_A_loss: 0.8842, G_B_loss: 0.3709\n",
      "Epoch [11/200], Step [301/1067], D_A_loss: 0.0452, D_B_loss: 0.1060, G_A_loss: 0.6574, G_B_loss: 0.7549\n",
      "Epoch [11/200], Step [311/1067], D_A_loss: 0.1490, D_B_loss: 0.1805, G_A_loss: 0.2385, G_B_loss: 0.3815\n",
      "Epoch [11/200], Step [321/1067], D_A_loss: 0.0482, D_B_loss: 0.0575, G_A_loss: 0.6182, G_B_loss: 0.8844\n",
      "Epoch [11/200], Step [331/1067], D_A_loss: 0.1058, D_B_loss: 0.1412, G_A_loss: 1.0305, G_B_loss: 0.2878\n",
      "Epoch [11/200], Step [341/1067], D_A_loss: 0.0795, D_B_loss: 0.0334, G_A_loss: 0.7690, G_B_loss: 0.8098\n",
      "Epoch [11/200], Step [351/1067], D_A_loss: 0.1117, D_B_loss: 0.1087, G_A_loss: 0.3476, G_B_loss: 0.6385\n",
      "Epoch [11/200], Step [361/1067], D_A_loss: 0.1379, D_B_loss: 0.1487, G_A_loss: 0.2525, G_B_loss: 0.4423\n",
      "Epoch [11/200], Step [371/1067], D_A_loss: 0.0861, D_B_loss: 0.0503, G_A_loss: 0.6739, G_B_loss: 0.4983\n",
      "Epoch [11/200], Step [381/1067], D_A_loss: 0.1152, D_B_loss: 0.0495, G_A_loss: 0.5154, G_B_loss: 0.2213\n",
      "Epoch [11/200], Step [391/1067], D_A_loss: 0.2205, D_B_loss: 0.0420, G_A_loss: 0.6577, G_B_loss: 0.1602\n",
      "Epoch [11/200], Step [401/1067], D_A_loss: 0.1333, D_B_loss: 0.2437, G_A_loss: 0.6542, G_B_loss: 0.3100\n",
      "Epoch [11/200], Step [411/1067], D_A_loss: 0.0311, D_B_loss: 0.1480, G_A_loss: 0.7547, G_B_loss: 0.4774\n",
      "Epoch [11/200], Step [421/1067], D_A_loss: 0.1905, D_B_loss: 0.1105, G_A_loss: 0.4836, G_B_loss: 0.2470\n",
      "Epoch [11/200], Step [431/1067], D_A_loss: 0.1080, D_B_loss: 0.0767, G_A_loss: 0.1326, G_B_loss: 0.7050\n",
      "Epoch [11/200], Step [441/1067], D_A_loss: 0.2293, D_B_loss: 0.0377, G_A_loss: 0.8265, G_B_loss: 0.4780\n",
      "Epoch [11/200], Step [451/1067], D_A_loss: 0.0680, D_B_loss: 0.0601, G_A_loss: 0.7161, G_B_loss: 0.4934\n",
      "Epoch [11/200], Step [461/1067], D_A_loss: 0.1241, D_B_loss: 0.0383, G_A_loss: 0.4199, G_B_loss: 0.5434\n",
      "Epoch [11/200], Step [471/1067], D_A_loss: 0.1437, D_B_loss: 0.0253, G_A_loss: 0.6840, G_B_loss: 0.6452\n",
      "Epoch [11/200], Step [481/1067], D_A_loss: 0.2209, D_B_loss: 0.0770, G_A_loss: 0.5072, G_B_loss: 0.1634\n",
      "Epoch [11/200], Step [491/1067], D_A_loss: 0.2924, D_B_loss: 0.0630, G_A_loss: 1.0192, G_B_loss: 0.1455\n",
      "Epoch [11/200], Step [501/1067], D_A_loss: 0.0916, D_B_loss: 0.2217, G_A_loss: 0.6368, G_B_loss: 0.4022\n",
      "Epoch [11/200], Step [511/1067], D_A_loss: 0.1159, D_B_loss: 0.0427, G_A_loss: 0.6981, G_B_loss: 0.3292\n",
      "Epoch [11/200], Step [521/1067], D_A_loss: 0.2812, D_B_loss: 0.0759, G_A_loss: 0.5351, G_B_loss: 0.9165\n",
      "Epoch [11/200], Step [531/1067], D_A_loss: 0.1014, D_B_loss: 0.3859, G_A_loss: 1.0330, G_B_loss: 0.6608\n",
      "Epoch [11/200], Step [541/1067], D_A_loss: 0.1644, D_B_loss: 0.1122, G_A_loss: 0.6053, G_B_loss: 0.1896\n",
      "Epoch [11/200], Step [551/1067], D_A_loss: 0.0994, D_B_loss: 0.0823, G_A_loss: 0.5048, G_B_loss: 0.3047\n",
      "Epoch [11/200], Step [561/1067], D_A_loss: 0.0493, D_B_loss: 0.0404, G_A_loss: 0.8895, G_B_loss: 0.3508\n",
      "Epoch [11/200], Step [571/1067], D_A_loss: 0.0493, D_B_loss: 0.0246, G_A_loss: 0.9486, G_B_loss: 0.4939\n",
      "Epoch [11/200], Step [581/1067], D_A_loss: 0.1736, D_B_loss: 0.1249, G_A_loss: 0.3415, G_B_loss: 0.0407\n",
      "Epoch [11/200], Step [591/1067], D_A_loss: 0.0962, D_B_loss: 0.1396, G_A_loss: 0.5462, G_B_loss: 0.3698\n",
      "Epoch [11/200], Step [601/1067], D_A_loss: 0.2057, D_B_loss: 0.0963, G_A_loss: 0.1846, G_B_loss: 0.3025\n",
      "Epoch [11/200], Step [611/1067], D_A_loss: 0.2293, D_B_loss: 0.0535, G_A_loss: 0.5866, G_B_loss: 0.3700\n",
      "Epoch [11/200], Step [621/1067], D_A_loss: 0.1182, D_B_loss: 0.1739, G_A_loss: 0.1252, G_B_loss: 0.3008\n",
      "Epoch [11/200], Step [631/1067], D_A_loss: 0.0393, D_B_loss: 0.0272, G_A_loss: 0.4884, G_B_loss: 0.7531\n",
      "Epoch [11/200], Step [641/1067], D_A_loss: 0.1177, D_B_loss: 0.0432, G_A_loss: 0.3749, G_B_loss: 0.1068\n",
      "Epoch [11/200], Step [651/1067], D_A_loss: 0.3869, D_B_loss: 0.0142, G_A_loss: 0.8816, G_B_loss: 0.0643\n",
      "Epoch [11/200], Step [661/1067], D_A_loss: 0.0614, D_B_loss: 0.1804, G_A_loss: 0.4050, G_B_loss: 0.2940\n",
      "Epoch [11/200], Step [671/1067], D_A_loss: 0.1193, D_B_loss: 0.0873, G_A_loss: 0.4833, G_B_loss: 0.3429\n",
      "Epoch [11/200], Step [681/1067], D_A_loss: 0.1793, D_B_loss: 0.2132, G_A_loss: 0.8048, G_B_loss: 0.0445\n",
      "Epoch [11/200], Step [691/1067], D_A_loss: 0.1828, D_B_loss: 0.1955, G_A_loss: 0.2256, G_B_loss: 0.4094\n",
      "Epoch [11/200], Step [701/1067], D_A_loss: 0.1124, D_B_loss: 0.0748, G_A_loss: 0.2998, G_B_loss: 0.3373\n",
      "Epoch [11/200], Step [711/1067], D_A_loss: 0.1670, D_B_loss: 0.1995, G_A_loss: 0.7386, G_B_loss: 0.5330\n",
      "Epoch [11/200], Step [721/1067], D_A_loss: 0.1191, D_B_loss: 0.0827, G_A_loss: 0.2718, G_B_loss: 0.3725\n",
      "Epoch [11/200], Step [731/1067], D_A_loss: 0.1503, D_B_loss: 0.0781, G_A_loss: 0.1298, G_B_loss: 0.2758\n",
      "Epoch [11/200], Step [741/1067], D_A_loss: 0.2058, D_B_loss: 0.0797, G_A_loss: 0.7934, G_B_loss: 0.6125\n",
      "Epoch [11/200], Step [751/1067], D_A_loss: 0.0309, D_B_loss: 0.1327, G_A_loss: 0.2486, G_B_loss: 0.2807\n",
      "Epoch [11/200], Step [761/1067], D_A_loss: 0.1871, D_B_loss: 0.1171, G_A_loss: 0.4746, G_B_loss: 0.3197\n",
      "Epoch [11/200], Step [771/1067], D_A_loss: 0.0278, D_B_loss: 0.0281, G_A_loss: 0.5235, G_B_loss: 0.1678\n",
      "Epoch [11/200], Step [781/1067], D_A_loss: 0.0911, D_B_loss: 0.0353, G_A_loss: 0.3576, G_B_loss: 0.6291\n",
      "Epoch [11/200], Step [791/1067], D_A_loss: 0.0566, D_B_loss: 0.0705, G_A_loss: 0.5255, G_B_loss: 0.7292\n",
      "Epoch [11/200], Step [801/1067], D_A_loss: 0.2288, D_B_loss: 0.0911, G_A_loss: 0.4310, G_B_loss: 0.1846\n",
      "Epoch [11/200], Step [811/1067], D_A_loss: 0.0730, D_B_loss: 0.0754, G_A_loss: 1.4596, G_B_loss: 0.2220\n",
      "Epoch [11/200], Step [821/1067], D_A_loss: 0.0813, D_B_loss: 0.0923, G_A_loss: 0.6370, G_B_loss: 0.1859\n",
      "Epoch [11/200], Step [831/1067], D_A_loss: 0.0837, D_B_loss: 0.2044, G_A_loss: 0.3433, G_B_loss: 0.4353\n",
      "Epoch [11/200], Step [841/1067], D_A_loss: 0.0787, D_B_loss: 0.0356, G_A_loss: 0.8269, G_B_loss: 0.5081\n",
      "Epoch [11/200], Step [851/1067], D_A_loss: 0.0943, D_B_loss: 0.0935, G_A_loss: 0.9212, G_B_loss: 0.4025\n",
      "Epoch [11/200], Step [861/1067], D_A_loss: 0.0624, D_B_loss: 0.1185, G_A_loss: 0.3817, G_B_loss: 0.6358\n",
      "Epoch [11/200], Step [871/1067], D_A_loss: 0.0732, D_B_loss: 0.1565, G_A_loss: 0.5664, G_B_loss: 0.6279\n",
      "Epoch [11/200], Step [881/1067], D_A_loss: 0.4033, D_B_loss: 0.0708, G_A_loss: 0.5744, G_B_loss: 0.0729\n",
      "Epoch [11/200], Step [891/1067], D_A_loss: 0.1303, D_B_loss: 0.0408, G_A_loss: 0.7938, G_B_loss: 0.3581\n",
      "Epoch [11/200], Step [901/1067], D_A_loss: 0.1174, D_B_loss: 0.1344, G_A_loss: 1.0038, G_B_loss: 0.4161\n",
      "Epoch [11/200], Step [911/1067], D_A_loss: 0.3022, D_B_loss: 0.2508, G_A_loss: 0.1227, G_B_loss: 0.5535\n",
      "Epoch [11/200], Step [921/1067], D_A_loss: 0.1851, D_B_loss: 0.0242, G_A_loss: 0.6216, G_B_loss: 0.3593\n",
      "Epoch [11/200], Step [931/1067], D_A_loss: 0.0702, D_B_loss: 0.0501, G_A_loss: 1.1147, G_B_loss: 0.1249\n",
      "Epoch [11/200], Step [941/1067], D_A_loss: 0.2042, D_B_loss: 0.1124, G_A_loss: 0.9594, G_B_loss: 0.4718\n",
      "Epoch [11/200], Step [951/1067], D_A_loss: 0.0480, D_B_loss: 0.2137, G_A_loss: 0.9671, G_B_loss: 0.6437\n",
      "Epoch [11/200], Step [961/1067], D_A_loss: 0.0625, D_B_loss: 0.0662, G_A_loss: 0.1063, G_B_loss: 0.1959\n",
      "Epoch [11/200], Step [971/1067], D_A_loss: 0.1115, D_B_loss: 0.0197, G_A_loss: 0.7906, G_B_loss: 0.7545\n",
      "Epoch [11/200], Step [981/1067], D_A_loss: 0.2724, D_B_loss: 0.1660, G_A_loss: 0.2301, G_B_loss: 0.4759\n",
      "Epoch [11/200], Step [991/1067], D_A_loss: 0.1868, D_B_loss: 0.0684, G_A_loss: 0.1242, G_B_loss: 0.1921\n",
      "Epoch [11/200], Step [1001/1067], D_A_loss: 0.2315, D_B_loss: 0.3890, G_A_loss: 1.2207, G_B_loss: 0.4049\n",
      "Epoch [11/200], Step [1011/1067], D_A_loss: 0.1565, D_B_loss: 0.1203, G_A_loss: 0.3569, G_B_loss: 0.5020\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/200], Step [1021/1067], D_A_loss: 0.0622, D_B_loss: 0.0426, G_A_loss: 0.6307, G_B_loss: 0.1917\n",
      "Epoch [11/200], Step [1031/1067], D_A_loss: 0.0226, D_B_loss: 0.0350, G_A_loss: 0.9315, G_B_loss: 0.3574\n",
      "Epoch [11/200], Step [1041/1067], D_A_loss: 0.0741, D_B_loss: 0.1405, G_A_loss: 0.6193, G_B_loss: 0.4900\n",
      "Epoch [11/200], Step [1051/1067], D_A_loss: 0.1370, D_B_loss: 0.1837, G_A_loss: 0.7187, G_B_loss: 0.4131\n",
      "Epoch [11/200], Step [1061/1067], D_A_loss: 0.1017, D_B_loss: 0.0485, G_A_loss: 0.9111, G_B_loss: 0.6104\n",
      "Epoch [12/200], Step [1/1067], D_A_loss: 0.1796, D_B_loss: 0.1748, G_A_loss: 0.7360, G_B_loss: 0.2193\n",
      "Epoch [12/200], Step [11/1067], D_A_loss: 0.0584, D_B_loss: 0.0463, G_A_loss: 0.5811, G_B_loss: 0.3405\n",
      "Epoch [12/200], Step [21/1067], D_A_loss: 0.0453, D_B_loss: 0.0203, G_A_loss: 0.8521, G_B_loss: 0.2738\n",
      "Epoch [12/200], Step [31/1067], D_A_loss: 0.1105, D_B_loss: 0.0662, G_A_loss: 0.5781, G_B_loss: 0.4827\n",
      "Epoch [12/200], Step [41/1067], D_A_loss: 0.0423, D_B_loss: 0.1294, G_A_loss: 0.3561, G_B_loss: 0.5171\n",
      "Epoch [12/200], Step [51/1067], D_A_loss: 0.1310, D_B_loss: 0.0298, G_A_loss: 0.2087, G_B_loss: 0.5586\n",
      "Epoch [12/200], Step [61/1067], D_A_loss: 0.1071, D_B_loss: 0.2312, G_A_loss: 1.1381, G_B_loss: 0.4922\n",
      "Epoch [12/200], Step [71/1067], D_A_loss: 0.0618, D_B_loss: 0.0545, G_A_loss: 0.4780, G_B_loss: 0.3376\n",
      "Epoch [12/200], Step [81/1067], D_A_loss: 0.2120, D_B_loss: 0.2509, G_A_loss: 0.1466, G_B_loss: 0.3859\n",
      "Epoch [12/200], Step [91/1067], D_A_loss: 0.0604, D_B_loss: 0.0921, G_A_loss: 0.2433, G_B_loss: 0.8187\n",
      "Epoch [12/200], Step [101/1067], D_A_loss: 0.0963, D_B_loss: 0.2753, G_A_loss: 0.1393, G_B_loss: 0.4018\n",
      "Epoch [12/200], Step [111/1067], D_A_loss: 0.0241, D_B_loss: 0.1303, G_A_loss: 0.0949, G_B_loss: 0.9180\n",
      "Epoch [12/200], Step [121/1067], D_A_loss: 0.2033, D_B_loss: 0.0610, G_A_loss: 0.4195, G_B_loss: 0.6037\n",
      "Epoch [12/200], Step [131/1067], D_A_loss: 0.1675, D_B_loss: 0.1371, G_A_loss: 0.3520, G_B_loss: 0.4863\n",
      "Epoch [12/200], Step [141/1067], D_A_loss: 0.1380, D_B_loss: 0.1300, G_A_loss: 0.4368, G_B_loss: 0.8168\n",
      "Epoch [12/200], Step [151/1067], D_A_loss: 0.1034, D_B_loss: 0.0276, G_A_loss: 0.4942, G_B_loss: 0.3368\n",
      "Epoch [12/200], Step [161/1067], D_A_loss: 0.1129, D_B_loss: 0.1299, G_A_loss: 0.9729, G_B_loss: 0.0263\n",
      "Epoch [12/200], Step [171/1067], D_A_loss: 0.1716, D_B_loss: 0.1412, G_A_loss: 0.3464, G_B_loss: 0.4651\n",
      "Epoch [12/200], Step [181/1067], D_A_loss: 0.1151, D_B_loss: 0.0834, G_A_loss: 0.5275, G_B_loss: 0.4682\n",
      "Epoch [12/200], Step [191/1067], D_A_loss: 0.2576, D_B_loss: 0.1777, G_A_loss: 0.3063, G_B_loss: 0.4656\n",
      "Epoch [12/200], Step [201/1067], D_A_loss: 0.1176, D_B_loss: 0.0624, G_A_loss: 0.8182, G_B_loss: 0.3932\n",
      "Epoch [12/200], Step [211/1067], D_A_loss: 0.1014, D_B_loss: 0.1054, G_A_loss: 0.5967, G_B_loss: 0.2403\n",
      "Epoch [12/200], Step [221/1067], D_A_loss: 0.0537, D_B_loss: 0.2008, G_A_loss: 0.4328, G_B_loss: 0.9259\n",
      "Epoch [12/200], Step [231/1067], D_A_loss: 0.0907, D_B_loss: 0.0526, G_A_loss: 0.5243, G_B_loss: 0.4933\n",
      "Epoch [12/200], Step [241/1067], D_A_loss: 0.1709, D_B_loss: 0.0381, G_A_loss: 0.8181, G_B_loss: 1.0077\n",
      "Epoch [12/200], Step [251/1067], D_A_loss: 0.0853, D_B_loss: 0.0602, G_A_loss: 0.7451, G_B_loss: 0.6909\n",
      "Epoch [12/200], Step [261/1067], D_A_loss: 0.2300, D_B_loss: 0.1618, G_A_loss: 0.2970, G_B_loss: 0.0824\n",
      "Epoch [12/200], Step [271/1067], D_A_loss: 0.1966, D_B_loss: 0.2684, G_A_loss: 0.1496, G_B_loss: 0.3664\n",
      "Epoch [12/200], Step [281/1067], D_A_loss: 0.1248, D_B_loss: 0.0606, G_A_loss: 0.5398, G_B_loss: 0.5669\n",
      "Epoch [12/200], Step [291/1067], D_A_loss: 0.0981, D_B_loss: 0.1024, G_A_loss: 0.3725, G_B_loss: 0.6841\n",
      "Epoch [12/200], Step [301/1067], D_A_loss: 0.2114, D_B_loss: 0.0214, G_A_loss: 0.3124, G_B_loss: 0.8292\n",
      "Epoch [12/200], Step [311/1067], D_A_loss: 0.0701, D_B_loss: 0.1042, G_A_loss: 1.1680, G_B_loss: 0.5170\n",
      "Epoch [12/200], Step [321/1067], D_A_loss: 0.1649, D_B_loss: 0.0125, G_A_loss: 0.6997, G_B_loss: 0.4813\n",
      "Epoch [12/200], Step [331/1067], D_A_loss: 0.1257, D_B_loss: 0.0986, G_A_loss: 0.3553, G_B_loss: 0.3525\n",
      "Epoch [12/200], Step [341/1067], D_A_loss: 0.2383, D_B_loss: 0.2337, G_A_loss: 0.3454, G_B_loss: 0.1470\n",
      "Epoch [12/200], Step [351/1067], D_A_loss: 0.0982, D_B_loss: 0.0843, G_A_loss: 0.4396, G_B_loss: 0.5098\n",
      "Epoch [12/200], Step [361/1067], D_A_loss: 0.0309, D_B_loss: 0.0158, G_A_loss: 0.4270, G_B_loss: 0.7083\n",
      "Epoch [12/200], Step [371/1067], D_A_loss: 0.1355, D_B_loss: 0.1238, G_A_loss: 0.3116, G_B_loss: 0.3800\n",
      "Epoch [12/200], Step [381/1067], D_A_loss: 0.0727, D_B_loss: 0.0452, G_A_loss: 0.4092, G_B_loss: 0.6014\n",
      "Epoch [12/200], Step [391/1067], D_A_loss: 0.0402, D_B_loss: 0.0906, G_A_loss: 0.4957, G_B_loss: 0.6343\n",
      "Epoch [12/200], Step [401/1067], D_A_loss: 0.1264, D_B_loss: 0.0565, G_A_loss: 0.6577, G_B_loss: 0.3860\n",
      "Epoch [12/200], Step [411/1067], D_A_loss: 0.2807, D_B_loss: 0.1411, G_A_loss: 0.3121, G_B_loss: 0.4612\n",
      "Epoch [12/200], Step [421/1067], D_A_loss: 0.1470, D_B_loss: 0.1016, G_A_loss: 0.4029, G_B_loss: 0.5963\n",
      "Epoch [12/200], Step [431/1067], D_A_loss: 0.0558, D_B_loss: 0.0572, G_A_loss: 0.7274, G_B_loss: 0.3024\n",
      "Epoch [12/200], Step [441/1067], D_A_loss: 0.0615, D_B_loss: 0.2069, G_A_loss: 0.8728, G_B_loss: 0.1633\n",
      "Epoch [12/200], Step [451/1067], D_A_loss: 0.1529, D_B_loss: 0.0256, G_A_loss: 0.7737, G_B_loss: 0.3140\n",
      "Epoch [12/200], Step [461/1067], D_A_loss: 0.0940, D_B_loss: 0.0788, G_A_loss: 0.4637, G_B_loss: 0.3710\n",
      "Epoch [12/200], Step [471/1067], D_A_loss: 0.1820, D_B_loss: 0.0822, G_A_loss: 0.2864, G_B_loss: 0.1741\n",
      "Epoch [12/200], Step [481/1067], D_A_loss: 0.1304, D_B_loss: 0.1372, G_A_loss: 0.5649, G_B_loss: 0.2527\n",
      "Epoch [12/200], Step [491/1067], D_A_loss: 0.0418, D_B_loss: 0.0914, G_A_loss: 0.5446, G_B_loss: 0.6689\n",
      "Epoch [12/200], Step [501/1067], D_A_loss: 0.0389, D_B_loss: 0.0494, G_A_loss: 0.5703, G_B_loss: 0.0377\n",
      "Epoch [12/200], Step [511/1067], D_A_loss: 0.1800, D_B_loss: 0.0442, G_A_loss: 0.2461, G_B_loss: 0.3026\n",
      "Epoch [12/200], Step [521/1067], D_A_loss: 0.0735, D_B_loss: 0.1460, G_A_loss: 0.4303, G_B_loss: 0.3014\n",
      "Epoch [12/200], Step [531/1067], D_A_loss: 0.0589, D_B_loss: 0.1571, G_A_loss: 0.5827, G_B_loss: 0.7718\n",
      "Epoch [12/200], Step [541/1067], D_A_loss: 0.1182, D_B_loss: 0.0496, G_A_loss: 0.4385, G_B_loss: 0.2497\n",
      "Epoch [12/200], Step [551/1067], D_A_loss: 0.2348, D_B_loss: 0.0872, G_A_loss: 0.4467, G_B_loss: 0.5648\n",
      "Epoch [12/200], Step [561/1067], D_A_loss: 0.2302, D_B_loss: 0.0751, G_A_loss: 0.4885, G_B_loss: 0.1467\n",
      "Epoch [12/200], Step [571/1067], D_A_loss: 0.2538, D_B_loss: 0.2108, G_A_loss: 0.7457, G_B_loss: 1.1352\n",
      "Epoch [12/200], Step [581/1067], D_A_loss: 0.0783, D_B_loss: 0.0390, G_A_loss: 0.7340, G_B_loss: 0.4732\n",
      "Epoch [12/200], Step [591/1067], D_A_loss: 0.1362, D_B_loss: 0.1070, G_A_loss: 0.7206, G_B_loss: 0.4522\n",
      "Epoch [12/200], Step [601/1067], D_A_loss: 0.2231, D_B_loss: 0.0708, G_A_loss: 0.5819, G_B_loss: 0.2442\n",
      "Epoch [12/200], Step [611/1067], D_A_loss: 0.3551, D_B_loss: 0.0479, G_A_loss: 0.7130, G_B_loss: 0.2437\n",
      "Epoch [12/200], Step [621/1067], D_A_loss: 0.1097, D_B_loss: 0.1472, G_A_loss: 0.1838, G_B_loss: 0.5417\n",
      "Epoch [12/200], Step [631/1067], D_A_loss: 0.1341, D_B_loss: 0.0599, G_A_loss: 0.5880, G_B_loss: 0.4723\n",
      "Epoch [12/200], Step [641/1067], D_A_loss: 0.0490, D_B_loss: 0.0572, G_A_loss: 0.7236, G_B_loss: 0.2750\n",
      "Epoch [12/200], Step [651/1067], D_A_loss: 0.2803, D_B_loss: 0.0767, G_A_loss: 0.6943, G_B_loss: 0.3862\n",
      "Epoch [12/200], Step [661/1067], D_A_loss: 0.1168, D_B_loss: 0.0619, G_A_loss: 0.2222, G_B_loss: 0.1441\n",
      "Epoch [12/200], Step [671/1067], D_A_loss: 0.1500, D_B_loss: 0.0125, G_A_loss: 0.7599, G_B_loss: 0.3620\n",
      "Epoch [12/200], Step [681/1067], D_A_loss: 0.1555, D_B_loss: 0.0300, G_A_loss: 0.8091, G_B_loss: 0.3388\n",
      "Epoch [12/200], Step [691/1067], D_A_loss: 0.1330, D_B_loss: 0.0592, G_A_loss: 0.7021, G_B_loss: 0.8934\n",
      "Epoch [12/200], Step [701/1067], D_A_loss: 0.0936, D_B_loss: 0.1381, G_A_loss: 0.2602, G_B_loss: 0.6142\n",
      "Epoch [12/200], Step [711/1067], D_A_loss: 0.1330, D_B_loss: 0.1124, G_A_loss: 0.7468, G_B_loss: 0.2278\n",
      "Epoch [12/200], Step [721/1067], D_A_loss: 0.0967, D_B_loss: 0.1185, G_A_loss: 0.7391, G_B_loss: 0.5801\n",
      "Epoch [12/200], Step [731/1067], D_A_loss: 0.2915, D_B_loss: 0.0178, G_A_loss: 1.0520, G_B_loss: 0.4658\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/200], Step [741/1067], D_A_loss: 0.1240, D_B_loss: 0.0997, G_A_loss: 0.3948, G_B_loss: 0.4033\n",
      "Epoch [12/200], Step [751/1067], D_A_loss: 0.2196, D_B_loss: 0.1210, G_A_loss: 0.6479, G_B_loss: 0.2340\n",
      "Epoch [12/200], Step [761/1067], D_A_loss: 0.2205, D_B_loss: 0.2544, G_A_loss: 0.1420, G_B_loss: 1.3289\n",
      "Epoch [13/200], Step [171/1067], D_A_loss: 0.2481, D_B_loss: 0.0228, G_A_loss: 0.7014, G_B_loss: 1.0608\n",
      "Epoch [13/200], Step [181/1067], D_A_loss: 0.0780, D_B_loss: 0.0381, G_A_loss: 0.8262, G_B_loss: 0.5459\n",
      "Epoch [13/200], Step [191/1067], D_A_loss: 0.0977, D_B_loss: 0.0133, G_A_loss: 1.0446, G_B_loss: 0.2491\n",
      "Epoch [13/200], Step [201/1067], D_A_loss: 0.1493, D_B_loss: 0.0288, G_A_loss: 0.4641, G_B_loss: 0.7037\n",
      "Epoch [13/200], Step [211/1067], D_A_loss: 0.1255, D_B_loss: 0.0338, G_A_loss: 0.7542, G_B_loss: 0.6129\n",
      "Epoch [13/200], Step [221/1067], D_A_loss: 0.1596, D_B_loss: 0.0998, G_A_loss: 0.7387, G_B_loss: 0.2548\n",
      "Epoch [13/200], Step [231/1067], D_A_loss: 0.0726, D_B_loss: 0.0459, G_A_loss: 0.6860, G_B_loss: 0.4962\n",
      "Epoch [13/200], Step [241/1067], D_A_loss: 0.0308, D_B_loss: 0.0259, G_A_loss: 0.4961, G_B_loss: 0.7042\n",
      "Epoch [13/200], Step [251/1067], D_A_loss: 0.0742, D_B_loss: 0.0372, G_A_loss: 0.5982, G_B_loss: 0.5233\n",
      "Epoch [13/200], Step [261/1067], D_A_loss: 0.0391, D_B_loss: 0.1648, G_A_loss: 0.6608, G_B_loss: 0.3436\n",
      "Epoch [13/200], Step [271/1067], D_A_loss: 0.0570, D_B_loss: 0.1135, G_A_loss: 0.3584, G_B_loss: 0.4914\n",
      "Epoch [13/200], Step [281/1067], D_A_loss: 0.2997, D_B_loss: 0.0872, G_A_loss: 0.4171, G_B_loss: 0.4994\n",
      "Epoch [13/200], Step [291/1067], D_A_loss: 0.1777, D_B_loss: 0.1148, G_A_loss: 0.4866, G_B_loss: 0.2807\n",
      "Epoch [13/200], Step [301/1067], D_A_loss: 0.0509, D_B_loss: 0.0341, G_A_loss: 0.6697, G_B_loss: 0.5676\n",
      "Epoch [13/200], Step [311/1067], D_A_loss: 0.2684, D_B_loss: 0.0305, G_A_loss: 0.4805, G_B_loss: 0.4658\n",
      "Epoch [13/200], Step [321/1067], D_A_loss: 0.0804, D_B_loss: 0.0752, G_A_loss: 0.9038, G_B_loss: 0.4509\n",
      "Epoch [13/200], Step [331/1067], D_A_loss: 0.1474, D_B_loss: 0.0795, G_A_loss: 0.9583, G_B_loss: 0.7377\n",
      "Epoch [13/200], Step [341/1067], D_A_loss: 0.1592, D_B_loss: 0.1360, G_A_loss: 0.4006, G_B_loss: 0.3956\n",
      "Epoch [13/200], Step [351/1067], D_A_loss: 0.0615, D_B_loss: 0.0447, G_A_loss: 0.3728, G_B_loss: 0.3056\n",
      "Epoch [13/200], Step [361/1067], D_A_loss: 0.1329, D_B_loss: 0.0521, G_A_loss: 0.6260, G_B_loss: 0.3337\n",
      "Epoch [13/200], Step [371/1067], D_A_loss: 0.0381, D_B_loss: 0.0189, G_A_loss: 0.6858, G_B_loss: 0.8111\n",
      "Epoch [13/200], Step [381/1067], D_A_loss: 0.1046, D_B_loss: 0.0660, G_A_loss: 0.7779, G_B_loss: 0.2814\n",
      "Epoch [13/200], Step [391/1067], D_A_loss: 0.3132, D_B_loss: 0.3337, G_A_loss: 0.2592, G_B_loss: 0.7250\n",
      "Epoch [13/200], Step [401/1067], D_A_loss: 0.1671, D_B_loss: 0.0576, G_A_loss: 0.5465, G_B_loss: 0.3563\n",
      "Epoch [13/200], Step [411/1067], D_A_loss: 0.1380, D_B_loss: 0.0541, G_A_loss: 0.6933, G_B_loss: 0.3060\n",
      "Epoch [13/200], Step [421/1067], D_A_loss: 0.0832, D_B_loss: 0.0678, G_A_loss: 0.7290, G_B_loss: 0.4684\n",
      "Epoch [13/200], Step [431/1067], D_A_loss: 0.2237, D_B_loss: 0.0219, G_A_loss: 0.3444, G_B_loss: 0.2979\n",
      "Epoch [13/200], Step [441/1067], D_A_loss: 0.1130, D_B_loss: 0.3076, G_A_loss: 1.1257, G_B_loss: 0.3393\n",
      "Epoch [13/200], Step [451/1067], D_A_loss: 0.1159, D_B_loss: 0.0944, G_A_loss: 0.6038, G_B_loss: 0.4517\n",
      "Epoch [13/200], Step [461/1067], D_A_loss: 0.1308, D_B_loss: 0.0457, G_A_loss: 0.5595, G_B_loss: 0.3787\n",
      "Epoch [13/200], Step [471/1067], D_A_loss: 0.3049, D_B_loss: 0.0430, G_A_loss: 0.3856, G_B_loss: 0.7453\n",
      "Epoch [13/200], Step [481/1067], D_A_loss: 0.0614, D_B_loss: 0.0431, G_A_loss: 1.0823, G_B_loss: 0.5959\n",
      "Epoch [13/200], Step [491/1067], D_A_loss: 0.0688, D_B_loss: 0.0602, G_A_loss: 0.4486, G_B_loss: 0.4829\n",
      "Epoch [13/200], Step [501/1067], D_A_loss: 0.1127, D_B_loss: 0.2906, G_A_loss: 0.0999, G_B_loss: 0.6482\n",
      "Epoch [13/200], Step [511/1067], D_A_loss: 0.1612, D_B_loss: 0.0392, G_A_loss: 0.9919, G_B_loss: 0.3929\n",
      "Epoch [13/200], Step [521/1067], D_A_loss: 0.0865, D_B_loss: 0.0399, G_A_loss: 0.3063, G_B_loss: 0.4469\n",
      "Epoch [13/200], Step [531/1067], D_A_loss: 0.0683, D_B_loss: 0.1510, G_A_loss: 0.4455, G_B_loss: 0.0932\n",
      "Epoch [13/200], Step [541/1067], D_A_loss: 0.1126, D_B_loss: 0.0184, G_A_loss: 1.0005, G_B_loss: 0.6226\n",
      "Epoch [13/200], Step [551/1067], D_A_loss: 0.1563, D_B_loss: 0.1556, G_A_loss: 0.4796, G_B_loss: 0.4424\n",
      "Epoch [13/200], Step [561/1067], D_A_loss: 0.0739, D_B_loss: 0.0628, G_A_loss: 0.5719, G_B_loss: 0.4924\n",
      "Epoch [13/200], Step [571/1067], D_A_loss: 0.1449, D_B_loss: 0.0756, G_A_loss: 0.4599, G_B_loss: 0.2152\n",
      "Epoch [13/200], Step [581/1067], D_A_loss: 0.1943, D_B_loss: 0.0711, G_A_loss: 0.5453, G_B_loss: 0.3968\n",
      "Epoch [13/200], Step [591/1067], D_A_loss: 0.2165, D_B_loss: 0.2431, G_A_loss: 0.2070, G_B_loss: 1.0716\n",
      "Epoch [13/200], Step [601/1067], D_A_loss: 0.1514, D_B_loss: 0.0241, G_A_loss: 0.7261, G_B_loss: 0.5421\n",
      "Epoch [13/200], Step [611/1067], D_A_loss: 0.1021, D_B_loss: 0.0675, G_A_loss: 0.4040, G_B_loss: 0.3691\n",
      "Epoch [13/200], Step [621/1067], D_A_loss: 0.0398, D_B_loss: 0.0597, G_A_loss: 1.2484, G_B_loss: 0.6294\n",
      "Epoch [13/200], Step [631/1067], D_A_loss: 0.1264, D_B_loss: 0.1500, G_A_loss: 0.1078, G_B_loss: 0.6467\n",
      "Epoch [13/200], Step [641/1067], D_A_loss: 0.0463, D_B_loss: 0.0941, G_A_loss: 0.7866, G_B_loss: 0.6347\n",
      "Epoch [13/200], Step [651/1067], D_A_loss: 0.0482, D_B_loss: 0.0299, G_A_loss: 0.7788, G_B_loss: 0.6527\n",
      "Epoch [13/200], Step [661/1067], D_A_loss: 0.2203, D_B_loss: 0.0520, G_A_loss: 0.5555, G_B_loss: 0.5051\n",
      "Epoch [13/200], Step [671/1067], D_A_loss: 0.0764, D_B_loss: 0.1590, G_A_loss: 0.9384, G_B_loss: 0.6169\n",
      "Epoch [13/200], Step [681/1067], D_A_loss: 0.0868, D_B_loss: 0.1044, G_A_loss: 0.3733, G_B_loss: 0.6726\n",
      "Epoch [13/200], Step [691/1067], D_A_loss: 0.0723, D_B_loss: 0.1976, G_A_loss: 0.2919, G_B_loss: 0.7815\n",
      "Epoch [13/200], Step [701/1067], D_A_loss: 0.1802, D_B_loss: 0.0297, G_A_loss: 0.6029, G_B_loss: 0.5262\n",
      "Epoch [13/200], Step [711/1067], D_A_loss: 0.1743, D_B_loss: 0.2659, G_A_loss: 0.9895, G_B_loss: 0.6917\n",
      "Epoch [13/200], Step [721/1067], D_A_loss: 0.1406, D_B_loss: 0.1908, G_A_loss: 0.3273, G_B_loss: 0.3788\n",
      "Epoch [13/200], Step [731/1067], D_A_loss: 0.0503, D_B_loss: 0.0293, G_A_loss: 0.5052, G_B_loss: 0.4294\n",
      "Epoch [13/200], Step [741/1067], D_A_loss: 0.1721, D_B_loss: 0.0197, G_A_loss: 0.2627, G_B_loss: 0.2907\n",
      "Epoch [13/200], Step [751/1067], D_A_loss: 0.0436, D_B_loss: 0.1763, G_A_loss: 0.2862, G_B_loss: 0.7174\n",
      "Epoch [13/200], Step [761/1067], D_A_loss: 0.0993, D_B_loss: 0.1676, G_A_loss: 0.2709, G_B_loss: 0.2686\n",
      "Epoch [13/200], Step [771/1067], D_A_loss: 0.3806, D_B_loss: 0.1094, G_A_loss: 0.4275, G_B_loss: 0.0943\n",
      "Epoch [13/200], Step [781/1067], D_A_loss: 0.0597, D_B_loss: 0.0840, G_A_loss: 0.6489, G_B_loss: 0.7380\n",
      "Epoch [13/200], Step [791/1067], D_A_loss: 0.2288, D_B_loss: 0.0277, G_A_loss: 0.9123, G_B_loss: 0.1327\n",
      "Epoch [13/200], Step [801/1067], D_A_loss: 0.0929, D_B_loss: 0.0927, G_A_loss: 0.4400, G_B_loss: 0.3823\n",
      "Epoch [13/200], Step [811/1067], D_A_loss: 0.1637, D_B_loss: 0.1802, G_A_loss: 0.4663, G_B_loss: 0.5136\n",
      "Epoch [13/200], Step [821/1067], D_A_loss: 0.1919, D_B_loss: 0.0625, G_A_loss: 0.7436, G_B_loss: 0.2885\n",
      "Epoch [13/200], Step [831/1067], D_A_loss: 0.0925, D_B_loss: 0.3686, G_A_loss: 1.0480, G_B_loss: 0.7064\n",
      "Epoch [13/200], Step [841/1067], D_A_loss: 0.2084, D_B_loss: 0.0831, G_A_loss: 0.9077, G_B_loss: 0.7695\n",
      "Epoch [13/200], Step [851/1067], D_A_loss: 0.1501, D_B_loss: 0.0489, G_A_loss: 0.3263, G_B_loss: 0.3826\n",
      "Epoch [13/200], Step [861/1067], D_A_loss: 0.0938, D_B_loss: 0.0379, G_A_loss: 0.9380, G_B_loss: 0.2698\n",
      "Epoch [13/200], Step [871/1067], D_A_loss: 0.0310, D_B_loss: 0.0298, G_A_loss: 0.4043, G_B_loss: 0.7802\n",
      "Epoch [13/200], Step [881/1067], D_A_loss: 0.1246, D_B_loss: 0.1578, G_A_loss: 0.2426, G_B_loss: 0.3357\n",
      "Epoch [13/200], Step [891/1067], D_A_loss: 0.0750, D_B_loss: 0.0208, G_A_loss: 0.5800, G_B_loss: 0.4568\n",
      "Epoch [13/200], Step [901/1067], D_A_loss: 0.1488, D_B_loss: 0.1618, G_A_loss: 0.9599, G_B_loss: 0.5024\n",
      "Epoch [13/200], Step [911/1067], D_A_loss: 0.1272, D_B_loss: 0.0797, G_A_loss: 0.4910, G_B_loss: 0.5330\n",
      "Epoch [13/200], Step [921/1067], D_A_loss: 0.3630, D_B_loss: 0.0860, G_A_loss: 0.4823, G_B_loss: 1.0694\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/200], Step [931/1067], D_A_loss: 0.2606, D_B_loss: 0.1272, G_A_loss: 0.2782, G_B_loss: 0.5715\n",
      "Epoch [13/200], Step [941/1067], D_A_loss: 0.0521, D_B_loss: 0.0370, G_A_loss: 0.6979, G_B_loss: 0.5350\n",
      "Epoch [13/200], Step [951/1067], D_A_loss: 0.1250, D_B_loss: 0.0824, G_A_loss: 0.7292, G_B_loss: 0.9337\n",
      "Epoch [13/200], Step [961/1067], D_A_loss: 0.0805, D_B_loss: 0.0309, G_A_loss: 0.6607, G_B_loss: 0.5052\n",
      "Epoch [13/200], Step [971/1067], D_A_loss: 0.0573, D_B_loss: 0.0689, G_A_loss: 0.6470, G_B_loss: 0.2482\n",
      "Epoch [13/200], Step [981/1067], D_A_loss: 0.1463, D_B_loss: 0.2289, G_A_loss: 1.1239, G_B_loss: 0.6058\n",
      "Epoch [13/200], Step [991/1067], D_A_loss: 0.0506, D_B_loss: 0.1798, G_A_loss: 0.2326, G_B_loss: 0.3789\n",
      "Epoch [13/200], Step [1001/1067], D_A_loss: 0.1473, D_B_loss: 0.0310, G_A_loss: 0.7559, G_B_loss: 0.5972\n",
      "Epoch [13/200], Step [1011/1067], D_A_loss: 0.1549, D_B_loss: 0.0536, G_A_loss: 0.0816, G_B_loss: 0.2602\n",
      "Epoch [13/200], Step [1021/1067], D_A_loss: 0.0542, D_B_loss: 0.2288, G_A_loss: 1.0154, G_B_loss: 0.5349\n",
      "Epoch [13/200], Step [1031/1067], D_A_loss: 0.0964, D_B_loss: 0.1084, G_A_loss: 0.8580, G_B_loss: 0.5080\n",
      "Epoch [13/200], Step [1041/1067], D_A_loss: 0.0842, D_B_loss: 0.1034, G_A_loss: 0.6300, G_B_loss: 0.5853\n",
      "Epoch [13/200], Step [1051/1067], D_A_loss: 0.3059, D_B_loss: 0.0176, G_A_loss: 1.0552, G_B_loss: 0.1075\n",
      "Epoch [13/200], Step [1061/1067], D_A_loss: 0.0901, D_B_loss: 0.0923, G_A_loss: 0.4654, G_B_loss: 0.4540\n",
      "Epoch [14/200], Step [1/1067], D_A_loss: 0.0996, D_B_loss: 0.0782, G_A_loss: 0.5801, G_B_loss: 0.4155\n",
      "Epoch [14/200], Step [11/1067], D_A_loss: 0.0794, D_B_loss: 0.0955, G_A_loss: 0.7769, G_B_loss: 0.6237\n",
      "Epoch [14/200], Step [21/1067], D_A_loss: 0.1096, D_B_loss: 0.0229, G_A_loss: 0.4857, G_B_loss: 0.3323\n",
      "Epoch [14/200], Step [31/1067], D_A_loss: 0.2289, D_B_loss: 0.0754, G_A_loss: 0.4586, G_B_loss: 0.3385\n",
      "Epoch [14/200], Step [41/1067], D_A_loss: 0.0462, D_B_loss: 0.2749, G_A_loss: 0.7123, G_B_loss: 0.3477\n",
      "Epoch [14/200], Step [51/1067], D_A_loss: 0.0682, D_B_loss: 0.0903, G_A_loss: 0.5084, G_B_loss: 0.3089\n",
      "Epoch [14/200], Step [61/1067], D_A_loss: 0.0909, D_B_loss: 0.0739, G_A_loss: 0.9608, G_B_loss: 1.0450\n",
      "Epoch [14/200], Step [71/1067], D_A_loss: 0.1715, D_B_loss: 0.1297, G_A_loss: 0.3579, G_B_loss: 0.2924\n",
      "Epoch [14/200], Step [81/1067], D_A_loss: 0.1437, D_B_loss: 0.1055, G_A_loss: 0.8432, G_B_loss: 0.6188\n",
      "Epoch [14/200], Step [91/1067], D_A_loss: 0.0558, D_B_loss: 0.0404, G_A_loss: 1.2273, G_B_loss: 0.7007\n",
      "Epoch [14/200], Step [101/1067], D_A_loss: 0.4004, D_B_loss: 0.0186, G_A_loss: 0.6284, G_B_loss: 1.0744\n",
      "Epoch [14/200], Step [111/1067], D_A_loss: 0.1843, D_B_loss: 0.0199, G_A_loss: 0.6821, G_B_loss: 0.3671\n",
      "Epoch [14/200], Step [121/1067], D_A_loss: 0.0638, D_B_loss: 0.2061, G_A_loss: 0.1890, G_B_loss: 0.1038\n",
      "Epoch [14/200], Step [131/1067], D_A_loss: 0.1216, D_B_loss: 0.0506, G_A_loss: 0.6018, G_B_loss: 0.3629\n",
      "Epoch [14/200], Step [141/1067], D_A_loss: 0.0543, D_B_loss: 0.0367, G_A_loss: 0.7091, G_B_loss: 0.5490\n",
      "Epoch [14/200], Step [151/1067], D_A_loss: 0.0406, D_B_loss: 0.0633, G_A_loss: 0.6492, G_B_loss: 0.4998\n",
      "Epoch [14/200], Step [161/1067], D_A_loss: 0.1752, D_B_loss: 0.0953, G_A_loss: 0.8088, G_B_loss: 0.3175\n",
      "Epoch [14/200], Step [171/1067], D_A_loss: 0.0516, D_B_loss: 0.1159, G_A_loss: 0.3752, G_B_loss: 0.6987\n",
      "Epoch [14/200], Step [181/1067], D_A_loss: 0.1447, D_B_loss: 0.0617, G_A_loss: 0.7139, G_B_loss: 0.9260\n",
      "Epoch [14/200], Step [191/1067], D_A_loss: 0.1607, D_B_loss: 0.1426, G_A_loss: 0.9758, G_B_loss: 0.6629\n",
      "Epoch [14/200], Step [201/1067], D_A_loss: 0.0629, D_B_loss: 0.0330, G_A_loss: 0.0977, G_B_loss: 0.2057\n",
      "Epoch [14/200], Step [211/1067], D_A_loss: 0.1053, D_B_loss: 0.0821, G_A_loss: 0.9047, G_B_loss: 0.6142\n",
      "Epoch [14/200], Step [221/1067], D_A_loss: 0.0581, D_B_loss: 0.1318, G_A_loss: 0.2335, G_B_loss: 0.5174\n",
      "Epoch [14/200], Step [231/1067], D_A_loss: 0.0316, D_B_loss: 0.0929, G_A_loss: 0.8770, G_B_loss: 0.5554\n",
      "Epoch [14/200], Step [241/1067], D_A_loss: 0.1191, D_B_loss: 0.0383, G_A_loss: 0.5475, G_B_loss: 0.3895\n",
      "Epoch [14/200], Step [251/1067], D_A_loss: 0.0765, D_B_loss: 0.0414, G_A_loss: 1.1438, G_B_loss: 0.7176\n",
      "Epoch [14/200], Step [261/1067], D_A_loss: 0.1429, D_B_loss: 0.2420, G_A_loss: 0.4940, G_B_loss: 0.6665\n",
      "Epoch [14/200], Step [271/1067], D_A_loss: 0.1822, D_B_loss: 0.0481, G_A_loss: 0.5722, G_B_loss: 0.8499\n",
      "Epoch [14/200], Step [281/1067], D_A_loss: 0.0879, D_B_loss: 0.1661, G_A_loss: 0.5963, G_B_loss: 0.3809\n",
      "Epoch [14/200], Step [291/1067], D_A_loss: 0.0420, D_B_loss: 0.0902, G_A_loss: 0.4048, G_B_loss: 0.1828\n",
      "Epoch [14/200], Step [301/1067], D_A_loss: 0.0509, D_B_loss: 0.1107, G_A_loss: 0.4859, G_B_loss: 0.9094\n",
      "Epoch [14/200], Step [311/1067], D_A_loss: 0.1260, D_B_loss: 0.0255, G_A_loss: 0.7864, G_B_loss: 0.2614\n",
      "Epoch [14/200], Step [321/1067], D_A_loss: 0.1315, D_B_loss: 0.1081, G_A_loss: 0.5618, G_B_loss: 0.5008\n",
      "Epoch [14/200], Step [331/1067], D_A_loss: 0.1515, D_B_loss: 0.1790, G_A_loss: 0.2274, G_B_loss: 1.0483\n",
      "Epoch [14/200], Step [341/1067], D_A_loss: 0.1153, D_B_loss: 0.0688, G_A_loss: 0.5872, G_B_loss: 0.9108\n",
      "Epoch [14/200], Step [351/1067], D_A_loss: 0.2873, D_B_loss: 0.0398, G_A_loss: 0.8734, G_B_loss: 0.8811\n",
      "Epoch [14/200], Step [361/1067], D_A_loss: 0.1258, D_B_loss: 0.1538, G_A_loss: 1.0960, G_B_loss: 0.7187\n",
      "Epoch [14/200], Step [371/1067], D_A_loss: 0.0662, D_B_loss: 0.0515, G_A_loss: 0.4942, G_B_loss: 0.5069\n",
      "Epoch [14/200], Step [381/1067], D_A_loss: 0.1148, D_B_loss: 0.0717, G_A_loss: 0.4545, G_B_loss: 0.7907\n",
      "Epoch [14/200], Step [391/1067], D_A_loss: 0.0786, D_B_loss: 0.0210, G_A_loss: 0.5686, G_B_loss: 0.7641\n",
      "Epoch [14/200], Step [401/1067], D_A_loss: 0.0155, D_B_loss: 0.1859, G_A_loss: 1.4083, G_B_loss: 0.3705\n",
      "Epoch [14/200], Step [411/1067], D_A_loss: 0.0955, D_B_loss: 0.0734, G_A_loss: 0.9553, G_B_loss: 0.4008\n",
      "Epoch [14/200], Step [421/1067], D_A_loss: 0.2380, D_B_loss: 0.1820, G_A_loss: 0.5929, G_B_loss: 0.2662\n",
      "Epoch [14/200], Step [431/1067], D_A_loss: 0.1342, D_B_loss: 0.3914, G_A_loss: 0.1312, G_B_loss: 1.0742\n",
      "Epoch [14/200], Step [441/1067], D_A_loss: 0.2207, D_B_loss: 0.0930, G_A_loss: 0.3319, G_B_loss: 0.2341\n",
      "Epoch [14/200], Step [451/1067], D_A_loss: 0.0328, D_B_loss: 0.0502, G_A_loss: 0.6212, G_B_loss: 0.6845\n",
      "Epoch [14/200], Step [461/1067], D_A_loss: 0.0482, D_B_loss: 0.0808, G_A_loss: 0.4665, G_B_loss: 0.6659\n",
      "Epoch [14/200], Step [471/1067], D_A_loss: 0.0686, D_B_loss: 0.2234, G_A_loss: 0.3622, G_B_loss: 0.1493\n",
      "Epoch [14/200], Step [481/1067], D_A_loss: 0.1842, D_B_loss: 0.0704, G_A_loss: 0.7073, G_B_loss: 0.2961\n",
      "Epoch [14/200], Step [491/1067], D_A_loss: 0.0317, D_B_loss: 0.0433, G_A_loss: 0.7501, G_B_loss: 0.6708\n",
      "Epoch [14/200], Step [501/1067], D_A_loss: 0.0652, D_B_loss: 0.0934, G_A_loss: 0.4722, G_B_loss: 0.7608\n",
      "Epoch [14/200], Step [511/1067], D_A_loss: 0.0957, D_B_loss: 0.0360, G_A_loss: 0.6781, G_B_loss: 0.3814\n",
      "Epoch [14/200], Step [521/1067], D_A_loss: 0.0678, D_B_loss: 0.1621, G_A_loss: 0.1120, G_B_loss: 0.3685\n",
      "Epoch [14/200], Step [531/1067], D_A_loss: 0.0580, D_B_loss: 0.0544, G_A_loss: 0.5796, G_B_loss: 0.5340\n",
      "Epoch [14/200], Step [541/1067], D_A_loss: 0.0569, D_B_loss: 0.0872, G_A_loss: 0.7078, G_B_loss: 0.7023\n",
      "Epoch [14/200], Step [551/1067], D_A_loss: 0.0723, D_B_loss: 0.0141, G_A_loss: 0.5068, G_B_loss: 0.1653\n",
      "Epoch [14/200], Step [561/1067], D_A_loss: 0.0364, D_B_loss: 0.0411, G_A_loss: 0.4051, G_B_loss: 0.3712\n",
      "Epoch [14/200], Step [571/1067], D_A_loss: 0.1047, D_B_loss: 0.1187, G_A_loss: 0.7044, G_B_loss: 0.3814\n",
      "Epoch [14/200], Step [581/1067], D_A_loss: 0.0890, D_B_loss: 0.0522, G_A_loss: 0.5696, G_B_loss: 0.5739\n",
      "Epoch [14/200], Step [591/1067], D_A_loss: 0.1543, D_B_loss: 0.0409, G_A_loss: 0.6963, G_B_loss: 0.3269\n",
      "Epoch [14/200], Step [601/1067], D_A_loss: 0.0564, D_B_loss: 0.0436, G_A_loss: 0.6504, G_B_loss: 0.7542\n",
      "Epoch [14/200], Step [611/1067], D_A_loss: 0.1367, D_B_loss: 0.1535, G_A_loss: 0.3514, G_B_loss: 0.7636\n",
      "Epoch [14/200], Step [621/1067], D_A_loss: 0.2374, D_B_loss: 0.1256, G_A_loss: 0.3443, G_B_loss: 0.1845\n",
      "Epoch [14/200], Step [631/1067], D_A_loss: 0.0431, D_B_loss: 0.0503, G_A_loss: 0.6208, G_B_loss: 0.6572\n",
      "Epoch [14/200], Step [641/1067], D_A_loss: 0.1485, D_B_loss: 0.0191, G_A_loss: 0.8880, G_B_loss: 0.3966\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/200], Step [651/1067], D_A_loss: 0.1642, D_B_loss: 0.0261, G_A_loss: 0.8561, G_B_loss: 0.7378\n",
      "Epoch [14/200], Step [661/1067], D_A_loss: 0.0468, D_B_loss: 0.0817, G_A_loss: 0.5075, G_B_loss: 0.6364\n",
      "Epoch [14/200], Step [671/1067], D_A_loss: 0.1161, D_B_loss: 0.0198, G_A_loss: 0.7616, G_B_loss: 0.3386\n",
      "Epoch [14/200], Step [681/1067], D_A_loss: 0.2021, D_B_loss: 0.0406, G_A_loss: 0.5376, G_B_loss: 0.4360\n",
      "Epoch [14/200], Step [691/1067], D_A_loss: 0.0661, D_B_loss: 0.0401, G_A_loss: 1.0917, G_B_loss: 0.6091\n",
      "Epoch [14/200], Step [701/1067], D_A_loss: 0.1149, D_B_loss: 0.0588, G_A_loss: 0.8390, G_B_loss: 0.3590\n",
      "Epoch [14/200], Step [711/1067], D_A_loss: 0.1206, D_B_loss: 0.2314, G_A_loss: 0.2829, G_B_loss: 0.2046\n",
      "Epoch [14/200], Step [721/1067], D_A_loss: 0.1990, D_B_loss: 0.0235, G_A_loss: 0.3655, G_B_loss: 0.1978\n",
      "Epoch [14/200], Step [731/1067], D_A_loss: 0.1476, D_B_loss: 0.0692, G_A_loss: 0.7878, G_B_loss: 0.2705\n",
      "Epoch [14/200], Step [741/1067], D_A_loss: 0.1456, D_B_loss: 0.1771, G_A_loss: 1.2094, G_B_loss: 0.1540\n",
      "Epoch [14/200], Step [751/1067], D_A_loss: 0.0492, D_B_loss: 0.0620, G_A_loss: 0.6100, G_B_loss: 0.7215\n",
      "Epoch [14/200], Step [761/1067], D_A_loss: 0.0865, D_B_loss: 0.1532, G_A_loss: 0.3574, G_B_loss: 0.4733\n",
      "Epoch [14/200], Step [771/1067], D_A_loss: 0.0353, D_B_loss: 0.0598, G_A_loss: 0.2814, G_B_loss: 0.6715\n",
      "Epoch [14/200], Step [781/1067], D_A_loss: 0.3337, D_B_loss: 0.1038, G_A_loss: 0.5416, G_B_loss: 0.0826\n",
      "Epoch [14/200], Step [791/1067], D_A_loss: 0.1095, D_B_loss: 0.0884, G_A_loss: 0.4410, G_B_loss: 0.7376\n",
      "Epoch [14/200], Step [801/1067], D_A_loss: 0.1169, D_B_loss: 0.2114, G_A_loss: 0.3943, G_B_loss: 0.8113\n",
      "Epoch [14/200], Step [811/1067], D_A_loss: 0.1994, D_B_loss: 0.0470, G_A_loss: 0.4268, G_B_loss: 0.6015\n",
      "Epoch [14/200], Step [821/1067], D_A_loss: 0.1097, D_B_loss: 0.0369, G_A_loss: 0.8807, G_B_loss: 0.8367\n",
      "Epoch [14/200], Step [831/1067], D_A_loss: 0.1919, D_B_loss: 0.1524, G_A_loss: 0.5428, G_B_loss: 0.2106\n",
      "Epoch [14/200], Step [841/1067], D_A_loss: 0.0403, D_B_loss: 0.1237, G_A_loss: 1.2225, G_B_loss: 0.5146\n",
      "Epoch [14/200], Step [851/1067], D_A_loss: 0.0628, D_B_loss: 0.1807, G_A_loss: 0.2716, G_B_loss: 0.4205\n",
      "Epoch [14/200], Step [861/1067], D_A_loss: 0.0900, D_B_loss: 0.0315, G_A_loss: 0.7084, G_B_loss: 0.4216\n",
      "Epoch [14/200], Step [871/1067], D_A_loss: 0.1052, D_B_loss: 0.0517, G_A_loss: 0.9713, G_B_loss: 0.4583\n",
      "Epoch [14/200], Step [881/1067], D_A_loss: 0.0322, D_B_loss: 0.0228, G_A_loss: 0.6539, G_B_loss: 0.3937\n",
      "Epoch [14/200], Step [891/1067], D_A_loss: 0.0655, D_B_loss: 0.1662, G_A_loss: 0.8049, G_B_loss: 0.2901\n",
      "Epoch [14/200], Step [901/1067], D_A_loss: 0.2702, D_B_loss: 0.0262, G_A_loss: 0.9357, G_B_loss: 0.1874\n",
      "Epoch [14/200], Step [911/1067], D_A_loss: 0.1143, D_B_loss: 0.1291, G_A_loss: 0.4311, G_B_loss: 0.3641\n",
      "Epoch [14/200], Step [921/1067], D_A_loss: 0.0570, D_B_loss: 0.0269, G_A_loss: 0.8835, G_B_loss: 0.3068\n",
      "Epoch [14/200], Step [931/1067], D_A_loss: 0.0775, D_B_loss: 0.0794, G_A_loss: 0.8396, G_B_loss: 0.6906\n",
      "Epoch [14/200], Step [941/1067], D_A_loss: 0.2471, D_B_loss: 0.0759, G_A_loss: 0.0822, G_B_loss: 0.6412\n",
      "Epoch [14/200], Step [951/1067], D_A_loss: 0.1665, D_B_loss: 0.1138, G_A_loss: 0.5664, G_B_loss: 0.2157\n",
      "Epoch [14/200], Step [961/1067], D_A_loss: 0.1479, D_B_loss: 0.2152, G_A_loss: 0.7647, G_B_loss: 0.4400\n",
      "Epoch [14/200], Step [971/1067], D_A_loss: 0.0412, D_B_loss: 0.0867, G_A_loss: 0.4673, G_B_loss: 0.5713\n",
      "Epoch [14/200], Step [981/1067], D_A_loss: 0.2694, D_B_loss: 0.3134, G_A_loss: 0.4795, G_B_loss: 0.1449\n",
      "Epoch [14/200], Step [991/1067], D_A_loss: 0.0484, D_B_loss: 0.3530, G_A_loss: 0.9468, G_B_loss: 0.1417\n",
      "Epoch [14/200], Step [1001/1067], D_A_loss: 0.0487, D_B_loss: 0.0627, G_A_loss: 0.9334, G_B_loss: 0.6490\n",
      "Epoch [14/200], Step [1011/1067], D_A_loss: 0.0366, D_B_loss: 0.0592, G_A_loss: 0.6972, G_B_loss: 0.1998\n",
      "Epoch [14/200], Step [1021/1067], D_A_loss: 0.0319, D_B_loss: 0.0965, G_A_loss: 0.3125, G_B_loss: 0.1968\n",
      "Epoch [14/200], Step [1031/1067], D_A_loss: 0.1737, D_B_loss: 0.0530, G_A_loss: 0.8468, G_B_loss: 0.2259\n",
      "Epoch [14/200], Step [1041/1067], D_A_loss: 0.4563, D_B_loss: 0.2311, G_A_loss: 0.3384, G_B_loss: 0.0527\n",
      "Epoch [14/200], Step [1051/1067], D_A_loss: 0.0958, D_B_loss: 0.1126, G_A_loss: 0.6665, G_B_loss: 0.4676\n",
      "Epoch [14/200], Step [1061/1067], D_A_loss: 0.0328, D_B_loss: 0.0718, G_A_loss: 0.6873, G_B_loss: 0.6833\n",
      "Epoch [15/200], Step [1/1067], D_A_loss: 0.2863, D_B_loss: 0.1136, G_A_loss: 0.7420, G_B_loss: 0.1214\n",
      "Epoch [15/200], Step [11/1067], D_A_loss: 0.1460, D_B_loss: 0.1223, G_A_loss: 0.4206, G_B_loss: 0.6726\n",
      "Epoch [15/200], Step [21/1067], D_A_loss: 0.0160, D_B_loss: 0.0396, G_A_loss: 0.6045, G_B_loss: 0.3684\n",
      "Epoch [15/200], Step [31/1067], D_A_loss: 0.0725, D_B_loss: 0.0289, G_A_loss: 0.4744, G_B_loss: 0.3337\n",
      "Epoch [15/200], Step [41/1067], D_A_loss: 0.1363, D_B_loss: 0.0475, G_A_loss: 0.5764, G_B_loss: 0.5547\n",
      "Epoch [15/200], Step [51/1067], D_A_loss: 0.2227, D_B_loss: 0.1045, G_A_loss: 0.3192, G_B_loss: 1.1121\n",
      "Epoch [15/200], Step [61/1067], D_A_loss: 0.1032, D_B_loss: 0.1456, G_A_loss: 0.3980, G_B_loss: 0.4703\n",
      "Epoch [15/200], Step [71/1067], D_A_loss: 0.0369, D_B_loss: 0.1400, G_A_loss: 1.0580, G_B_loss: 0.9019\n",
      "Epoch [15/200], Step [81/1067], D_A_loss: 0.0909, D_B_loss: 0.0894, G_A_loss: 0.4652, G_B_loss: 0.6363\n",
      "Epoch [15/200], Step [91/1067], D_A_loss: 0.1706, D_B_loss: 0.1440, G_A_loss: 0.2904, G_B_loss: 0.2341\n",
      "Epoch [15/200], Step [101/1067], D_A_loss: 0.0650, D_B_loss: 0.0940, G_A_loss: 0.3198, G_B_loss: 0.2938\n",
      "Epoch [15/200], Step [111/1067], D_A_loss: 0.0821, D_B_loss: 0.0710, G_A_loss: 0.9294, G_B_loss: 0.2350\n",
      "Epoch [15/200], Step [121/1067], D_A_loss: 0.0504, D_B_loss: 0.0207, G_A_loss: 1.0309, G_B_loss: 0.2316\n",
      "Epoch [15/200], Step [131/1067], D_A_loss: 0.0792, D_B_loss: 0.2013, G_A_loss: 0.9847, G_B_loss: 0.3689\n",
      "Epoch [15/200], Step [141/1067], D_A_loss: 0.1162, D_B_loss: 0.0539, G_A_loss: 0.6957, G_B_loss: 0.5102\n",
      "Epoch [15/200], Step [151/1067], D_A_loss: 0.0361, D_B_loss: 0.0275, G_A_loss: 0.8196, G_B_loss: 0.9319\n",
      "Epoch [15/200], Step [161/1067], D_A_loss: 0.0470, D_B_loss: 0.1427, G_A_loss: 0.5261, G_B_loss: 0.9055\n",
      "Epoch [15/200], Step [171/1067], D_A_loss: 0.2807, D_B_loss: 0.0757, G_A_loss: 0.6253, G_B_loss: 0.4663\n",
      "Epoch [15/200], Step [181/1067], D_A_loss: 0.1606, D_B_loss: 0.0868, G_A_loss: 0.3986, G_B_loss: 0.3058\n",
      "Epoch [15/200], Step [191/1067], D_A_loss: 0.2966, D_B_loss: 0.0342, G_A_loss: 1.1058, G_B_loss: 0.0917\n",
      "Epoch [15/200], Step [201/1067], D_A_loss: 0.0543, D_B_loss: 0.0977, G_A_loss: 0.6373, G_B_loss: 0.1914\n",
      "Epoch [15/200], Step [211/1067], D_A_loss: 0.1125, D_B_loss: 0.0243, G_A_loss: 0.1951, G_B_loss: 0.5825\n",
      "Epoch [15/200], Step [221/1067], D_A_loss: 0.1149, D_B_loss: 0.0583, G_A_loss: 0.6371, G_B_loss: 0.6285\n",
      "Epoch [15/200], Step [231/1067], D_A_loss: 0.1309, D_B_loss: 0.0663, G_A_loss: 0.6205, G_B_loss: 0.2930\n",
      "Epoch [15/200], Step [241/1067], D_A_loss: 0.1146, D_B_loss: 0.0926, G_A_loss: 0.3967, G_B_loss: 0.3753\n",
      "Epoch [15/200], Step [251/1067], D_A_loss: 0.1831, D_B_loss: 0.1938, G_A_loss: 1.2958, G_B_loss: 0.2218\n",
      "Epoch [15/200], Step [261/1067], D_A_loss: 0.0472, D_B_loss: 0.0642, G_A_loss: 0.5693, G_B_loss: 0.7730\n",
      "Epoch [15/200], Step [271/1067], D_A_loss: 0.1037, D_B_loss: 0.0408, G_A_loss: 0.6033, G_B_loss: 0.2661\n",
      "Epoch [15/200], Step [281/1067], D_A_loss: 0.0791, D_B_loss: 0.0135, G_A_loss: 0.3901, G_B_loss: 0.6868\n",
      "Epoch [15/200], Step [291/1067], D_A_loss: 0.0861, D_B_loss: 0.0703, G_A_loss: 0.5218, G_B_loss: 0.5770\n",
      "Epoch [15/200], Step [301/1067], D_A_loss: 0.2734, D_B_loss: 0.1749, G_A_loss: 0.3492, G_B_loss: 0.1585\n",
      "Epoch [15/200], Step [311/1067], D_A_loss: 0.1183, D_B_loss: 0.0266, G_A_loss: 0.8250, G_B_loss: 1.3051\n",
      "Epoch [15/200], Step [321/1067], D_A_loss: 0.2025, D_B_loss: 0.0275, G_A_loss: 0.9665, G_B_loss: 0.2132\n",
      "Epoch [15/200], Step [331/1067], D_A_loss: 0.0209, D_B_loss: 0.1375, G_A_loss: 0.3960, G_B_loss: 0.5780\n",
      "Epoch [15/200], Step [341/1067], D_A_loss: 0.0858, D_B_loss: 0.0510, G_A_loss: 0.3921, G_B_loss: 0.5868\n",
      "Epoch [15/200], Step [351/1067], D_A_loss: 0.1089, D_B_loss: 0.0726, G_A_loss: 1.0346, G_B_loss: 0.3508\n",
      "Epoch [15/200], Step [361/1067], D_A_loss: 0.0508, D_B_loss: 0.0866, G_A_loss: 0.4361, G_B_loss: 0.4728\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/200], Step [371/1067], D_A_loss: 0.0478, D_B_loss: 0.0267, G_A_loss: 0.7895, G_B_loss: 0.7041\n",
      "Epoch [15/200], Step [381/1067], D_A_loss: 0.2151, D_B_loss: 0.0200, G_A_loss: 0.3287, G_B_loss: 0.3150\n",
      "Epoch [15/200], Step [391/1067], D_A_loss: 0.0313, D_B_loss: 0.1631, G_A_loss: 1.4358, G_B_loss: 0.7889\n",
      "Epoch [15/200], Step [401/1067], D_A_loss: 0.0527, D_B_loss: 0.0349, G_A_loss: 0.7679, G_B_loss: 0.6039\n",
      "Epoch [15/200], Step [411/1067], D_A_loss: 0.0965, D_B_loss: 0.1692, G_A_loss: 0.9230, G_B_loss: 0.8616\n",
      "Epoch [15/200], Step [421/1067], D_A_loss: 0.1088, D_B_loss: 0.0277, G_A_loss: 0.6896, G_B_loss: 0.3817\n",
      "Epoch [15/200], Step [431/1067], D_A_loss: 0.0763, D_B_loss: 0.0619, G_A_loss: 0.4850, G_B_loss: 0.5715\n",
      "Epoch [15/200], Step [441/1067], D_A_loss: 0.2587, D_B_loss: 0.0279, G_A_loss: 0.6373, G_B_loss: 0.4028\n",
      "Epoch [15/200], Step [451/1067], D_A_loss: 0.0329, D_B_loss: 0.0904, G_A_loss: 0.5683, G_B_loss: 0.6838\n",
      "Epoch [15/200], Step [461/1067], D_A_loss: 0.1383, D_B_loss: 0.0269, G_A_loss: 0.1901, G_B_loss: 0.6151\n",
      "Epoch [15/200], Step [471/1067], D_A_loss: 0.0669, D_B_loss: 0.1496, G_A_loss: 0.9398, G_B_loss: 0.9480\n",
      "Epoch [15/200], Step [481/1067], D_A_loss: 0.0782, D_B_loss: 0.0423, G_A_loss: 0.6233, G_B_loss: 0.4326\n",
      "Epoch [15/200], Step [491/1067], D_A_loss: 0.1479, D_B_loss: 0.1300, G_A_loss: 0.4010, G_B_loss: 0.2929\n",
      "Epoch [15/200], Step [501/1067], D_A_loss: 0.0834, D_B_loss: 0.0614, G_A_loss: 0.9119, G_B_loss: 0.5199\n",
      "Epoch [15/200], Step [511/1067], D_A_loss: 0.1535, D_B_loss: 0.1348, G_A_loss: 0.5603, G_B_loss: 0.9343\n",
      "Epoch [15/200], Step [521/1067], D_A_loss: 0.0528, D_B_loss: 0.1044, G_A_loss: 0.8594, G_B_loss: 0.5563\n",
      "Epoch [15/200], Step [531/1067], D_A_loss: 0.1431, D_B_loss: 0.0589, G_A_loss: 0.6361, G_B_loss: 0.1424\n",
      "Epoch [15/200], Step [541/1067], D_A_loss: 0.2471, D_B_loss: 0.1517, G_A_loss: 0.2282, G_B_loss: 0.4521\n",
      "Epoch [15/200], Step [551/1067], D_A_loss: 0.1261, D_B_loss: 0.0261, G_A_loss: 0.4093, G_B_loss: 0.9697\n",
      "Epoch [15/200], Step [561/1067], D_A_loss: 0.0569, D_B_loss: 0.0364, G_A_loss: 0.5720, G_B_loss: 0.7915\n",
      "Epoch [15/200], Step [571/1067], D_A_loss: 0.2331, D_B_loss: 0.0981, G_A_loss: 0.3803, G_B_loss: 0.5216\n",
      "Epoch [15/200], Step [581/1067], D_A_loss: 0.0613, D_B_loss: 0.0729, G_A_loss: 0.5885, G_B_loss: 0.3990\n",
      "Epoch [15/200], Step [591/1067], D_A_loss: 0.1518, D_B_loss: 0.0273, G_A_loss: 0.7057, G_B_loss: 0.4964\n",
      "Epoch [15/200], Step [601/1067], D_A_loss: 0.0583, D_B_loss: 0.1011, G_A_loss: 0.3987, G_B_loss: 0.2754\n",
      "Epoch [15/200], Step [611/1067], D_A_loss: 0.1258, D_B_loss: 0.0574, G_A_loss: 0.9064, G_B_loss: 0.3489\n",
      "Epoch [15/200], Step [621/1067], D_A_loss: 0.2074, D_B_loss: 0.1666, G_A_loss: 0.6957, G_B_loss: 0.4116\n",
      "Epoch [15/200], Step [631/1067], D_A_loss: 0.0812, D_B_loss: 0.0364, G_A_loss: 0.5965, G_B_loss: 0.6290\n",
      "Epoch [15/200], Step [641/1067], D_A_loss: 0.0881, D_B_loss: 0.1345, G_A_loss: 0.6560, G_B_loss: 0.5571\n",
      "Epoch [15/200], Step [651/1067], D_A_loss: 0.0874, D_B_loss: 0.0390, G_A_loss: 0.8839, G_B_loss: 0.4591\n",
      "Epoch [15/200], Step [661/1067], D_A_loss: 0.1062, D_B_loss: 0.0465, G_A_loss: 0.8373, G_B_loss: 0.3750\n",
      "Epoch [15/200], Step [671/1067], D_A_loss: 0.0773, D_B_loss: 0.0651, G_A_loss: 0.6783, G_B_loss: 0.7661\n",
      "Epoch [15/200], Step [681/1067], D_A_loss: 0.2495, D_B_loss: 0.1411, G_A_loss: 1.0477, G_B_loss: 0.5724\n",
      "Epoch [15/200], Step [691/1067], D_A_loss: 0.3382, D_B_loss: 0.0930, G_A_loss: 0.6399, G_B_loss: 0.1486\n",
      "Epoch [15/200], Step [701/1067], D_A_loss: 0.2424, D_B_loss: 0.0517, G_A_loss: 0.5126, G_B_loss: 0.2754\n",
      "Epoch [15/200], Step [711/1067], D_A_loss: 0.1830, D_B_loss: 0.0244, G_A_loss: 0.5435, G_B_loss: 0.2118\n",
      "Epoch [15/200], Step [721/1067], D_A_loss: 0.0587, D_B_loss: 0.1032, G_A_loss: 0.5081, G_B_loss: 0.5935\n",
      "Epoch [15/200], Step [731/1067], D_A_loss: 0.1346, D_B_loss: 0.0292, G_A_loss: 0.4276, G_B_loss: 0.6644\n",
      "Epoch [15/200], Step [741/1067], D_A_loss: 0.0930, D_B_loss: 0.0610, G_A_loss: 0.6349, G_B_loss: 0.5816\n",
      "Epoch [15/200], Step [751/1067], D_A_loss: 0.0706, D_B_loss: 0.0320, G_A_loss: 0.7522, G_B_loss: 0.3763\n",
      "Epoch [15/200], Step [761/1067], D_A_loss: 0.0789, D_B_loss: 0.0802, G_A_loss: 0.6742, G_B_loss: 0.5490\n",
      "Epoch [15/200], Step [771/1067], D_A_loss: 0.1062, D_B_loss: 0.0247, G_A_loss: 0.9804, G_B_loss: 0.3993\n",
      "Epoch [15/200], Step [781/1067], D_A_loss: 0.1215, D_B_loss: 0.0549, G_A_loss: 0.6940, G_B_loss: 0.3473\n",
      "Epoch [15/200], Step [791/1067], D_A_loss: 0.2525, D_B_loss: 0.0247, G_A_loss: 0.9879, G_B_loss: 0.1563\n",
      "Epoch [15/200], Step [801/1067], D_A_loss: 0.1634, D_B_loss: 0.1823, G_A_loss: 0.2797, G_B_loss: 0.4969\n",
      "Epoch [15/200], Step [811/1067], D_A_loss: 0.0879, D_B_loss: 0.1683, G_A_loss: 0.2911, G_B_loss: 0.4981\n",
      "Epoch [15/200], Step [821/1067], D_A_loss: 0.0665, D_B_loss: 0.0220, G_A_loss: 0.9190, G_B_loss: 0.6814\n",
      "Epoch [15/200], Step [831/1067], D_A_loss: 0.0407, D_B_loss: 0.0339, G_A_loss: 0.6172, G_B_loss: 0.3868\n",
      "Epoch [15/200], Step [841/1067], D_A_loss: 0.1536, D_B_loss: 0.0529, G_A_loss: 0.5872, G_B_loss: 0.9014\n",
      "Epoch [15/200], Step [851/1067], D_A_loss: 0.1339, D_B_loss: 0.0510, G_A_loss: 0.7429, G_B_loss: 0.3073\n",
      "Epoch [15/200], Step [861/1067], D_A_loss: 0.0657, D_B_loss: 0.0727, G_A_loss: 0.7251, G_B_loss: 0.4358\n",
      "Epoch [15/200], Step [871/1067], D_A_loss: 0.0656, D_B_loss: 0.1334, G_A_loss: 0.5962, G_B_loss: 0.5373\n",
      "Epoch [15/200], Step [881/1067], D_A_loss: 0.0466, D_B_loss: 0.1641, G_A_loss: 0.3145, G_B_loss: 1.0919\n",
      "Epoch [15/200], Step [891/1067], D_A_loss: 0.0424, D_B_loss: 0.0812, G_A_loss: 0.4130, G_B_loss: 0.6905\n",
      "Epoch [15/200], Step [901/1067], D_A_loss: 0.0361, D_B_loss: 0.0977, G_A_loss: 0.6247, G_B_loss: 0.5993\n",
      "Epoch [15/200], Step [911/1067], D_A_loss: 0.0869, D_B_loss: 0.1303, G_A_loss: 0.3967, G_B_loss: 0.2374\n",
      "Epoch [15/200], Step [921/1067], D_A_loss: 0.1190, D_B_loss: 0.0330, G_A_loss: 0.8618, G_B_loss: 0.3565\n",
      "Epoch [15/200], Step [931/1067], D_A_loss: 0.1063, D_B_loss: 0.1442, G_A_loss: 0.3825, G_B_loss: 0.5309\n",
      "Epoch [15/200], Step [941/1067], D_A_loss: 0.3363, D_B_loss: 0.0375, G_A_loss: 0.7333, G_B_loss: 0.8059\n",
      "Epoch [15/200], Step [951/1067], D_A_loss: 0.0676, D_B_loss: 0.2360, G_A_loss: 1.2801, G_B_loss: 0.8181\n",
      "Epoch [15/200], Step [961/1067], D_A_loss: 0.1096, D_B_loss: 0.0287, G_A_loss: 0.4573, G_B_loss: 1.1228\n",
      "Epoch [15/200], Step [971/1067], D_A_loss: 0.0754, D_B_loss: 0.0369, G_A_loss: 1.0704, G_B_loss: 0.5973\n",
      "Epoch [15/200], Step [981/1067], D_A_loss: 0.1525, D_B_loss: 0.0743, G_A_loss: 0.5645, G_B_loss: 0.4948\n",
      "Epoch [15/200], Step [991/1067], D_A_loss: 0.1377, D_B_loss: 0.0288, G_A_loss: 0.6673, G_B_loss: 0.6661\n",
      "Epoch [15/200], Step [1001/1067], D_A_loss: 0.0463, D_B_loss: 0.0860, G_A_loss: 0.5599, G_B_loss: 0.2862\n",
      "Epoch [15/200], Step [1011/1067], D_A_loss: 0.1100, D_B_loss: 0.0620, G_A_loss: 0.7319, G_B_loss: 0.5385\n",
      "Epoch [15/200], Step [1021/1067], D_A_loss: 0.0850, D_B_loss: 0.0365, G_A_loss: 0.6883, G_B_loss: 0.6973\n",
      "Epoch [15/200], Step [1031/1067], D_A_loss: 0.1544, D_B_loss: 0.0899, G_A_loss: 0.4290, G_B_loss: 0.2883\n",
      "Epoch [15/200], Step [1041/1067], D_A_loss: 0.1387, D_B_loss: 0.0590, G_A_loss: 0.5752, G_B_loss: 0.6047\n",
      "Epoch [15/200], Step [1051/1067], D_A_loss: 0.1061, D_B_loss: 0.0494, G_A_loss: 0.5745, G_B_loss: 0.6197\n",
      "Epoch [15/200], Step [1061/1067], D_A_loss: 0.0956, D_B_loss: 0.0798, G_A_loss: 0.7739, G_B_loss: 0.2417\n",
      "Epoch [16/200], Step [1/1067], D_A_loss: 0.0550, D_B_loss: 0.0642, G_A_loss: 0.5271, G_B_loss: 0.3303\n",
      "Epoch [16/200], Step [11/1067], D_A_loss: 0.1983, D_B_loss: 0.0526, G_A_loss: 1.0222, G_B_loss: 0.9004\n",
      "Epoch [16/200], Step [21/1067], D_A_loss: 0.1882, D_B_loss: 0.1345, G_A_loss: 1.5417, G_B_loss: 0.3208\n",
      "Epoch [16/200], Step [31/1067], D_A_loss: 0.1701, D_B_loss: 0.0970, G_A_loss: 0.2112, G_B_loss: 0.2174\n",
      "Epoch [16/200], Step [41/1067], D_A_loss: 0.0814, D_B_loss: 0.0532, G_A_loss: 0.6574, G_B_loss: 0.5073\n",
      "Epoch [16/200], Step [51/1067], D_A_loss: 0.0541, D_B_loss: 0.4339, G_A_loss: 0.4852, G_B_loss: 0.2516\n",
      "Epoch [16/200], Step [61/1067], D_A_loss: 0.0744, D_B_loss: 0.1857, G_A_loss: 0.2598, G_B_loss: 0.4362\n",
      "Epoch [16/200], Step [71/1067], D_A_loss: 0.0808, D_B_loss: 0.0507, G_A_loss: 0.5655, G_B_loss: 0.5249\n",
      "Epoch [16/200], Step [81/1067], D_A_loss: 0.1177, D_B_loss: 0.0421, G_A_loss: 0.6277, G_B_loss: 0.3615\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/200], Step [91/1067], D_A_loss: 0.2375, D_B_loss: 0.0686, G_A_loss: 0.6157, G_B_loss: 0.8648\n",
      "Epoch [16/200], Step [101/1067], D_A_loss: 0.0329, D_B_loss: 0.0951, G_A_loss: 1.3073, G_B_loss: 0.7010\n",
      "Epoch [16/200], Step [111/1067], D_A_loss: 0.1159, D_B_loss: 0.0441, G_A_loss: 0.8851, G_B_loss: 0.2320\n",
      "Epoch [16/200], Step [121/1067], D_A_loss: 0.0298, D_B_loss: 0.1774, G_A_loss: 0.9435, G_B_loss: 0.4023\n",
      "Epoch [16/200], Step [131/1067], D_A_loss: 0.1186, D_B_loss: 0.0264, G_A_loss: 0.5000, G_B_loss: 0.5027\n",
      "Epoch [16/200], Step [141/1067], D_A_loss: 0.0673, D_B_loss: 0.1756, G_A_loss: 0.7411, G_B_loss: 0.3113\n",
      "Epoch [16/200], Step [151/1067], D_A_loss: 0.3744, D_B_loss: 0.0670, G_A_loss: 0.5734, G_B_loss: 0.9509\n",
      "Epoch [16/200], Step [161/1067], D_A_loss: 0.0509, D_B_loss: 0.0759, G_A_loss: 1.2931, G_B_loss: 0.5654\n",
      "Epoch [16/200], Step [171/1067], D_A_loss: 0.2756, D_B_loss: 0.0335, G_A_loss: 0.8744, G_B_loss: 0.3764\n",
      "Epoch [16/200], Step [181/1067], D_A_loss: 0.1760, D_B_loss: 0.0272, G_A_loss: 0.7256, G_B_loss: 0.3933\n",
      "Epoch [16/200], Step [191/1067], D_A_loss: 0.0969, D_B_loss: 0.0569, G_A_loss: 0.4026, G_B_loss: 0.5794\n",
      "Epoch [16/200], Step [201/1067], D_A_loss: 0.1028, D_B_loss: 0.0933, G_A_loss: 0.6246, G_B_loss: 0.6533\n",
      "Epoch [16/200], Step [211/1067], D_A_loss: 0.2327, D_B_loss: 0.0930, G_A_loss: 0.4497, G_B_loss: 0.3849\n",
      "Epoch [16/200], Step [221/1067], D_A_loss: 0.0916, D_B_loss: 0.0498, G_A_loss: 0.5972, G_B_loss: 0.2208\n",
      "Epoch [16/200], Step [231/1067], D_A_loss: 0.0518, D_B_loss: 0.0167, G_A_loss: 0.7104, G_B_loss: 0.6202\n",
      "Epoch [16/200], Step [241/1067], D_A_loss: 0.1053, D_B_loss: 0.0167, G_A_loss: 0.2154, G_B_loss: 1.0483\n",
      "Epoch [16/200], Step [251/1067], D_A_loss: 0.0311, D_B_loss: 0.1263, G_A_loss: 0.3812, G_B_loss: 0.7774\n",
      "Epoch [16/200], Step [261/1067], D_A_loss: 0.0586, D_B_loss: 0.1287, G_A_loss: 0.7218, G_B_loss: 0.6964\n",
      "Epoch [16/200], Step [271/1067], D_A_loss: 0.1373, D_B_loss: 0.0412, G_A_loss: 0.3991, G_B_loss: 0.3960\n",
      "Epoch [16/200], Step [281/1067], D_A_loss: 0.1414, D_B_loss: 0.0356, G_A_loss: 0.6959, G_B_loss: 0.8183\n",
      "Epoch [16/200], Step [291/1067], D_A_loss: 0.1821, D_B_loss: 0.0555, G_A_loss: 0.6127, G_B_loss: 0.5504\n",
      "Epoch [16/200], Step [301/1067], D_A_loss: 0.1500, D_B_loss: 0.1324, G_A_loss: 0.2949, G_B_loss: 0.8101\n",
      "Epoch [16/200], Step [311/1067], D_A_loss: 0.0255, D_B_loss: 0.1331, G_A_loss: 0.7468, G_B_loss: 0.6216\n",
      "Epoch [16/200], Step [321/1067], D_A_loss: 0.0891, D_B_loss: 0.0381, G_A_loss: 0.9282, G_B_loss: 0.1325\n",
      "Epoch [16/200], Step [331/1067], D_A_loss: 0.1536, D_B_loss: 0.0786, G_A_loss: 0.4465, G_B_loss: 0.7119\n",
      "Epoch [16/200], Step [341/1067], D_A_loss: 0.0303, D_B_loss: 0.1059, G_A_loss: 0.3646, G_B_loss: 0.5708\n",
      "Epoch [16/200], Step [351/1067], D_A_loss: 0.1018, D_B_loss: 0.0538, G_A_loss: 0.3997, G_B_loss: 0.3572\n",
      "Epoch [16/200], Step [361/1067], D_A_loss: 0.0543, D_B_loss: 0.1746, G_A_loss: 0.5472, G_B_loss: 0.4439\n",
      "Epoch [16/200], Step [371/1067], D_A_loss: 0.1437, D_B_loss: 0.0582, G_A_loss: 0.5937, G_B_loss: 0.7012\n",
      "Epoch [16/200], Step [381/1067], D_A_loss: 0.1847, D_B_loss: 0.0390, G_A_loss: 0.6363, G_B_loss: 0.8059\n",
      "Epoch [16/200], Step [391/1067], D_A_loss: 0.0803, D_B_loss: 0.0518, G_A_loss: 0.6341, G_B_loss: 0.6681\n",
      "Epoch [16/200], Step [401/1067], D_A_loss: 0.1454, D_B_loss: 0.5350, G_A_loss: 1.6745, G_B_loss: 0.2748\n",
      "Epoch [16/200], Step [411/1067], D_A_loss: 0.2954, D_B_loss: 0.0669, G_A_loss: 0.2282, G_B_loss: 0.1565\n",
      "Epoch [16/200], Step [421/1067], D_A_loss: 0.0807, D_B_loss: 0.0410, G_A_loss: 0.6613, G_B_loss: 0.6682\n",
      "Epoch [16/200], Step [431/1067], D_A_loss: 0.1367, D_B_loss: 0.0360, G_A_loss: 0.4365, G_B_loss: 0.2985\n",
      "Epoch [16/200], Step [441/1067], D_A_loss: 0.1600, D_B_loss: 0.1891, G_A_loss: 0.2388, G_B_loss: 0.5379\n",
      "Epoch [16/200], Step [451/1067], D_A_loss: 0.0719, D_B_loss: 0.0253, G_A_loss: 0.8358, G_B_loss: 0.5618\n",
      "Epoch [16/200], Step [461/1067], D_A_loss: 0.0399, D_B_loss: 0.0674, G_A_loss: 0.3762, G_B_loss: 0.2455\n",
      "Epoch [16/200], Step [471/1067], D_A_loss: 0.1555, D_B_loss: 0.1249, G_A_loss: 0.6245, G_B_loss: 0.3386\n",
      "Epoch [16/200], Step [481/1067], D_A_loss: 0.1156, D_B_loss: 0.0435, G_A_loss: 0.7655, G_B_loss: 0.3948\n",
      "Epoch [16/200], Step [491/1067], D_A_loss: 0.0329, D_B_loss: 0.1446, G_A_loss: 0.4329, G_B_loss: 0.2753\n",
      "Epoch [16/200], Step [501/1067], D_A_loss: 0.0561, D_B_loss: 0.2009, G_A_loss: 0.2058, G_B_loss: 0.5440\n",
      "Epoch [16/200], Step [511/1067], D_A_loss: 0.2169, D_B_loss: 0.0441, G_A_loss: 0.8183, G_B_loss: 0.1650\n",
      "Epoch [16/200], Step [521/1067], D_A_loss: 0.0620, D_B_loss: 0.1515, G_A_loss: 0.5777, G_B_loss: 0.9174\n",
      "Epoch [16/200], Step [531/1067], D_A_loss: 0.1078, D_B_loss: 0.0360, G_A_loss: 0.9133, G_B_loss: 0.3671\n",
      "Epoch [16/200], Step [541/1067], D_A_loss: 0.1252, D_B_loss: 0.1596, G_A_loss: 0.8795, G_B_loss: 0.3819\n",
      "Epoch [16/200], Step [551/1067], D_A_loss: 0.0886, D_B_loss: 0.0519, G_A_loss: 0.6054, G_B_loss: 0.2456\n",
      "Epoch [16/200], Step [561/1067], D_A_loss: 0.0418, D_B_loss: 0.0410, G_A_loss: 0.6364, G_B_loss: 0.4614\n",
      "Epoch [16/200], Step [571/1067], D_A_loss: 0.1082, D_B_loss: 0.2499, G_A_loss: 0.1307, G_B_loss: 0.4146\n",
      "Epoch [16/200], Step [581/1067], D_A_loss: 0.0705, D_B_loss: 0.1702, G_A_loss: 0.6450, G_B_loss: 0.5037\n",
      "Epoch [16/200], Step [591/1067], D_A_loss: 0.1147, D_B_loss: 0.0741, G_A_loss: 1.1453, G_B_loss: 0.3572\n",
      "Epoch [16/200], Step [601/1067], D_A_loss: 0.0762, D_B_loss: 0.0275, G_A_loss: 0.6314, G_B_loss: 0.2893\n",
      "Epoch [16/200], Step [611/1067], D_A_loss: 0.0637, D_B_loss: 0.1212, G_A_loss: 0.5779, G_B_loss: 0.6970\n",
      "Epoch [16/200], Step [621/1067], D_A_loss: 0.0730, D_B_loss: 0.0320, G_A_loss: 0.3919, G_B_loss: 0.3590\n",
      "Epoch [16/200], Step [631/1067], D_A_loss: 0.1691, D_B_loss: 0.1262, G_A_loss: 0.8000, G_B_loss: 0.2728\n",
      "Epoch [16/200], Step [641/1067], D_A_loss: 0.1875, D_B_loss: 0.0961, G_A_loss: 0.3904, G_B_loss: 0.7617\n",
      "Epoch [16/200], Step [651/1067], D_A_loss: 0.1611, D_B_loss: 0.0314, G_A_loss: 0.4003, G_B_loss: 0.2542\n",
      "Epoch [16/200], Step [661/1067], D_A_loss: 0.1078, D_B_loss: 0.0370, G_A_loss: 0.3035, G_B_loss: 0.5017\n",
      "Epoch [16/200], Step [671/1067], D_A_loss: 0.0616, D_B_loss: 0.0144, G_A_loss: 0.6849, G_B_loss: 0.7174\n",
      "Epoch [16/200], Step [681/1067], D_A_loss: 0.0905, D_B_loss: 0.0570, G_A_loss: 0.6224, G_B_loss: 0.3489\n",
      "Epoch [16/200], Step [691/1067], D_A_loss: 0.0332, D_B_loss: 0.0495, G_A_loss: 0.6081, G_B_loss: 0.5352\n",
      "Epoch [16/200], Step [701/1067], D_A_loss: 0.0729, D_B_loss: 0.0473, G_A_loss: 0.9601, G_B_loss: 0.4190\n",
      "Epoch [16/200], Step [711/1067], D_A_loss: 0.1165, D_B_loss: 0.0308, G_A_loss: 0.6882, G_B_loss: 0.9857\n",
      "Epoch [16/200], Step [721/1067], D_A_loss: 0.0415, D_B_loss: 0.0217, G_A_loss: 0.8877, G_B_loss: 0.6363\n",
      "Epoch [16/200], Step [731/1067], D_A_loss: 0.0868, D_B_loss: 0.1482, G_A_loss: 0.3236, G_B_loss: 0.3768\n",
      "Epoch [16/200], Step [741/1067], D_A_loss: 0.2298, D_B_loss: 0.0495, G_A_loss: 0.7019, G_B_loss: 0.1991\n",
      "Epoch [16/200], Step [751/1067], D_A_loss: 0.1415, D_B_loss: 0.0165, G_A_loss: 0.5976, G_B_loss: 0.6507\n",
      "Epoch [16/200], Step [761/1067], D_A_loss: 0.0338, D_B_loss: 0.0184, G_A_loss: 0.4084, G_B_loss: 0.5974\n",
      "Epoch [16/200], Step [771/1067], D_A_loss: 0.1300, D_B_loss: 0.0362, G_A_loss: 0.6701, G_B_loss: 0.3962\n",
      "Epoch [16/200], Step [781/1067], D_A_loss: 0.1117, D_B_loss: 0.0350, G_A_loss: 0.7505, G_B_loss: 0.6685\n",
      "Epoch [16/200], Step [791/1067], D_A_loss: 0.1347, D_B_loss: 0.0701, G_A_loss: 0.4611, G_B_loss: 0.5066\n",
      "Epoch [16/200], Step [801/1067], D_A_loss: 0.0396, D_B_loss: 0.0818, G_A_loss: 0.7283, G_B_loss: 0.1851\n",
      "Epoch [16/200], Step [811/1067], D_A_loss: 0.0308, D_B_loss: 0.0452, G_A_loss: 0.5692, G_B_loss: 0.4869\n",
      "Epoch [16/200], Step [821/1067], D_A_loss: 0.1071, D_B_loss: 0.1239, G_A_loss: 0.6924, G_B_loss: 0.3963\n",
      "Epoch [16/200], Step [831/1067], D_A_loss: 0.1451, D_B_loss: 0.1405, G_A_loss: 0.4609, G_B_loss: 0.4980\n",
      "Epoch [16/200], Step [841/1067], D_A_loss: 0.0676, D_B_loss: 0.3808, G_A_loss: 1.0012, G_B_loss: 0.3461\n",
      "Epoch [16/200], Step [851/1067], D_A_loss: 0.0448, D_B_loss: 0.0563, G_A_loss: 0.1214, G_B_loss: 0.8578\n",
      "Epoch [16/200], Step [861/1067], D_A_loss: 0.0896, D_B_loss: 0.0349, G_A_loss: 0.3868, G_B_loss: 0.3457\n",
      "Epoch [16/200], Step [871/1067], D_A_loss: 0.1329, D_B_loss: 0.0595, G_A_loss: 0.5261, G_B_loss: 0.8362\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/200], Step [881/1067], D_A_loss: 0.0837, D_B_loss: 0.1577, G_A_loss: 0.5937, G_B_loss: 0.9447\n",
      "Epoch [16/200], Step [891/1067], D_A_loss: 0.1575, D_B_loss: 0.0636, G_A_loss: 0.7961, G_B_loss: 0.3391\n",
      "Epoch [16/200], Step [901/1067], D_A_loss: 0.1648, D_B_loss: 0.0419, G_A_loss: 0.4434, G_B_loss: 0.2947\n",
      "Epoch [16/200], Step [911/1067], D_A_loss: 0.0487, D_B_loss: 0.0364, G_A_loss: 0.6613, G_B_loss: 0.7910\n",
      "Epoch [16/200], Step [921/1067], D_A_loss: 0.0566, D_B_loss: 0.1996, G_A_loss: 0.1744, G_B_loss: 0.6789\n",
      "Epoch [16/200], Step [931/1067], D_A_loss: 0.0274, D_B_loss: 0.0538, G_A_loss: 1.0087, G_B_loss: 0.9440\n",
      "Epoch [16/200], Step [941/1067], D_A_loss: 0.1329, D_B_loss: 0.0362, G_A_loss: 0.4483, G_B_loss: 0.8317\n",
      "Epoch [16/200], Step [951/1067], D_A_loss: 0.1375, D_B_loss: 0.0848, G_A_loss: 0.4701, G_B_loss: 0.6055\n",
      "Epoch [16/200], Step [961/1067], D_A_loss: 0.1318, D_B_loss: 0.0706, G_A_loss: 1.0031, G_B_loss: 0.3009\n",
      "Epoch [16/200], Step [971/1067], D_A_loss: 0.0512, D_B_loss: 0.1670, G_A_loss: 0.3575, G_B_loss: 0.7138\n",
      "Epoch [16/200], Step [981/1067], D_A_loss: 0.1503, D_B_loss: 0.0402, G_A_loss: 0.7785, G_B_loss: 0.9068\n",
      "Epoch [16/200], Step [991/1067], D_A_loss: 0.0919, D_B_loss: 0.0169, G_A_loss: 0.5293, G_B_loss: 0.5124\n",
      "Epoch [16/200], Step [1001/1067], D_A_loss: 0.0545, D_B_loss: 0.0525, G_A_loss: 0.7413, G_B_loss: 0.7293\n",
      "Epoch [16/200], Step [1011/1067], D_A_loss: 0.1379, D_B_loss: 0.0915, G_A_loss: 0.4195, G_B_loss: 0.3685\n",
      "Epoch [16/200], Step [1021/1067], D_A_loss: 0.0649, D_B_loss: 0.0946, G_A_loss: 0.5110, G_B_loss: 0.5507\n",
      "Epoch [16/200], Step [1031/1067], D_A_loss: 0.0374, D_B_loss: 0.0685, G_A_loss: 0.6336, G_B_loss: 0.6012\n",
      "Epoch [16/200], Step [1041/1067], D_A_loss: 0.2029, D_B_loss: 0.0796, G_A_loss: 0.4894, G_B_loss: 0.6845\n",
      "Epoch [16/200], Step [1051/1067], D_A_loss: 0.2350, D_B_loss: 0.0907, G_A_loss: 0.4279, G_B_loss: 0.6008\n",
      "Epoch [16/200], Step [1061/1067], D_A_loss: 0.0543, D_B_loss: 0.1577, G_A_loss: 0.3011, G_B_loss: 1.1293\n",
      "Epoch [17/200], Step [1/1067], D_A_loss: 0.1752, D_B_loss: 0.0576, G_A_loss: 0.3249, G_B_loss: 0.4789\n",
      "Epoch [17/200], Step [11/1067], D_A_loss: 0.0732, D_B_loss: 0.0487, G_A_loss: 0.7684, G_B_loss: 1.0174\n",
      "Epoch [17/200], Step [21/1067], D_A_loss: 0.1611, D_B_loss: 0.0565, G_A_loss: 0.4903, G_B_loss: 0.3077\n",
      "Epoch [17/200], Step [31/1067], D_A_loss: 0.0873, D_B_loss: 0.0730, G_A_loss: 0.8933, G_B_loss: 0.8860\n",
      "Epoch [17/200], Step [41/1067], D_A_loss: 0.1049, D_B_loss: 0.1192, G_A_loss: 0.6044, G_B_loss: 0.4054\n",
      "Epoch [17/200], Step [51/1067], D_A_loss: 0.0877, D_B_loss: 0.0512, G_A_loss: 0.7609, G_B_loss: 1.1274\n",
      "Epoch [17/200], Step [61/1067], D_A_loss: 0.0403, D_B_loss: 0.0834, G_A_loss: 0.7599, G_B_loss: 0.8778\n",
      "Epoch [17/200], Step [71/1067], D_A_loss: 0.2580, D_B_loss: 0.0901, G_A_loss: 0.9136, G_B_loss: 0.5456\n",
      "Epoch [17/200], Step [81/1067], D_A_loss: 0.0465, D_B_loss: 0.0873, G_A_loss: 0.8552, G_B_loss: 0.8100\n",
      "Epoch [17/200], Step [91/1067], D_A_loss: 0.1050, D_B_loss: 0.0785, G_A_loss: 0.4386, G_B_loss: 0.4809\n",
      "Epoch [17/200], Step [101/1067], D_A_loss: 0.0287, D_B_loss: 0.0314, G_A_loss: 0.7912, G_B_loss: 0.3280\n",
      "Epoch [17/200], Step [111/1067], D_A_loss: 0.0523, D_B_loss: 0.2050, G_A_loss: 0.2691, G_B_loss: 0.4022\n",
      "Epoch [17/200], Step [121/1067], D_A_loss: 0.1969, D_B_loss: 0.0704, G_A_loss: 0.7177, G_B_loss: 1.1343\n",
      "Epoch [17/200], Step [131/1067], D_A_loss: 0.1666, D_B_loss: 0.0263, G_A_loss: 0.2676, G_B_loss: 0.2598\n",
      "Epoch [17/200], Step [141/1067], D_A_loss: 0.1181, D_B_loss: 0.0512, G_A_loss: 0.5902, G_B_loss: 0.3375\n",
      "Epoch [17/200], Step [151/1067], D_A_loss: 0.0975, D_B_loss: 0.1429, G_A_loss: 1.0395, G_B_loss: 0.5250\n",
      "Epoch [17/200], Step [161/1067], D_A_loss: 0.4858, D_B_loss: 0.0771, G_A_loss: 0.9260, G_B_loss: 1.0725\n",
      "Epoch [17/200], Step [171/1067], D_A_loss: 0.1269, D_B_loss: 0.0689, G_A_loss: 0.5220, G_B_loss: 0.5073\n",
      "Epoch [17/200], Step [181/1067], D_A_loss: 0.2548, D_B_loss: 0.0873, G_A_loss: 0.5231, G_B_loss: 0.8446\n",
      "Epoch [17/200], Step [191/1067], D_A_loss: 0.1262, D_B_loss: 0.1298, G_A_loss: 0.3284, G_B_loss: 0.7545\n",
      "Epoch [17/200], Step [201/1067], D_A_loss: 0.1084, D_B_loss: 0.0519, G_A_loss: 0.5807, G_B_loss: 0.5424\n",
      "Epoch [17/200], Step [211/1067], D_A_loss: 0.2466, D_B_loss: 0.0784, G_A_loss: 0.6840, G_B_loss: 0.3562\n",
      "Epoch [17/200], Step [221/1067], D_A_loss: 0.1510, D_B_loss: 0.1401, G_A_loss: 0.7265, G_B_loss: 0.4173\n",
      "Epoch [17/200], Step [231/1067], D_A_loss: 0.0887, D_B_loss: 0.1181, G_A_loss: 0.3227, G_B_loss: 0.5708\n",
      "Epoch [17/200], Step [241/1067], D_A_loss: 0.2159, D_B_loss: 0.0570, G_A_loss: 0.3144, G_B_loss: 1.1650\n",
      "Epoch [17/200], Step [251/1067], D_A_loss: 0.0784, D_B_loss: 0.2577, G_A_loss: 0.6160, G_B_loss: 0.2734\n",
      "Epoch [17/200], Step [261/1067], D_A_loss: 0.0861, D_B_loss: 0.1019, G_A_loss: 0.4071, G_B_loss: 0.1609\n",
      "Epoch [17/200], Step [271/1067], D_A_loss: 0.1271, D_B_loss: 0.1295, G_A_loss: 0.2025, G_B_loss: 0.3297\n",
      "Epoch [17/200], Step [281/1067], D_A_loss: 0.0571, D_B_loss: 0.0305, G_A_loss: 0.6991, G_B_loss: 0.8353\n",
      "Epoch [17/200], Step [291/1067], D_A_loss: 0.0722, D_B_loss: 0.0288, G_A_loss: 1.0463, G_B_loss: 1.0634\n",
      "Epoch [17/200], Step [301/1067], D_A_loss: 0.1017, D_B_loss: 0.0589, G_A_loss: 0.9562, G_B_loss: 0.4076\n",
      "Epoch [17/200], Step [311/1067], D_A_loss: 0.0536, D_B_loss: 0.0258, G_A_loss: 0.6912, G_B_loss: 1.0615\n",
      "Epoch [17/200], Step [321/1067], D_A_loss: 0.1306, D_B_loss: 0.0898, G_A_loss: 0.6257, G_B_loss: 0.8575\n",
      "Epoch [17/200], Step [331/1067], D_A_loss: 0.0370, D_B_loss: 0.0731, G_A_loss: 0.8026, G_B_loss: 0.5848\n",
      "Epoch [17/200], Step [341/1067], D_A_loss: 0.0466, D_B_loss: 0.1038, G_A_loss: 0.7697, G_B_loss: 0.2329\n",
      "Epoch [17/200], Step [351/1067], D_A_loss: 0.1112, D_B_loss: 0.0190, G_A_loss: 0.6670, G_B_loss: 0.3414\n",
      "Epoch [17/200], Step [361/1067], D_A_loss: 0.0632, D_B_loss: 0.1453, G_A_loss: 0.2967, G_B_loss: 0.3164\n",
      "Epoch [17/200], Step [371/1067], D_A_loss: 0.0585, D_B_loss: 0.1005, G_A_loss: 1.3410, G_B_loss: 0.3780\n",
      "Epoch [17/200], Step [381/1067], D_A_loss: 0.1493, D_B_loss: 0.0316, G_A_loss: 0.6910, G_B_loss: 0.8456\n",
      "Epoch [17/200], Step [391/1067], D_A_loss: 0.1066, D_B_loss: 0.0719, G_A_loss: 0.8251, G_B_loss: 0.4968\n",
      "Epoch [17/200], Step [401/1067], D_A_loss: 0.0919, D_B_loss: 0.0623, G_A_loss: 0.3503, G_B_loss: 0.6291\n",
      "Epoch [17/200], Step [411/1067], D_A_loss: 0.1650, D_B_loss: 0.2090, G_A_loss: 0.3345, G_B_loss: 0.2616\n",
      "Epoch [17/200], Step [421/1067], D_A_loss: 0.1555, D_B_loss: 0.2240, G_A_loss: 0.1907, G_B_loss: 0.7521\n",
      "Epoch [17/200], Step [431/1067], D_A_loss: 0.0859, D_B_loss: 0.0175, G_A_loss: 0.7468, G_B_loss: 0.7975\n",
      "Epoch [17/200], Step [441/1067], D_A_loss: 0.1323, D_B_loss: 0.1578, G_A_loss: 0.4751, G_B_loss: 0.4543\n",
      "Epoch [17/200], Step [451/1067], D_A_loss: 0.1437, D_B_loss: 0.1510, G_A_loss: 1.1073, G_B_loss: 0.2467\n",
      "Epoch [17/200], Step [461/1067], D_A_loss: 0.0409, D_B_loss: 0.1541, G_A_loss: 0.3579, G_B_loss: 0.6749\n",
      "Epoch [17/200], Step [471/1067], D_A_loss: 0.0209, D_B_loss: 0.0301, G_A_loss: 0.5119, G_B_loss: 1.0789\n",
      "Epoch [17/200], Step [481/1067], D_A_loss: 0.1424, D_B_loss: 0.0635, G_A_loss: 0.8637, G_B_loss: 0.7905\n",
      "Epoch [17/200], Step [491/1067], D_A_loss: 0.1150, D_B_loss: 0.1202, G_A_loss: 0.7349, G_B_loss: 0.7688\n",
      "Epoch [17/200], Step [501/1067], D_A_loss: 0.1455, D_B_loss: 0.0531, G_A_loss: 0.6784, G_B_loss: 0.4726\n",
      "Epoch [17/200], Step [511/1067], D_A_loss: 0.1081, D_B_loss: 0.0375, G_A_loss: 0.6350, G_B_loss: 0.6056\n",
      "Epoch [17/200], Step [521/1067], D_A_loss: 0.1340, D_B_loss: 0.1297, G_A_loss: 0.5721, G_B_loss: 0.3423\n",
      "Epoch [17/200], Step [531/1067], D_A_loss: 0.0479, D_B_loss: 0.0884, G_A_loss: 0.8581, G_B_loss: 0.5398\n",
      "Epoch [17/200], Step [541/1067], D_A_loss: 0.0606, D_B_loss: 0.1076, G_A_loss: 0.4025, G_B_loss: 0.5094\n",
      "Epoch [17/200], Step [551/1067], D_A_loss: 0.0245, D_B_loss: 0.0906, G_A_loss: 0.4114, G_B_loss: 0.4059\n",
      "Epoch [17/200], Step [561/1067], D_A_loss: 0.2749, D_B_loss: 0.0211, G_A_loss: 0.9080, G_B_loss: 0.1712\n",
      "Epoch [17/200], Step [571/1067], D_A_loss: 0.0787, D_B_loss: 0.1004, G_A_loss: 0.4302, G_B_loss: 0.5176\n",
      "Epoch [17/200], Step [581/1067], D_A_loss: 0.2101, D_B_loss: 0.0252, G_A_loss: 0.6151, G_B_loss: 0.7433\n",
      "Epoch [17/200], Step [591/1067], D_A_loss: 0.2234, D_B_loss: 0.1374, G_A_loss: 1.1584, G_B_loss: 0.1743\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/200], Step [601/1067], D_A_loss: 0.1805, D_B_loss: 0.0208, G_A_loss: 0.6041, G_B_loss: 0.3332\n",
      "Epoch [17/200], Step [611/1067], D_A_loss: 0.0270, D_B_loss: 0.1190, G_A_loss: 0.9917, G_B_loss: 0.6262\n",
      "Epoch [17/200], Step [621/1067], D_A_loss: 0.0227, D_B_loss: 0.1417, G_A_loss: 0.6518, G_B_loss: 0.3309\n",
      "Epoch [17/200], Step [631/1067], D_A_loss: 0.1722, D_B_loss: 0.0618, G_A_loss: 0.7166, G_B_loss: 0.7586\n",
      "Epoch [17/200], Step [641/1067], D_A_loss: 0.1480, D_B_loss: 0.1448, G_A_loss: 0.8604, G_B_loss: 1.0085\n",
      "Epoch [17/200], Step [651/1067], D_A_loss: 0.1076, D_B_loss: 0.0284, G_A_loss: 0.3955, G_B_loss: 0.4295\n",
      "Epoch [17/200], Step [661/1067], D_A_loss: 0.1458, D_B_loss: 0.1073, G_A_loss: 0.5174, G_B_loss: 0.7582\n",
      "Epoch [17/200], Step [671/1067], D_A_loss: 0.0913, D_B_loss: 0.0689, G_A_loss: 0.8321, G_B_loss: 0.8891\n",
      "Epoch [17/200], Step [681/1067], D_A_loss: 0.1426, D_B_loss: 0.0949, G_A_loss: 0.8024, G_B_loss: 0.3304\n",
      "Epoch [17/200], Step [691/1067], D_A_loss: 0.0556, D_B_loss: 0.0875, G_A_loss: 0.4806, G_B_loss: 0.7621\n",
      "Epoch [17/200], Step [701/1067], D_A_loss: 0.2196, D_B_loss: 0.0162, G_A_loss: 0.7518, G_B_loss: 1.2358\n",
      "Epoch [17/200], Step [711/1067], D_A_loss: 0.2201, D_B_loss: 0.1197, G_A_loss: 0.7345, G_B_loss: 0.2035\n",
      "Epoch [17/200], Step [721/1067], D_A_loss: 0.1226, D_B_loss: 0.1259, G_A_loss: 0.3528, G_B_loss: 0.4076\n",
      "Epoch [17/200], Step [731/1067], D_A_loss: 0.3226, D_B_loss: 0.1241, G_A_loss: 0.3772, G_B_loss: 0.0880\n",
      "Epoch [17/200], Step [741/1067], D_A_loss: 0.1970, D_B_loss: 0.1390, G_A_loss: 0.5050, G_B_loss: 0.5981\n",
      "Epoch [17/200], Step [751/1067], D_A_loss: 0.0616, D_B_loss: 0.0471, G_A_loss: 0.5596, G_B_loss: 0.6796\n",
      "Epoch [17/200], Step [761/1067], D_A_loss: 0.4716, D_B_loss: 0.0480, G_A_loss: 0.5944, G_B_loss: 0.0276\n",
      "Epoch [17/200], Step [771/1067], D_A_loss: 0.1385, D_B_loss: 0.0423, G_A_loss: 0.3686, G_B_loss: 0.4620\n",
      "Epoch [17/200], Step [781/1067], D_A_loss: 0.0433, D_B_loss: 0.0874, G_A_loss: 0.6318, G_B_loss: 0.4285\n",
      "Epoch [17/200], Step [791/1067], D_A_loss: 0.0405, D_B_loss: 0.0316, G_A_loss: 0.7372, G_B_loss: 0.5608\n",
      "Epoch [17/200], Step [801/1067], D_A_loss: 0.0411, D_B_loss: 0.0439, G_A_loss: 0.8842, G_B_loss: 0.3838\n",
      "Epoch [17/200], Step [811/1067], D_A_loss: 0.0747, D_B_loss: 0.0520, G_A_loss: 0.5591, G_B_loss: 0.4684\n",
      "Epoch [17/200], Step [821/1067], D_A_loss: 0.1550, D_B_loss: 0.3260, G_A_loss: 0.7271, G_B_loss: 0.3785\n",
      "Epoch [17/200], Step [831/1067], D_A_loss: 0.1850, D_B_loss: 0.0617, G_A_loss: 0.5477, G_B_loss: 0.4042\n",
      "Epoch [17/200], Step [841/1067], D_A_loss: 0.0528, D_B_loss: 0.1269, G_A_loss: 0.4592, G_B_loss: 0.2901\n",
      "Epoch [17/200], Step [851/1067], D_A_loss: 0.0962, D_B_loss: 0.0308, G_A_loss: 0.3860, G_B_loss: 0.6665\n",
      "Epoch [17/200], Step [861/1067], D_A_loss: 0.2645, D_B_loss: 0.0332, G_A_loss: 0.1337, G_B_loss: 0.9418\n",
      "Epoch [17/200], Step [871/1067], D_A_loss: 0.2268, D_B_loss: 0.1222, G_A_loss: 0.6054, G_B_loss: 0.2397\n",
      "Epoch [17/200], Step [881/1067], D_A_loss: 0.2268, D_B_loss: 0.0631, G_A_loss: 0.5299, G_B_loss: 0.3059\n",
      "Epoch [17/200], Step [891/1067], D_A_loss: 0.0439, D_B_loss: 0.0801, G_A_loss: 0.4669, G_B_loss: 0.9136\n",
      "Epoch [17/200], Step [901/1067], D_A_loss: 0.1020, D_B_loss: 0.0855, G_A_loss: 0.8045, G_B_loss: 0.1149\n",
      "Epoch [17/200], Step [911/1067], D_A_loss: 0.1018, D_B_loss: 0.1299, G_A_loss: 0.3017, G_B_loss: 0.4768\n",
      "Epoch [17/200], Step [921/1067], D_A_loss: 0.1241, D_B_loss: 0.1138, G_A_loss: 0.8921, G_B_loss: 0.6504\n",
      "Epoch [17/200], Step [931/1067], D_A_loss: 0.0709, D_B_loss: 0.0300, G_A_loss: 0.3719, G_B_loss: 0.6260\n",
      "Epoch [17/200], Step [941/1067], D_A_loss: 0.0410, D_B_loss: 0.0407, G_A_loss: 0.9281, G_B_loss: 0.3563\n",
      "Epoch [17/200], Step [951/1067], D_A_loss: 0.0811, D_B_loss: 0.0597, G_A_loss: 0.6036, G_B_loss: 0.6234\n",
      "Epoch [17/200], Step [961/1067], D_A_loss: 0.1933, D_B_loss: 0.1850, G_A_loss: 0.6479, G_B_loss: 0.1789\n",
      "Epoch [17/200], Step [971/1067], D_A_loss: 0.1277, D_B_loss: 0.1485, G_A_loss: 0.5062, G_B_loss: 0.5919\n",
      "Epoch [17/200], Step [981/1067], D_A_loss: 0.1366, D_B_loss: 0.0565, G_A_loss: 0.5788, G_B_loss: 0.5388\n",
      "Epoch [17/200], Step [991/1067], D_A_loss: 0.4547, D_B_loss: 0.1774, G_A_loss: 0.2727, G_B_loss: 0.0584\n",
      "Epoch [17/200], Step [1001/1067], D_A_loss: 0.1154, D_B_loss: 0.1590, G_A_loss: 1.3050, G_B_loss: 0.5147\n",
      "Epoch [17/200], Step [1011/1067], D_A_loss: 0.0960, D_B_loss: 0.0249, G_A_loss: 0.7099, G_B_loss: 0.3834\n",
      "Epoch [17/200], Step [1021/1067], D_A_loss: 0.0470, D_B_loss: 0.1748, G_A_loss: 0.8712, G_B_loss: 0.4919\n",
      "Epoch [17/200], Step [1031/1067], D_A_loss: 0.0652, D_B_loss: 0.0647, G_A_loss: 0.4751, G_B_loss: 0.0947\n",
      "Epoch [17/200], Step [1041/1067], D_A_loss: 0.1210, D_B_loss: 0.0715, G_A_loss: 0.5449, G_B_loss: 0.3820\n",
      "Epoch [17/200], Step [1051/1067], D_A_loss: 0.0994, D_B_loss: 0.2047, G_A_loss: 0.5550, G_B_loss: 0.5964\n",
      "Epoch [17/200], Step [1061/1067], D_A_loss: 0.2156, D_B_loss: 0.0330, G_A_loss: 0.3921, G_B_loss: 0.1503\n",
      "Epoch [18/200], Step [1/1067], D_A_loss: 0.2409, D_B_loss: 0.1340, G_A_loss: 0.5641, G_B_loss: 0.2257\n",
      "Epoch [18/200], Step [11/1067], D_A_loss: 0.0492, D_B_loss: 0.1077, G_A_loss: 0.3765, G_B_loss: 0.7986\n",
      "Epoch [18/200], Step [21/1067], D_A_loss: 0.0642, D_B_loss: 0.1896, G_A_loss: 0.2724, G_B_loss: 0.7198\n",
      "Epoch [18/200], Step [31/1067], D_A_loss: 0.0778, D_B_loss: 0.0544, G_A_loss: 0.6408, G_B_loss: 0.5199\n",
      "Epoch [18/200], Step [41/1067], D_A_loss: 0.0607, D_B_loss: 0.3757, G_A_loss: 0.7140, G_B_loss: 0.4012\n",
      "Epoch [18/200], Step [51/1067], D_A_loss: 0.0632, D_B_loss: 0.1240, G_A_loss: 0.3599, G_B_loss: 0.5158\n",
      "Epoch [18/200], Step [61/1067], D_A_loss: 0.0707, D_B_loss: 0.0376, G_A_loss: 0.5786, G_B_loss: 0.5341\n",
      "Epoch [18/200], Step [71/1067], D_A_loss: 0.1284, D_B_loss: 0.1098, G_A_loss: 0.4578, G_B_loss: 0.2955\n",
      "Epoch [18/200], Step [81/1067], D_A_loss: 0.0619, D_B_loss: 0.1627, G_A_loss: 0.8542, G_B_loss: 0.5856\n",
      "Epoch [18/200], Step [91/1067], D_A_loss: 0.0263, D_B_loss: 0.0859, G_A_loss: 1.0651, G_B_loss: 0.5412\n",
      "Epoch [18/200], Step [101/1067], D_A_loss: 0.0924, D_B_loss: 0.0652, G_A_loss: 0.7910, G_B_loss: 0.7471\n",
      "Epoch [18/200], Step [111/1067], D_A_loss: 0.0454, D_B_loss: 0.0889, G_A_loss: 0.6866, G_B_loss: 0.4081\n",
      "Epoch [18/200], Step [121/1067], D_A_loss: 0.1744, D_B_loss: 0.0496, G_A_loss: 0.6695, G_B_loss: 0.2951\n",
      "Epoch [18/200], Step [131/1067], D_A_loss: 0.0218, D_B_loss: 0.0325, G_A_loss: 0.8408, G_B_loss: 0.6307\n",
      "Epoch [18/200], Step [141/1067], D_A_loss: 0.0385, D_B_loss: 0.0217, G_A_loss: 0.8854, G_B_loss: 0.9565\n",
      "Epoch [18/200], Step [151/1067], D_A_loss: 0.1062, D_B_loss: 0.0485, G_A_loss: 0.8917, G_B_loss: 0.8278\n",
      "Epoch [18/200], Step [161/1067], D_A_loss: 0.0432, D_B_loss: 0.0684, G_A_loss: 0.5173, G_B_loss: 0.4895\n",
      "Epoch [18/200], Step [171/1067], D_A_loss: 0.1244, D_B_loss: 0.1852, G_A_loss: 0.4050, G_B_loss: 0.4589\n",
      "Epoch [18/200], Step [181/1067], D_A_loss: 0.0757, D_B_loss: 0.0321, G_A_loss: 0.7239, G_B_loss: 0.7331\n",
      "Epoch [18/200], Step [191/1067], D_A_loss: 0.0623, D_B_loss: 0.1167, G_A_loss: 1.0752, G_B_loss: 0.5943\n",
      "Epoch [18/200], Step [201/1067], D_A_loss: 0.1187, D_B_loss: 0.0224, G_A_loss: 0.9495, G_B_loss: 0.7859\n",
      "Epoch [18/200], Step [211/1067], D_A_loss: 0.0452, D_B_loss: 0.0465, G_A_loss: 1.0112, G_B_loss: 0.4144\n",
      "Epoch [18/200], Step [221/1067], D_A_loss: 0.0571, D_B_loss: 0.1041, G_A_loss: 0.4832, G_B_loss: 0.3002\n",
      "Epoch [18/200], Step [231/1067], D_A_loss: 0.0403, D_B_loss: 0.0992, G_A_loss: 0.6702, G_B_loss: 0.4734\n",
      "Epoch [18/200], Step [241/1067], D_A_loss: 0.1053, D_B_loss: 0.0492, G_A_loss: 0.3880, G_B_loss: 0.4352\n",
      "Epoch [18/200], Step [251/1067], D_A_loss: 0.1245, D_B_loss: 0.0554, G_A_loss: 0.5750, G_B_loss: 0.5822\n",
      "Epoch [18/200], Step [261/1067], D_A_loss: 0.1842, D_B_loss: 0.1520, G_A_loss: 0.3133, G_B_loss: 0.4219\n",
      "Epoch [18/200], Step [271/1067], D_A_loss: 0.0888, D_B_loss: 0.0324, G_A_loss: 0.8894, G_B_loss: 0.4088\n",
      "Epoch [18/200], Step [281/1067], D_A_loss: 0.0531, D_B_loss: 0.0256, G_A_loss: 0.7113, G_B_loss: 0.8997\n",
      "Epoch [18/200], Step [291/1067], D_A_loss: 0.0917, D_B_loss: 0.0205, G_A_loss: 0.6543, G_B_loss: 0.8216\n",
      "Epoch [18/200], Step [301/1067], D_A_loss: 0.1368, D_B_loss: 0.2779, G_A_loss: 0.7563, G_B_loss: 0.3901\n",
      "Epoch [18/200], Step [311/1067], D_A_loss: 0.0575, D_B_loss: 0.1018, G_A_loss: 0.6997, G_B_loss: 0.5078\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/200], Step [321/1067], D_A_loss: 0.0623, D_B_loss: 0.0767, G_A_loss: 0.5543, G_B_loss: 0.4835\n",
      "Epoch [18/200], Step [331/1067], D_A_loss: 0.2272, D_B_loss: 0.0358, G_A_loss: 0.4118, G_B_loss: 0.3402\n",
      "Epoch [18/200], Step [341/1067], D_A_loss: 0.1630, D_B_loss: 0.0328, G_A_loss: 0.3102, G_B_loss: 0.2433\n",
      "Epoch [18/200], Step [351/1067], D_A_loss: 0.1099, D_B_loss: 0.0571, G_A_loss: 0.7863, G_B_loss: 0.3822\n",
      "Epoch [18/200], Step [361/1067], D_A_loss: 0.0953, D_B_loss: 0.0367, G_A_loss: 1.0015, G_B_loss: 0.4143\n",
      "Epoch [18/200], Step [371/1067], D_A_loss: 0.2036, D_B_loss: 0.0583, G_A_loss: 0.5538, G_B_loss: 0.2423\n",
      "Epoch [18/200], Step [381/1067], D_A_loss: 0.0839, D_B_loss: 0.0188, G_A_loss: 0.6848, G_B_loss: 1.0351\n",
      "Epoch [18/200], Step [391/1067], D_A_loss: 0.1163, D_B_loss: 0.0500, G_A_loss: 0.6120, G_B_loss: 0.3830\n",
      "Epoch [18/200], Step [401/1067], D_A_loss: 0.0493, D_B_loss: 0.0604, G_A_loss: 0.5414, G_B_loss: 0.5118\n",
      "Epoch [18/200], Step [411/1067], D_A_loss: 0.2494, D_B_loss: 0.1030, G_A_loss: 0.4228, G_B_loss: 0.4537\n",
      "Epoch [18/200], Step [421/1067], D_A_loss: 0.0858, D_B_loss: 0.0530, G_A_loss: 0.5918, G_B_loss: 0.5969\n",
      "Epoch [18/200], Step [431/1067], D_A_loss: 0.1438, D_B_loss: 0.1227, G_A_loss: 0.6583, G_B_loss: 0.3198\n",
      "Epoch [18/200], Step [441/1067], D_A_loss: 0.0449, D_B_loss: 0.0401, G_A_loss: 0.7091, G_B_loss: 0.5381\n",
      "Epoch [18/200], Step [451/1067], D_A_loss: 0.0881, D_B_loss: 0.1890, G_A_loss: 0.7766, G_B_loss: 0.4183\n",
      "Epoch [18/200], Step [461/1067], D_A_loss: 0.0321, D_B_loss: 0.0205, G_A_loss: 0.6387, G_B_loss: 0.2098\n",
      "Epoch [18/200], Step [471/1067], D_A_loss: 0.1536, D_B_loss: 0.0224, G_A_loss: 0.7268, G_B_loss: 0.3762\n",
      "Epoch [18/200], Step [481/1067], D_A_loss: 0.1310, D_B_loss: 0.0691, G_A_loss: 0.6291, G_B_loss: 0.4874\n",
      "Epoch [18/200], Step [491/1067], D_A_loss: 0.2521, D_B_loss: 0.0177, G_A_loss: 0.9730, G_B_loss: 1.0795\n",
      "Epoch [18/200], Step [501/1067], D_A_loss: 0.2197, D_B_loss: 0.0680, G_A_loss: 0.5353, G_B_loss: 0.1917\n",
      "Epoch [18/200], Step [511/1067], D_A_loss: 0.0299, D_B_loss: 0.0537, G_A_loss: 0.6086, G_B_loss: 0.4349\n",
      "Epoch [18/200], Step [521/1067], D_A_loss: 0.0733, D_B_loss: 0.0194, G_A_loss: 0.9906, G_B_loss: 0.6105\n",
      "Epoch [18/200], Step [531/1067], D_A_loss: 0.1648, D_B_loss: 0.0282, G_A_loss: 0.6020, G_B_loss: 0.4285\n",
      "Epoch [18/200], Step [541/1067], D_A_loss: 0.0472, D_B_loss: 0.0746, G_A_loss: 0.4392, G_B_loss: 1.2069\n",
      "Epoch [18/200], Step [551/1067], D_A_loss: 0.3042, D_B_loss: 0.1598, G_A_loss: 0.5619, G_B_loss: 0.4809\n",
      "Epoch [18/200], Step [561/1067], D_A_loss: 0.0522, D_B_loss: 0.0281, G_A_loss: 0.4960, G_B_loss: 0.8530\n",
      "Epoch [18/200], Step [571/1067], D_A_loss: 0.2472, D_B_loss: 0.0280, G_A_loss: 0.9673, G_B_loss: 0.4327\n",
      "Epoch [18/200], Step [581/1067], D_A_loss: 0.0409, D_B_loss: 0.1680, G_A_loss: 0.6113, G_B_loss: 0.9231\n",
      "Epoch [18/200], Step [591/1067], D_A_loss: 0.0832, D_B_loss: 0.2053, G_A_loss: 0.7146, G_B_loss: 0.5661\n",
      "Epoch [18/200], Step [601/1067], D_A_loss: 0.0373, D_B_loss: 0.0710, G_A_loss: 0.7508, G_B_loss: 1.0993\n",
      "Epoch [18/200], Step [611/1067], D_A_loss: 0.0211, D_B_loss: 0.0477, G_A_loss: 0.8749, G_B_loss: 0.9920\n",
      "Epoch [18/200], Step [621/1067], D_A_loss: 0.1472, D_B_loss: 0.0387, G_A_loss: 0.5145, G_B_loss: 0.9168\n",
      "Epoch [18/200], Step [631/1067], D_A_loss: 0.0406, D_B_loss: 0.0406, G_A_loss: 0.5578, G_B_loss: 0.5354\n",
      "Epoch [18/200], Step [641/1067], D_A_loss: 0.1347, D_B_loss: 0.0613, G_A_loss: 0.5153, G_B_loss: 0.3762\n",
      "Epoch [18/200], Step [651/1067], D_A_loss: 0.1046, D_B_loss: 0.0130, G_A_loss: 0.5644, G_B_loss: 0.4421\n",
      "Epoch [18/200], Step [661/1067], D_A_loss: 0.0467, D_B_loss: 0.0846, G_A_loss: 0.4404, G_B_loss: 0.6504\n",
      "Epoch [18/200], Step [671/1067], D_A_loss: 0.0335, D_B_loss: 0.1527, G_A_loss: 0.2405, G_B_loss: 0.1841\n",
      "Epoch [18/200], Step [681/1067], D_A_loss: 0.0341, D_B_loss: 0.0929, G_A_loss: 0.4468, G_B_loss: 0.6787\n",
      "Epoch [18/200], Step [691/1067], D_A_loss: 0.2708, D_B_loss: 0.1343, G_A_loss: 0.3930, G_B_loss: 0.9234\n",
      "Epoch [18/200], Step [701/1067], D_A_loss: 0.2023, D_B_loss: 0.0246, G_A_loss: 0.6606, G_B_loss: 0.1897\n",
      "Epoch [18/200], Step [711/1067], D_A_loss: 0.0648, D_B_loss: 0.0164, G_A_loss: 0.6767, G_B_loss: 0.8566\n",
      "Epoch [18/200], Step [721/1067], D_A_loss: 0.0409, D_B_loss: 0.0551, G_A_loss: 0.6647, G_B_loss: 0.5255\n",
      "Epoch [18/200], Step [731/1067], D_A_loss: 0.0886, D_B_loss: 0.0514, G_A_loss: 0.6676, G_B_loss: 0.5186\n",
      "Epoch [18/200], Step [741/1067], D_A_loss: 0.1786, D_B_loss: 0.0959, G_A_loss: 0.4265, G_B_loss: 0.2572\n",
      "Epoch [18/200], Step [751/1067], D_A_loss: 0.1442, D_B_loss: 0.1689, G_A_loss: 0.3826, G_B_loss: 0.2201\n",
      "Epoch [18/200], Step [761/1067], D_A_loss: 0.1216, D_B_loss: 0.2050, G_A_loss: 0.4784, G_B_loss: 0.4367\n",
      "Epoch [18/200], Step [771/1067], D_A_loss: 0.1751, D_B_loss: 0.0874, G_A_loss: 1.1701, G_B_loss: 0.3872\n",
      "Epoch [18/200], Step [781/1067], D_A_loss: 0.0761, D_B_loss: 0.2104, G_A_loss: 0.8585, G_B_loss: 0.2658\n",
      "Epoch [18/200], Step [791/1067], D_A_loss: 0.0819, D_B_loss: 0.0924, G_A_loss: 0.1917, G_B_loss: 0.4993\n",
      "Epoch [18/200], Step [801/1067], D_A_loss: 0.1244, D_B_loss: 0.0673, G_A_loss: 0.6887, G_B_loss: 0.4675\n",
      "Epoch [18/200], Step [811/1067], D_A_loss: 0.1577, D_B_loss: 0.0758, G_A_loss: 0.5735, G_B_loss: 0.2907\n",
      "Epoch [18/200], Step [821/1067], D_A_loss: 0.1185, D_B_loss: 0.2086, G_A_loss: 0.3021, G_B_loss: 0.3950\n",
      "Epoch [18/200], Step [831/1067], D_A_loss: 0.0566, D_B_loss: 0.1301, G_A_loss: 0.7391, G_B_loss: 1.2669\n",
      "Epoch [18/200], Step [841/1067], D_A_loss: 0.1057, D_B_loss: 0.0280, G_A_loss: 0.8766, G_B_loss: 0.4961\n",
      "Epoch [18/200], Step [851/1067], D_A_loss: 0.1856, D_B_loss: 0.0763, G_A_loss: 0.3872, G_B_loss: 0.2751\n",
      "Epoch [18/200], Step [861/1067], D_A_loss: 0.0515, D_B_loss: 0.0374, G_A_loss: 0.8382, G_B_loss: 0.6386\n",
      "Epoch [18/200], Step [871/1067], D_A_loss: 0.1213, D_B_loss: 0.0443, G_A_loss: 1.0398, G_B_loss: 0.6740\n",
      "Epoch [18/200], Step [881/1067], D_A_loss: 0.1291, D_B_loss: 0.1120, G_A_loss: 0.4121, G_B_loss: 0.2391\n",
      "Epoch [18/200], Step [891/1067], D_A_loss: 0.1427, D_B_loss: 0.0986, G_A_loss: 0.3970, G_B_loss: 0.2879\n",
      "Epoch [18/200], Step [901/1067], D_A_loss: 0.0434, D_B_loss: 0.1761, G_A_loss: 1.0608, G_B_loss: 0.5227\n",
      "Epoch [18/200], Step [911/1067], D_A_loss: 0.0912, D_B_loss: 0.0721, G_A_loss: 1.0855, G_B_loss: 0.5590\n",
      "Epoch [18/200], Step [921/1067], D_A_loss: 0.1483, D_B_loss: 0.1332, G_A_loss: 0.3173, G_B_loss: 0.8352\n",
      "Epoch [18/200], Step [931/1067], D_A_loss: 0.1805, D_B_loss: 0.0303, G_A_loss: 0.8339, G_B_loss: 0.3561\n",
      "Epoch [18/200], Step [941/1067], D_A_loss: 0.0312, D_B_loss: 0.1505, G_A_loss: 0.4697, G_B_loss: 0.4713\n",
      "Epoch [18/200], Step [951/1067], D_A_loss: 0.1609, D_B_loss: 0.0560, G_A_loss: 0.5487, G_B_loss: 0.3460\n",
      "Epoch [18/200], Step [961/1067], D_A_loss: 0.0911, D_B_loss: 0.1163, G_A_loss: 0.8960, G_B_loss: 0.4352\n",
      "Epoch [18/200], Step [971/1067], D_A_loss: 0.0854, D_B_loss: 0.0160, G_A_loss: 0.9997, G_B_loss: 0.4781\n",
      "Epoch [18/200], Step [981/1067], D_A_loss: 0.1538, D_B_loss: 0.0545, G_A_loss: 0.8727, G_B_loss: 0.3889\n",
      "Epoch [18/200], Step [991/1067], D_A_loss: 0.0902, D_B_loss: 0.1376, G_A_loss: 1.1004, G_B_loss: 0.4151\n",
      "Epoch [18/200], Step [1001/1067], D_A_loss: 0.0351, D_B_loss: 0.0424, G_A_loss: 0.6304, G_B_loss: 0.9461\n",
      "Epoch [18/200], Step [1011/1067], D_A_loss: 0.1913, D_B_loss: 0.0911, G_A_loss: 0.5684, G_B_loss: 0.6810\n",
      "Epoch [18/200], Step [1021/1067], D_A_loss: 0.0618, D_B_loss: 0.2620, G_A_loss: 1.3143, G_B_loss: 0.5986\n",
      "Epoch [18/200], Step [1031/1067], D_A_loss: 0.0518, D_B_loss: 0.0162, G_A_loss: 0.6245, G_B_loss: 0.8260\n",
      "Epoch [18/200], Step [1041/1067], D_A_loss: 0.0489, D_B_loss: 0.0889, G_A_loss: 1.2438, G_B_loss: 1.0441\n",
      "Epoch [18/200], Step [1051/1067], D_A_loss: 0.1745, D_B_loss: 0.0343, G_A_loss: 1.4953, G_B_loss: 0.2225\n",
      "Epoch [18/200], Step [1061/1067], D_A_loss: 0.4324, D_B_loss: 0.2118, G_A_loss: 0.8327, G_B_loss: 0.4815\n",
      "Epoch [19/200], Step [1/1067], D_A_loss: 0.1116, D_B_loss: 0.1552, G_A_loss: 0.3084, G_B_loss: 0.5377\n",
      "Epoch [19/200], Step [11/1067], D_A_loss: 0.1537, D_B_loss: 0.1259, G_A_loss: 0.4493, G_B_loss: 0.3770\n",
      "Epoch [19/200], Step [21/1067], D_A_loss: 0.0623, D_B_loss: 0.1291, G_A_loss: 0.5572, G_B_loss: 0.6216\n",
      "Epoch [19/200], Step [31/1067], D_A_loss: 0.2724, D_B_loss: 0.0388, G_A_loss: 0.5153, G_B_loss: 0.6002\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/200], Step [41/1067], D_A_loss: 0.0327, D_B_loss: 0.0227, G_A_loss: 0.5318, G_B_loss: 0.5455\n",
      "Epoch [19/200], Step [51/1067], D_A_loss: 0.1067, D_B_loss: 0.1330, G_A_loss: 1.0292, G_B_loss: 0.3017\n",
      "Epoch [19/200], Step [61/1067], D_A_loss: 0.0468, D_B_loss: 0.0301, G_A_loss: 0.7387, G_B_loss: 0.6136\n",
      "Epoch [19/200], Step [71/1067], D_A_loss: 0.0870, D_B_loss: 0.1198, G_A_loss: 1.0808, G_B_loss: 0.4388\n",
      "Epoch [19/200], Step [81/1067], D_A_loss: 0.1285, D_B_loss: 0.0550, G_A_loss: 1.0379, G_B_loss: 0.4041\n",
      "Epoch [19/200], Step [91/1067], D_A_loss: 0.0849, D_B_loss: 0.0563, G_A_loss: 0.7338, G_B_loss: 0.5229\n",
      "Epoch [19/200], Step [101/1067], D_A_loss: 0.2175, D_B_loss: 0.1747, G_A_loss: 0.3939, G_B_loss: 1.1621\n",
      "Epoch [19/200], Step [111/1067], D_A_loss: 0.0317, D_B_loss: 0.1167, G_A_loss: 0.3644, G_B_loss: 0.8010\n",
      "Epoch [19/200], Step [121/1067], D_A_loss: 0.0652, D_B_loss: 0.0996, G_A_loss: 0.3381, G_B_loss: 0.3640\n",
      "Epoch [19/200], Step [131/1067], D_A_loss: 0.3293, D_B_loss: 0.0487, G_A_loss: 0.7883, G_B_loss: 0.6600\n",
      "Epoch [19/200], Step [141/1067], D_A_loss: 0.1732, D_B_loss: 0.1543, G_A_loss: 0.6831, G_B_loss: 0.3799\n",
      "Epoch [19/200], Step [151/1067], D_A_loss: 0.1395, D_B_loss: 0.0649, G_A_loss: 0.6984, G_B_loss: 0.5026\n",
      "Epoch [19/200], Step [161/1067], D_A_loss: 0.1877, D_B_loss: 0.1849, G_A_loss: 0.2683, G_B_loss: 0.2803\n",
      "Epoch [19/200], Step [171/1067], D_A_loss: 0.0402, D_B_loss: 0.0235, G_A_loss: 1.0461, G_B_loss: 0.7858\n",
      "Epoch [19/200], Step [181/1067], D_A_loss: 0.0958, D_B_loss: 0.0357, G_A_loss: 0.9555, G_B_loss: 0.7494\n",
      "Epoch [19/200], Step [191/1067], D_A_loss: 0.1139, D_B_loss: 0.1119, G_A_loss: 0.4449, G_B_loss: 1.0201\n",
      "Epoch [19/200], Step [201/1067], D_A_loss: 0.0346, D_B_loss: 0.0630, G_A_loss: 0.4986, G_B_loss: 0.6946\n",
      "Epoch [19/200], Step [211/1067], D_A_loss: 0.1110, D_B_loss: 0.1118, G_A_loss: 0.3689, G_B_loss: 0.4870\n",
      "Epoch [19/200], Step [221/1067], D_A_loss: 0.1322, D_B_loss: 0.0443, G_A_loss: 0.1657, G_B_loss: 1.4545\n",
      "Epoch [19/200], Step [231/1067], D_A_loss: 0.0778, D_B_loss: 0.0205, G_A_loss: 0.4549, G_B_loss: 0.9726\n",
      "Epoch [19/200], Step [241/1067], D_A_loss: 0.3017, D_B_loss: 0.0390, G_A_loss: 0.9999, G_B_loss: 0.4997\n",
      "Epoch [19/200], Step [251/1067], D_A_loss: 0.0792, D_B_loss: 0.0724, G_A_loss: 0.1008, G_B_loss: 0.8646\n",
      "Epoch [19/200], Step [261/1067], D_A_loss: 0.1335, D_B_loss: 0.0323, G_A_loss: 0.9995, G_B_loss: 0.3548\n",
      "Epoch [19/200], Step [271/1067], D_A_loss: 0.1480, D_B_loss: 0.1025, G_A_loss: 0.3762, G_B_loss: 0.7495\n",
      "Epoch [19/200], Step [281/1067], D_A_loss: 0.1481, D_B_loss: 0.1137, G_A_loss: 1.0027, G_B_loss: 0.7062\n",
      "Epoch [19/200], Step [291/1067], D_A_loss: 0.1119, D_B_loss: 0.0811, G_A_loss: 0.4612, G_B_loss: 0.8528\n",
      "Epoch [19/200], Step [301/1067], D_A_loss: 0.0787, D_B_loss: 0.0451, G_A_loss: 0.3513, G_B_loss: 0.5688\n",
      "Epoch [19/200], Step [311/1067], D_A_loss: 0.0612, D_B_loss: 0.0648, G_A_loss: 0.5878, G_B_loss: 0.3955\n",
      "Epoch [19/200], Step [321/1067], D_A_loss: 0.1510, D_B_loss: 0.2296, G_A_loss: 0.8092, G_B_loss: 0.3161\n",
      "Epoch [19/200], Step [331/1067], D_A_loss: 0.0437, D_B_loss: 0.1117, G_A_loss: 0.3968, G_B_loss: 0.4410\n",
      "Epoch [19/200], Step [341/1067], D_A_loss: 0.2610, D_B_loss: 0.1041, G_A_loss: 0.9569, G_B_loss: 0.4470\n",
      "Epoch [19/200], Step [351/1067], D_A_loss: 0.0786, D_B_loss: 0.1036, G_A_loss: 0.4447, G_B_loss: 1.2402\n",
      "Epoch [19/200], Step [361/1067], D_A_loss: 0.0926, D_B_loss: 0.0572, G_A_loss: 1.0137, G_B_loss: 0.7788\n",
      "Epoch [19/200], Step [371/1067], D_A_loss: 0.0476, D_B_loss: 0.1293, G_A_loss: 0.6718, G_B_loss: 0.4444\n",
      "Epoch [19/200], Step [381/1067], D_A_loss: 0.0840, D_B_loss: 0.1141, G_A_loss: 0.7973, G_B_loss: 0.5337\n",
      "Epoch [19/200], Step [391/1067], D_A_loss: 0.0536, D_B_loss: 0.0616, G_A_loss: 0.5856, G_B_loss: 0.6425\n",
      "Epoch [19/200], Step [401/1067], D_A_loss: 0.2025, D_B_loss: 0.2690, G_A_loss: 0.9323, G_B_loss: 0.5686\n",
      "Epoch [19/200], Step [411/1067], D_A_loss: 0.0445, D_B_loss: 0.0282, G_A_loss: 0.4461, G_B_loss: 0.5915\n",
      "Epoch [19/200], Step [421/1067], D_A_loss: 0.1686, D_B_loss: 0.2732, G_A_loss: 1.0073, G_B_loss: 0.7153\n",
      "Epoch [19/200], Step [431/1067], D_A_loss: 0.0418, D_B_loss: 0.0300, G_A_loss: 1.1757, G_B_loss: 0.7535\n",
      "Epoch [19/200], Step [441/1067], D_A_loss: 0.0595, D_B_loss: 0.1862, G_A_loss: 0.2442, G_B_loss: 0.9125\n",
      "Epoch [19/200], Step [451/1067], D_A_loss: 0.0314, D_B_loss: 0.0719, G_A_loss: 0.4382, G_B_loss: 0.8234\n",
      "Epoch [19/200], Step [461/1067], D_A_loss: 0.2143, D_B_loss: 0.0242, G_A_loss: 0.7392, G_B_loss: 0.2279\n",
      "Epoch [19/200], Step [471/1067], D_A_loss: 0.1927, D_B_loss: 0.0184, G_A_loss: 0.5514, G_B_loss: 0.3082\n",
      "Epoch [19/200], Step [481/1067], D_A_loss: 0.1123, D_B_loss: 0.1946, G_A_loss: 0.2707, G_B_loss: 0.4141\n",
      "Epoch [19/200], Step [491/1067], D_A_loss: 0.0478, D_B_loss: 0.0834, G_A_loss: 0.6269, G_B_loss: 0.6373\n",
      "Epoch [19/200], Step [501/1067], D_A_loss: 0.0299, D_B_loss: 0.0206, G_A_loss: 0.8828, G_B_loss: 0.7859\n",
      "Epoch [19/200], Step [511/1067], D_A_loss: 0.0674, D_B_loss: 0.0299, G_A_loss: 0.2307, G_B_loss: 0.4472\n",
      "Epoch [19/200], Step [521/1067], D_A_loss: 0.0805, D_B_loss: 0.2866, G_A_loss: 0.9805, G_B_loss: 0.5808\n",
      "Epoch [19/200], Step [531/1067], D_A_loss: 0.1874, D_B_loss: 0.0553, G_A_loss: 0.5373, G_B_loss: 0.4963\n",
      "Epoch [19/200], Step [541/1067], D_A_loss: 0.3793, D_B_loss: 0.0721, G_A_loss: 0.7557, G_B_loss: 0.3274\n",
      "Epoch [19/200], Step [551/1067], D_A_loss: 0.0781, D_B_loss: 0.0887, G_A_loss: 0.4537, G_B_loss: 0.2572\n",
      "Epoch [19/200], Step [561/1067], D_A_loss: 0.0743, D_B_loss: 0.0631, G_A_loss: 0.5493, G_B_loss: 0.5193\n",
      "Epoch [19/200], Step [571/1067], D_A_loss: 0.0614, D_B_loss: 0.1296, G_A_loss: 0.4332, G_B_loss: 0.3989\n",
      "Epoch [19/200], Step [581/1067], D_A_loss: 0.0773, D_B_loss: 0.1533, G_A_loss: 0.8035, G_B_loss: 0.4846\n",
      "Epoch [19/200], Step [591/1067], D_A_loss: 0.1817, D_B_loss: 0.0564, G_A_loss: 0.5199, G_B_loss: 0.4136\n",
      "Epoch [19/200], Step [601/1067], D_A_loss: 0.1050, D_B_loss: 0.0589, G_A_loss: 0.1106, G_B_loss: 0.7783\n",
      "Epoch [19/200], Step [611/1067], D_A_loss: 0.0966, D_B_loss: 0.0668, G_A_loss: 0.7554, G_B_loss: 0.4338\n",
      "Epoch [19/200], Step [621/1067], D_A_loss: 0.0521, D_B_loss: 0.0273, G_A_loss: 0.9933, G_B_loss: 0.9407\n",
      "Epoch [19/200], Step [631/1067], D_A_loss: 0.3302, D_B_loss: 0.0603, G_A_loss: 0.8612, G_B_loss: 0.0587\n",
      "Epoch [19/200], Step [641/1067], D_A_loss: 0.0989, D_B_loss: 0.2339, G_A_loss: 1.2590, G_B_loss: 0.3893\n",
      "Epoch [19/200], Step [651/1067], D_A_loss: 0.2052, D_B_loss: 0.1179, G_A_loss: 0.3678, G_B_loss: 0.4137\n",
      "Epoch [19/200], Step [661/1067], D_A_loss: 0.1841, D_B_loss: 0.0557, G_A_loss: 0.7115, G_B_loss: 0.3768\n",
      "Epoch [19/200], Step [671/1067], D_A_loss: 0.0712, D_B_loss: 0.0700, G_A_loss: 0.8831, G_B_loss: 0.4973\n",
      "Epoch [19/200], Step [681/1067], D_A_loss: 0.0395, D_B_loss: 0.0482, G_A_loss: 0.6500, G_B_loss: 1.1298\n",
      "Epoch [19/200], Step [691/1067], D_A_loss: 0.0650, D_B_loss: 0.0208, G_A_loss: 0.2781, G_B_loss: 0.5716\n",
      "Epoch [19/200], Step [701/1067], D_A_loss: 0.0520, D_B_loss: 0.0381, G_A_loss: 0.7116, G_B_loss: 0.6012\n",
      "Epoch [19/200], Step [711/1067], D_A_loss: 0.0298, D_B_loss: 0.0590, G_A_loss: 0.5602, G_B_loss: 0.7575\n",
      "Epoch [19/200], Step [721/1067], D_A_loss: 0.0947, D_B_loss: 0.0572, G_A_loss: 0.5448, G_B_loss: 0.5164\n",
      "Epoch [19/200], Step [731/1067], D_A_loss: 0.1663, D_B_loss: 0.0516, G_A_loss: 0.8889, G_B_loss: 0.2382\n",
      "Epoch [19/200], Step [741/1067], D_A_loss: 0.0420, D_B_loss: 0.0718, G_A_loss: 0.7936, G_B_loss: 0.7527\n",
      "Epoch [19/200], Step [751/1067], D_A_loss: 0.0713, D_B_loss: 0.0370, G_A_loss: 0.2710, G_B_loss: 0.2891\n",
      "Epoch [19/200], Step [761/1067], D_A_loss: 0.0875, D_B_loss: 0.0628, G_A_loss: 0.5512, G_B_loss: 0.2563\n",
      "Epoch [19/200], Step [771/1067], D_A_loss: 0.0946, D_B_loss: 0.0349, G_A_loss: 0.4544, G_B_loss: 1.0523\n",
      "Epoch [19/200], Step [781/1067], D_A_loss: 0.0538, D_B_loss: 0.0549, G_A_loss: 0.8627, G_B_loss: 0.6899\n",
      "Epoch [19/200], Step [791/1067], D_A_loss: 0.0901, D_B_loss: 0.2540, G_A_loss: 0.1449, G_B_loss: 0.7620\n",
      "Epoch [19/200], Step [801/1067], D_A_loss: 0.0256, D_B_loss: 0.1381, G_A_loss: 0.5194, G_B_loss: 0.7277\n",
      "Epoch [19/200], Step [811/1067], D_A_loss: 0.1008, D_B_loss: 0.0844, G_A_loss: 0.6683, G_B_loss: 0.5714\n",
      "Epoch [19/200], Step [821/1067], D_A_loss: 0.0566, D_B_loss: 0.0691, G_A_loss: 0.7075, G_B_loss: 0.5581\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/200], Step [831/1067], D_A_loss: 0.0582, D_B_loss: 0.0444, G_A_loss: 0.1461, G_B_loss: 0.8568\n",
      "Epoch [19/200], Step [841/1067], D_A_loss: 0.1790, D_B_loss: 0.0933, G_A_loss: 0.4309, G_B_loss: 0.9101\n",
      "Epoch [19/200], Step [851/1067], D_A_loss: 0.0545, D_B_loss: 0.0431, G_A_loss: 0.7021, G_B_loss: 0.5681\n",
      "Epoch [19/200], Step [861/1067], D_A_loss: 0.0183, D_B_loss: 0.0201, G_A_loss: 0.8868, G_B_loss: 0.6318\n",
      "Epoch [19/200], Step [871/1067], D_A_loss: 0.2266, D_B_loss: 0.0248, G_A_loss: 0.8043, G_B_loss: 0.7402\n",
      "Epoch [19/200], Step [881/1067], D_A_loss: 0.2413, D_B_loss: 0.0270, G_A_loss: 0.6655, G_B_loss: 0.0831\n",
      "Epoch [19/200], Step [891/1067], D_A_loss: 0.1023, D_B_loss: 0.0213, G_A_loss: 0.9757, G_B_loss: 0.3502\n",
      "Epoch [19/200], Step [901/1067], D_A_loss: 0.0758, D_B_loss: 0.0706, G_A_loss: 0.6796, G_B_loss: 0.4664\n",
      "Epoch [19/200], Step [911/1067], D_A_loss: 0.1079, D_B_loss: 0.0670, G_A_loss: 0.5884, G_B_loss: 0.4532\n",
      "Epoch [19/200], Step [921/1067], D_A_loss: 0.1049, D_B_loss: 0.0521, G_A_loss: 0.7057, G_B_loss: 1.3314\n",
      "Epoch [19/200], Step [931/1067], D_A_loss: 0.0706, D_B_loss: 0.1051, G_A_loss: 0.3544, G_B_loss: 0.6745\n",
      "Epoch [19/200], Step [941/1067], D_A_loss: 0.1007, D_B_loss: 0.0186, G_A_loss: 0.3737, G_B_loss: 0.4030\n",
      "Epoch [19/200], Step [951/1067], D_A_loss: 0.0871, D_B_loss: 0.1076, G_A_loss: 1.0992, G_B_loss: 0.4820\n",
      "Epoch [19/200], Step [961/1067], D_A_loss: 0.1564, D_B_loss: 0.0963, G_A_loss: 0.5182, G_B_loss: 0.9011\n",
      "Epoch [19/200], Step [971/1067], D_A_loss: 0.1001, D_B_loss: 0.2377, G_A_loss: 0.3861, G_B_loss: 0.3307\n",
      "Epoch [19/200], Step [981/1067], D_A_loss: 0.1069, D_B_loss: 0.0383, G_A_loss: 0.9172, G_B_loss: 0.3790\n",
      "Epoch [19/200], Step [991/1067], D_A_loss: 0.1403, D_B_loss: 0.0211, G_A_loss: 0.4600, G_B_loss: 0.3450\n",
      "Epoch [19/200], Step [1001/1067], D_A_loss: 0.1859, D_B_loss: 0.0456, G_A_loss: 0.6549, G_B_loss: 0.1888\n",
      "Epoch [19/200], Step [1011/1067], D_A_loss: 0.0674, D_B_loss: 0.1448, G_A_loss: 0.7752, G_B_loss: 0.6240\n",
      "Epoch [19/200], Step [1021/1067], D_A_loss: 0.0665, D_B_loss: 0.0230, G_A_loss: 0.9095, G_B_loss: 0.5339\n",
      "Epoch [19/200], Step [1031/1067], D_A_loss: 0.1948, D_B_loss: 0.3234, G_A_loss: 0.1390, G_B_loss: 0.2055\n",
      "Epoch [19/200], Step [1041/1067], D_A_loss: 0.0651, D_B_loss: 0.0407, G_A_loss: 0.8482, G_B_loss: 0.4770\n",
      "Epoch [19/200], Step [1051/1067], D_A_loss: 0.1087, D_B_loss: 0.0737, G_A_loss: 1.0310, G_B_loss: 0.7337\n",
      "Epoch [19/200], Step [1061/1067], D_A_loss: 0.0697, D_B_loss: 0.0771, G_A_loss: 0.6101, G_B_loss: 0.8645\n",
      "Epoch [20/200], Step [1/1067], D_A_loss: 0.0575, D_B_loss: 0.0220, G_A_loss: 0.7874, G_B_loss: 0.7028\n",
      "Epoch [20/200], Step [11/1067], D_A_loss: 0.1969, D_B_loss: 0.0170, G_A_loss: 1.0411, G_B_loss: 0.2556\n",
      "Epoch [20/200], Step [21/1067], D_A_loss: 0.2459, D_B_loss: 0.0449, G_A_loss: 0.3067, G_B_loss: 0.3743\n",
      "Epoch [20/200], Step [31/1067], D_A_loss: 0.0910, D_B_loss: 0.0377, G_A_loss: 0.7534, G_B_loss: 0.7071\n",
      "Epoch [20/200], Step [41/1067], D_A_loss: 0.0693, D_B_loss: 0.1638, G_A_loss: 0.7046, G_B_loss: 0.5556\n",
      "Epoch [20/200], Step [51/1067], D_A_loss: 0.1774, D_B_loss: 0.0562, G_A_loss: 1.0261, G_B_loss: 0.8889\n",
      "Epoch [20/200], Step [61/1067], D_A_loss: 0.3655, D_B_loss: 0.1711, G_A_loss: 0.2537, G_B_loss: 0.3305\n",
      "Epoch [20/200], Step [71/1067], D_A_loss: 0.0932, D_B_loss: 0.1115, G_A_loss: 0.5252, G_B_loss: 0.6874\n",
      "Epoch [20/200], Step [81/1067], D_A_loss: 0.0534, D_B_loss: 0.0438, G_A_loss: 0.7218, G_B_loss: 0.7465\n",
      "Epoch [20/200], Step [91/1067], D_A_loss: 0.0903, D_B_loss: 0.0329, G_A_loss: 0.5641, G_B_loss: 0.4866\n",
      "Epoch [20/200], Step [101/1067], D_A_loss: 0.2643, D_B_loss: 0.0934, G_A_loss: 0.4164, G_B_loss: 0.8738\n",
      "Epoch [20/200], Step [111/1067], D_A_loss: 0.0858, D_B_loss: 0.0460, G_A_loss: 0.5464, G_B_loss: 0.4716\n",
      "Epoch [20/200], Step [121/1067], D_A_loss: 0.0315, D_B_loss: 0.1962, G_A_loss: 0.7370, G_B_loss: 0.4572\n",
      "Epoch [20/200], Step [131/1067], D_A_loss: 0.0415, D_B_loss: 0.0875, G_A_loss: 0.4110, G_B_loss: 0.2988\n",
      "Epoch [20/200], Step [141/1067], D_A_loss: 0.0997, D_B_loss: 0.0296, G_A_loss: 0.4094, G_B_loss: 0.8470\n",
      "Epoch [20/200], Step [151/1067], D_A_loss: 0.0712, D_B_loss: 0.1199, G_A_loss: 0.3734, G_B_loss: 0.5363\n",
      "Epoch [20/200], Step [161/1067], D_A_loss: 0.0732, D_B_loss: 0.2467, G_A_loss: 0.3191, G_B_loss: 0.5213\n",
      "Epoch [20/200], Step [171/1067], D_A_loss: 0.1229, D_B_loss: 0.1453, G_A_loss: 0.8425, G_B_loss: 0.3061\n",
      "Epoch [20/200], Step [181/1067], D_A_loss: 0.0456, D_B_loss: 0.0209, G_A_loss: 0.4249, G_B_loss: 0.5567\n",
      "Epoch [20/200], Step [191/1067], D_A_loss: 0.1567, D_B_loss: 0.0437, G_A_loss: 0.4985, G_B_loss: 0.3300\n",
      "Epoch [20/200], Step [201/1067], D_A_loss: 0.0407, D_B_loss: 0.0157, G_A_loss: 1.0553, G_B_loss: 0.5665\n",
      "Epoch [20/200], Step [211/1067], D_A_loss: 0.1354, D_B_loss: 0.2361, G_A_loss: 0.1424, G_B_loss: 0.7528\n",
      "Epoch [20/200], Step [221/1067], D_A_loss: 0.0860, D_B_loss: 0.0823, G_A_loss: 1.1016, G_B_loss: 0.4191\n",
      "Epoch [20/200], Step [231/1067], D_A_loss: 0.0291, D_B_loss: 0.2137, G_A_loss: 0.5900, G_B_loss: 0.1522\n",
      "Epoch [20/200], Step [241/1067], D_A_loss: 0.1114, D_B_loss: 0.0411, G_A_loss: 0.8729, G_B_loss: 0.3072\n",
      "Epoch [20/200], Step [251/1067], D_A_loss: 0.1442, D_B_loss: 0.0449, G_A_loss: 0.6199, G_B_loss: 0.3197\n",
      "Epoch [20/200], Step [261/1067], D_A_loss: 0.0639, D_B_loss: 0.2262, G_A_loss: 1.5489, G_B_loss: 0.5380\n",
      "Epoch [20/200], Step [271/1067], D_A_loss: 0.0387, D_B_loss: 0.0715, G_A_loss: 0.8575, G_B_loss: 0.6265\n",
      "Epoch [20/200], Step [281/1067], D_A_loss: 0.0502, D_B_loss: 0.0612, G_A_loss: 0.7192, G_B_loss: 0.6690\n",
      "Epoch [20/200], Step [291/1067], D_A_loss: 0.3360, D_B_loss: 0.0353, G_A_loss: 1.1799, G_B_loss: 0.8822\n",
      "Epoch [20/200], Step [301/1067], D_A_loss: 0.0479, D_B_loss: 0.0300, G_A_loss: 0.6479, G_B_loss: 0.2388\n",
      "Epoch [20/200], Step [311/1067], D_A_loss: 0.1335, D_B_loss: 0.0194, G_A_loss: 0.8372, G_B_loss: 0.7888\n",
      "Epoch [20/200], Step [321/1067], D_A_loss: 0.2046, D_B_loss: 0.0345, G_A_loss: 0.8671, G_B_loss: 1.7484\n",
      "Epoch [20/200], Step [331/1067], D_A_loss: 0.0825, D_B_loss: 0.1056, G_A_loss: 0.4522, G_B_loss: 0.9123\n",
      "Epoch [20/200], Step [341/1067], D_A_loss: 0.0756, D_B_loss: 0.0481, G_A_loss: 0.6301, G_B_loss: 0.5378\n",
      "Epoch [20/200], Step [351/1067], D_A_loss: 0.0453, D_B_loss: 0.0867, G_A_loss: 0.6848, G_B_loss: 0.3486\n",
      "Epoch [20/200], Step [361/1067], D_A_loss: 0.2067, D_B_loss: 0.0594, G_A_loss: 0.9306, G_B_loss: 0.6320\n",
      "Epoch [20/200], Step [371/1067], D_A_loss: 0.0572, D_B_loss: 0.1173, G_A_loss: 0.4340, G_B_loss: 0.5663\n",
      "Epoch [20/200], Step [381/1067], D_A_loss: 0.0798, D_B_loss: 0.0940, G_A_loss: 0.8183, G_B_loss: 0.5291\n",
      "Epoch [20/200], Step [391/1067], D_A_loss: 0.1057, D_B_loss: 0.0432, G_A_loss: 0.7928, G_B_loss: 0.3756\n",
      "Epoch [20/200], Step [401/1067], D_A_loss: 0.1277, D_B_loss: 0.0507, G_A_loss: 0.4608, G_B_loss: 0.7819\n",
      "Epoch [20/200], Step [411/1067], D_A_loss: 0.0485, D_B_loss: 0.0873, G_A_loss: 0.4082, G_B_loss: 0.7012\n",
      "Epoch [20/200], Step [421/1067], D_A_loss: 0.0207, D_B_loss: 0.0345, G_A_loss: 0.6933, G_B_loss: 1.0013\n",
      "Epoch [20/200], Step [431/1067], D_A_loss: 0.1591, D_B_loss: 0.0718, G_A_loss: 0.6542, G_B_loss: 0.2732\n",
      "Epoch [20/200], Step [441/1067], D_A_loss: 0.0326, D_B_loss: 0.0414, G_A_loss: 1.2752, G_B_loss: 0.8816\n",
      "Epoch [20/200], Step [451/1067], D_A_loss: 0.1384, D_B_loss: 0.0390, G_A_loss: 0.6520, G_B_loss: 0.5749\n",
      "Epoch [20/200], Step [461/1067], D_A_loss: 0.1521, D_B_loss: 0.1554, G_A_loss: 0.6333, G_B_loss: 0.3024\n",
      "Epoch [20/200], Step [471/1067], D_A_loss: 0.0388, D_B_loss: 0.1223, G_A_loss: 0.3185, G_B_loss: 0.7064\n",
      "Epoch [20/200], Step [481/1067], D_A_loss: 0.1880, D_B_loss: 0.3260, G_A_loss: 1.2163, G_B_loss: 0.2070\n",
      "Epoch [20/200], Step [491/1067], D_A_loss: 0.2326, D_B_loss: 0.0384, G_A_loss: 0.6614, G_B_loss: 0.1463\n",
      "Epoch [20/200], Step [501/1067], D_A_loss: 0.0346, D_B_loss: 0.0827, G_A_loss: 1.2500, G_B_loss: 0.6526\n",
      "Epoch [20/200], Step [511/1067], D_A_loss: 0.1359, D_B_loss: 0.0616, G_A_loss: 0.7339, G_B_loss: 0.8506\n",
      "Epoch [20/200], Step [521/1067], D_A_loss: 0.0435, D_B_loss: 0.0430, G_A_loss: 0.5533, G_B_loss: 0.7371\n",
      "Epoch [20/200], Step [531/1067], D_A_loss: 0.1487, D_B_loss: 0.0563, G_A_loss: 0.7389, G_B_loss: 0.3037\n",
      "Epoch [20/200], Step [541/1067], D_A_loss: 0.0406, D_B_loss: 0.0986, G_A_loss: 1.1845, G_B_loss: 0.7939\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/200], Step [551/1067], D_A_loss: 0.0815, D_B_loss: 0.0518, G_A_loss: 0.4068, G_B_loss: 0.5132\n",
      "Epoch [20/200], Step [561/1067], D_A_loss: 0.0911, D_B_loss: 0.0633, G_A_loss: 0.4485, G_B_loss: 0.6421\n",
      "Epoch [20/200], Step [571/1067], D_A_loss: 0.1709, D_B_loss: 0.2872, G_A_loss: 1.1107, G_B_loss: 0.2695\n",
      "Epoch [20/200], Step [581/1067], D_A_loss: 0.0627, D_B_loss: 0.1375, G_A_loss: 0.7964, G_B_loss: 0.9080\n",
      "Epoch [20/200], Step [591/1067], D_A_loss: 0.1484, D_B_loss: 0.1620, G_A_loss: 0.6871, G_B_loss: 0.2669\n",
      "Epoch [20/200], Step [601/1067], D_A_loss: 0.0681, D_B_loss: 0.0615, G_A_loss: 0.5122, G_B_loss: 0.4806\n",
      "Epoch [20/200], Step [611/1067], D_A_loss: 0.0901, D_B_loss: 0.0910, G_A_loss: 0.4184, G_B_loss: 0.4387\n",
      "Epoch [20/200], Step [621/1067], D_A_loss: 0.1283, D_B_loss: 0.0714, G_A_loss: 0.5347, G_B_loss: 0.3402\n",
      "Epoch [20/200], Step [631/1067], D_A_loss: 0.0605, D_B_loss: 0.0255, G_A_loss: 0.4298, G_B_loss: 0.9199\n",
      "Epoch [20/200], Step [641/1067], D_A_loss: 0.0295, D_B_loss: 0.0531, G_A_loss: 0.5063, G_B_loss: 0.6725\n",
      "Epoch [20/200], Step [651/1067], D_A_loss: 0.2282, D_B_loss: 0.0995, G_A_loss: 0.4556, G_B_loss: 0.5211\n",
      "Epoch [20/200], Step [661/1067], D_A_loss: 0.0658, D_B_loss: 0.0530, G_A_loss: 0.4227, G_B_loss: 0.5141\n",
      "Epoch [20/200], Step [671/1067], D_A_loss: 0.1351, D_B_loss: 0.0541, G_A_loss: 0.5921, G_B_loss: 0.3362\n",
      "Epoch [20/200], Step [681/1067], D_A_loss: 0.1087, D_B_loss: 0.0862, G_A_loss: 0.6094, G_B_loss: 0.3946\n",
      "Epoch [20/200], Step [691/1067], D_A_loss: 0.0550, D_B_loss: 0.0300, G_A_loss: 1.0273, G_B_loss: 0.2749\n",
      "Epoch [20/200], Step [701/1067], D_A_loss: 0.1288, D_B_loss: 0.0340, G_A_loss: 0.7846, G_B_loss: 0.3613\n",
      "Epoch [20/200], Step [711/1067], D_A_loss: 0.2207, D_B_loss: 0.0421, G_A_loss: 0.6245, G_B_loss: 0.5044\n",
      "Epoch [20/200], Step [721/1067], D_A_loss: 0.1526, D_B_loss: 0.0403, G_A_loss: 1.3022, G_B_loss: 0.2969\n",
      "Epoch [20/200], Step [731/1067], D_A_loss: 0.0849, D_B_loss: 0.0176, G_A_loss: 0.5892, G_B_loss: 0.5043\n",
      "Epoch [20/200], Step [741/1067], D_A_loss: 0.0622, D_B_loss: 0.0899, G_A_loss: 0.5780, G_B_loss: 0.6749\n",
      "Epoch [20/200], Step [751/1067], D_A_loss: 0.0787, D_B_loss: 0.0284, G_A_loss: 0.5407, G_B_loss: 0.7818\n",
      "Epoch [20/200], Step [761/1067], D_A_loss: 0.2012, D_B_loss: 0.0788, G_A_loss: 0.5729, G_B_loss: 0.5679\n",
      "Epoch [20/200], Step [771/1067], D_A_loss: 0.0434, D_B_loss: 0.0805, G_A_loss: 0.8781, G_B_loss: 0.6601\n",
      "Epoch [20/200], Step [781/1067], D_A_loss: 0.0406, D_B_loss: 0.1883, G_A_loss: 0.6073, G_B_loss: 0.1932\n",
      "Epoch [20/200], Step [791/1067], D_A_loss: 0.0348, D_B_loss: 0.0424, G_A_loss: 0.5919, G_B_loss: 0.8749\n",
      "Epoch [20/200], Step [801/1067], D_A_loss: 0.0289, D_B_loss: 0.0252, G_A_loss: 0.7568, G_B_loss: 0.2426\n",
      "Epoch [20/200], Step [811/1067], D_A_loss: 0.1294, D_B_loss: 0.0552, G_A_loss: 0.5918, G_B_loss: 1.0074\n",
      "Epoch [20/200], Step [821/1067], D_A_loss: 0.0423, D_B_loss: 0.0705, G_A_loss: 0.6154, G_B_loss: 0.7669\n",
      "Epoch [20/200], Step [831/1067], D_A_loss: 0.0583, D_B_loss: 0.0161, G_A_loss: 0.6211, G_B_loss: 0.6874\n",
      "Epoch [20/200], Step [841/1067], D_A_loss: 0.0593, D_B_loss: 0.0308, G_A_loss: 0.8190, G_B_loss: 0.5358\n",
      "Epoch [20/200], Step [851/1067], D_A_loss: 0.2168, D_B_loss: 0.0605, G_A_loss: 0.7921, G_B_loss: 0.2044\n",
      "Epoch [20/200], Step [861/1067], D_A_loss: 0.1290, D_B_loss: 0.2045, G_A_loss: 0.2428, G_B_loss: 1.1014\n",
      "Epoch [20/200], Step [871/1067], D_A_loss: 0.0758, D_B_loss: 0.1173, G_A_loss: 0.7549, G_B_loss: 0.8020\n",
      "Epoch [20/200], Step [881/1067], D_A_loss: 0.3247, D_B_loss: 0.1291, G_A_loss: 0.7275, G_B_loss: 0.2338\n",
      "Epoch [20/200], Step [891/1067], D_A_loss: 0.1066, D_B_loss: 0.0859, G_A_loss: 0.4017, G_B_loss: 0.5643\n",
      "Epoch [20/200], Step [901/1067], D_A_loss: 0.0975, D_B_loss: 0.1298, G_A_loss: 0.6801, G_B_loss: 0.4320\n",
      "Epoch [20/200], Step [911/1067], D_A_loss: 0.1785, D_B_loss: 0.0594, G_A_loss: 0.9410, G_B_loss: 0.5836\n",
      "Epoch [20/200], Step [921/1067], D_A_loss: 0.1697, D_B_loss: 0.0161, G_A_loss: 0.3373, G_B_loss: 0.6261\n",
      "Epoch [20/200], Step [931/1067], D_A_loss: 0.0468, D_B_loss: 0.0977, G_A_loss: 0.9713, G_B_loss: 0.5739\n",
      "Epoch [20/200], Step [941/1067], D_A_loss: 0.1084, D_B_loss: 0.0753, G_A_loss: 0.6033, G_B_loss: 0.2106\n",
      "Epoch [20/200], Step [951/1067], D_A_loss: 0.0323, D_B_loss: 0.0550, G_A_loss: 0.8736, G_B_loss: 0.6584\n",
      "Epoch [20/200], Step [961/1067], D_A_loss: 0.0491, D_B_loss: 0.0296, G_A_loss: 0.5273, G_B_loss: 0.9060\n",
      "Epoch [20/200], Step [971/1067], D_A_loss: 0.0385, D_B_loss: 0.0368, G_A_loss: 0.9509, G_B_loss: 0.7216\n",
      "Epoch [20/200], Step [981/1067], D_A_loss: 0.0368, D_B_loss: 0.0663, G_A_loss: 0.5896, G_B_loss: 0.6399\n",
      "Epoch [20/200], Step [991/1067], D_A_loss: 0.0924, D_B_loss: 0.0616, G_A_loss: 1.1036, G_B_loss: 0.6888\n",
      "Epoch [20/200], Step [1001/1067], D_A_loss: 0.2206, D_B_loss: 0.2240, G_A_loss: 0.4437, G_B_loss: 0.1850\n",
      "Epoch [20/200], Step [1011/1067], D_A_loss: 0.0668, D_B_loss: 0.0333, G_A_loss: 0.8085, G_B_loss: 0.8464\n",
      "Epoch [20/200], Step [1021/1067], D_A_loss: 0.0499, D_B_loss: 0.0587, G_A_loss: 1.2780, G_B_loss: 0.6207\n",
      "Epoch [20/200], Step [1031/1067], D_A_loss: 0.1024, D_B_loss: 0.0413, G_A_loss: 0.6363, G_B_loss: 0.4019\n",
      "Epoch [20/200], Step [1041/1067], D_A_loss: 0.1103, D_B_loss: 0.0215, G_A_loss: 0.5123, G_B_loss: 0.5468\n",
      "Epoch [20/200], Step [1051/1067], D_A_loss: 0.0800, D_B_loss: 0.0484, G_A_loss: 0.5568, G_B_loss: 0.8538\n",
      "Epoch [20/200], Step [1061/1067], D_A_loss: 0.0679, D_B_loss: 0.0558, G_A_loss: 0.5413, G_B_loss: 1.0209\n",
      "Epoch [21/200], Step [1/1067], D_A_loss: 0.0194, D_B_loss: 0.2013, G_A_loss: 1.2925, G_B_loss: 0.3441\n",
      "Epoch [21/200], Step [11/1067], D_A_loss: 0.0783, D_B_loss: 0.0522, G_A_loss: 0.8167, G_B_loss: 0.5681\n",
      "Epoch [21/200], Step [21/1067], D_A_loss: 0.0640, D_B_loss: 0.1329, G_A_loss: 0.3486, G_B_loss: 0.7305\n",
      "Epoch [21/200], Step [31/1067], D_A_loss: 0.1513, D_B_loss: 0.0352, G_A_loss: 1.1283, G_B_loss: 0.7221\n",
      "Epoch [21/200], Step [41/1067], D_A_loss: 0.1228, D_B_loss: 0.0258, G_A_loss: 0.4597, G_B_loss: 0.3092\n",
      "Epoch [21/200], Step [51/1067], D_A_loss: 0.0873, D_B_loss: 0.0567, G_A_loss: 0.5956, G_B_loss: 0.4912\n",
      "Epoch [21/200], Step [61/1067], D_A_loss: 0.1548, D_B_loss: 0.0522, G_A_loss: 1.2237, G_B_loss: 0.2439\n",
      "Epoch [21/200], Step [71/1067], D_A_loss: 0.2462, D_B_loss: 0.0422, G_A_loss: 0.5963, G_B_loss: 0.2636\n",
      "Epoch [21/200], Step [81/1067], D_A_loss: 0.0859, D_B_loss: 0.0239, G_A_loss: 0.6240, G_B_loss: 0.7204\n",
      "Epoch [21/200], Step [91/1067], D_A_loss: 0.0777, D_B_loss: 0.0363, G_A_loss: 0.8656, G_B_loss: 0.9334\n",
      "Epoch [21/200], Step [101/1067], D_A_loss: 0.1122, D_B_loss: 0.0307, G_A_loss: 0.3763, G_B_loss: 0.3748\n",
      "Epoch [21/200], Step [111/1067], D_A_loss: 0.0480, D_B_loss: 0.0373, G_A_loss: 0.7021, G_B_loss: 0.7650\n",
      "Epoch [21/200], Step [121/1067], D_A_loss: 0.0402, D_B_loss: 0.0162, G_A_loss: 0.8189, G_B_loss: 0.4431\n",
      "Epoch [21/200], Step [131/1067], D_A_loss: 0.1107, D_B_loss: 0.0990, G_A_loss: 0.6318, G_B_loss: 0.4932\n",
      "Epoch [21/200], Step [141/1067], D_A_loss: 0.1016, D_B_loss: 0.0618, G_A_loss: 0.5418, G_B_loss: 0.6541\n",
      "Epoch [21/200], Step [151/1067], D_A_loss: 0.0557, D_B_loss: 0.0962, G_A_loss: 0.4298, G_B_loss: 0.2804\n",
      "Epoch [21/200], Step [161/1067], D_A_loss: 0.2191, D_B_loss: 0.0187, G_A_loss: 0.5565, G_B_loss: 0.4171\n",
      "Epoch [21/200], Step [171/1067], D_A_loss: 0.0939, D_B_loss: 0.0892, G_A_loss: 1.1619, G_B_loss: 0.6389\n",
      "Epoch [21/200], Step [181/1067], D_A_loss: 0.0446, D_B_loss: 0.1100, G_A_loss: 0.3833, G_B_loss: 0.5316\n",
      "Epoch [21/200], Step [191/1067], D_A_loss: 0.1749, D_B_loss: 0.1599, G_A_loss: 0.2898, G_B_loss: 0.2789\n",
      "Epoch [21/200], Step [201/1067], D_A_loss: 0.1133, D_B_loss: 0.0512, G_A_loss: 0.4698, G_B_loss: 0.5614\n",
      "Epoch [21/200], Step [211/1067], D_A_loss: 0.0573, D_B_loss: 0.0299, G_A_loss: 0.8604, G_B_loss: 0.3314\n",
      "Epoch [21/200], Step [221/1067], D_A_loss: 0.0338, D_B_loss: 0.0188, G_A_loss: 0.4666, G_B_loss: 0.5622\n",
      "Epoch [21/200], Step [231/1067], D_A_loss: 0.2066, D_B_loss: 0.0999, G_A_loss: 0.5713, G_B_loss: 0.9239\n",
      "Epoch [21/200], Step [241/1067], D_A_loss: 0.0475, D_B_loss: 0.0842, G_A_loss: 0.7405, G_B_loss: 0.6976\n",
      "Epoch [21/200], Step [251/1067], D_A_loss: 0.1208, D_B_loss: 0.1211, G_A_loss: 0.7076, G_B_loss: 0.7906\n",
      "Epoch [21/200], Step [261/1067], D_A_loss: 0.0435, D_B_loss: 0.0326, G_A_loss: 0.5106, G_B_loss: 1.0233\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21/200], Step [271/1067], D_A_loss: 0.0289, D_B_loss: 0.0460, G_A_loss: 0.7908, G_B_loss: 0.6725\n",
      "Epoch [21/200], Step [281/1067], D_A_loss: 0.0422, D_B_loss: 0.0605, G_A_loss: 0.8061, G_B_loss: 0.7798\n",
      "Epoch [21/200], Step [291/1067], D_A_loss: 0.0648, D_B_loss: 0.0544, G_A_loss: 1.5671, G_B_loss: 0.4128\n",
      "Epoch [21/200], Step [301/1067], D_A_loss: 0.1274, D_B_loss: 0.0208, G_A_loss: 0.3665, G_B_loss: 0.4555\n",
      "Epoch [21/200], Step [311/1067], D_A_loss: 0.2772, D_B_loss: 0.0565, G_A_loss: 0.5633, G_B_loss: 0.5632\n",
      "Epoch [21/200], Step [321/1067], D_A_loss: 0.1387, D_B_loss: 0.1509, G_A_loss: 0.3964, G_B_loss: 0.5134\n",
      "Epoch [21/200], Step [331/1067], D_A_loss: 0.0523, D_B_loss: 0.1056, G_A_loss: 0.3621, G_B_loss: 0.6297\n",
      "Epoch [21/200], Step [341/1067], D_A_loss: 0.0559, D_B_loss: 0.3795, G_A_loss: 1.8437, G_B_loss: 0.6206\n",
      "Epoch [21/200], Step [351/1067], D_A_loss: 0.0782, D_B_loss: 0.0225, G_A_loss: 0.5649, G_B_loss: 0.5619\n",
      "Epoch [21/200], Step [361/1067], D_A_loss: 0.2095, D_B_loss: 0.2242, G_A_loss: 1.0130, G_B_loss: 0.3924\n",
      "Epoch [21/200], Step [371/1067], D_A_loss: 0.1140, D_B_loss: 0.0326, G_A_loss: 0.5464, G_B_loss: 0.4973\n",
      "Epoch [21/200], Step [381/1067], D_A_loss: 0.0260, D_B_loss: 0.1690, G_A_loss: 0.8773, G_B_loss: 0.3573\n",
      "Epoch [21/200], Step [391/1067], D_A_loss: 0.2605, D_B_loss: 0.0672, G_A_loss: 0.1782, G_B_loss: 0.6503\n",
      "Epoch [21/200], Step [401/1067], D_A_loss: 0.0669, D_B_loss: 0.2175, G_A_loss: 0.6562, G_B_loss: 0.4896\n",
      "Epoch [21/200], Step [411/1067], D_A_loss: 0.0957, D_B_loss: 0.0788, G_A_loss: 0.7107, G_B_loss: 0.4719\n",
      "Epoch [21/200], Step [421/1067], D_A_loss: 0.1049, D_B_loss: 0.0609, G_A_loss: 0.8826, G_B_loss: 0.7860\n",
      "Epoch [21/200], Step [431/1067], D_A_loss: 0.0954, D_B_loss: 0.0981, G_A_loss: 0.4124, G_B_loss: 0.5423\n",
      "Epoch [21/200], Step [441/1067], D_A_loss: 0.0215, D_B_loss: 0.1097, G_A_loss: 0.2731, G_B_loss: 0.4488\n",
      "Epoch [21/200], Step [451/1067], D_A_loss: 0.0522, D_B_loss: 0.2371, G_A_loss: 0.7545, G_B_loss: 0.5108\n",
      "Epoch [21/200], Step [461/1067], D_A_loss: 0.0877, D_B_loss: 0.0183, G_A_loss: 0.4396, G_B_loss: 0.6140\n",
      "Epoch [21/200], Step [471/1067], D_A_loss: 0.0911, D_B_loss: 0.0346, G_A_loss: 0.7093, G_B_loss: 0.4244\n",
      "Epoch [21/200], Step [481/1067], D_A_loss: 0.0566, D_B_loss: 0.1006, G_A_loss: 0.4008, G_B_loss: 1.0624\n",
      "Epoch [21/200], Step [491/1067], D_A_loss: 0.1211, D_B_loss: 0.2117, G_A_loss: 0.9204, G_B_loss: 0.3781\n",
      "Epoch [21/200], Step [501/1067], D_A_loss: 0.0401, D_B_loss: 0.1508, G_A_loss: 1.2798, G_B_loss: 1.0181\n",
      "Epoch [21/200], Step [511/1067], D_A_loss: 0.1873, D_B_loss: 0.2551, G_A_loss: 0.1274, G_B_loss: 0.3105\n",
      "Epoch [21/200], Step [521/1067], D_A_loss: 0.0307, D_B_loss: 0.0857, G_A_loss: 0.4592, G_B_loss: 0.5973\n",
      "Epoch [21/200], Step [531/1067], D_A_loss: 0.0795, D_B_loss: 0.0646, G_A_loss: 0.6059, G_B_loss: 0.4745\n",
      "Epoch [21/200], Step [541/1067], D_A_loss: 0.0978, D_B_loss: 0.0692, G_A_loss: 0.4868, G_B_loss: 0.4476\n",
      "Epoch [21/200], Step [551/1067], D_A_loss: 0.0928, D_B_loss: 0.0555, G_A_loss: 0.6361, G_B_loss: 0.4364\n",
      "Epoch [21/200], Step [561/1067], D_A_loss: 0.1217, D_B_loss: 0.0175, G_A_loss: 0.8335, G_B_loss: 0.5437\n",
      "Epoch [21/200], Step [571/1067], D_A_loss: 0.1577, D_B_loss: 0.0687, G_A_loss: 0.6419, G_B_loss: 0.7855\n",
      "Epoch [21/200], Step [581/1067], D_A_loss: 0.0232, D_B_loss: 0.0183, G_A_loss: 0.6423, G_B_loss: 0.5399\n",
      "Epoch [21/200], Step [591/1067], D_A_loss: 0.0731, D_B_loss: 0.1132, G_A_loss: 0.4404, G_B_loss: 0.5953\n",
      "Epoch [21/200], Step [601/1067], D_A_loss: 0.0377, D_B_loss: 0.0278, G_A_loss: 1.1214, G_B_loss: 0.8859\n",
      "Epoch [21/200], Step [611/1067], D_A_loss: 0.1450, D_B_loss: 0.1190, G_A_loss: 0.4541, G_B_loss: 0.2736\n",
      "Epoch [21/200], Step [621/1067], D_A_loss: 0.0285, D_B_loss: 0.0931, G_A_loss: 1.0374, G_B_loss: 0.6308\n",
      "Epoch [21/200], Step [631/1067], D_A_loss: 0.0270, D_B_loss: 0.0346, G_A_loss: 0.6531, G_B_loss: 0.7191\n",
      "Epoch [21/200], Step [641/1067], D_A_loss: 0.0748, D_B_loss: 0.1499, G_A_loss: 1.2245, G_B_loss: 0.6192\n",
      "Epoch [21/200], Step [651/1067], D_A_loss: 0.0588, D_B_loss: 0.0245, G_A_loss: 0.8662, G_B_loss: 0.8876\n",
      "Epoch [21/200], Step [661/1067], D_A_loss: 0.1212, D_B_loss: 0.0228, G_A_loss: 0.5255, G_B_loss: 0.5708\n",
      "Epoch [21/200], Step [671/1067], D_A_loss: 0.0325, D_B_loss: 0.2283, G_A_loss: 1.1006, G_B_loss: 0.8332\n",
      "Epoch [21/200], Step [681/1067], D_A_loss: 0.0860, D_B_loss: 0.1227, G_A_loss: 0.3784, G_B_loss: 0.3317\n",
      "Epoch [21/200], Step [691/1067], D_A_loss: 0.0653, D_B_loss: 0.0945, G_A_loss: 0.6076, G_B_loss: 0.6086\n",
      "Epoch [21/200], Step [701/1067], D_A_loss: 0.1512, D_B_loss: 0.1321, G_A_loss: 0.5302, G_B_loss: 0.7314\n",
      "Epoch [21/200], Step [711/1067], D_A_loss: 0.0593, D_B_loss: 0.1613, G_A_loss: 0.2570, G_B_loss: 1.0082\n",
      "Epoch [21/200], Step [721/1067], D_A_loss: 0.1412, D_B_loss: 0.0776, G_A_loss: 0.4198, G_B_loss: 0.3423\n",
      "Epoch [21/200], Step [731/1067], D_A_loss: 0.0623, D_B_loss: 0.0703, G_A_loss: 0.2070, G_B_loss: 0.5514\n",
      "Epoch [21/200], Step [741/1067], D_A_loss: 0.1796, D_B_loss: 0.0266, G_A_loss: 1.0759, G_B_loss: 0.7833\n",
      "Epoch [21/200], Step [751/1067], D_A_loss: 0.0531, D_B_loss: 0.2464, G_A_loss: 0.1527, G_B_loss: 0.4361\n",
      "Epoch [21/200], Step [761/1067], D_A_loss: 0.0873, D_B_loss: 0.0894, G_A_loss: 0.4373, G_B_loss: 0.4805\n",
      "Epoch [21/200], Step [771/1067], D_A_loss: 0.0728, D_B_loss: 0.0397, G_A_loss: 0.8838, G_B_loss: 0.5735\n",
      "Epoch [21/200], Step [781/1067], D_A_loss: 0.0640, D_B_loss: 0.0493, G_A_loss: 0.4091, G_B_loss: 0.3452\n",
      "Epoch [21/200], Step [791/1067], D_A_loss: 0.0486, D_B_loss: 0.0175, G_A_loss: 0.8402, G_B_loss: 0.5220\n",
      "Epoch [21/200], Step [801/1067], D_A_loss: 0.3307, D_B_loss: 0.0572, G_A_loss: 0.4290, G_B_loss: 0.3947\n",
      "Epoch [21/200], Step [811/1067], D_A_loss: 0.0652, D_B_loss: 0.0482, G_A_loss: 0.5999, G_B_loss: 0.5779\n",
      "Epoch [21/200], Step [821/1067], D_A_loss: 0.0733, D_B_loss: 0.0264, G_A_loss: 0.9200, G_B_loss: 0.5652\n",
      "Epoch [21/200], Step [831/1067], D_A_loss: 0.0365, D_B_loss: 0.0203, G_A_loss: 0.5705, G_B_loss: 0.7153\n",
      "Epoch [21/200], Step [841/1067], D_A_loss: 0.0454, D_B_loss: 0.1299, G_A_loss: 0.3146, G_B_loss: 0.4217\n",
      "Epoch [21/200], Step [851/1067], D_A_loss: 0.1553, D_B_loss: 0.0493, G_A_loss: 0.2643, G_B_loss: 0.3223\n",
      "Epoch [21/200], Step [861/1067], D_A_loss: 0.0527, D_B_loss: 0.0641, G_A_loss: 0.7722, G_B_loss: 0.8179\n",
      "Epoch [21/200], Step [871/1067], D_A_loss: 0.0372, D_B_loss: 0.1343, G_A_loss: 0.6891, G_B_loss: 0.4874\n",
      "Epoch [21/200], Step [881/1067], D_A_loss: 0.0590, D_B_loss: 0.0423, G_A_loss: 0.7280, G_B_loss: 0.2456\n",
      "Epoch [21/200], Step [891/1067], D_A_loss: 0.1418, D_B_loss: 0.1566, G_A_loss: 0.4911, G_B_loss: 0.2926\n",
      "Epoch [21/200], Step [901/1067], D_A_loss: 0.0937, D_B_loss: 0.0397, G_A_loss: 0.2468, G_B_loss: 0.3298\n",
      "Epoch [21/200], Step [911/1067], D_A_loss: 0.0689, D_B_loss: 0.0409, G_A_loss: 0.8610, G_B_loss: 0.5869\n",
      "Epoch [21/200], Step [921/1067], D_A_loss: 0.0449, D_B_loss: 0.0401, G_A_loss: 0.8250, G_B_loss: 0.6885\n",
      "Epoch [21/200], Step [931/1067], D_A_loss: 0.0744, D_B_loss: 0.0689, G_A_loss: 0.3660, G_B_loss: 0.6206\n",
      "Epoch [21/200], Step [941/1067], D_A_loss: 0.0944, D_B_loss: 0.0508, G_A_loss: 1.0907, G_B_loss: 1.0413\n",
      "Epoch [21/200], Step [951/1067], D_A_loss: 0.0888, D_B_loss: 0.3233, G_A_loss: 0.0901, G_B_loss: 0.4346\n",
      "Epoch [21/200], Step [961/1067], D_A_loss: 0.1536, D_B_loss: 0.0645, G_A_loss: 0.5028, G_B_loss: 0.4977\n",
      "Epoch [21/200], Step [971/1067], D_A_loss: 0.0932, D_B_loss: 0.0144, G_A_loss: 0.6052, G_B_loss: 0.4371\n",
      "Epoch [21/200], Step [981/1067], D_A_loss: 0.1218, D_B_loss: 0.0255, G_A_loss: 0.7985, G_B_loss: 0.3688\n",
      "Epoch [21/200], Step [991/1067], D_A_loss: 0.0445, D_B_loss: 0.1919, G_A_loss: 1.0950, G_B_loss: 0.7116\n",
      "Epoch [21/200], Step [1001/1067], D_A_loss: 0.1146, D_B_loss: 0.2889, G_A_loss: 1.0478, G_B_loss: 0.4629\n",
      "Epoch [21/200], Step [1011/1067], D_A_loss: 0.0502, D_B_loss: 0.0340, G_A_loss: 0.7109, G_B_loss: 0.6418\n",
      "Epoch [21/200], Step [1021/1067], D_A_loss: 0.0599, D_B_loss: 0.1062, G_A_loss: 0.3895, G_B_loss: 0.5520\n",
      "Epoch [21/200], Step [1031/1067], D_A_loss: 0.2064, D_B_loss: 0.0731, G_A_loss: 1.2494, G_B_loss: 0.2980\n",
      "Epoch [21/200], Step [1041/1067], D_A_loss: 0.0394, D_B_loss: 0.0726, G_A_loss: 0.5338, G_B_loss: 0.6576\n",
      "Epoch [21/200], Step [1051/1067], D_A_loss: 0.1875, D_B_loss: 0.0224, G_A_loss: 0.4703, G_B_loss: 0.4972\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21/200], Step [1061/1067], D_A_loss: 0.1267, D_B_loss: 0.0607, G_A_loss: 1.0238, G_B_loss: 0.4118\n",
      "Epoch [22/200], Step [1/1067], D_A_loss: 0.0307, D_B_loss: 0.0289, G_A_loss: 0.6678, G_B_loss: 0.4505\n",
      "Epoch [22/200], Step [11/1067], D_A_loss: 0.0664, D_B_loss: 0.1330, G_A_loss: 0.9179, G_B_loss: 0.9987\n",
      "Epoch [22/200], Step [21/1067], D_A_loss: 0.3585, D_B_loss: 0.1472, G_A_loss: 0.8761, G_B_loss: 0.5290\n",
      "Epoch [22/200], Step [31/1067], D_A_loss: 0.0474, D_B_loss: 0.0649, G_A_loss: 0.5470, G_B_loss: 0.6877\n",
      "Epoch [22/200], Step [41/1067], D_A_loss: 0.0846, D_B_loss: 0.0522, G_A_loss: 0.5365, G_B_loss: 0.3940\n",
      "Epoch [22/200], Step [51/1067], D_A_loss: 0.1529, D_B_loss: 0.1270, G_A_loss: 1.2964, G_B_loss: 0.7151\n",
      "Epoch [22/200], Step [61/1067], D_A_loss: 0.0934, D_B_loss: 0.0201, G_A_loss: 1.1568, G_B_loss: 0.5721\n",
      "Epoch [22/200], Step [71/1067], D_A_loss: 0.1347, D_B_loss: 0.1201, G_A_loss: 0.7761, G_B_loss: 0.3989\n",
      "Epoch [22/200], Step [81/1067], D_A_loss: 0.0463, D_B_loss: 0.1184, G_A_loss: 0.9177, G_B_loss: 0.3559\n",
      "Epoch [22/200], Step [91/1067], D_A_loss: 0.0738, D_B_loss: 0.0729, G_A_loss: 0.5606, G_B_loss: 0.6926\n",
      "Epoch [22/200], Step [101/1067], D_A_loss: 0.0648, D_B_loss: 0.0731, G_A_loss: 0.8792, G_B_loss: 0.3676\n",
      "Epoch [22/200], Step [111/1067], D_A_loss: 0.0283, D_B_loss: 0.0976, G_A_loss: 0.3934, G_B_loss: 0.7473\n",
      "Epoch [22/200], Step [121/1067], D_A_loss: 0.0914, D_B_loss: 0.1783, G_A_loss: 0.7156, G_B_loss: 0.4936\n",
      "Epoch [22/200], Step [131/1067], D_A_loss: 0.2078, D_B_loss: 0.0185, G_A_loss: 0.4616, G_B_loss: 0.2577\n",
      "Epoch [22/200], Step [141/1067], D_A_loss: 0.1885, D_B_loss: 0.0310, G_A_loss: 0.7626, G_B_loss: 0.3555\n",
      "Epoch [22/200], Step [151/1067], D_A_loss: 0.3466, D_B_loss: 0.0480, G_A_loss: 0.4242, G_B_loss: 0.1935\n",
      "Epoch [22/200], Step [161/1067], D_A_loss: 0.0918, D_B_loss: 0.1047, G_A_loss: 0.5066, G_B_loss: 0.5128\n",
      "Epoch [22/200], Step [171/1067], D_A_loss: 0.0519, D_B_loss: 0.2649, G_A_loss: 0.7802, G_B_loss: 0.4633\n",
      "Epoch [22/200], Step [181/1067], D_A_loss: 0.0758, D_B_loss: 0.1507, G_A_loss: 0.2672, G_B_loss: 0.5012\n",
      "Epoch [22/200], Step [191/1067], D_A_loss: 0.0963, D_B_loss: 0.0231, G_A_loss: 0.7614, G_B_loss: 0.4300\n",
      "Epoch [22/200], Step [201/1067], D_A_loss: 0.0696, D_B_loss: 0.0549, G_A_loss: 0.7132, G_B_loss: 0.5444\n",
      "Epoch [22/200], Step [211/1067], D_A_loss: 0.1539, D_B_loss: 0.0209, G_A_loss: 0.4929, G_B_loss: 0.4583\n",
      "Epoch [22/200], Step [221/1067], D_A_loss: 0.0978, D_B_loss: 0.0550, G_A_loss: 0.3160, G_B_loss: 0.6711\n",
      "Epoch [22/200], Step [231/1067], D_A_loss: 0.0538, D_B_loss: 0.0308, G_A_loss: 0.8837, G_B_loss: 0.5190\n",
      "Epoch [22/200], Step [241/1067], D_A_loss: 0.1059, D_B_loss: 0.0837, G_A_loss: 0.4254, G_B_loss: 0.3401\n",
      "Epoch [22/200], Step [251/1067], D_A_loss: 0.0434, D_B_loss: 0.0336, G_A_loss: 0.7870, G_B_loss: 0.7207\n",
      "Epoch [22/200], Step [261/1067], D_A_loss: 0.1744, D_B_loss: 0.0506, G_A_loss: 0.7381, G_B_loss: 0.9939\n",
      "Epoch [22/200], Step [271/1067], D_A_loss: 0.0505, D_B_loss: 0.0851, G_A_loss: 0.9904, G_B_loss: 0.6896\n",
      "Epoch [22/200], Step [281/1067], D_A_loss: 0.0841, D_B_loss: 0.0985, G_A_loss: 0.3918, G_B_loss: 0.4324\n",
      "Epoch [22/200], Step [291/1067], D_A_loss: 0.0407, D_B_loss: 0.0807, G_A_loss: 0.6778, G_B_loss: 0.6497\n",
      "Epoch [22/200], Step [301/1067], D_A_loss: 0.0747, D_B_loss: 0.1545, G_A_loss: 0.2472, G_B_loss: 0.7896\n",
      "Epoch [22/200], Step [311/1067], D_A_loss: 0.1449, D_B_loss: 0.0507, G_A_loss: 0.5414, G_B_loss: 0.7378\n",
      "Epoch [22/200], Step [321/1067], D_A_loss: 0.1376, D_B_loss: 0.0179, G_A_loss: 0.3286, G_B_loss: 0.8041\n",
      "Epoch [22/200], Step [331/1067], D_A_loss: 0.0414, D_B_loss: 0.1328, G_A_loss: 0.4637, G_B_loss: 0.3039\n",
      "Epoch [22/200], Step [341/1067], D_A_loss: 0.1590, D_B_loss: 0.0180, G_A_loss: 0.7241, G_B_loss: 0.3293\n",
      "Epoch [22/200], Step [351/1067], D_A_loss: 0.0422, D_B_loss: 0.0405, G_A_loss: 0.5551, G_B_loss: 0.6922\n",
      "Epoch [22/200], Step [361/1067], D_A_loss: 0.1682, D_B_loss: 0.1766, G_A_loss: 0.3850, G_B_loss: 0.2326\n",
      "Epoch [22/200], Step [371/1067], D_A_loss: 0.0386, D_B_loss: 0.1722, G_A_loss: 0.8022, G_B_loss: 0.7089\n",
      "Epoch [22/200], Step [381/1067], D_A_loss: 0.0633, D_B_loss: 0.0516, G_A_loss: 0.5622, G_B_loss: 0.6423\n",
      "Epoch [22/200], Step [391/1067], D_A_loss: 0.0619, D_B_loss: 0.0321, G_A_loss: 0.6827, G_B_loss: 0.3887\n",
      "Epoch [22/200], Step [401/1067], D_A_loss: 0.0383, D_B_loss: 0.3049, G_A_loss: 0.7572, G_B_loss: 0.4362\n",
      "Epoch [22/200], Step [411/1067], D_A_loss: 0.1254, D_B_loss: 0.0483, G_A_loss: 0.5449, G_B_loss: 0.3733\n",
      "Epoch [22/200], Step [421/1067], D_A_loss: 0.1499, D_B_loss: 0.2454, G_A_loss: 0.8453, G_B_loss: 0.2810\n",
      "Epoch [22/200], Step [431/1067], D_A_loss: 0.1061, D_B_loss: 0.1025, G_A_loss: 0.6750, G_B_loss: 0.1588\n",
      "Epoch [22/200], Step [441/1067], D_A_loss: 0.0463, D_B_loss: 0.0840, G_A_loss: 0.8219, G_B_loss: 0.5932\n",
      "Epoch [22/200], Step [451/1067], D_A_loss: 0.1443, D_B_loss: 0.1307, G_A_loss: 0.4981, G_B_loss: 0.4105\n",
      "Epoch [22/200], Step [461/1067], D_A_loss: 0.1775, D_B_loss: 0.2289, G_A_loss: 0.2994, G_B_loss: 0.5020\n",
      "Epoch [22/200], Step [471/1067], D_A_loss: 0.1321, D_B_loss: 0.0507, G_A_loss: 0.8079, G_B_loss: 0.8126\n",
      "Epoch [22/200], Step [481/1067], D_A_loss: 0.1265, D_B_loss: 0.0440, G_A_loss: 0.4041, G_B_loss: 0.9146\n",
      "Epoch [22/200], Step [491/1067], D_A_loss: 0.1601, D_B_loss: 0.0480, G_A_loss: 0.8165, G_B_loss: 0.3088\n",
      "Epoch [22/200], Step [501/1067], D_A_loss: 0.1584, D_B_loss: 0.0703, G_A_loss: 0.5315, G_B_loss: 0.6913\n",
      "Epoch [22/200], Step [511/1067], D_A_loss: 0.0319, D_B_loss: 0.1766, G_A_loss: 0.3883, G_B_loss: 0.2804\n",
      "Epoch [22/200], Step [521/1067], D_A_loss: 0.0497, D_B_loss: 0.0143, G_A_loss: 0.5135, G_B_loss: 0.7572\n",
      "Epoch [22/200], Step [531/1067], D_A_loss: 0.1115, D_B_loss: 0.0274, G_A_loss: 0.3535, G_B_loss: 0.4095\n",
      "Epoch [22/200], Step [541/1067], D_A_loss: 0.0332, D_B_loss: 0.0419, G_A_loss: 0.9252, G_B_loss: 0.7621\n",
      "Epoch [22/200], Step [551/1067], D_A_loss: 0.0446, D_B_loss: 0.2696, G_A_loss: 1.0951, G_B_loss: 0.2276\n",
      "Epoch [22/200], Step [561/1067], D_A_loss: 0.1902, D_B_loss: 0.0376, G_A_loss: 0.6260, G_B_loss: 0.5067\n",
      "Epoch [22/200], Step [571/1067], D_A_loss: 0.1815, D_B_loss: 0.1012, G_A_loss: 0.6664, G_B_loss: 0.4277\n",
      "Epoch [22/200], Step [581/1067], D_A_loss: 0.0738, D_B_loss: 0.0546, G_A_loss: 0.9872, G_B_loss: 0.6594\n",
      "Epoch [22/200], Step [591/1067], D_A_loss: 0.1125, D_B_loss: 0.1060, G_A_loss: 1.0355, G_B_loss: 0.8471\n",
      "Epoch [22/200], Step [601/1067], D_A_loss: 0.1143, D_B_loss: 0.1782, G_A_loss: 0.3014, G_B_loss: 0.6935\n",
      "Epoch [22/200], Step [611/1067], D_A_loss: 0.2115, D_B_loss: 0.1700, G_A_loss: 1.0475, G_B_loss: 0.7505\n",
      "Epoch [22/200], Step [621/1067], D_A_loss: 0.1044, D_B_loss: 0.2598, G_A_loss: 0.1343, G_B_loss: 0.5319\n",
      "Epoch [22/200], Step [631/1067], D_A_loss: 0.0640, D_B_loss: 0.2524, G_A_loss: 1.0995, G_B_loss: 0.6392\n",
      "Epoch [22/200], Step [641/1067], D_A_loss: 0.1357, D_B_loss: 0.0764, G_A_loss: 0.6964, G_B_loss: 0.8491\n",
      "Epoch [22/200], Step [651/1067], D_A_loss: 0.1818, D_B_loss: 0.0534, G_A_loss: 0.8137, G_B_loss: 0.5928\n",
      "Epoch [22/200], Step [661/1067], D_A_loss: 0.1295, D_B_loss: 0.0526, G_A_loss: 0.3684, G_B_loss: 0.7535\n",
      "Epoch [22/200], Step [671/1067], D_A_loss: 0.1340, D_B_loss: 0.0678, G_A_loss: 0.7585, G_B_loss: 0.8392\n",
      "Epoch [22/200], Step [681/1067], D_A_loss: 0.0597, D_B_loss: 0.0644, G_A_loss: 0.5506, G_B_loss: 1.0990\n",
      "Epoch [22/200], Step [691/1067], D_A_loss: 0.1479, D_B_loss: 0.0551, G_A_loss: 0.5878, G_B_loss: 0.7929\n",
      "Epoch [22/200], Step [701/1067], D_A_loss: 0.0881, D_B_loss: 0.0225, G_A_loss: 0.7483, G_B_loss: 0.6538\n",
      "Epoch [22/200], Step [711/1067], D_A_loss: 0.2227, D_B_loss: 0.0306, G_A_loss: 0.7525, G_B_loss: 0.9436\n",
      "Epoch [22/200], Step [721/1067], D_A_loss: 0.0503, D_B_loss: 0.0727, G_A_loss: 0.9722, G_B_loss: 0.2014\n",
      "Epoch [22/200], Step [731/1067], D_A_loss: 0.0229, D_B_loss: 0.0184, G_A_loss: 0.7709, G_B_loss: 0.9013\n",
      "Epoch [22/200], Step [741/1067], D_A_loss: 0.1414, D_B_loss: 0.0325, G_A_loss: 0.7044, G_B_loss: 0.3621\n",
      "Epoch [22/200], Step [751/1067], D_A_loss: 0.0872, D_B_loss: 0.0614, G_A_loss: 0.6632, G_B_loss: 1.2453\n",
      "Epoch [22/200], Step [761/1067], D_A_loss: 0.2176, D_B_loss: 0.0934, G_A_loss: 0.2828, G_B_loss: 0.5335\n",
      "Epoch [22/200], Step [771/1067], D_A_loss: 0.0555, D_B_loss: 0.0919, G_A_loss: 0.2274, G_B_loss: 0.7863\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22/200], Step [781/1067], D_A_loss: 0.1391, D_B_loss: 0.0658, G_A_loss: 0.7983, G_B_loss: 0.3497\n",
      "Epoch [22/200], Step [791/1067], D_A_loss: 0.0646, D_B_loss: 0.0453, G_A_loss: 0.9354, G_B_loss: 0.3863\n",
      "Epoch [22/200], Step [801/1067], D_A_loss: 0.0477, D_B_loss: 0.0379, G_A_loss: 0.6518, G_B_loss: 0.6442\n",
      "Epoch [22/200], Step [811/1067], D_A_loss: 0.0694, D_B_loss: 0.0309, G_A_loss: 0.6911, G_B_loss: 0.5864\n",
      "Epoch [22/200], Step [821/1067], D_A_loss: 0.0603, D_B_loss: 0.1331, G_A_loss: 1.4500, G_B_loss: 0.4158\n",
      "Epoch [22/200], Step [831/1067], D_A_loss: 0.0200, D_B_loss: 0.0828, G_A_loss: 0.7868, G_B_loss: 0.4149\n",
      "Epoch [22/200], Step [841/1067], D_A_loss: 0.0344, D_B_loss: 0.0662, G_A_loss: 0.9127, G_B_loss: 0.6549\n",
      "Epoch [22/200], Step [851/1067], D_A_loss: 0.1688, D_B_loss: 0.0505, G_A_loss: 0.7138, G_B_loss: 0.2617\n",
      "Epoch [22/200], Step [861/1067], D_A_loss: 0.0728, D_B_loss: 0.0492, G_A_loss: 0.6334, G_B_loss: 0.6930\n",
      "Epoch [22/200], Step [871/1067], D_A_loss: 0.0863, D_B_loss: 0.0367, G_A_loss: 0.6417, G_B_loss: 0.8138\n",
      "Epoch [22/200], Step [881/1067], D_A_loss: 0.1282, D_B_loss: 0.1335, G_A_loss: 1.4864, G_B_loss: 0.4868\n",
      "Epoch [22/200], Step [891/1067], D_A_loss: 0.0976, D_B_loss: 0.0308, G_A_loss: 0.8607, G_B_loss: 0.5224\n",
      "Epoch [22/200], Step [901/1067], D_A_loss: 0.0431, D_B_loss: 0.0360, G_A_loss: 0.7291, G_B_loss: 0.6841\n",
      "Epoch [22/200], Step [911/1067], D_A_loss: 0.1876, D_B_loss: 0.1416, G_A_loss: 0.7097, G_B_loss: 0.6419\n",
      "Epoch [22/200], Step [921/1067], D_A_loss: 0.0457, D_B_loss: 0.0588, G_A_loss: 0.5053, G_B_loss: 0.6828\n",
      "Epoch [22/200], Step [931/1067], D_A_loss: 0.0357, D_B_loss: 0.0990, G_A_loss: 0.9492, G_B_loss: 0.5507\n",
      "Epoch [22/200], Step [941/1067], D_A_loss: 0.0584, D_B_loss: 0.0431, G_A_loss: 0.7422, G_B_loss: 0.3999\n",
      "Epoch [22/200], Step [951/1067], D_A_loss: 0.0621, D_B_loss: 0.0534, G_A_loss: 0.5685, G_B_loss: 0.2524\n",
      "Epoch [22/200], Step [961/1067], D_A_loss: 0.1143, D_B_loss: 0.0185, G_A_loss: 0.5482, G_B_loss: 0.6018\n",
      "Epoch [22/200], Step [971/1067], D_A_loss: 0.0978, D_B_loss: 0.0727, G_A_loss: 0.3243, G_B_loss: 0.7259\n",
      "Epoch [22/200], Step [981/1067], D_A_loss: 0.0396, D_B_loss: 0.0929, G_A_loss: 0.9006, G_B_loss: 0.8845\n",
      "Epoch [22/200], Step [991/1067], D_A_loss: 0.1834, D_B_loss: 0.1974, G_A_loss: 0.7997, G_B_loss: 0.2743\n",
      "Epoch [22/200], Step [1001/1067], D_A_loss: 0.0292, D_B_loss: 0.0665, G_A_loss: 0.6873, G_B_loss: 0.4201\n",
      "Epoch [22/200], Step [1011/1067], D_A_loss: 0.0837, D_B_loss: 0.0836, G_A_loss: 0.7260, G_B_loss: 0.4803\n",
      "Epoch [22/200], Step [1021/1067], D_A_loss: 0.0317, D_B_loss: 0.1541, G_A_loss: 0.8937, G_B_loss: 0.7035\n",
      "Epoch [22/200], Step [1031/1067], D_A_loss: 0.2262, D_B_loss: 0.1038, G_A_loss: 0.3053, G_B_loss: 0.2223\n",
      "Epoch [22/200], Step [1041/1067], D_A_loss: 0.3544, D_B_loss: 0.0406, G_A_loss: 0.2646, G_B_loss: 1.0288\n",
      "Epoch [22/200], Step [1051/1067], D_A_loss: 0.0907, D_B_loss: 0.0688, G_A_loss: 0.4724, G_B_loss: 0.7072\n",
      "Epoch [22/200], Step [1061/1067], D_A_loss: 0.0683, D_B_loss: 0.0666, G_A_loss: 0.5304, G_B_loss: 0.9478\n",
      "Epoch [23/200], Step [1/1067], D_A_loss: 0.0318, D_B_loss: 0.1236, G_A_loss: 0.4008, G_B_loss: 0.6565\n",
      "Epoch [23/200], Step [11/1067], D_A_loss: 0.0761, D_B_loss: 0.0461, G_A_loss: 1.1381, G_B_loss: 0.7231\n",
      "Epoch [23/200], Step [21/1067], D_A_loss: 0.0455, D_B_loss: 0.0243, G_A_loss: 0.5189, G_B_loss: 0.5475\n",
      "Epoch [23/200], Step [31/1067], D_A_loss: 0.0829, D_B_loss: 0.0620, G_A_loss: 0.5078, G_B_loss: 0.4748\n",
      "Epoch [23/200], Step [41/1067], D_A_loss: 0.0598, D_B_loss: 0.0342, G_A_loss: 0.6896, G_B_loss: 0.5355\n",
      "Epoch [23/200], Step [51/1067], D_A_loss: 0.0551, D_B_loss: 0.0492, G_A_loss: 1.4688, G_B_loss: 0.5777\n",
      "Epoch [23/200], Step [61/1067], D_A_loss: 0.0474, D_B_loss: 0.0159, G_A_loss: 1.0186, G_B_loss: 0.6856\n",
      "Epoch [23/200], Step [71/1067], D_A_loss: 0.0868, D_B_loss: 0.0316, G_A_loss: 0.6972, G_B_loss: 0.9482\n",
      "Epoch [23/200], Step [81/1067], D_A_loss: 0.0533, D_B_loss: 0.0243, G_A_loss: 0.6078, G_B_loss: 0.6224\n",
      "Epoch [23/200], Step [91/1067], D_A_loss: 0.1047, D_B_loss: 0.1213, G_A_loss: 0.6552, G_B_loss: 0.6468\n",
      "Epoch [23/200], Step [101/1067], D_A_loss: 0.0966, D_B_loss: 0.1168, G_A_loss: 0.3921, G_B_loss: 0.4744\n",
      "Epoch [23/200], Step [111/1067], D_A_loss: 0.1633, D_B_loss: 0.0292, G_A_loss: 0.6050, G_B_loss: 0.3911\n",
      "Epoch [23/200], Step [121/1067], D_A_loss: 0.0730, D_B_loss: 0.1712, G_A_loss: 0.3293, G_B_loss: 0.6079\n",
      "Epoch [23/200], Step [131/1067], D_A_loss: 0.0375, D_B_loss: 0.0308, G_A_loss: 0.4913, G_B_loss: 0.9523\n",
      "Epoch [23/200], Step [141/1067], D_A_loss: 0.1037, D_B_loss: 0.0556, G_A_loss: 0.6531, G_B_loss: 0.8589\n",
      "Epoch [23/200], Step [151/1067], D_A_loss: 0.0604, D_B_loss: 0.1750, G_A_loss: 0.8027, G_B_loss: 0.5561\n",
      "Epoch [23/200], Step [161/1067], D_A_loss: 0.0239, D_B_loss: 0.0530, G_A_loss: 0.9853, G_B_loss: 0.3852\n",
      "Epoch [23/200], Step [171/1067], D_A_loss: 0.1406, D_B_loss: 0.1837, G_A_loss: 0.4412, G_B_loss: 0.4715\n",
      "Epoch [23/200], Step [181/1067], D_A_loss: 0.0442, D_B_loss: 0.0677, G_A_loss: 0.5830, G_B_loss: 0.2493\n",
      "Epoch [23/200], Step [191/1067], D_A_loss: 0.1578, D_B_loss: 0.1673, G_A_loss: 0.2474, G_B_loss: 0.2952\n",
      "Epoch [23/200], Step [201/1067], D_A_loss: 0.0368, D_B_loss: 0.0647, G_A_loss: 0.6781, G_B_loss: 0.5000\n",
      "Epoch [23/200], Step [211/1067], D_A_loss: 0.1752, D_B_loss: 0.1458, G_A_loss: 0.7682, G_B_loss: 0.3580\n",
      "Epoch [23/200], Step [221/1067], D_A_loss: 0.2041, D_B_loss: 0.0677, G_A_loss: 0.3409, G_B_loss: 0.2161\n",
      "Epoch [23/200], Step [231/1067], D_A_loss: 0.0495, D_B_loss: 0.1454, G_A_loss: 0.6752, G_B_loss: 0.6452\n",
      "Epoch [23/200], Step [241/1067], D_A_loss: 0.0603, D_B_loss: 0.0322, G_A_loss: 0.8397, G_B_loss: 0.5508\n",
      "Epoch [23/200], Step [251/1067], D_A_loss: 0.0752, D_B_loss: 0.3056, G_A_loss: 0.1632, G_B_loss: 0.3329\n",
      "Epoch [23/200], Step [261/1067], D_A_loss: 0.0455, D_B_loss: 0.0609, G_A_loss: 0.6740, G_B_loss: 0.5540\n",
      "Epoch [23/200], Step [271/1067], D_A_loss: 0.0982, D_B_loss: 0.0336, G_A_loss: 0.6299, G_B_loss: 0.4363\n",
      "Epoch [23/200], Step [281/1067], D_A_loss: 0.1000, D_B_loss: 0.1141, G_A_loss: 0.3831, G_B_loss: 0.4631\n",
      "Epoch [23/200], Step [291/1067], D_A_loss: 0.2102, D_B_loss: 0.1439, G_A_loss: 1.2357, G_B_loss: 0.1614\n",
      "Epoch [23/200], Step [301/1067], D_A_loss: 0.1740, D_B_loss: 0.0374, G_A_loss: 0.6790, G_B_loss: 0.2905\n",
      "Epoch [23/200], Step [311/1067], D_A_loss: 0.1815, D_B_loss: 0.0697, G_A_loss: 0.6823, G_B_loss: 0.5418\n",
      "Epoch [23/200], Step [321/1067], D_A_loss: 0.1071, D_B_loss: 0.0231, G_A_loss: 0.7533, G_B_loss: 0.9685\n",
      "Epoch [23/200], Step [331/1067], D_A_loss: 0.0631, D_B_loss: 0.0959, G_A_loss: 0.5154, G_B_loss: 0.7289\n",
      "Epoch [23/200], Step [341/1067], D_A_loss: 0.1703, D_B_loss: 0.1254, G_A_loss: 0.4892, G_B_loss: 0.7812\n",
      "Epoch [23/200], Step [351/1067], D_A_loss: 0.0756, D_B_loss: 0.0149, G_A_loss: 0.6978, G_B_loss: 0.5156\n",
      "Epoch [23/200], Step [361/1067], D_A_loss: 0.0785, D_B_loss: 0.1335, G_A_loss: 0.6622, G_B_loss: 0.4534\n",
      "Epoch [23/200], Step [371/1067], D_A_loss: 0.0516, D_B_loss: 0.0408, G_A_loss: 0.6422, G_B_loss: 0.3994\n",
      "Epoch [23/200], Step [381/1067], D_A_loss: 0.0770, D_B_loss: 0.0491, G_A_loss: 0.5564, G_B_loss: 0.6572\n",
      "Epoch [23/200], Step [391/1067], D_A_loss: 0.0561, D_B_loss: 0.0848, G_A_loss: 0.5505, G_B_loss: 0.5307\n",
      "Epoch [23/200], Step [401/1067], D_A_loss: 0.1571, D_B_loss: 0.0302, G_A_loss: 0.8297, G_B_loss: 0.4070\n",
      "Epoch [23/200], Step [411/1067], D_A_loss: 0.1491, D_B_loss: 0.2266, G_A_loss: 0.2214, G_B_loss: 0.3691\n",
      "Epoch [23/200], Step [421/1067], D_A_loss: 0.1235, D_B_loss: 0.0327, G_A_loss: 0.9248, G_B_loss: 0.7033\n",
      "Epoch [23/200], Step [431/1067], D_A_loss: 0.1023, D_B_loss: 0.1649, G_A_loss: 0.3573, G_B_loss: 0.7990\n",
      "Epoch [23/200], Step [441/1067], D_A_loss: 0.1175, D_B_loss: 0.0515, G_A_loss: 0.4569, G_B_loss: 0.5469\n",
      "Epoch [23/200], Step [451/1067], D_A_loss: 0.0983, D_B_loss: 0.0624, G_A_loss: 0.7145, G_B_loss: 0.5262\n",
      "Epoch [23/200], Step [461/1067], D_A_loss: 0.1396, D_B_loss: 0.0271, G_A_loss: 0.5721, G_B_loss: 0.7396\n",
      "Epoch [23/200], Step [471/1067], D_A_loss: 0.0308, D_B_loss: 0.0565, G_A_loss: 0.3681, G_B_loss: 0.5848\n",
      "Epoch [23/200], Step [481/1067], D_A_loss: 0.1059, D_B_loss: 0.0241, G_A_loss: 0.5096, G_B_loss: 0.7810\n",
      "Epoch [23/200], Step [491/1067], D_A_loss: 0.2274, D_B_loss: 0.0304, G_A_loss: 1.0334, G_B_loss: 0.3630\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23/200], Step [501/1067], D_A_loss: 0.1192, D_B_loss: 0.1097, G_A_loss: 0.4357, G_B_loss: 0.4874\n",
      "Epoch [23/200], Step [511/1067], D_A_loss: 0.1030, D_B_loss: 0.0675, G_A_loss: 0.5260, G_B_loss: 0.5416\n",
      "Epoch [23/200], Step [521/1067], D_A_loss: 0.2059, D_B_loss: 0.0311, G_A_loss: 0.8185, G_B_loss: 0.6259\n",
      "Epoch [23/200], Step [531/1067], D_A_loss: 0.0725, D_B_loss: 0.1019, G_A_loss: 0.8909, G_B_loss: 0.7629\n",
      "Epoch [23/200], Step [541/1067], D_A_loss: 0.0783, D_B_loss: 0.0427, G_A_loss: 0.3938, G_B_loss: 0.6390\n",
      "Epoch [23/200], Step [551/1067], D_A_loss: 0.2405, D_B_loss: 0.0835, G_A_loss: 0.9805, G_B_loss: 0.3570\n",
      "Epoch [23/200], Step [561/1067], D_A_loss: 0.0827, D_B_loss: 0.0346, G_A_loss: 0.5453, G_B_loss: 0.5701\n",
      "Epoch [23/200], Step [571/1067], D_A_loss: 0.2371, D_B_loss: 0.0615, G_A_loss: 0.2684, G_B_loss: 0.1928\n",
      "Epoch [23/200], Step [581/1067], D_A_loss: 0.1079, D_B_loss: 0.0372, G_A_loss: 0.6589, G_B_loss: 0.4811\n",
      "Epoch [23/200], Step [591/1067], D_A_loss: 0.1260, D_B_loss: 0.0268, G_A_loss: 0.9425, G_B_loss: 0.3619\n",
      "Epoch [23/200], Step [601/1067], D_A_loss: 0.0723, D_B_loss: 0.1062, G_A_loss: 0.6545, G_B_loss: 0.4931\n",
      "Epoch [23/200], Step [611/1067], D_A_loss: 0.0599, D_B_loss: 0.1084, G_A_loss: 0.2106, G_B_loss: 0.7196\n",
      "Epoch [23/200], Step [621/1067], D_A_loss: 0.0744, D_B_loss: 0.0589, G_A_loss: 0.4870, G_B_loss: 1.0011\n",
      "Epoch [23/200], Step [631/1067], D_A_loss: 0.1047, D_B_loss: 0.1063, G_A_loss: 0.4702, G_B_loss: 0.6555\n",
      "Epoch [23/200], Step [641/1067], D_A_loss: 0.0359, D_B_loss: 0.0188, G_A_loss: 0.7990, G_B_loss: 0.5782\n",
      "Epoch [23/200], Step [651/1067], D_A_loss: 0.0630, D_B_loss: 0.1584, G_A_loss: 0.9930, G_B_loss: 0.8126\n",
      "Epoch [23/200], Step [661/1067], D_A_loss: 0.0983, D_B_loss: 0.1270, G_A_loss: 0.5535, G_B_loss: 0.4707\n",
      "Epoch [23/200], Step [671/1067], D_A_loss: 0.1213, D_B_loss: 0.0577, G_A_loss: 0.6599, G_B_loss: 0.8236\n",
      "Epoch [23/200], Step [681/1067], D_A_loss: 0.1704, D_B_loss: 0.1535, G_A_loss: 0.8952, G_B_loss: 0.2581\n",
      "Epoch [23/200], Step [691/1067], D_A_loss: 0.3799, D_B_loss: 0.0725, G_A_loss: 1.0017, G_B_loss: 1.0586\n",
      "Epoch [23/200], Step [701/1067], D_A_loss: 0.0987, D_B_loss: 0.0621, G_A_loss: 0.7853, G_B_loss: 0.5703\n",
      "Epoch [23/200], Step [711/1067], D_A_loss: 0.1059, D_B_loss: 0.0839, G_A_loss: 0.5021, G_B_loss: 0.8577\n",
      "Epoch [23/200], Step [721/1067], D_A_loss: 0.0951, D_B_loss: 0.1272, G_A_loss: 1.1948, G_B_loss: 0.5962\n",
      "Epoch [23/200], Step [731/1067], D_A_loss: 0.1580, D_B_loss: 0.0923, G_A_loss: 0.4278, G_B_loss: 0.6914\n",
      "Epoch [23/200], Step [741/1067], D_A_loss: 0.2692, D_B_loss: 0.0295, G_A_loss: 0.5640, G_B_loss: 1.0476\n",
      "Epoch [23/200], Step [751/1067], D_A_loss: 0.0542, D_B_loss: 0.0178, G_A_loss: 0.5461, G_B_loss: 0.4045\n",
      "Epoch [23/200], Step [761/1067], D_A_loss: 0.0342, D_B_loss: 0.0289, G_A_loss: 0.7327, G_B_loss: 0.6206\n",
      "Epoch [23/200], Step [771/1067], D_A_loss: 0.0485, D_B_loss: 0.0408, G_A_loss: 0.4424, G_B_loss: 0.7191\n",
      "Epoch [23/200], Step [781/1067], D_A_loss: 0.1970, D_B_loss: 0.0421, G_A_loss: 1.0598, G_B_loss: 0.5188\n",
      "Epoch [23/200], Step [791/1067], D_A_loss: 0.1037, D_B_loss: 0.0387, G_A_loss: 0.6821, G_B_loss: 0.3826\n",
      "Epoch [23/200], Step [801/1067], D_A_loss: 0.0560, D_B_loss: 0.0993, G_A_loss: 1.0429, G_B_loss: 0.2773\n",
      "Epoch [23/200], Step [811/1067], D_A_loss: 0.0909, D_B_loss: 0.2911, G_A_loss: 0.2420, G_B_loss: 0.4986\n",
      "Epoch [23/200], Step [821/1067], D_A_loss: 0.1253, D_B_loss: 0.0325, G_A_loss: 0.7630, G_B_loss: 0.4144\n",
      "Epoch [23/200], Step [831/1067], D_A_loss: 0.0967, D_B_loss: 0.0155, G_A_loss: 0.5996, G_B_loss: 0.7094\n",
      "Epoch [23/200], Step [841/1067], D_A_loss: 0.0883, D_B_loss: 0.0289, G_A_loss: 0.8790, G_B_loss: 0.2051\n",
      "Epoch [23/200], Step [851/1067], D_A_loss: 0.0559, D_B_loss: 0.0213, G_A_loss: 0.9657, G_B_loss: 0.3691\n",
      "Epoch [23/200], Step [861/1067], D_A_loss: 0.2130, D_B_loss: 0.0267, G_A_loss: 0.8583, G_B_loss: 0.1838\n",
      "Epoch [23/200], Step [871/1067], D_A_loss: 0.1144, D_B_loss: 0.0287, G_A_loss: 0.7542, G_B_loss: 0.3566\n",
      "Epoch [23/200], Step [881/1067], D_A_loss: 0.0616, D_B_loss: 0.1825, G_A_loss: 0.9125, G_B_loss: 0.5941\n",
      "Epoch [23/200], Step [891/1067], D_A_loss: 0.0226, D_B_loss: 0.0405, G_A_loss: 0.7771, G_B_loss: 0.9567\n",
      "Epoch [23/200], Step [901/1067], D_A_loss: 0.0674, D_B_loss: 0.1747, G_A_loss: 0.9306, G_B_loss: 0.5059\n",
      "Epoch [23/200], Step [911/1067], D_A_loss: 0.0781, D_B_loss: 0.0276, G_A_loss: 0.7671, G_B_loss: 0.4760\n",
      "Epoch [23/200], Step [921/1067], D_A_loss: 0.0560, D_B_loss: 0.0421, G_A_loss: 0.8900, G_B_loss: 0.6817\n",
      "Epoch [23/200], Step [931/1067], D_A_loss: 0.0500, D_B_loss: 0.0871, G_A_loss: 0.5118, G_B_loss: 0.2801\n",
      "Epoch [23/200], Step [941/1067], D_A_loss: 0.0536, D_B_loss: 0.0521, G_A_loss: 0.5812, G_B_loss: 0.6311\n",
      "Epoch [23/200], Step [951/1067], D_A_loss: 0.0737, D_B_loss: 0.1387, G_A_loss: 1.0271, G_B_loss: 1.1038\n",
      "Epoch [23/200], Step [961/1067], D_A_loss: 0.1314, D_B_loss: 0.0241, G_A_loss: 0.6172, G_B_loss: 0.9263\n",
      "Epoch [23/200], Step [971/1067], D_A_loss: 0.1617, D_B_loss: 0.1338, G_A_loss: 0.3232, G_B_loss: 0.9254\n",
      "Epoch [23/200], Step [981/1067], D_A_loss: 0.0305, D_B_loss: 0.0467, G_A_loss: 0.6965, G_B_loss: 0.4152\n",
      "Epoch [23/200], Step [991/1067], D_A_loss: 0.0699, D_B_loss: 0.0330, G_A_loss: 1.3859, G_B_loss: 0.4934\n",
      "Epoch [23/200], Step [1001/1067], D_A_loss: 0.1059, D_B_loss: 0.0411, G_A_loss: 0.6198, G_B_loss: 0.2259\n",
      "Epoch [23/200], Step [1011/1067], D_A_loss: 0.0202, D_B_loss: 0.0285, G_A_loss: 0.8640, G_B_loss: 0.7920\n",
      "Epoch [23/200], Step [1021/1067], D_A_loss: 0.1329, D_B_loss: 0.0785, G_A_loss: 0.4663, G_B_loss: 0.6773\n",
      "Epoch [23/200], Step [1031/1067], D_A_loss: 0.0504, D_B_loss: 0.1409, G_A_loss: 0.5869, G_B_loss: 0.3245\n",
      "Epoch [23/200], Step [1041/1067], D_A_loss: 0.0382, D_B_loss: 0.0566, G_A_loss: 0.6576, G_B_loss: 0.7160\n",
      "Epoch [23/200], Step [1051/1067], D_A_loss: 0.0637, D_B_loss: 0.1253, G_A_loss: 0.9205, G_B_loss: 0.4601\n",
      "Epoch [23/200], Step [1061/1067], D_A_loss: 0.0519, D_B_loss: 0.0854, G_A_loss: 0.7037, G_B_loss: 0.8143\n",
      "Epoch [24/200], Step [1/1067], D_A_loss: 0.0786, D_B_loss: 0.0497, G_A_loss: 0.5923, G_B_loss: 0.5791\n",
      "Epoch [24/200], Step [11/1067], D_A_loss: 0.0689, D_B_loss: 0.0662, G_A_loss: 0.4892, G_B_loss: 0.3697\n",
      "Epoch [24/200], Step [21/1067], D_A_loss: 0.0458, D_B_loss: 0.0352, G_A_loss: 0.5938, G_B_loss: 0.5647\n",
      "Epoch [24/200], Step [31/1067], D_A_loss: 0.1400, D_B_loss: 0.0231, G_A_loss: 0.7065, G_B_loss: 0.6675\n",
      "Epoch [24/200], Step [41/1067], D_A_loss: 0.0828, D_B_loss: 0.0537, G_A_loss: 0.5840, G_B_loss: 0.8829\n",
      "Epoch [24/200], Step [51/1067], D_A_loss: 0.1130, D_B_loss: 0.0462, G_A_loss: 0.6537, G_B_loss: 0.5649\n",
      "Epoch [24/200], Step [61/1067], D_A_loss: 0.0967, D_B_loss: 0.0170, G_A_loss: 0.4947, G_B_loss: 0.4178\n",
      "Epoch [24/200], Step [71/1067], D_A_loss: 0.1460, D_B_loss: 0.0600, G_A_loss: 0.8836, G_B_loss: 0.3678\n",
      "Epoch [24/200], Step [81/1067], D_A_loss: 0.0873, D_B_loss: 0.1419, G_A_loss: 0.4592, G_B_loss: 0.6189\n",
      "Epoch [24/200], Step [91/1067], D_A_loss: 0.0227, D_B_loss: 0.0356, G_A_loss: 0.7954, G_B_loss: 0.6086\n",
      "Epoch [24/200], Step [101/1067], D_A_loss: 0.0346, D_B_loss: 0.0358, G_A_loss: 0.8939, G_B_loss: 0.6264\n",
      "Epoch [24/200], Step [111/1067], D_A_loss: 0.0229, D_B_loss: 0.0596, G_A_loss: 0.7026, G_B_loss: 0.5843\n",
      "Epoch [24/200], Step [121/1067], D_A_loss: 0.0561, D_B_loss: 0.0200, G_A_loss: 0.9430, G_B_loss: 0.3841\n",
      "Epoch [24/200], Step [131/1067], D_A_loss: 0.1438, D_B_loss: 0.0255, G_A_loss: 0.5612, G_B_loss: 0.9782\n",
      "Epoch [24/200], Step [141/1067], D_A_loss: 0.2415, D_B_loss: 0.0346, G_A_loss: 0.8152, G_B_loss: 0.4648\n",
      "Epoch [24/200], Step [151/1067], D_A_loss: 0.1042, D_B_loss: 0.0583, G_A_loss: 0.4255, G_B_loss: 0.6983\n",
      "Epoch [24/200], Step [161/1067], D_A_loss: 0.0713, D_B_loss: 0.0941, G_A_loss: 0.9671, G_B_loss: 0.9120\n",
      "Epoch [24/200], Step [171/1067], D_A_loss: 0.1036, D_B_loss: 0.0173, G_A_loss: 0.7233, G_B_loss: 0.4391\n",
      "Epoch [24/200], Step [181/1067], D_A_loss: 0.2183, D_B_loss: 0.0775, G_A_loss: 0.5581, G_B_loss: 0.4683\n",
      "Epoch [24/200], Step [191/1067], D_A_loss: 0.0433, D_B_loss: 0.1575, G_A_loss: 0.5761, G_B_loss: 0.6725\n",
      "Epoch [24/200], Step [201/1067], D_A_loss: 0.0886, D_B_loss: 0.0359, G_A_loss: 0.4759, G_B_loss: 0.4273\n",
      "Epoch [24/200], Step [211/1067], D_A_loss: 0.0473, D_B_loss: 0.0284, G_A_loss: 0.7953, G_B_loss: 0.1508\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24/200], Step [221/1067], D_A_loss: 0.0815, D_B_loss: 0.0522, G_A_loss: 1.1049, G_B_loss: 0.2335\n",
      "Epoch [24/200], Step [231/1067], D_A_loss: 0.0460, D_B_loss: 0.0136, G_A_loss: 0.9688, G_B_loss: 0.4588\n",
      "Epoch [24/200], Step [241/1067], D_A_loss: 0.0763, D_B_loss: 0.2983, G_A_loss: 0.5507, G_B_loss: 0.6339\n",
      "Epoch [24/200], Step [251/1067], D_A_loss: 0.0598, D_B_loss: 0.0749, G_A_loss: 0.6402, G_B_loss: 0.5347\n",
      "Epoch [24/200], Step [261/1067], D_A_loss: 0.1683, D_B_loss: 0.0526, G_A_loss: 0.9565, G_B_loss: 0.2935\n",
      "Epoch [24/200], Step [271/1067], D_A_loss: 0.0341, D_B_loss: 0.0298, G_A_loss: 0.7216, G_B_loss: 0.6273\n",
      "Epoch [24/200], Step [281/1067], D_A_loss: 0.0591, D_B_loss: 0.0923, G_A_loss: 0.9870, G_B_loss: 0.5109\n",
      "Epoch [24/200], Step [291/1067], D_A_loss: 0.1169, D_B_loss: 0.1502, G_A_loss: 0.2943, G_B_loss: 0.7661\n",
      "Epoch [24/200], Step [301/1067], D_A_loss: 0.0873, D_B_loss: 0.0555, G_A_loss: 0.3875, G_B_loss: 0.8412\n",
      "Epoch [24/200], Step [311/1067], D_A_loss: 0.0513, D_B_loss: 0.1542, G_A_loss: 1.2826, G_B_loss: 0.7260\n",
      "Epoch [24/200], Step [321/1067], D_A_loss: 0.0917, D_B_loss: 0.0388, G_A_loss: 1.1341, G_B_loss: 0.7109\n",
      "Epoch [24/200], Step [331/1067], D_A_loss: 0.1858, D_B_loss: 0.0430, G_A_loss: 0.6876, G_B_loss: 0.6496\n",
      "Epoch [24/200], Step [341/1067], D_A_loss: 0.0965, D_B_loss: 0.0741, G_A_loss: 0.4948, G_B_loss: 0.4115\n",
      "Epoch [24/200], Step [351/1067], D_A_loss: 0.1445, D_B_loss: 0.1992, G_A_loss: 0.6437, G_B_loss: 0.3197\n",
      "Epoch [24/200], Step [361/1067], D_A_loss: 0.1063, D_B_loss: 0.0650, G_A_loss: 0.5554, G_B_loss: 0.3744\n",
      "Epoch [24/200], Step [371/1067], D_A_loss: 0.2109, D_B_loss: 0.0464, G_A_loss: 0.4639, G_B_loss: 0.5911\n",
      "Epoch [24/200], Step [381/1067], D_A_loss: 0.0502, D_B_loss: 0.0592, G_A_loss: 0.6222, G_B_loss: 0.5811\n",
      "Epoch [24/200], Step [391/1067], D_A_loss: 0.0225, D_B_loss: 0.0873, G_A_loss: 0.7795, G_B_loss: 0.4340\n",
      "Epoch [24/200], Step [401/1067], D_A_loss: 0.0682, D_B_loss: 0.1843, G_A_loss: 0.3201, G_B_loss: 0.6436\n",
      "Epoch [24/200], Step [411/1067], D_A_loss: 0.0456, D_B_loss: 0.0538, G_A_loss: 0.9392, G_B_loss: 0.9876\n",
      "Epoch [24/200], Step [421/1067], D_A_loss: 0.0927, D_B_loss: 0.0424, G_A_loss: 0.7826, G_B_loss: 0.5851\n",
      "Epoch [24/200], Step [431/1067], D_A_loss: 0.1080, D_B_loss: 0.1399, G_A_loss: 0.4132, G_B_loss: 1.0908\n",
      "Epoch [24/200], Step [441/1067], D_A_loss: 0.0993, D_B_loss: 0.0925, G_A_loss: 0.4576, G_B_loss: 0.6760\n",
      "Epoch [24/200], Step [451/1067], D_A_loss: 0.0704, D_B_loss: 0.0297, G_A_loss: 0.9787, G_B_loss: 0.5000\n",
      "Epoch [24/200], Step [461/1067], D_A_loss: 0.0786, D_B_loss: 0.0752, G_A_loss: 0.3027, G_B_loss: 0.3837\n",
      "Epoch [24/200], Step [471/1067], D_A_loss: 0.0442, D_B_loss: 0.0583, G_A_loss: 0.5828, G_B_loss: 0.7116\n",
      "Epoch [24/200], Step [481/1067], D_A_loss: 0.0836, D_B_loss: 0.1011, G_A_loss: 0.6195, G_B_loss: 0.9460\n",
      "Epoch [24/200], Step [491/1067], D_A_loss: 0.0518, D_B_loss: 0.0633, G_A_loss: 0.6128, G_B_loss: 1.0338\n",
      "Epoch [24/200], Step [501/1067], D_A_loss: 0.0758, D_B_loss: 0.0475, G_A_loss: 0.6879, G_B_loss: 0.1578\n",
      "Epoch [24/200], Step [511/1067], D_A_loss: 0.0800, D_B_loss: 0.0569, G_A_loss: 0.7934, G_B_loss: 0.4953\n",
      "Epoch [24/200], Step [521/1067], D_A_loss: 0.1108, D_B_loss: 0.0601, G_A_loss: 0.5874, G_B_loss: 0.5449\n",
      "Epoch [24/200], Step [531/1067], D_A_loss: 0.0243, D_B_loss: 0.0143, G_A_loss: 0.5732, G_B_loss: 0.9915\n",
      "Epoch [24/200], Step [541/1067], D_A_loss: 0.0808, D_B_loss: 0.1672, G_A_loss: 1.1038, G_B_loss: 0.4450\n",
      "Epoch [24/200], Step [551/1067], D_A_loss: 0.0710, D_B_loss: 0.0571, G_A_loss: 0.6911, G_B_loss: 1.2056\n",
      "Epoch [24/200], Step [561/1067], D_A_loss: 0.2129, D_B_loss: 0.0331, G_A_loss: 0.6989, G_B_loss: 0.0782\n",
      "Epoch [24/200], Step [571/1067], D_A_loss: 0.0986, D_B_loss: 0.0983, G_A_loss: 0.4695, G_B_loss: 0.4432\n",
      "Epoch [24/200], Step [581/1067], D_A_loss: 0.1400, D_B_loss: 0.0289, G_A_loss: 0.7800, G_B_loss: 0.2826\n",
      "Epoch [24/200], Step [591/1067], D_A_loss: 0.0481, D_B_loss: 0.1158, G_A_loss: 0.9880, G_B_loss: 0.6991\n",
      "Epoch [24/200], Step [601/1067], D_A_loss: 0.0569, D_B_loss: 0.0492, G_A_loss: 0.7240, G_B_loss: 0.7017\n",
      "Epoch [24/200], Step [611/1067], D_A_loss: 0.2626, D_B_loss: 0.1206, G_A_loss: 0.3224, G_B_loss: 0.9739\n",
      "Epoch [24/200], Step [621/1067], D_A_loss: 0.0925, D_B_loss: 0.1110, G_A_loss: 0.4759, G_B_loss: 0.5049\n",
      "Epoch [24/200], Step [631/1067], D_A_loss: 0.0378, D_B_loss: 0.0419, G_A_loss: 0.6591, G_B_loss: 1.0892\n",
      "Epoch [24/200], Step [641/1067], D_A_loss: 0.0823, D_B_loss: 0.1073, G_A_loss: 0.3926, G_B_loss: 0.3709\n",
      "Epoch [24/200], Step [651/1067], D_A_loss: 0.1346, D_B_loss: 0.0444, G_A_loss: 0.6147, G_B_loss: 0.3372\n",
      "Epoch [24/200], Step [661/1067], D_A_loss: 0.0243, D_B_loss: 0.1329, G_A_loss: 0.8930, G_B_loss: 0.4303\n",
      "Epoch [24/200], Step [671/1067], D_A_loss: 0.0568, D_B_loss: 0.0592, G_A_loss: 0.5737, G_B_loss: 0.7875\n",
      "Epoch [24/200], Step [681/1067], D_A_loss: 0.0866, D_B_loss: 0.0249, G_A_loss: 0.7722, G_B_loss: 1.0960\n",
      "Epoch [24/200], Step [691/1067], D_A_loss: 0.0962, D_B_loss: 0.0415, G_A_loss: 0.6404, G_B_loss: 0.4343\n",
      "Epoch [24/200], Step [701/1067], D_A_loss: 0.0458, D_B_loss: 0.0413, G_A_loss: 0.6836, G_B_loss: 0.3021\n",
      "Epoch [24/200], Step [711/1067], D_A_loss: 0.0938, D_B_loss: 0.0961, G_A_loss: 0.9293, G_B_loss: 0.4536\n",
      "Epoch [24/200], Step [721/1067], D_A_loss: 0.1688, D_B_loss: 0.0623, G_A_loss: 0.5444, G_B_loss: 1.0139\n",
      "Epoch [24/200], Step [731/1067], D_A_loss: 0.1360, D_B_loss: 0.0536, G_A_loss: 0.7815, G_B_loss: 1.0172\n",
      "Epoch [24/200], Step [741/1067], D_A_loss: 0.1145, D_B_loss: 0.0309, G_A_loss: 0.9585, G_B_loss: 0.9451\n",
      "Epoch [24/200], Step [751/1067], D_A_loss: 0.1625, D_B_loss: 0.0267, G_A_loss: 0.4670, G_B_loss: 1.1747\n",
      "Epoch [24/200], Step [761/1067], D_A_loss: 0.0554, D_B_loss: 0.1717, G_A_loss: 0.3975, G_B_loss: 0.4847\n",
      "Epoch [24/200], Step [771/1067], D_A_loss: 0.1194, D_B_loss: 0.0559, G_A_loss: 0.9012, G_B_loss: 0.3437\n",
      "Epoch [24/200], Step [781/1067], D_A_loss: 0.1361, D_B_loss: 0.0832, G_A_loss: 0.4213, G_B_loss: 0.6776\n",
      "Epoch [24/200], Step [791/1067], D_A_loss: 0.0462, D_B_loss: 0.0530, G_A_loss: 0.5294, G_B_loss: 0.5440\n",
      "Epoch [24/200], Step [801/1067], D_A_loss: 0.0861, D_B_loss: 0.0307, G_A_loss: 0.3706, G_B_loss: 0.5553\n",
      "Epoch [24/200], Step [811/1067], D_A_loss: 0.0527, D_B_loss: 0.0150, G_A_loss: 0.6294, G_B_loss: 0.4868\n",
      "Epoch [24/200], Step [821/1067], D_A_loss: 0.0810, D_B_loss: 0.0468, G_A_loss: 0.7118, G_B_loss: 0.5354\n",
      "Epoch [24/200], Step [831/1067], D_A_loss: 0.0343, D_B_loss: 0.1242, G_A_loss: 0.3579, G_B_loss: 0.8078\n",
      "Epoch [24/200], Step [841/1067], D_A_loss: 0.1517, D_B_loss: 0.0466, G_A_loss: 0.4736, G_B_loss: 0.7304\n",
      "Epoch [24/200], Step [851/1067], D_A_loss: 0.3102, D_B_loss: 0.0619, G_A_loss: 0.5112, G_B_loss: 0.0919\n",
      "Epoch [24/200], Step [861/1067], D_A_loss: 0.1055, D_B_loss: 0.0586, G_A_loss: 0.3126, G_B_loss: 0.3813\n",
      "Epoch [24/200], Step [871/1067], D_A_loss: 0.2417, D_B_loss: 0.0461, G_A_loss: 0.6837, G_B_loss: 0.4244\n",
      "Epoch [24/200], Step [881/1067], D_A_loss: 0.0679, D_B_loss: 0.0355, G_A_loss: 0.5555, G_B_loss: 0.3619\n",
      "Epoch [24/200], Step [891/1067], D_A_loss: 0.0494, D_B_loss: 0.1062, G_A_loss: 0.4003, G_B_loss: 0.5896\n",
      "Epoch [24/200], Step [901/1067], D_A_loss: 0.0377, D_B_loss: 0.0348, G_A_loss: 0.6538, G_B_loss: 0.9938\n",
      "Epoch [24/200], Step [911/1067], D_A_loss: 0.1698, D_B_loss: 0.0829, G_A_loss: 0.4931, G_B_loss: 0.9403\n",
      "Epoch [24/200], Step [921/1067], D_A_loss: 0.1177, D_B_loss: 0.0703, G_A_loss: 0.6551, G_B_loss: 0.3497\n",
      "Epoch [24/200], Step [931/1067], D_A_loss: 0.1059, D_B_loss: 0.0199, G_A_loss: 0.9973, G_B_loss: 1.3480\n",
      "Epoch [24/200], Step [941/1067], D_A_loss: 0.1123, D_B_loss: 0.0765, G_A_loss: 0.8331, G_B_loss: 0.3495\n",
      "Epoch [24/200], Step [951/1067], D_A_loss: 0.0252, D_B_loss: 0.0679, G_A_loss: 0.4796, G_B_loss: 0.3096\n",
      "Epoch [24/200], Step [961/1067], D_A_loss: 0.0476, D_B_loss: 0.1483, G_A_loss: 1.1849, G_B_loss: 0.7817\n",
      "Epoch [24/200], Step [971/1067], D_A_loss: 0.1282, D_B_loss: 0.0894, G_A_loss: 0.4100, G_B_loss: 0.4460\n",
      "Epoch [24/200], Step [981/1067], D_A_loss: 0.1041, D_B_loss: 0.0576, G_A_loss: 1.1543, G_B_loss: 0.5082\n",
      "Epoch [24/200], Step [991/1067], D_A_loss: 0.2036, D_B_loss: 0.0297, G_A_loss: 0.5721, G_B_loss: 0.4707\n",
      "Epoch [24/200], Step [1001/1067], D_A_loss: 0.1035, D_B_loss: 0.0429, G_A_loss: 0.6449, G_B_loss: 0.3920\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24/200], Step [1011/1067], D_A_loss: 0.0941, D_B_loss: 0.0286, G_A_loss: 0.7258, G_B_loss: 0.7994\n",
      "Epoch [24/200], Step [1021/1067], D_A_loss: 0.0751, D_B_loss: 0.0812, G_A_loss: 0.7096, G_B_loss: 0.4922\n",
      "Epoch [24/200], Step [1031/1067], D_A_loss: 0.0362, D_B_loss: 0.0265, G_A_loss: 0.8232, G_B_loss: 0.3979\n",
      "Epoch [24/200], Step [1041/1067], D_A_loss: 0.0507, D_B_loss: 0.0768, G_A_loss: 0.8771, G_B_loss: 0.6037\n",
      "Epoch [24/200], Step [1051/1067], D_A_loss: 0.1241, D_B_loss: 0.0262, G_A_loss: 0.7086, G_B_loss: 0.6855\n",
      "Epoch [24/200], Step [1061/1067], D_A_loss: 0.1015, D_B_loss: 0.0306, G_A_loss: 0.7291, G_B_loss: 0.5082\n",
      "Epoch [25/200], Step [1/1067], D_A_loss: 0.0451, D_B_loss: 0.0256, G_A_loss: 0.8868, G_B_loss: 0.4328\n",
      "Epoch [25/200], Step [11/1067], D_A_loss: 0.0211, D_B_loss: 0.0897, G_A_loss: 0.8558, G_B_loss: 0.7735\n",
      "Epoch [25/200], Step [21/1067], D_A_loss: 0.0604, D_B_loss: 0.0991, G_A_loss: 0.2607, G_B_loss: 0.6821\n",
      "Epoch [25/200], Step [31/1067], D_A_loss: 0.0299, D_B_loss: 0.0501, G_A_loss: 0.6398, G_B_loss: 0.7017\n",
      "Epoch [25/200], Step [41/1067], D_A_loss: 0.0615, D_B_loss: 0.0958, G_A_loss: 0.3742, G_B_loss: 0.7694\n",
      "Epoch [25/200], Step [51/1067], D_A_loss: 0.0921, D_B_loss: 0.0220, G_A_loss: 1.1695, G_B_loss: 0.7118\n",
      "Epoch [25/200], Step [61/1067], D_A_loss: 0.0525, D_B_loss: 0.1917, G_A_loss: 0.3256, G_B_loss: 0.4007\n",
      "Epoch [25/200], Step [71/1067], D_A_loss: 0.0379, D_B_loss: 0.0680, G_A_loss: 0.2787, G_B_loss: 0.7095\n",
      "Epoch [25/200], Step [81/1067], D_A_loss: 0.0716, D_B_loss: 0.0177, G_A_loss: 0.4923, G_B_loss: 0.9207\n",
      "Epoch [25/200], Step [91/1067], D_A_loss: 0.0875, D_B_loss: 0.0985, G_A_loss: 0.4212, G_B_loss: 0.4418\n",
      "Epoch [25/200], Step [101/1067], D_A_loss: 0.0935, D_B_loss: 0.1044, G_A_loss: 0.7684, G_B_loss: 0.4008\n",
      "Epoch [25/200], Step [111/1067], D_A_loss: 0.1673, D_B_loss: 0.0980, G_A_loss: 0.5192, G_B_loss: 0.8925\n",
      "Epoch [25/200], Step [121/1067], D_A_loss: 0.0458, D_B_loss: 0.0753, G_A_loss: 0.5195, G_B_loss: 0.9178\n",
      "Epoch [25/200], Step [131/1067], D_A_loss: 0.0723, D_B_loss: 0.1026, G_A_loss: 0.2836, G_B_loss: 0.5639\n",
      "Epoch [25/200], Step [141/1067], D_A_loss: 0.1109, D_B_loss: 0.0815, G_A_loss: 0.4966, G_B_loss: 0.7957\n",
      "Epoch [25/200], Step [151/1067], D_A_loss: 0.0456, D_B_loss: 0.0997, G_A_loss: 1.2061, G_B_loss: 0.7127\n",
      "Epoch [25/200], Step [161/1067], D_A_loss: 0.0786, D_B_loss: 0.2736, G_A_loss: 0.9330, G_B_loss: 0.5534\n",
      "Epoch [25/200], Step [171/1067], D_A_loss: 0.3472, D_B_loss: 0.0650, G_A_loss: 1.0757, G_B_loss: 0.5212\n",
      "Epoch [25/200], Step [181/1067], D_A_loss: 0.1107, D_B_loss: 0.2392, G_A_loss: 0.6312, G_B_loss: 0.5441\n",
      "Epoch [25/200], Step [191/1067], D_A_loss: 0.0343, D_B_loss: 0.0679, G_A_loss: 0.6162, G_B_loss: 0.7332\n",
      "Epoch [25/200], Step [201/1067], D_A_loss: 0.1044, D_B_loss: 0.1424, G_A_loss: 0.7128, G_B_loss: 0.4558\n",
      "Epoch [25/200], Step [211/1067], D_A_loss: 0.1158, D_B_loss: 0.0470, G_A_loss: 0.8854, G_B_loss: 0.9664\n",
      "Epoch [25/200], Step [221/1067], D_A_loss: 0.1007, D_B_loss: 0.0624, G_A_loss: 0.8087, G_B_loss: 0.6132\n",
      "Epoch [25/200], Step [231/1067], D_A_loss: 0.2984, D_B_loss: 0.0706, G_A_loss: 0.4559, G_B_loss: 0.8970\n",
      "Epoch [25/200], Step [241/1067], D_A_loss: 0.0304, D_B_loss: 0.0572, G_A_loss: 0.5672, G_B_loss: 0.7784\n",
      "Epoch [25/200], Step [251/1067], D_A_loss: 0.0587, D_B_loss: 0.1674, G_A_loss: 0.4343, G_B_loss: 0.6049\n",
      "Epoch [25/200], Step [261/1067], D_A_loss: 0.1306, D_B_loss: 0.0759, G_A_loss: 0.4580, G_B_loss: 0.4656\n",
      "Epoch [25/200], Step [271/1067], D_A_loss: 0.0437, D_B_loss: 0.1556, G_A_loss: 0.3506, G_B_loss: 0.4278\n",
      "Epoch [25/200], Step [281/1067], D_A_loss: 0.0708, D_B_loss: 0.0337, G_A_loss: 0.8249, G_B_loss: 0.5310\n",
      "Epoch [25/200], Step [291/1067], D_A_loss: 0.0422, D_B_loss: 0.1334, G_A_loss: 0.4183, G_B_loss: 0.6296\n",
      "Epoch [25/200], Step [301/1067], D_A_loss: 0.0942, D_B_loss: 0.0233, G_A_loss: 0.6753, G_B_loss: 0.5278\n",
      "Epoch [25/200], Step [311/1067], D_A_loss: 0.1467, D_B_loss: 0.0702, G_A_loss: 0.5210, G_B_loss: 0.2900\n",
      "Epoch [25/200], Step [321/1067], D_A_loss: 0.0911, D_B_loss: 0.0563, G_A_loss: 0.6734, G_B_loss: 0.4615\n",
      "Epoch [25/200], Step [331/1067], D_A_loss: 0.0898, D_B_loss: 0.0427, G_A_loss: 0.8621, G_B_loss: 0.5902\n",
      "Epoch [25/200], Step [341/1067], D_A_loss: 0.1171, D_B_loss: 0.1408, G_A_loss: 0.6655, G_B_loss: 0.5556\n",
      "Epoch [25/200], Step [351/1067], D_A_loss: 0.1322, D_B_loss: 0.1186, G_A_loss: 0.4148, G_B_loss: 0.6519\n",
      "Epoch [25/200], Step [361/1067], D_A_loss: 0.0481, D_B_loss: 0.0220, G_A_loss: 0.5873, G_B_loss: 0.6963\n",
      "Epoch [25/200], Step [371/1067], D_A_loss: 0.0276, D_B_loss: 0.0991, G_A_loss: 0.9836, G_B_loss: 0.3417\n",
      "Epoch [25/200], Step [381/1067], D_A_loss: 0.0279, D_B_loss: 0.0281, G_A_loss: 1.0044, G_B_loss: 0.9462\n",
      "Epoch [25/200], Step [391/1067], D_A_loss: 0.1780, D_B_loss: 0.0684, G_A_loss: 0.5115, G_B_loss: 0.4300\n",
      "Epoch [25/200], Step [401/1067], D_A_loss: 0.0879, D_B_loss: 0.0507, G_A_loss: 0.3966, G_B_loss: 0.6310\n",
      "Epoch [25/200], Step [411/1067], D_A_loss: 0.1187, D_B_loss: 0.0467, G_A_loss: 0.6495, G_B_loss: 0.3880\n",
      "Epoch [25/200], Step [421/1067], D_A_loss: 0.0839, D_B_loss: 0.0381, G_A_loss: 0.6511, G_B_loss: 0.6472\n",
      "Epoch [25/200], Step [431/1067], D_A_loss: 0.1520, D_B_loss: 0.0491, G_A_loss: 0.9978, G_B_loss: 0.6515\n",
      "Epoch [25/200], Step [441/1067], D_A_loss: 0.1164, D_B_loss: 0.0385, G_A_loss: 0.8446, G_B_loss: 0.3997\n",
      "Epoch [25/200], Step [451/1067], D_A_loss: 0.0813, D_B_loss: 0.0218, G_A_loss: 0.6696, G_B_loss: 0.6660\n",
      "Epoch [25/200], Step [461/1067], D_A_loss: 0.0813, D_B_loss: 0.0402, G_A_loss: 0.7249, G_B_loss: 0.7927\n",
      "Epoch [25/200], Step [471/1067], D_A_loss: 0.0726, D_B_loss: 0.0151, G_A_loss: 0.4731, G_B_loss: 0.5961\n",
      "Epoch [25/200], Step [481/1067], D_A_loss: 0.0760, D_B_loss: 0.0719, G_A_loss: 0.6572, G_B_loss: 0.4600\n",
      "Epoch [25/200], Step [491/1067], D_A_loss: 0.0441, D_B_loss: 0.0406, G_A_loss: 0.9289, G_B_loss: 0.4756\n",
      "Epoch [25/200], Step [501/1067], D_A_loss: 0.1073, D_B_loss: 0.0174, G_A_loss: 0.8564, G_B_loss: 0.4987\n",
      "Epoch [25/200], Step [511/1067], D_A_loss: 0.0602, D_B_loss: 0.0211, G_A_loss: 1.0624, G_B_loss: 0.7138\n",
      "Epoch [25/200], Step [521/1067], D_A_loss: 0.0241, D_B_loss: 0.0389, G_A_loss: 0.6286, G_B_loss: 0.1902\n",
      "Epoch [25/200], Step [531/1067], D_A_loss: 0.0195, D_B_loss: 0.0908, G_A_loss: 0.4506, G_B_loss: 0.4679\n",
      "Epoch [25/200], Step [541/1067], D_A_loss: 0.0579, D_B_loss: 0.0934, G_A_loss: 0.2773, G_B_loss: 0.7480\n",
      "Epoch [25/200], Step [551/1067], D_A_loss: 0.2180, D_B_loss: 0.0760, G_A_loss: 0.4501, G_B_loss: 0.4459\n",
      "Epoch [25/200], Step [561/1067], D_A_loss: 0.0722, D_B_loss: 0.0668, G_A_loss: 0.7376, G_B_loss: 0.4951\n",
      "Epoch [25/200], Step [571/1067], D_A_loss: 0.2030, D_B_loss: 0.0889, G_A_loss: 0.6684, G_B_loss: 0.1898\n",
      "Epoch [25/200], Step [581/1067], D_A_loss: 0.2049, D_B_loss: 0.1034, G_A_loss: 0.5303, G_B_loss: 0.6633\n",
      "Epoch [25/200], Step [591/1067], D_A_loss: 0.0450, D_B_loss: 0.0236, G_A_loss: 0.7928, G_B_loss: 0.6871\n",
      "Epoch [25/200], Step [601/1067], D_A_loss: 0.1432, D_B_loss: 0.0490, G_A_loss: 0.5320, G_B_loss: 0.3655\n",
      "Epoch [25/200], Step [611/1067], D_A_loss: 0.0191, D_B_loss: 0.0477, G_A_loss: 0.5941, G_B_loss: 0.3772\n",
      "Epoch [25/200], Step [621/1067], D_A_loss: 0.2491, D_B_loss: 0.1138, G_A_loss: 0.6231, G_B_loss: 0.3340\n",
      "Epoch [25/200], Step [631/1067], D_A_loss: 0.0727, D_B_loss: 0.0149, G_A_loss: 0.9136, G_B_loss: 0.9236\n",
      "Epoch [25/200], Step [641/1067], D_A_loss: 0.0409, D_B_loss: 0.1121, G_A_loss: 0.9343, G_B_loss: 0.8982\n",
      "Epoch [25/200], Step [651/1067], D_A_loss: 0.2595, D_B_loss: 0.0444, G_A_loss: 0.6056, G_B_loss: 0.1796\n",
      "Epoch [25/200], Step [661/1067], D_A_loss: 0.0732, D_B_loss: 0.1604, G_A_loss: 0.3199, G_B_loss: 0.6337\n",
      "Epoch [25/200], Step [671/1067], D_A_loss: 0.1220, D_B_loss: 0.0201, G_A_loss: 0.2093, G_B_loss: 0.4396\n",
      "Epoch [25/200], Step [681/1067], D_A_loss: 0.1374, D_B_loss: 0.0330, G_A_loss: 0.7232, G_B_loss: 0.4667\n",
      "Epoch [25/200], Step [691/1067], D_A_loss: 0.1615, D_B_loss: 0.1277, G_A_loss: 0.7216, G_B_loss: 0.7956\n",
      "Epoch [25/200], Step [701/1067], D_A_loss: 0.0843, D_B_loss: 0.0162, G_A_loss: 0.9428, G_B_loss: 0.3845\n",
      "Epoch [25/200], Step [711/1067], D_A_loss: 0.2305, D_B_loss: 0.0403, G_A_loss: 0.6132, G_B_loss: 0.1361\n",
      "Epoch [25/200], Step [721/1067], D_A_loss: 0.0699, D_B_loss: 0.0319, G_A_loss: 0.6777, G_B_loss: 0.5835\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25/200], Step [731/1067], D_A_loss: 0.0299, D_B_loss: 0.0527, G_A_loss: 1.4280, G_B_loss: 0.8770\n",
      "Epoch [25/200], Step [741/1067], D_A_loss: 0.1339, D_B_loss: 0.0221, G_A_loss: 0.8379, G_B_loss: 0.2895\n",
      "Epoch [25/200], Step [751/1067], D_A_loss: 0.0880, D_B_loss: 0.0330, G_A_loss: 1.4593, G_B_loss: 1.9575\n",
      "Epoch [25/200], Step [761/1067], D_A_loss: 0.0770, D_B_loss: 0.0561, G_A_loss: 0.5222, G_B_loss: 0.3293\n",
      "Epoch [25/200], Step [771/1067], D_A_loss: 0.1809, D_B_loss: 0.0897, G_A_loss: 0.9398, G_B_loss: 0.1913\n",
      "Epoch [25/200], Step [781/1067], D_A_loss: 0.0732, D_B_loss: 0.0161, G_A_loss: 0.9068, G_B_loss: 0.5352\n",
      "Epoch [25/200], Step [791/1067], D_A_loss: 0.0857, D_B_loss: 0.0927, G_A_loss: 0.4102, G_B_loss: 0.5218\n",
      "Epoch [25/200], Step [801/1067], D_A_loss: 0.1810, D_B_loss: 0.0254, G_A_loss: 0.7918, G_B_loss: 0.2522\n",
      "Epoch [25/200], Step [811/1067], D_A_loss: 0.1153, D_B_loss: 0.1509, G_A_loss: 0.7506, G_B_loss: 0.4107\n",
      "Epoch [25/200], Step [821/1067], D_A_loss: 0.0630, D_B_loss: 0.1081, G_A_loss: 0.6135, G_B_loss: 0.6591\n",
      "Epoch [25/200], Step [831/1067], D_A_loss: 0.0352, D_B_loss: 0.0616, G_A_loss: 0.6407, G_B_loss: 0.1930\n",
      "Epoch [25/200], Step [841/1067], D_A_loss: 0.0975, D_B_loss: 0.0146, G_A_loss: 0.4632, G_B_loss: 0.9566\n",
      "Epoch [25/200], Step [851/1067], D_A_loss: 0.0531, D_B_loss: 0.1841, G_A_loss: 0.8026, G_B_loss: 0.5105\n",
      "Epoch [25/200], Step [861/1067], D_A_loss: 0.1278, D_B_loss: 0.0272, G_A_loss: 0.9376, G_B_loss: 0.9219\n",
      "Epoch [25/200], Step [871/1067], D_A_loss: 0.1688, D_B_loss: 0.0431, G_A_loss: 0.6220, G_B_loss: 1.0041\n",
      "Epoch [25/200], Step [881/1067], D_A_loss: 0.0946, D_B_loss: 0.1049, G_A_loss: 0.7804, G_B_loss: 0.7879\n",
      "Epoch [25/200], Step [891/1067], D_A_loss: 0.2891, D_B_loss: 0.0573, G_A_loss: 0.4091, G_B_loss: 0.1078\n",
      "Epoch [25/200], Step [901/1067], D_A_loss: 0.1426, D_B_loss: 0.0654, G_A_loss: 0.2177, G_B_loss: 0.8826\n",
      "Epoch [25/200], Step [911/1067], D_A_loss: 0.0913, D_B_loss: 0.0487, G_A_loss: 0.5868, G_B_loss: 0.3841\n",
      "Epoch [25/200], Step [921/1067], D_A_loss: 0.3643, D_B_loss: 0.0180, G_A_loss: 0.4881, G_B_loss: 0.8449\n",
      "Epoch [25/200], Step [931/1067], D_A_loss: 0.0959, D_B_loss: 0.0201, G_A_loss: 0.6240, G_B_loss: 0.3907\n",
      "Epoch [25/200], Step [941/1067], D_A_loss: 0.1077, D_B_loss: 0.0592, G_A_loss: 0.5528, G_B_loss: 0.4006\n",
      "Epoch [25/200], Step [951/1067], D_A_loss: 0.1533, D_B_loss: 0.0157, G_A_loss: 0.8460, G_B_loss: 0.2606\n",
      "Epoch [25/200], Step [961/1067], D_A_loss: 0.0528, D_B_loss: 0.0845, G_A_loss: 1.4015, G_B_loss: 0.5785\n",
      "Epoch [25/200], Step [971/1067], D_A_loss: 0.1262, D_B_loss: 0.1153, G_A_loss: 0.3402, G_B_loss: 0.6620\n",
      "Epoch [25/200], Step [981/1067], D_A_loss: 0.2793, D_B_loss: 0.0535, G_A_loss: 0.5244, G_B_loss: 0.1613\n",
      "Epoch [25/200], Step [991/1067], D_A_loss: 0.2276, D_B_loss: 0.1107, G_A_loss: 0.7091, G_B_loss: 0.1490\n",
      "Epoch [25/200], Step [1001/1067], D_A_loss: 0.0186, D_B_loss: 0.0608, G_A_loss: 0.6369, G_B_loss: 0.8669\n",
      "Epoch [25/200], Step [1011/1067], D_A_loss: 0.0529, D_B_loss: 0.0156, G_A_loss: 0.5980, G_B_loss: 0.3089\n",
      "Epoch [25/200], Step [1021/1067], D_A_loss: 0.0386, D_B_loss: 0.0926, G_A_loss: 0.9822, G_B_loss: 0.9674\n",
      "Epoch [25/200], Step [1031/1067], D_A_loss: 0.1049, D_B_loss: 0.1000, G_A_loss: 0.7844, G_B_loss: 0.4022\n",
      "Epoch [25/200], Step [1041/1067], D_A_loss: 0.1638, D_B_loss: 0.0239, G_A_loss: 0.9394, G_B_loss: 0.6579\n",
      "Epoch [25/200], Step [1051/1067], D_A_loss: 0.0545, D_B_loss: 0.0199, G_A_loss: 0.5742, G_B_loss: 0.7839\n",
      "Epoch [25/200], Step [1061/1067], D_A_loss: 0.0273, D_B_loss: 0.1147, G_A_loss: 0.4375, G_B_loss: 0.5484\n",
      "Epoch [26/200], Step [1/1067], D_A_loss: 0.0554, D_B_loss: 0.2348, G_A_loss: 0.1877, G_B_loss: 0.4210\n",
      "Epoch [26/200], Step [11/1067], D_A_loss: 0.0283, D_B_loss: 0.0564, G_A_loss: 0.5496, G_B_loss: 0.8078\n",
      "Epoch [26/200], Step [21/1067], D_A_loss: 0.0452, D_B_loss: 0.0148, G_A_loss: 0.5160, G_B_loss: 0.4858\n",
      "Epoch [26/200], Step [31/1067], D_A_loss: 0.1296, D_B_loss: 0.0254, G_A_loss: 0.5206, G_B_loss: 0.5960\n",
      "Epoch [26/200], Step [41/1067], D_A_loss: 0.1444, D_B_loss: 0.1624, G_A_loss: 0.4423, G_B_loss: 0.2662\n",
      "Epoch [26/200], Step [51/1067], D_A_loss: 0.1099, D_B_loss: 0.1847, G_A_loss: 0.2350, G_B_loss: 0.3451\n",
      "Epoch [26/200], Step [61/1067], D_A_loss: 0.0671, D_B_loss: 0.0623, G_A_loss: 0.7987, G_B_loss: 0.4995\n",
      "Epoch [26/200], Step [71/1067], D_A_loss: 0.4105, D_B_loss: 0.1040, G_A_loss: 1.1347, G_B_loss: 0.2947\n",
      "Epoch [26/200], Step [81/1067], D_A_loss: 0.0635, D_B_loss: 0.0741, G_A_loss: 0.6504, G_B_loss: 0.5152\n",
      "Epoch [26/200], Step [91/1067], D_A_loss: 0.0852, D_B_loss: 0.0509, G_A_loss: 0.6296, G_B_loss: 0.5035\n",
      "Epoch [26/200], Step [101/1067], D_A_loss: 0.2515, D_B_loss: 0.0211, G_A_loss: 0.8057, G_B_loss: 0.4854\n",
      "Epoch [26/200], Step [111/1067], D_A_loss: 0.1279, D_B_loss: 0.0712, G_A_loss: 0.4425, G_B_loss: 0.5985\n",
      "Epoch [26/200], Step [121/1067], D_A_loss: 0.0392, D_B_loss: 0.0987, G_A_loss: 0.4939, G_B_loss: 0.6287\n",
      "Epoch [26/200], Step [131/1067], D_A_loss: 0.0528, D_B_loss: 0.0896, G_A_loss: 0.5010, G_B_loss: 0.6195\n",
      "Epoch [26/200], Step [141/1067], D_A_loss: 0.0845, D_B_loss: 0.0503, G_A_loss: 1.1713, G_B_loss: 0.5056\n",
      "Epoch [26/200], Step [151/1067], D_A_loss: 0.1511, D_B_loss: 0.0807, G_A_loss: 1.2136, G_B_loss: 0.3671\n",
      "Epoch [26/200], Step [161/1067], D_A_loss: 0.0230, D_B_loss: 0.0380, G_A_loss: 0.6976, G_B_loss: 0.6772\n",
      "Epoch [26/200], Step [171/1067], D_A_loss: 0.0734, D_B_loss: 0.0458, G_A_loss: 0.5371, G_B_loss: 0.5223\n",
      "Epoch [26/200], Step [181/1067], D_A_loss: 0.0446, D_B_loss: 0.0193, G_A_loss: 0.7359, G_B_loss: 0.6782\n",
      "Epoch [26/200], Step [191/1067], D_A_loss: 0.4613, D_B_loss: 0.1841, G_A_loss: 0.5134, G_B_loss: 0.0885\n",
      "Epoch [26/200], Step [201/1067], D_A_loss: 0.1302, D_B_loss: 0.0431, G_A_loss: 1.0418, G_B_loss: 0.7347\n",
      "Epoch [26/200], Step [211/1067], D_A_loss: 0.0628, D_B_loss: 0.0222, G_A_loss: 0.7706, G_B_loss: 0.8842\n",
      "Epoch [26/200], Step [221/1067], D_A_loss: 0.0676, D_B_loss: 0.0703, G_A_loss: 0.8330, G_B_loss: 0.3277\n",
      "Epoch [26/200], Step [231/1067], D_A_loss: 0.1020, D_B_loss: 0.0357, G_A_loss: 0.6525, G_B_loss: 0.9970\n",
      "Epoch [26/200], Step [241/1067], D_A_loss: 0.0947, D_B_loss: 0.0409, G_A_loss: 0.7628, G_B_loss: 0.3787\n",
      "Epoch [26/200], Step [251/1067], D_A_loss: 0.0870, D_B_loss: 0.0141, G_A_loss: 0.5039, G_B_loss: 0.8449\n",
      "Epoch [26/200], Step [261/1067], D_A_loss: 0.1428, D_B_loss: 0.0718, G_A_loss: 0.7456, G_B_loss: 0.3561\n",
      "Epoch [26/200], Step [271/1067], D_A_loss: 0.0557, D_B_loss: 0.1087, G_A_loss: 0.2874, G_B_loss: 0.5824\n",
      "Epoch [26/200], Step [281/1067], D_A_loss: 0.1045, D_B_loss: 0.1241, G_A_loss: 0.5447, G_B_loss: 0.5903\n",
      "Epoch [26/200], Step [291/1067], D_A_loss: 0.0384, D_B_loss: 0.0141, G_A_loss: 0.7925, G_B_loss: 0.6929\n",
      "Epoch [26/200], Step [301/1067], D_A_loss: 0.1451, D_B_loss: 0.0400, G_A_loss: 0.6732, G_B_loss: 0.8014\n",
      "Epoch [26/200], Step [311/1067], D_A_loss: 0.0217, D_B_loss: 0.1448, G_A_loss: 0.6390, G_B_loss: 0.5807\n",
      "Epoch [26/200], Step [321/1067], D_A_loss: 0.0520, D_B_loss: 0.0278, G_A_loss: 0.5777, G_B_loss: 0.6317\n",
      "Epoch [26/200], Step [331/1067], D_A_loss: 0.0461, D_B_loss: 0.0419, G_A_loss: 1.1618, G_B_loss: 0.8434\n",
      "Epoch [26/200], Step [341/1067], D_A_loss: 0.1444, D_B_loss: 0.1609, G_A_loss: 0.4553, G_B_loss: 0.5627\n",
      "Epoch [26/200], Step [351/1067], D_A_loss: 0.3122, D_B_loss: 0.0993, G_A_loss: 0.5212, G_B_loss: 0.1154\n",
      "Epoch [26/200], Step [361/1067], D_A_loss: 0.0178, D_B_loss: 0.0260, G_A_loss: 0.7692, G_B_loss: 0.4446\n",
      "Epoch [26/200], Step [371/1067], D_A_loss: 0.2602, D_B_loss: 0.0821, G_A_loss: 0.4459, G_B_loss: 0.8503\n",
      "Epoch [26/200], Step [381/1067], D_A_loss: 0.0513, D_B_loss: 0.0668, G_A_loss: 0.5226, G_B_loss: 0.4907\n",
      "Epoch [26/200], Step [391/1067], D_A_loss: 0.1078, D_B_loss: 0.1149, G_A_loss: 0.8722, G_B_loss: 0.3594\n",
      "Epoch [26/200], Step [401/1067], D_A_loss: 0.0857, D_B_loss: 0.0951, G_A_loss: 0.4293, G_B_loss: 0.7118\n",
      "Epoch [26/200], Step [411/1067], D_A_loss: 0.0428, D_B_loss: 0.0288, G_A_loss: 0.2956, G_B_loss: 0.7777\n",
      "Epoch [26/200], Step [421/1067], D_A_loss: 0.2262, D_B_loss: 0.2045, G_A_loss: 0.2154, G_B_loss: 0.5060\n",
      "Epoch [26/200], Step [431/1067], D_A_loss: 0.0372, D_B_loss: 0.0375, G_A_loss: 0.9961, G_B_loss: 1.1360\n",
      "Epoch [26/200], Step [441/1067], D_A_loss: 0.0778, D_B_loss: 0.0484, G_A_loss: 1.0215, G_B_loss: 0.5388\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [26/200], Step [451/1067], D_A_loss: 0.1001, D_B_loss: 0.0340, G_A_loss: 0.6806, G_B_loss: 1.6033\n",
      "Epoch [26/200], Step [461/1067], D_A_loss: 0.1957, D_B_loss: 0.1299, G_A_loss: 0.3355, G_B_loss: 0.3606\n",
      "Epoch [26/200], Step [471/1067], D_A_loss: 0.1836, D_B_loss: 0.0188, G_A_loss: 0.8343, G_B_loss: 0.4832\n",
      "Epoch [26/200], Step [481/1067], D_A_loss: 0.0416, D_B_loss: 0.0449, G_A_loss: 0.6251, G_B_loss: 0.5082\n",
      "Epoch [26/200], Step [491/1067], D_A_loss: 0.0549, D_B_loss: 0.0661, G_A_loss: 0.5072, G_B_loss: 0.1252\n",
      "Epoch [26/200], Step [501/1067], D_A_loss: 0.0501, D_B_loss: 0.0264, G_A_loss: 0.7820, G_B_loss: 0.6332\n",
      "Epoch [26/200], Step [511/1067], D_A_loss: 0.0874, D_B_loss: 0.0478, G_A_loss: 0.5777, G_B_loss: 0.4345\n",
      "Epoch [26/200], Step [521/1067], D_A_loss: 0.0200, D_B_loss: 0.0783, G_A_loss: 0.3234, G_B_loss: 0.6400\n",
      "Epoch [26/200], Step [531/1067], D_A_loss: 0.1993, D_B_loss: 0.0769, G_A_loss: 0.5928, G_B_loss: 0.7874\n",
      "Epoch [26/200], Step [541/1067], D_A_loss: 0.0438, D_B_loss: 0.0171, G_A_loss: 0.5804, G_B_loss: 0.3734\n",
      "Epoch [26/200], Step [551/1067], D_A_loss: 0.1176, D_B_loss: 0.1069, G_A_loss: 0.9486, G_B_loss: 0.3225\n",
      "Epoch [26/200], Step [561/1067], D_A_loss: 0.0445, D_B_loss: 0.0453, G_A_loss: 1.0553, G_B_loss: 0.3430\n",
      "Epoch [26/200], Step [571/1067], D_A_loss: 0.1282, D_B_loss: 0.0539, G_A_loss: 0.7296, G_B_loss: 1.1345\n",
      "Epoch [26/200], Step [581/1067], D_A_loss: 0.0678, D_B_loss: 0.0313, G_A_loss: 0.5511, G_B_loss: 0.4580\n",
      "Epoch [26/200], Step [591/1067], D_A_loss: 0.1161, D_B_loss: 0.0707, G_A_loss: 1.4263, G_B_loss: 0.3511\n",
      "Epoch [26/200], Step [601/1067], D_A_loss: 0.0528, D_B_loss: 0.3207, G_A_loss: 0.9845, G_B_loss: 0.3948\n",
      "Epoch [26/200], Step [611/1067], D_A_loss: 0.0396, D_B_loss: 0.1183, G_A_loss: 0.9128, G_B_loss: 0.6364\n",
      "Epoch [26/200], Step [621/1067], D_A_loss: 0.1484, D_B_loss: 0.0572, G_A_loss: 0.1589, G_B_loss: 0.2916\n",
      "Epoch [26/200], Step [631/1067], D_A_loss: 0.0742, D_B_loss: 0.0607, G_A_loss: 0.5232, G_B_loss: 0.6132\n",
      "Epoch [26/200], Step [641/1067], D_A_loss: 0.1022, D_B_loss: 0.1671, G_A_loss: 0.8987, G_B_loss: 0.6516\n",
      "Epoch [26/200], Step [651/1067], D_A_loss: 0.0308, D_B_loss: 0.2333, G_A_loss: 0.2894, G_B_loss: 0.5830\n",
      "Epoch [26/200], Step [661/1067], D_A_loss: 0.1591, D_B_loss: 0.0650, G_A_loss: 0.4344, G_B_loss: 0.2600\n",
      "Epoch [26/200], Step [671/1067], D_A_loss: 0.0590, D_B_loss: 0.0623, G_A_loss: 0.5204, G_B_loss: 0.4987\n",
      "Epoch [26/200], Step [681/1067], D_A_loss: 0.1049, D_B_loss: 0.1575, G_A_loss: 0.4846, G_B_loss: 0.5079\n",
      "Epoch [26/200], Step [691/1067], D_A_loss: 0.2428, D_B_loss: 0.0405, G_A_loss: 0.6868, G_B_loss: 0.2047\n",
      "Epoch [26/200], Step [701/1067], D_A_loss: 0.0413, D_B_loss: 0.1200, G_A_loss: 0.7543, G_B_loss: 0.3079\n",
      "Epoch [26/200], Step [711/1067], D_A_loss: 0.0515, D_B_loss: 0.0748, G_A_loss: 1.1605, G_B_loss: 0.3315\n",
      "Epoch [26/200], Step [721/1067], D_A_loss: 0.0464, D_B_loss: 0.0243, G_A_loss: 0.8773, G_B_loss: 0.4973\n",
      "Epoch [26/200], Step [731/1067], D_A_loss: 0.0287, D_B_loss: 0.0208, G_A_loss: 0.9979, G_B_loss: 0.6011\n",
      "Epoch [26/200], Step [741/1067], D_A_loss: 0.0492, D_B_loss: 0.1309, G_A_loss: 0.7897, G_B_loss: 0.5766\n",
      "Epoch [26/200], Step [751/1067], D_A_loss: 0.0728, D_B_loss: 0.0239, G_A_loss: 0.7181, G_B_loss: 0.6170\n",
      "Epoch [26/200], Step [761/1067], D_A_loss: 0.0587, D_B_loss: 0.1714, G_A_loss: 0.7916, G_B_loss: 0.3039\n",
      "Epoch [26/200], Step [771/1067], D_A_loss: 0.0130, D_B_loss: 0.0278, G_A_loss: 0.4209, G_B_loss: 0.5180\n",
      "Epoch [26/200], Step [781/1067], D_A_loss: 0.0908, D_B_loss: 0.1410, G_A_loss: 1.0236, G_B_loss: 0.6015\n",
      "Epoch [26/200], Step [791/1067], D_A_loss: 0.0431, D_B_loss: 0.0640, G_A_loss: 0.5701, G_B_loss: 0.7714\n",
      "Epoch [26/200], Step [801/1067], D_A_loss: 0.1791, D_B_loss: 0.0119, G_A_loss: 0.9614, G_B_loss: 0.3370\n",
      "Epoch [26/200], Step [811/1067], D_A_loss: 0.1705, D_B_loss: 0.0189, G_A_loss: 0.5808, G_B_loss: 0.9880\n",
      "Epoch [26/200], Step [821/1067], D_A_loss: 0.0702, D_B_loss: 0.1241, G_A_loss: 1.2559, G_B_loss: 0.6974\n",
      "Epoch [26/200], Step [831/1067], D_A_loss: 0.0323, D_B_loss: 0.0351, G_A_loss: 0.7634, G_B_loss: 0.6466\n",
      "Epoch [26/200], Step [841/1067], D_A_loss: 0.1247, D_B_loss: 0.0358, G_A_loss: 0.6963, G_B_loss: 0.3553\n",
      "Epoch [26/200], Step [851/1067], D_A_loss: 0.1014, D_B_loss: 0.0349, G_A_loss: 0.7590, G_B_loss: 1.3061\n",
      "Epoch [26/200], Step [861/1067], D_A_loss: 0.1182, D_B_loss: 0.0200, G_A_loss: 0.9089, G_B_loss: 0.3857\n",
      "Epoch [26/200], Step [871/1067], D_A_loss: 0.1012, D_B_loss: 0.0990, G_A_loss: 0.4156, G_B_loss: 0.5355\n",
      "Epoch [26/200], Step [881/1067], D_A_loss: 0.1387, D_B_loss: 0.1286, G_A_loss: 0.3281, G_B_loss: 0.6813\n",
      "Epoch [26/200], Step [891/1067], D_A_loss: 0.0838, D_B_loss: 0.0207, G_A_loss: 0.8822, G_B_loss: 0.4550\n",
      "Epoch [26/200], Step [901/1067], D_A_loss: 0.0813, D_B_loss: 0.0469, G_A_loss: 0.4880, G_B_loss: 0.5258\n",
      "Epoch [26/200], Step [911/1067], D_A_loss: 0.0669, D_B_loss: 0.1824, G_A_loss: 0.1911, G_B_loss: 0.1992\n",
      "Epoch [26/200], Step [921/1067], D_A_loss: 0.0873, D_B_loss: 0.0438, G_A_loss: 0.5509, G_B_loss: 0.5765\n",
      "Epoch [26/200], Step [931/1067], D_A_loss: 0.1137, D_B_loss: 0.0425, G_A_loss: 0.8616, G_B_loss: 0.6875\n",
      "Epoch [26/200], Step [941/1067], D_A_loss: 0.0463, D_B_loss: 0.0468, G_A_loss: 0.6076, G_B_loss: 1.2061\n",
      "Epoch [26/200], Step [951/1067], D_A_loss: 0.0722, D_B_loss: 0.0252, G_A_loss: 0.6934, G_B_loss: 0.4821\n",
      "Epoch [26/200], Step [961/1067], D_A_loss: 0.0419, D_B_loss: 0.1049, G_A_loss: 0.6210, G_B_loss: 0.6216\n",
      "Epoch [26/200], Step [971/1067], D_A_loss: 0.0562, D_B_loss: 0.1222, G_A_loss: 0.6140, G_B_loss: 0.5695\n",
      "Epoch [26/200], Step [981/1067], D_A_loss: 0.1357, D_B_loss: 0.0748, G_A_loss: 0.4384, G_B_loss: 0.5499\n",
      "Epoch [26/200], Step [991/1067], D_A_loss: 0.0703, D_B_loss: 0.1348, G_A_loss: 1.0840, G_B_loss: 0.6918\n",
      "Epoch [26/200], Step [1001/1067], D_A_loss: 0.1038, D_B_loss: 0.0470, G_A_loss: 0.4790, G_B_loss: 0.4697\n",
      "Epoch [26/200], Step [1011/1067], D_A_loss: 0.2775, D_B_loss: 0.1071, G_A_loss: 0.4846, G_B_loss: 0.9899\n",
      "Epoch [26/200], Step [1021/1067], D_A_loss: 0.0776, D_B_loss: 0.0704, G_A_loss: 1.0104, G_B_loss: 0.5249\n",
      "Epoch [26/200], Step [1031/1067], D_A_loss: 0.0907, D_B_loss: 0.0699, G_A_loss: 0.4605, G_B_loss: 0.4615\n",
      "Epoch [26/200], Step [1041/1067], D_A_loss: 0.0288, D_B_loss: 0.0698, G_A_loss: 0.6354, G_B_loss: 0.7438\n",
      "Epoch [26/200], Step [1051/1067], D_A_loss: 0.0350, D_B_loss: 0.0313, G_A_loss: 1.0750, G_B_loss: 0.5036\n",
      "Epoch [26/200], Step [1061/1067], D_A_loss: 0.0454, D_B_loss: 0.0826, G_A_loss: 0.4523, G_B_loss: 0.4438\n",
      "Epoch [27/200], Step [1/1067], D_A_loss: 0.0209, D_B_loss: 0.0439, G_A_loss: 1.0281, G_B_loss: 0.5535\n",
      "Epoch [27/200], Step [11/1067], D_A_loss: 0.0410, D_B_loss: 0.0584, G_A_loss: 0.8267, G_B_loss: 0.4291\n",
      "Epoch [27/200], Step [21/1067], D_A_loss: 0.0430, D_B_loss: 0.1207, G_A_loss: 0.3424, G_B_loss: 0.7372\n",
      "Epoch [27/200], Step [31/1067], D_A_loss: 0.0395, D_B_loss: 0.0503, G_A_loss: 0.3915, G_B_loss: 0.8206\n",
      "Epoch [27/200], Step [41/1067], D_A_loss: 0.0334, D_B_loss: 0.0992, G_A_loss: 0.4185, G_B_loss: 0.6609\n",
      "Epoch [27/200], Step [51/1067], D_A_loss: 0.0869, D_B_loss: 0.0782, G_A_loss: 0.6737, G_B_loss: 1.1966\n",
      "Epoch [27/200], Step [61/1067], D_A_loss: 0.1955, D_B_loss: 0.1080, G_A_loss: 0.2394, G_B_loss: 1.1703\n",
      "Epoch [27/200], Step [71/1067], D_A_loss: 0.0309, D_B_loss: 0.0157, G_A_loss: 0.5341, G_B_loss: 0.6027\n",
      "Epoch [27/200], Step [81/1067], D_A_loss: 0.0171, D_B_loss: 0.0462, G_A_loss: 0.8322, G_B_loss: 0.6737\n",
      "Epoch [27/200], Step [91/1067], D_A_loss: 0.0721, D_B_loss: 0.0410, G_A_loss: 0.8544, G_B_loss: 0.5300\n",
      "Epoch [27/200], Step [101/1067], D_A_loss: 0.1250, D_B_loss: 0.0375, G_A_loss: 0.7316, G_B_loss: 0.4436\n",
      "Epoch [27/200], Step [111/1067], D_A_loss: 0.0824, D_B_loss: 0.0352, G_A_loss: 0.7788, G_B_loss: 0.6971\n",
      "Epoch [27/200], Step [121/1067], D_A_loss: 0.1750, D_B_loss: 0.0294, G_A_loss: 0.8687, G_B_loss: 0.5174\n",
      "Epoch [27/200], Step [131/1067], D_A_loss: 0.2125, D_B_loss: 0.0169, G_A_loss: 0.9513, G_B_loss: 0.1549\n",
      "Epoch [27/200], Step [141/1067], D_A_loss: 0.1015, D_B_loss: 0.0901, G_A_loss: 0.2430, G_B_loss: 0.2883\n",
      "Epoch [27/200], Step [151/1067], D_A_loss: 0.1900, D_B_loss: 0.0338, G_A_loss: 0.7850, G_B_loss: 0.5463\n",
      "Epoch [27/200], Step [161/1067], D_A_loss: 0.0333, D_B_loss: 0.0402, G_A_loss: 0.6812, G_B_loss: 0.8528\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [27/200], Step [171/1067], D_A_loss: 0.0445, D_B_loss: 0.0781, G_A_loss: 0.5976, G_B_loss: 0.9640\n",
      "Epoch [27/200], Step [181/1067], D_A_loss: 0.0350, D_B_loss: 0.0875, G_A_loss: 1.0498, G_B_loss: 0.3744\n",
      "Epoch [27/200], Step [191/1067], D_A_loss: 0.1506, D_B_loss: 0.0980, G_A_loss: 1.2840, G_B_loss: 0.3272\n",
      "Epoch [27/200], Step [201/1067], D_A_loss: 0.1536, D_B_loss: 0.0703, G_A_loss: 0.2952, G_B_loss: 0.3052\n",
      "Epoch [27/200], Step [211/1067], D_A_loss: 0.0312, D_B_loss: 0.1330, G_A_loss: 0.4310, G_B_loss: 0.3235\n",
      "Epoch [27/200], Step [221/1067], D_A_loss: 0.0181, D_B_loss: 0.2161, G_A_loss: 0.3962, G_B_loss: 0.8690\n",
      "Epoch [27/200], Step [231/1067], D_A_loss: 0.1148, D_B_loss: 0.0619, G_A_loss: 0.6295, G_B_loss: 0.5475\n",
      "Epoch [27/200], Step [241/1067], D_A_loss: 0.1530, D_B_loss: 0.0288, G_A_loss: 0.7034, G_B_loss: 1.1333\n",
      "Epoch [27/200], Step [251/1067], D_A_loss: 0.1071, D_B_loss: 0.0185, G_A_loss: 0.7414, G_B_loss: 0.4805\n",
      "Epoch [27/200], Step [261/1067], D_A_loss: 0.0388, D_B_loss: 0.0110, G_A_loss: 0.8843, G_B_loss: 0.3928\n",
      "Epoch [27/200], Step [271/1067], D_A_loss: 0.0983, D_B_loss: 0.0940, G_A_loss: 0.4133, G_B_loss: 0.3057\n",
      "Epoch [27/200], Step [281/1067], D_A_loss: 0.0611, D_B_loss: 0.0395, G_A_loss: 0.7809, G_B_loss: 0.6568\n",
      "Epoch [27/200], Step [291/1067], D_A_loss: 0.0358, D_B_loss: 0.0694, G_A_loss: 0.6362, G_B_loss: 0.5736\n",
      "Epoch [27/200], Step [301/1067], D_A_loss: 0.0239, D_B_loss: 0.0235, G_A_loss: 0.9330, G_B_loss: 0.7977\n",
      "Epoch [27/200], Step [311/1067], D_A_loss: 0.0430, D_B_loss: 0.0460, G_A_loss: 0.7481, G_B_loss: 1.0980\n",
      "Epoch [27/200], Step [321/1067], D_A_loss: 0.0347, D_B_loss: 0.0238, G_A_loss: 1.1337, G_B_loss: 0.9379\n",
      "Epoch [27/200], Step [331/1067], D_A_loss: 0.0310, D_B_loss: 0.1057, G_A_loss: 1.1068, G_B_loss: 0.6272\n",
      "Epoch [27/200], Step [341/1067], D_A_loss: 0.1066, D_B_loss: 0.0230, G_A_loss: 0.8241, G_B_loss: 0.7591\n",
      "Epoch [27/200], Step [351/1067], D_A_loss: 0.3855, D_B_loss: 0.1683, G_A_loss: 0.2372, G_B_loss: 0.9823\n",
      "Epoch [27/200], Step [361/1067], D_A_loss: 0.0577, D_B_loss: 0.1550, G_A_loss: 0.8433, G_B_loss: 0.5373\n",
      "Epoch [27/200], Step [371/1067], D_A_loss: 0.0984, D_B_loss: 0.0122, G_A_loss: 0.9884, G_B_loss: 0.6068\n",
      "Epoch [27/200], Step [381/1067], D_A_loss: 0.1464, D_B_loss: 0.0302, G_A_loss: 0.8927, G_B_loss: 0.4950\n",
      "Epoch [27/200], Step [391/1067], D_A_loss: 0.1054, D_B_loss: 0.1203, G_A_loss: 0.3218, G_B_loss: 0.6343\n",
      "Epoch [27/200], Step [401/1067], D_A_loss: 0.1513, D_B_loss: 0.0998, G_A_loss: 0.7748, G_B_loss: 0.3790\n",
      "Epoch [27/200], Step [411/1067], D_A_loss: 0.0374, D_B_loss: 0.0690, G_A_loss: 1.3322, G_B_loss: 0.4904\n",
      "Epoch [27/200], Step [421/1067], D_A_loss: 0.1226, D_B_loss: 0.0352, G_A_loss: 0.5843, G_B_loss: 0.2972\n",
      "Epoch [27/200], Step [431/1067], D_A_loss: 0.0255, D_B_loss: 0.0200, G_A_loss: 0.8671, G_B_loss: 0.9999\n",
      "Epoch [27/200], Step [441/1067], D_A_loss: 0.0753, D_B_loss: 0.0244, G_A_loss: 0.8059, G_B_loss: 1.2623\n",
      "Epoch [27/200], Step [451/1067], D_A_loss: 0.0355, D_B_loss: 0.0143, G_A_loss: 0.9909, G_B_loss: 0.6697\n",
      "Epoch [27/200], Step [461/1067], D_A_loss: 0.0329, D_B_loss: 0.0330, G_A_loss: 0.6809, G_B_loss: 1.1329\n",
      "Epoch [27/200], Step [471/1067], D_A_loss: 0.3628, D_B_loss: 0.0638, G_A_loss: 0.5158, G_B_loss: 1.1230\n",
      "Epoch [27/200], Step [481/1067], D_A_loss: 0.1261, D_B_loss: 0.0778, G_A_loss: 0.8628, G_B_loss: 0.7126\n",
      "Epoch [27/200], Step [491/1067], D_A_loss: 0.1060, D_B_loss: 0.0276, G_A_loss: 0.8636, G_B_loss: 0.5700\n",
      "Epoch [27/200], Step [501/1067], D_A_loss: 0.0476, D_B_loss: 0.0614, G_A_loss: 0.3371, G_B_loss: 0.6040\n",
      "Epoch [27/200], Step [511/1067], D_A_loss: 0.0647, D_B_loss: 0.1149, G_A_loss: 0.3386, G_B_loss: 0.7409\n",
      "Epoch [27/200], Step [521/1067], D_A_loss: 0.0581, D_B_loss: 0.0837, G_A_loss: 0.2947, G_B_loss: 1.0743\n",
      "Epoch [27/200], Step [531/1067], D_A_loss: 0.0904, D_B_loss: 0.0550, G_A_loss: 0.5670, G_B_loss: 0.4255\n",
      "Epoch [27/200], Step [541/1067], D_A_loss: 0.0683, D_B_loss: 0.0212, G_A_loss: 0.7310, G_B_loss: 0.3441\n",
      "Epoch [27/200], Step [551/1067], D_A_loss: 0.0242, D_B_loss: 0.0171, G_A_loss: 0.6802, G_B_loss: 0.7029\n",
      "Epoch [27/200], Step [561/1067], D_A_loss: 0.0532, D_B_loss: 0.0493, G_A_loss: 0.6027, G_B_loss: 0.6021\n",
      "Epoch [27/200], Step [571/1067], D_A_loss: 0.0818, D_B_loss: 0.0502, G_A_loss: 1.4233, G_B_loss: 0.4974\n",
      "Epoch [27/200], Step [581/1067], D_A_loss: 0.0552, D_B_loss: 0.0586, G_A_loss: 0.4816, G_B_loss: 0.6658\n",
      "Epoch [27/200], Step [591/1067], D_A_loss: 0.0926, D_B_loss: 0.1662, G_A_loss: 0.2559, G_B_loss: 0.1167\n",
      "Epoch [27/200], Step [601/1067], D_A_loss: 0.1403, D_B_loss: 0.0496, G_A_loss: 0.6596, G_B_loss: 0.3040\n",
      "Epoch [27/200], Step [611/1067], D_A_loss: 0.0935, D_B_loss: 0.0130, G_A_loss: 0.9532, G_B_loss: 0.7252\n",
      "Epoch [27/200], Step [621/1067], D_A_loss: 0.1227, D_B_loss: 0.0330, G_A_loss: 0.6488, G_B_loss: 0.9248\n",
      "Epoch [27/200], Step [631/1067], D_A_loss: 0.1328, D_B_loss: 0.1277, G_A_loss: 0.4335, G_B_loss: 0.4229\n",
      "Epoch [27/200], Step [641/1067], D_A_loss: 0.0397, D_B_loss: 0.0215, G_A_loss: 1.2048, G_B_loss: 0.9074\n",
      "Epoch [27/200], Step [651/1067], D_A_loss: 0.0195, D_B_loss: 0.0347, G_A_loss: 0.6507, G_B_loss: 0.7931\n",
      "Epoch [27/200], Step [661/1067], D_A_loss: 0.0643, D_B_loss: 0.0434, G_A_loss: 0.7649, G_B_loss: 0.7764\n",
      "Epoch [27/200], Step [671/1067], D_A_loss: 0.1064, D_B_loss: 0.0830, G_A_loss: 0.4917, G_B_loss: 0.2101\n",
      "Epoch [27/200], Step [681/1067], D_A_loss: 0.0907, D_B_loss: 0.0874, G_A_loss: 0.7364, G_B_loss: 0.2325\n",
      "Epoch [27/200], Step [691/1067], D_A_loss: 0.3718, D_B_loss: 0.0929, G_A_loss: 0.7241, G_B_loss: 0.0846\n",
      "Epoch [27/200], Step [701/1067], D_A_loss: 0.0748, D_B_loss: 0.0540, G_A_loss: 0.3079, G_B_loss: 0.7796\n",
      "Epoch [27/200], Step [711/1067], D_A_loss: 0.1674, D_B_loss: 0.0269, G_A_loss: 0.6850, G_B_loss: 0.6822\n",
      "Epoch [27/200], Step [721/1067], D_A_loss: 0.0316, D_B_loss: 0.0230, G_A_loss: 0.8057, G_B_loss: 0.7796\n",
      "Epoch [27/200], Step [731/1067], D_A_loss: 0.0514, D_B_loss: 0.0454, G_A_loss: 0.8006, G_B_loss: 0.6003\n",
      "Epoch [27/200], Step [741/1067], D_A_loss: 0.1325, D_B_loss: 0.0348, G_A_loss: 0.8017, G_B_loss: 0.3448\n",
      "Epoch [27/200], Step [751/1067], D_A_loss: 0.0561, D_B_loss: 0.0250, G_A_loss: 0.8737, G_B_loss: 0.4492\n",
      "Epoch [27/200], Step [761/1067], D_A_loss: 0.0641, D_B_loss: 0.0301, G_A_loss: 0.7096, G_B_loss: 0.3264\n",
      "Epoch [27/200], Step [771/1067], D_A_loss: 0.0360, D_B_loss: 0.0990, G_A_loss: 0.6855, G_B_loss: 0.4340\n",
      "Epoch [27/200], Step [781/1067], D_A_loss: 0.3326, D_B_loss: 0.0202, G_A_loss: 1.1078, G_B_loss: 0.6233\n",
      "Epoch [27/200], Step [791/1067], D_A_loss: 0.0526, D_B_loss: 0.0133, G_A_loss: 0.9049, G_B_loss: 0.4142\n",
      "Epoch [27/200], Step [801/1067], D_A_loss: 0.0462, D_B_loss: 0.0432, G_A_loss: 0.7306, G_B_loss: 0.8538\n",
      "Epoch [27/200], Step [811/1067], D_A_loss: 0.0329, D_B_loss: 0.1393, G_A_loss: 0.3977, G_B_loss: 0.8298\n",
      "Epoch [27/200], Step [821/1067], D_A_loss: 0.0553, D_B_loss: 0.1089, G_A_loss: 0.8002, G_B_loss: 0.3156\n",
      "Epoch [27/200], Step [831/1067], D_A_loss: 0.1212, D_B_loss: 0.0366, G_A_loss: 0.4400, G_B_loss: 0.3276\n",
      "Epoch [27/200], Step [841/1067], D_A_loss: 0.0721, D_B_loss: 0.0277, G_A_loss: 0.8143, G_B_loss: 0.5220\n",
      "Epoch [27/200], Step [851/1067], D_A_loss: 0.0650, D_B_loss: 0.0458, G_A_loss: 0.7478, G_B_loss: 0.5929\n",
      "Epoch [27/200], Step [861/1067], D_A_loss: 0.0456, D_B_loss: 0.0614, G_A_loss: 0.5941, G_B_loss: 0.5952\n",
      "Epoch [27/200], Step [871/1067], D_A_loss: 0.0522, D_B_loss: 0.0673, G_A_loss: 0.7480, G_B_loss: 0.6980\n",
      "Epoch [27/200], Step [881/1067], D_A_loss: 0.0648, D_B_loss: 0.0384, G_A_loss: 0.8345, G_B_loss: 0.2752\n",
      "Epoch [27/200], Step [891/1067], D_A_loss: 0.0879, D_B_loss: 0.1587, G_A_loss: 0.9595, G_B_loss: 0.3302\n",
      "Epoch [27/200], Step [901/1067], D_A_loss: 0.2255, D_B_loss: 0.1092, G_A_loss: 0.4248, G_B_loss: 0.3751\n",
      "Epoch [27/200], Step [911/1067], D_A_loss: 0.0312, D_B_loss: 0.0383, G_A_loss: 0.6685, G_B_loss: 0.6828\n",
      "Epoch [27/200], Step [921/1067], D_A_loss: 0.0628, D_B_loss: 0.0286, G_A_loss: 0.9636, G_B_loss: 0.5713\n",
      "Epoch [27/200], Step [931/1067], D_A_loss: 0.0648, D_B_loss: 0.0547, G_A_loss: 0.7550, G_B_loss: 0.5288\n",
      "Epoch [27/200], Step [941/1067], D_A_loss: 0.0664, D_B_loss: 0.0322, G_A_loss: 0.5751, G_B_loss: 0.5913\n",
      "Epoch [27/200], Step [951/1067], D_A_loss: 0.0652, D_B_loss: 0.0702, G_A_loss: 0.3573, G_B_loss: 0.8079\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [27/200], Step [961/1067], D_A_loss: 0.1688, D_B_loss: 0.0364, G_A_loss: 0.5570, G_B_loss: 0.3953\n",
      "Epoch [27/200], Step [971/1067], D_A_loss: 0.0302, D_B_loss: 0.0424, G_A_loss: 0.9566, G_B_loss: 0.5404\n",
      "Epoch [27/200], Step [981/1067], D_A_loss: 0.0311, D_B_loss: 0.0191, G_A_loss: 0.8952, G_B_loss: 0.5949\n",
      "Epoch [27/200], Step [991/1067], D_A_loss: 0.1457, D_B_loss: 0.0281, G_A_loss: 0.6805, G_B_loss: 0.3131\n",
      "Epoch [27/200], Step [1001/1067], D_A_loss: 0.0384, D_B_loss: 0.0269, G_A_loss: 0.9165, G_B_loss: 0.3880\n",
      "Epoch [27/200], Step [1011/1067], D_A_loss: 0.0595, D_B_loss: 0.0352, G_A_loss: 0.6052, G_B_loss: 0.5295\n",
      "Epoch [27/200], Step [1021/1067], D_A_loss: 0.0737, D_B_loss: 0.0758, G_A_loss: 0.4384, G_B_loss: 1.1118\n",
      "Epoch [27/200], Step [1031/1067], D_A_loss: 0.1793, D_B_loss: 0.0726, G_A_loss: 0.5643, G_B_loss: 1.2601\n",
      "Epoch [27/200], Step [1041/1067], D_A_loss: 0.0796, D_B_loss: 0.0772, G_A_loss: 0.7409, G_B_loss: 0.5821\n",
      "Epoch [27/200], Step [1051/1067], D_A_loss: 0.0336, D_B_loss: 0.0641, G_A_loss: 0.5370, G_B_loss: 0.7405\n",
      "Epoch [27/200], Step [1061/1067], D_A_loss: 0.1284, D_B_loss: 0.0314, G_A_loss: 0.6484, G_B_loss: 1.0952\n",
      "Epoch [28/200], Step [1/1067], D_A_loss: 0.1285, D_B_loss: 0.0150, G_A_loss: 0.5255, G_B_loss: 0.3740\n",
      "Epoch [28/200], Step [11/1067], D_A_loss: 0.1393, D_B_loss: 0.1052, G_A_loss: 1.2618, G_B_loss: 0.3221\n",
      "Epoch [28/200], Step [21/1067], D_A_loss: 0.0245, D_B_loss: 0.0965, G_A_loss: 0.5645, G_B_loss: 0.6646\n",
      "Epoch [28/200], Step [31/1067], D_A_loss: 0.1079, D_B_loss: 0.1142, G_A_loss: 0.5505, G_B_loss: 0.3881\n",
      "Epoch [28/200], Step [41/1067], D_A_loss: 0.0798, D_B_loss: 0.0231, G_A_loss: 0.8686, G_B_loss: 0.4436\n",
      "Epoch [28/200], Step [51/1067], D_A_loss: 0.1345, D_B_loss: 0.0691, G_A_loss: 0.3712, G_B_loss: 0.3480\n",
      "Epoch [28/200], Step [61/1067], D_A_loss: 0.1064, D_B_loss: 0.0355, G_A_loss: 0.5614, G_B_loss: 0.3805\n",
      "Epoch [28/200], Step [71/1067], D_A_loss: 0.0755, D_B_loss: 0.1145, G_A_loss: 0.6742, G_B_loss: 0.7213\n",
      "Epoch [28/200], Step [81/1067], D_A_loss: 0.1152, D_B_loss: 0.0239, G_A_loss: 0.7820, G_B_loss: 0.4263\n",
      "Epoch [28/200], Step [91/1067], D_A_loss: 0.1432, D_B_loss: 0.0384, G_A_loss: 0.7288, G_B_loss: 0.5544\n",
      "Epoch [28/200], Step [101/1067], D_A_loss: 0.0563, D_B_loss: 0.0201, G_A_loss: 1.0885, G_B_loss: 0.6552\n",
      "Epoch [28/200], Step [111/1067], D_A_loss: 0.0647, D_B_loss: 0.0403, G_A_loss: 0.6475, G_B_loss: 0.5340\n",
      "Epoch [28/200], Step [121/1067], D_A_loss: 0.0751, D_B_loss: 0.0513, G_A_loss: 0.5598, G_B_loss: 0.7375\n",
      "Epoch [28/200], Step [131/1067], D_A_loss: 0.0424, D_B_loss: 0.0823, G_A_loss: 1.0808, G_B_loss: 0.5395\n",
      "Epoch [28/200], Step [141/1067], D_A_loss: 0.0246, D_B_loss: 0.0501, G_A_loss: 0.6308, G_B_loss: 0.5579\n",
      "Epoch [28/200], Step [151/1067], D_A_loss: 0.0892, D_B_loss: 0.0374, G_A_loss: 0.6115, G_B_loss: 0.3592\n",
      "Epoch [28/200], Step [161/1067], D_A_loss: 0.0398, D_B_loss: 0.0228, G_A_loss: 1.0729, G_B_loss: 0.5298\n",
      "Epoch [28/200], Step [171/1067], D_A_loss: 0.0728, D_B_loss: 0.0218, G_A_loss: 1.0413, G_B_loss: 0.1693\n",
      "Epoch [28/200], Step [181/1067], D_A_loss: 0.0359, D_B_loss: 0.0993, G_A_loss: 0.3529, G_B_loss: 0.9089\n",
      "Epoch [28/200], Step [191/1067], D_A_loss: 0.0671, D_B_loss: 0.0414, G_A_loss: 0.8964, G_B_loss: 0.4321\n",
      "Epoch [28/200], Step [201/1067], D_A_loss: 0.0765, D_B_loss: 0.0246, G_A_loss: 0.8492, G_B_loss: 0.4644\n",
      "Epoch [28/200], Step [211/1067], D_A_loss: 0.1599, D_B_loss: 0.0192, G_A_loss: 0.7391, G_B_loss: 0.2885\n",
      "Epoch [28/200], Step [221/1067], D_A_loss: 0.0619, D_B_loss: 0.0423, G_A_loss: 0.9043, G_B_loss: 0.3234\n",
      "Epoch [28/200], Step [231/1067], D_A_loss: 0.0833, D_B_loss: 0.0379, G_A_loss: 0.4815, G_B_loss: 0.6171\n",
      "Epoch [28/200], Step [241/1067], D_A_loss: 0.0309, D_B_loss: 0.0311, G_A_loss: 0.5442, G_B_loss: 0.5364\n",
      "Epoch [28/200], Step [251/1067], D_A_loss: 0.1647, D_B_loss: 0.1085, G_A_loss: 0.7612, G_B_loss: 0.4913\n",
      "Epoch [28/200], Step [261/1067], D_A_loss: 0.0897, D_B_loss: 0.1880, G_A_loss: 0.9873, G_B_loss: 0.5036\n",
      "Epoch [28/200], Step [271/1067], D_A_loss: 0.0191, D_B_loss: 0.0565, G_A_loss: 1.0855, G_B_loss: 0.9922\n",
      "Epoch [28/200], Step [281/1067], D_A_loss: 0.0674, D_B_loss: 0.0411, G_A_loss: 0.5840, G_B_loss: 0.9645\n",
      "Epoch [28/200], Step [291/1067], D_A_loss: 0.0659, D_B_loss: 0.0243, G_A_loss: 0.8131, G_B_loss: 1.2186\n",
      "Epoch [28/200], Step [301/1067], D_A_loss: 0.0360, D_B_loss: 0.0501, G_A_loss: 0.8183, G_B_loss: 0.6279\n",
      "Epoch [28/200], Step [311/1067], D_A_loss: 0.0519, D_B_loss: 0.0647, G_A_loss: 0.4988, G_B_loss: 0.7140\n",
      "Epoch [28/200], Step [321/1067], D_A_loss: 0.0474, D_B_loss: 0.0136, G_A_loss: 0.6789, G_B_loss: 0.7805\n",
      "Epoch [28/200], Step [331/1067], D_A_loss: 0.2019, D_B_loss: 0.0528, G_A_loss: 0.7572, G_B_loss: 0.2279\n",
      "Epoch [28/200], Step [341/1067], D_A_loss: 0.1789, D_B_loss: 0.0990, G_A_loss: 0.4455, G_B_loss: 0.5143\n",
      "Epoch [28/200], Step [351/1067], D_A_loss: 0.0838, D_B_loss: 0.0165, G_A_loss: 0.9176, G_B_loss: 0.4470\n",
      "Epoch [28/200], Step [361/1067], D_A_loss: 0.0333, D_B_loss: 0.0345, G_A_loss: 0.7164, G_B_loss: 0.6010\n",
      "Epoch [28/200], Step [371/1067], D_A_loss: 0.0659, D_B_loss: 0.0763, G_A_loss: 0.6043, G_B_loss: 0.8414\n",
      "Epoch [28/200], Step [381/1067], D_A_loss: 0.0375, D_B_loss: 0.0905, G_A_loss: 0.4406, G_B_loss: 0.7431\n",
      "Epoch [28/200], Step [391/1067], D_A_loss: 0.0311, D_B_loss: 0.0501, G_A_loss: 0.9568, G_B_loss: 0.5061\n",
      "Epoch [28/200], Step [401/1067], D_A_loss: 0.0581, D_B_loss: 0.0952, G_A_loss: 0.4761, G_B_loss: 0.7251\n",
      "Epoch [28/200], Step [411/1067], D_A_loss: 0.0206, D_B_loss: 0.0232, G_A_loss: 0.8318, G_B_loss: 1.1283\n",
      "Epoch [28/200], Step [421/1067], D_A_loss: 0.0302, D_B_loss: 0.0128, G_A_loss: 0.5965, G_B_loss: 0.4763\n",
      "Epoch [28/200], Step [431/1067], D_A_loss: 0.0445, D_B_loss: 0.2078, G_A_loss: 0.8069, G_B_loss: 0.7925\n",
      "Epoch [28/200], Step [441/1067], D_A_loss: 0.2481, D_B_loss: 0.1362, G_A_loss: 0.3977, G_B_loss: 0.8066\n",
      "Epoch [28/200], Step [451/1067], D_A_loss: 0.1366, D_B_loss: 0.0407, G_A_loss: 0.1538, G_B_loss: 0.3848\n",
      "Epoch [28/200], Step [461/1067], D_A_loss: 0.1439, D_B_loss: 0.0825, G_A_loss: 0.2673, G_B_loss: 0.3143\n",
      "Epoch [28/200], Step [471/1067], D_A_loss: 0.1233, D_B_loss: 0.0516, G_A_loss: 0.5532, G_B_loss: 0.5156\n",
      "Epoch [28/200], Step [481/1067], D_A_loss: 0.2203, D_B_loss: 0.1511, G_A_loss: 0.9554, G_B_loss: 0.2002\n",
      "Epoch [28/200], Step [491/1067], D_A_loss: 0.0889, D_B_loss: 0.0332, G_A_loss: 1.1821, G_B_loss: 0.7219\n",
      "Epoch [28/200], Step [501/1067], D_A_loss: 0.0883, D_B_loss: 0.0378, G_A_loss: 0.6383, G_B_loss: 0.5327\n",
      "Epoch [28/200], Step [511/1067], D_A_loss: 0.1112, D_B_loss: 0.0474, G_A_loss: 0.7995, G_B_loss: 0.3767\n",
      "Epoch [28/200], Step [521/1067], D_A_loss: 0.1289, D_B_loss: 0.1473, G_A_loss: 0.2540, G_B_loss: 0.9785\n",
      "Epoch [28/200], Step [531/1067], D_A_loss: 0.0401, D_B_loss: 0.0209, G_A_loss: 0.9767, G_B_loss: 0.9770\n",
      "Epoch [28/200], Step [541/1067], D_A_loss: 0.0836, D_B_loss: 0.0485, G_A_loss: 1.2365, G_B_loss: 0.4920\n",
      "Epoch [28/200], Step [551/1067], D_A_loss: 0.0655, D_B_loss: 0.0746, G_A_loss: 0.4704, G_B_loss: 0.5620\n",
      "Epoch [28/200], Step [561/1067], D_A_loss: 0.1136, D_B_loss: 0.0317, G_A_loss: 0.4588, G_B_loss: 0.3180\n",
      "Epoch [28/200], Step [571/1067], D_A_loss: 0.1777, D_B_loss: 0.0098, G_A_loss: 0.4969, G_B_loss: 0.5464\n",
      "Epoch [28/200], Step [581/1067], D_A_loss: 0.1436, D_B_loss: 0.0410, G_A_loss: 0.6294, G_B_loss: 0.3847\n",
      "Epoch [28/200], Step [591/1067], D_A_loss: 0.2669, D_B_loss: 0.0607, G_A_loss: 1.0840, G_B_loss: 0.1199\n",
      "Epoch [28/200], Step [601/1067], D_A_loss: 0.0409, D_B_loss: 0.1586, G_A_loss: 0.7637, G_B_loss: 0.4050\n",
      "Epoch [28/200], Step [611/1067], D_A_loss: 0.0893, D_B_loss: 0.0589, G_A_loss: 0.5954, G_B_loss: 0.6207\n",
      "Epoch [28/200], Step [621/1067], D_A_loss: 0.0989, D_B_loss: 0.0320, G_A_loss: 0.9463, G_B_loss: 0.4656\n",
      "Epoch [28/200], Step [631/1067], D_A_loss: 0.0391, D_B_loss: 0.0327, G_A_loss: 0.7644, G_B_loss: 0.4799\n",
      "Epoch [28/200], Step [641/1067], D_A_loss: 0.1154, D_B_loss: 0.0318, G_A_loss: 0.8458, G_B_loss: 0.3891\n",
      "Epoch [28/200], Step [651/1067], D_A_loss: 0.2232, D_B_loss: 0.0317, G_A_loss: 0.8222, G_B_loss: 0.5555\n",
      "Epoch [28/200], Step [661/1067], D_A_loss: 0.0264, D_B_loss: 0.0229, G_A_loss: 0.6391, G_B_loss: 1.0056\n",
      "Epoch [28/200], Step [671/1067], D_A_loss: 0.0438, D_B_loss: 0.1383, G_A_loss: 0.4002, G_B_loss: 0.8278\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [28/200], Step [681/1067], D_A_loss: 0.0760, D_B_loss: 0.0188, G_A_loss: 0.7593, G_B_loss: 0.6347\n",
      "Epoch [28/200], Step [691/1067], D_A_loss: 0.1163, D_B_loss: 0.0239, G_A_loss: 0.3952, G_B_loss: 0.5655\n",
      "Epoch [28/200], Step [701/1067], D_A_loss: 0.0270, D_B_loss: 0.0550, G_A_loss: 0.5093, G_B_loss: 0.4865\n",
      "Epoch [28/200], Step [711/1067], D_A_loss: 0.0322, D_B_loss: 0.0513, G_A_loss: 0.9468, G_B_loss: 0.4106\n",
      "Epoch [28/200], Step [721/1067], D_A_loss: 0.0521, D_B_loss: 0.0615, G_A_loss: 0.7457, G_B_loss: 0.6428\n",
      "Epoch [28/200], Step [731/1067], D_A_loss: 0.0888, D_B_loss: 0.2448, G_A_loss: 0.4893, G_B_loss: 0.5954\n",
      "Epoch [28/200], Step [741/1067], D_A_loss: 0.0905, D_B_loss: 0.0794, G_A_loss: 1.0635, G_B_loss: 0.2659\n",
      "Epoch [28/200], Step [751/1067], D_A_loss: 0.0434, D_B_loss: 0.1240, G_A_loss: 0.3204, G_B_loss: 0.6271\n",
      "Epoch [28/200], Step [761/1067], D_A_loss: 0.0520, D_B_loss: 0.0496, G_A_loss: 0.2470, G_B_loss: 1.0447\n",
      "Epoch [28/200], Step [771/1067], D_A_loss: 0.0454, D_B_loss: 0.1494, G_A_loss: 0.6841, G_B_loss: 0.4727\n",
      "Epoch [28/200], Step [781/1067], D_A_loss: 0.2679, D_B_loss: 0.0822, G_A_loss: 0.9217, G_B_loss: 0.1282\n",
      "Epoch [28/200], Step [791/1067], D_A_loss: 0.0532, D_B_loss: 0.0247, G_A_loss: 0.6588, G_B_loss: 0.5875\n",
      "Epoch [28/200], Step [801/1067], D_A_loss: 0.0855, D_B_loss: 0.0743, G_A_loss: 0.6291, G_B_loss: 0.3542\n",
      "Epoch [28/200], Step [811/1067], D_A_loss: 0.0268, D_B_loss: 0.0210, G_A_loss: 0.9319, G_B_loss: 0.2868\n",
      "Epoch [28/200], Step [821/1067], D_A_loss: 0.0458, D_B_loss: 0.0183, G_A_loss: 0.5294, G_B_loss: 0.6029\n",
      "Epoch [28/200], Step [831/1067], D_A_loss: 0.0631, D_B_loss: 0.0926, G_A_loss: 0.4073, G_B_loss: 0.6445\n",
      "Epoch [28/200], Step [841/1067], D_A_loss: 0.1396, D_B_loss: 0.0800, G_A_loss: 0.5912, G_B_loss: 0.3364\n",
      "Epoch [28/200], Step [851/1067], D_A_loss: 0.1230, D_B_loss: 0.1169, G_A_loss: 0.6848, G_B_loss: 0.3930\n",
      "Epoch [28/200], Step [861/1067], D_A_loss: 0.1612, D_B_loss: 0.2517, G_A_loss: 0.1194, G_B_loss: 0.3561\n",
      "Epoch [28/200], Step [871/1067], D_A_loss: 0.0278, D_B_loss: 0.0193, G_A_loss: 0.7658, G_B_loss: 0.4922\n",
      "Epoch [28/200], Step [881/1067], D_A_loss: 0.0344, D_B_loss: 0.0592, G_A_loss: 0.8263, G_B_loss: 0.6050\n",
      "Epoch [28/200], Step [891/1067], D_A_loss: 0.1024, D_B_loss: 0.2083, G_A_loss: 0.7392, G_B_loss: 0.8326\n",
      "Epoch [28/200], Step [901/1067], D_A_loss: 0.0800, D_B_loss: 0.0295, G_A_loss: 1.0739, G_B_loss: 0.5076\n",
      "Epoch [28/200], Step [911/1067], D_A_loss: 0.0778, D_B_loss: 0.0324, G_A_loss: 0.7031, G_B_loss: 0.5836\n",
      "Epoch [28/200], Step [921/1067], D_A_loss: 0.0519, D_B_loss: 0.0577, G_A_loss: 0.7420, G_B_loss: 0.3807\n",
      "Epoch [28/200], Step [931/1067], D_A_loss: 0.1329, D_B_loss: 0.0247, G_A_loss: 0.9730, G_B_loss: 0.3591\n",
      "Epoch [28/200], Step [941/1067], D_A_loss: 0.0706, D_B_loss: 0.0492, G_A_loss: 0.8183, G_B_loss: 0.2686\n",
      "Epoch [28/200], Step [951/1067], D_A_loss: 0.0906, D_B_loss: 0.0292, G_A_loss: 0.7021, G_B_loss: 0.4118\n",
      "Epoch [28/200], Step [961/1067], D_A_loss: 0.1571, D_B_loss: 0.1227, G_A_loss: 0.4738, G_B_loss: 0.3063\n",
      "Epoch [28/200], Step [971/1067], D_A_loss: 0.2508, D_B_loss: 0.0593, G_A_loss: 0.8813, G_B_loss: 0.1193\n",
      "Epoch [28/200], Step [981/1067], D_A_loss: 0.0163, D_B_loss: 0.0236, G_A_loss: 0.9715, G_B_loss: 0.9912\n",
      "Epoch [28/200], Step [991/1067], D_A_loss: 0.0333, D_B_loss: 0.0335, G_A_loss: 0.6070, G_B_loss: 0.3724\n",
      "Epoch [28/200], Step [1001/1067], D_A_loss: 0.0362, D_B_loss: 0.0702, G_A_loss: 0.5414, G_B_loss: 1.1180\n",
      "Epoch [28/200], Step [1011/1067], D_A_loss: 0.0336, D_B_loss: 0.1589, G_A_loss: 0.6111, G_B_loss: 0.4809\n",
      "Epoch [28/200], Step [1021/1067], D_A_loss: 0.1627, D_B_loss: 0.1530, G_A_loss: 0.9945, G_B_loss: 0.6779\n",
      "Epoch [28/200], Step [1031/1067], D_A_loss: 0.0485, D_B_loss: 0.0785, G_A_loss: 0.4877, G_B_loss: 0.6304\n",
      "Epoch [28/200], Step [1041/1067], D_A_loss: 0.0815, D_B_loss: 0.0792, G_A_loss: 0.5951, G_B_loss: 0.4581\n",
      "Epoch [28/200], Step [1051/1067], D_A_loss: 0.0949, D_B_loss: 0.1142, G_A_loss: 0.4225, G_B_loss: 0.8343\n",
      "Epoch [28/200], Step [1061/1067], D_A_loss: 0.0490, D_B_loss: 0.0483, G_A_loss: 0.5389, G_B_loss: 0.7255\n",
      "Epoch [29/200], Step [1/1067], D_A_loss: 0.0589, D_B_loss: 0.0593, G_A_loss: 0.6044, G_B_loss: 0.5524\n",
      "Epoch [29/200], Step [11/1067], D_A_loss: 0.0540, D_B_loss: 0.0251, G_A_loss: 1.1471, G_B_loss: 0.5010\n",
      "Epoch [29/200], Step [21/1067], D_A_loss: 0.1241, D_B_loss: 0.0435, G_A_loss: 0.8231, G_B_loss: 0.3303\n",
      "Epoch [29/200], Step [31/1067], D_A_loss: 0.0519, D_B_loss: 0.0383, G_A_loss: 0.7088, G_B_loss: 0.6342\n",
      "Epoch [29/200], Step [41/1067], D_A_loss: 0.0761, D_B_loss: 0.0336, G_A_loss: 0.7512, G_B_loss: 0.5616\n",
      "Epoch [29/200], Step [51/1067], D_A_loss: 0.0496, D_B_loss: 0.0435, G_A_loss: 0.7009, G_B_loss: 0.2467\n",
      "Epoch [29/200], Step [61/1067], D_A_loss: 0.1246, D_B_loss: 0.0715, G_A_loss: 0.5767, G_B_loss: 0.7434\n",
      "Epoch [29/200], Step [71/1067], D_A_loss: 0.0499, D_B_loss: 0.2139, G_A_loss: 0.2528, G_B_loss: 0.6754\n",
      "Epoch [29/200], Step [81/1067], D_A_loss: 0.1188, D_B_loss: 0.0258, G_A_loss: 0.8107, G_B_loss: 0.6025\n",
      "Epoch [29/200], Step [91/1067], D_A_loss: 0.1306, D_B_loss: 0.0133, G_A_loss: 0.9751, G_B_loss: 0.4233\n",
      "Epoch [29/200], Step [101/1067], D_A_loss: 0.0720, D_B_loss: 0.0148, G_A_loss: 1.1221, G_B_loss: 0.5598\n",
      "Epoch [29/200], Step [111/1067], D_A_loss: 0.0591, D_B_loss: 0.1148, G_A_loss: 0.2491, G_B_loss: 0.8005\n",
      "Epoch [29/200], Step [121/1067], D_A_loss: 0.0354, D_B_loss: 0.1163, G_A_loss: 0.6034, G_B_loss: 0.4673\n",
      "Epoch [29/200], Step [131/1067], D_A_loss: 0.1614, D_B_loss: 0.0321, G_A_loss: 0.5233, G_B_loss: 0.3551\n",
      "Epoch [29/200], Step [141/1067], D_A_loss: 0.2847, D_B_loss: 0.0838, G_A_loss: 0.7057, G_B_loss: 1.0043\n",
      "Epoch [29/200], Step [151/1067], D_A_loss: 0.1279, D_B_loss: 0.1318, G_A_loss: 0.3902, G_B_loss: 0.6220\n",
      "Epoch [29/200], Step [161/1067], D_A_loss: 0.2344, D_B_loss: 0.0453, G_A_loss: 0.5612, G_B_loss: 0.6421\n",
      "Epoch [29/200], Step [171/1067], D_A_loss: 0.1264, D_B_loss: 0.0325, G_A_loss: 0.7942, G_B_loss: 0.3947\n",
      "Epoch [29/200], Step [181/1067], D_A_loss: 0.0850, D_B_loss: 0.1559, G_A_loss: 1.0676, G_B_loss: 0.5814\n",
      "Epoch [29/200], Step [191/1067], D_A_loss: 0.1652, D_B_loss: 0.0721, G_A_loss: 0.9021, G_B_loss: 0.2748\n",
      "Epoch [29/200], Step [201/1067], D_A_loss: 0.0477, D_B_loss: 0.0318, G_A_loss: 0.7379, G_B_loss: 0.9711\n",
      "Epoch [29/200], Step [211/1067], D_A_loss: 0.0497, D_B_loss: 0.1119, G_A_loss: 0.3138, G_B_loss: 0.6472\n",
      "Epoch [29/200], Step [221/1067], D_A_loss: 0.1650, D_B_loss: 0.0632, G_A_loss: 0.4843, G_B_loss: 0.2883\n",
      "Epoch [29/200], Step [231/1067], D_A_loss: 0.0264, D_B_loss: 0.0198, G_A_loss: 0.9811, G_B_loss: 0.7031\n",
      "Epoch [29/200], Step [241/1067], D_A_loss: 0.0573, D_B_loss: 0.0424, G_A_loss: 0.6344, G_B_loss: 0.8109\n",
      "Epoch [29/200], Step [251/1067], D_A_loss: 0.1237, D_B_loss: 0.0194, G_A_loss: 0.8131, G_B_loss: 1.1084\n",
      "Epoch [29/200], Step [261/1067], D_A_loss: 0.1591, D_B_loss: 0.1313, G_A_loss: 0.3897, G_B_loss: 0.3454\n",
      "Epoch [29/200], Step [271/1067], D_A_loss: 0.0447, D_B_loss: 0.0299, G_A_loss: 0.4937, G_B_loss: 0.9986\n",
      "Epoch [29/200], Step [281/1067], D_A_loss: 0.0764, D_B_loss: 0.0191, G_A_loss: 0.7568, G_B_loss: 0.7713\n",
      "Epoch [29/200], Step [291/1067], D_A_loss: 0.0377, D_B_loss: 0.0762, G_A_loss: 0.8414, G_B_loss: 0.3776\n",
      "Epoch [29/200], Step [301/1067], D_A_loss: 0.1235, D_B_loss: 0.2338, G_A_loss: 0.7740, G_B_loss: 0.5099\n",
      "Epoch [29/200], Step [311/1067], D_A_loss: 0.0203, D_B_loss: 0.0183, G_A_loss: 0.7898, G_B_loss: 0.8595\n",
      "Epoch [29/200], Step [321/1067], D_A_loss: 0.0795, D_B_loss: 0.0330, G_A_loss: 0.7326, G_B_loss: 0.4802\n",
      "Epoch [29/200], Step [331/1067], D_A_loss: 0.0438, D_B_loss: 0.0146, G_A_loss: 0.7937, G_B_loss: 0.8174\n",
      "Epoch [29/200], Step [341/1067], D_A_loss: 0.1023, D_B_loss: 0.0162, G_A_loss: 0.9353, G_B_loss: 0.4740\n",
      "Epoch [29/200], Step [351/1067], D_A_loss: 0.0607, D_B_loss: 0.0386, G_A_loss: 0.7633, G_B_loss: 0.3178\n",
      "Epoch [29/200], Step [361/1067], D_A_loss: 0.2267, D_B_loss: 0.0244, G_A_loss: 0.6996, G_B_loss: 0.1674\n",
      "Epoch [29/200], Step [371/1067], D_A_loss: 0.0927, D_B_loss: 0.0748, G_A_loss: 0.4735, G_B_loss: 0.6937\n",
      "Epoch [29/200], Step [381/1067], D_A_loss: 0.1290, D_B_loss: 0.0593, G_A_loss: 0.5605, G_B_loss: 0.3323\n",
      "Epoch [29/200], Step [391/1067], D_A_loss: 0.0440, D_B_loss: 0.0555, G_A_loss: 0.5810, G_B_loss: 0.8401\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [29/200], Step [401/1067], D_A_loss: 0.1632, D_B_loss: 0.0316, G_A_loss: 0.8189, G_B_loss: 0.2386\n",
      "Epoch [29/200], Step [411/1067], D_A_loss: 0.0535, D_B_loss: 0.0123, G_A_loss: 1.0122, G_B_loss: 0.5447\n",
      "Epoch [29/200], Step [421/1067], D_A_loss: 0.0331, D_B_loss: 0.0580, G_A_loss: 0.8557, G_B_loss: 0.4220\n",
      "Epoch [29/200], Step [431/1067], D_A_loss: 0.0715, D_B_loss: 0.0888, G_A_loss: 0.4032, G_B_loss: 0.4297\n",
      "Epoch [29/200], Step [441/1067], D_A_loss: 0.0689, D_B_loss: 0.0464, G_A_loss: 0.6492, G_B_loss: 0.5650\n",
      "Epoch [29/200], Step [451/1067], D_A_loss: 0.2233, D_B_loss: 0.1038, G_A_loss: 0.4483, G_B_loss: 0.5274\n",
      "Epoch [29/200], Step [461/1067], D_A_loss: 0.0989, D_B_loss: 0.1117, G_A_loss: 0.9501, G_B_loss: 1.0770\n",
      "Epoch [29/200], Step [471/1067], D_A_loss: 0.0523, D_B_loss: 0.1242, G_A_loss: 0.6994, G_B_loss: 0.5869\n",
      "Epoch [29/200], Step [481/1067], D_A_loss: 0.0468, D_B_loss: 0.0601, G_A_loss: 0.5044, G_B_loss: 0.7639\n",
      "Epoch [29/200], Step [491/1067], D_A_loss: 0.1952, D_B_loss: 0.0228, G_A_loss: 0.4594, G_B_loss: 0.2820\n",
      "Epoch [29/200], Step [501/1067], D_A_loss: 0.1186, D_B_loss: 0.0445, G_A_loss: 0.8697, G_B_loss: 0.3532\n",
      "Epoch [29/200], Step [511/1067], D_A_loss: 0.1233, D_B_loss: 0.0191, G_A_loss: 0.8240, G_B_loss: 0.5435\n",
      "Epoch [29/200], Step [521/1067], D_A_loss: 0.0728, D_B_loss: 0.0267, G_A_loss: 1.1221, G_B_loss: 0.5275\n",
      "Epoch [29/200], Step [531/1067], D_A_loss: 0.1841, D_B_loss: 0.0160, G_A_loss: 0.7838, G_B_loss: 0.4469\n",
      "Epoch [29/200], Step [541/1067], D_A_loss: 0.0877, D_B_loss: 0.0134, G_A_loss: 0.5145, G_B_loss: 1.0801\n",
      "Epoch [29/200], Step [551/1067], D_A_loss: 0.0303, D_B_loss: 0.1468, G_A_loss: 0.5984, G_B_loss: 0.8753\n",
      "Epoch [29/200], Step [561/1067], D_A_loss: 0.2691, D_B_loss: 0.0403, G_A_loss: 1.0962, G_B_loss: 0.1065\n",
      "Epoch [29/200], Step [571/1067], D_A_loss: 0.0909, D_B_loss: 0.0532, G_A_loss: 0.6599, G_B_loss: 1.1060\n",
      "Epoch [29/200], Step [581/1067], D_A_loss: 0.0588, D_B_loss: 0.0917, G_A_loss: 0.4451, G_B_loss: 0.6584\n",
      "Epoch [29/200], Step [591/1067], D_A_loss: 0.0605, D_B_loss: 0.0286, G_A_loss: 0.7932, G_B_loss: 0.5901\n",
      "Epoch [29/200], Step [601/1067], D_A_loss: 0.0495, D_B_loss: 0.0241, G_A_loss: 1.1927, G_B_loss: 0.6642\n",
      "Epoch [29/200], Step [611/1067], D_A_loss: 0.0408, D_B_loss: 0.0343, G_A_loss: 0.7622, G_B_loss: 0.7465\n",
      "Epoch [29/200], Step [621/1067], D_A_loss: 0.0495, D_B_loss: 0.0953, G_A_loss: 0.3651, G_B_loss: 0.5167\n",
      "Epoch [29/200], Step [631/1067], D_A_loss: 0.0626, D_B_loss: 0.0742, G_A_loss: 0.6486, G_B_loss: 0.5736\n",
      "Epoch [29/200], Step [641/1067], D_A_loss: 0.0492, D_B_loss: 0.0273, G_A_loss: 0.9392, G_B_loss: 0.7285\n",
      "Epoch [29/200], Step [651/1067], D_A_loss: 0.0891, D_B_loss: 0.0274, G_A_loss: 0.9106, G_B_loss: 0.5728\n",
      "Epoch [29/200], Step [661/1067], D_A_loss: 0.0948, D_B_loss: 0.0228, G_A_loss: 0.6711, G_B_loss: 0.4529\n",
      "Epoch [29/200], Step [671/1067], D_A_loss: 0.1812, D_B_loss: 0.0226, G_A_loss: 0.8106, G_B_loss: 0.3006\n",
      "Epoch [29/200], Step [681/1067], D_A_loss: 0.0577, D_B_loss: 0.0253, G_A_loss: 0.8257, G_B_loss: 0.5965\n",
      "Epoch [29/200], Step [691/1067], D_A_loss: 0.2065, D_B_loss: 0.1015, G_A_loss: 0.8220, G_B_loss: 0.6729\n",
      "Epoch [29/200], Step [701/1067], D_A_loss: 0.0678, D_B_loss: 0.3005, G_A_loss: 0.5470, G_B_loss: 0.6469\n",
      "Epoch [29/200], Step [711/1067], D_A_loss: 0.0979, D_B_loss: 0.0291, G_A_loss: 0.8307, G_B_loss: 0.7555\n",
      "Epoch [29/200], Step [721/1067], D_A_loss: 0.1108, D_B_loss: 0.0637, G_A_loss: 0.4375, G_B_loss: 0.7906\n",
      "Epoch [29/200], Step [731/1067], D_A_loss: 0.0703, D_B_loss: 0.0302, G_A_loss: 0.7311, G_B_loss: 0.4999\n",
      "Epoch [29/200], Step [741/1067], D_A_loss: 0.1495, D_B_loss: 0.0469, G_A_loss: 0.8844, G_B_loss: 0.3328\n",
      "Epoch [29/200], Step [751/1067], D_A_loss: 0.1291, D_B_loss: 0.0177, G_A_loss: 0.6116, G_B_loss: 0.4263\n",
      "Epoch [29/200], Step [761/1067], D_A_loss: 0.1972, D_B_loss: 0.0447, G_A_loss: 0.8664, G_B_loss: 0.2345\n",
      "Epoch [29/200], Step [771/1067], D_A_loss: 0.0296, D_B_loss: 0.0472, G_A_loss: 0.7118, G_B_loss: 0.4966\n",
      "Epoch [29/200], Step [781/1067], D_A_loss: 0.0687, D_B_loss: 0.0948, G_A_loss: 0.3977, G_B_loss: 1.0510\n",
      "Epoch [29/200], Step [791/1067], D_A_loss: 0.0772, D_B_loss: 0.0301, G_A_loss: 0.6131, G_B_loss: 0.5461\n",
      "Epoch [29/200], Step [801/1067], D_A_loss: 0.0350, D_B_loss: 0.0254, G_A_loss: 0.5635, G_B_loss: 0.6868\n",
      "Epoch [29/200], Step [811/1067], D_A_loss: 0.0859, D_B_loss: 0.0179, G_A_loss: 0.9743, G_B_loss: 0.6841\n",
      "Epoch [29/200], Step [821/1067], D_A_loss: 0.2384, D_B_loss: 0.0249, G_A_loss: 0.8754, G_B_loss: 0.7297\n",
      "Epoch [29/200], Step [831/1067], D_A_loss: 0.0314, D_B_loss: 0.0429, G_A_loss: 1.1717, G_B_loss: 0.4742\n",
      "Epoch [29/200], Step [841/1067], D_A_loss: 0.0972, D_B_loss: 0.0512, G_A_loss: 1.1099, G_B_loss: 0.6865\n",
      "Epoch [29/200], Step [851/1067], D_A_loss: 0.2816, D_B_loss: 0.0350, G_A_loss: 0.9236, G_B_loss: 0.9664\n",
      "Epoch [29/200], Step [861/1067], D_A_loss: 0.0953, D_B_loss: 0.0160, G_A_loss: 0.7212, G_B_loss: 0.6839\n",
      "Epoch [29/200], Step [871/1067], D_A_loss: 0.0284, D_B_loss: 0.0237, G_A_loss: 0.7867, G_B_loss: 0.7610\n",
      "Epoch [29/200], Step [881/1067], D_A_loss: 0.1455, D_B_loss: 0.0911, G_A_loss: 0.6241, G_B_loss: 0.3041\n",
      "Epoch [29/200], Step [891/1067], D_A_loss: 0.1044, D_B_loss: 0.0185, G_A_loss: 0.3706, G_B_loss: 0.3485\n",
      "Epoch [29/200], Step [901/1067], D_A_loss: 0.3269, D_B_loss: 0.0713, G_A_loss: 0.6795, G_B_loss: 0.6159\n",
      "Epoch [29/200], Step [911/1067], D_A_loss: 0.1077, D_B_loss: 0.1266, G_A_loss: 0.3515, G_B_loss: 0.4653\n",
      "Epoch [29/200], Step [921/1067], D_A_loss: 0.1457, D_B_loss: 0.0910, G_A_loss: 0.7150, G_B_loss: 0.7191\n",
      "Epoch [29/200], Step [931/1067], D_A_loss: 0.0305, D_B_loss: 0.0500, G_A_loss: 0.6590, G_B_loss: 0.7931\n",
      "Epoch [29/200], Step [941/1067], D_A_loss: 0.0447, D_B_loss: 0.0335, G_A_loss: 0.7266, G_B_loss: 1.0779\n",
      "Epoch [29/200], Step [951/1067], D_A_loss: 0.0770, D_B_loss: 0.0314, G_A_loss: 1.1566, G_B_loss: 0.5263\n",
      "Epoch [29/200], Step [961/1067], D_A_loss: 0.1345, D_B_loss: 0.1209, G_A_loss: 0.7085, G_B_loss: 0.2286\n",
      "Epoch [29/200], Step [971/1067], D_A_loss: 0.0383, D_B_loss: 0.1131, G_A_loss: 1.4410, G_B_loss: 0.3156\n",
      "Epoch [29/200], Step [981/1067], D_A_loss: 0.1647, D_B_loss: 0.2210, G_A_loss: 0.2865, G_B_loss: 0.2961\n",
      "Epoch [29/200], Step [991/1067], D_A_loss: 0.0562, D_B_loss: 0.3971, G_A_loss: 0.0476, G_B_loss: 0.5251\n",
      "Epoch [29/200], Step [1001/1067], D_A_loss: 0.0406, D_B_loss: 0.0259, G_A_loss: 0.6467, G_B_loss: 0.6417\n",
      "Epoch [29/200], Step [1011/1067], D_A_loss: 0.2051, D_B_loss: 0.0887, G_A_loss: 0.6425, G_B_loss: 0.1694\n",
      "Epoch [29/200], Step [1021/1067], D_A_loss: 0.1272, D_B_loss: 0.0200, G_A_loss: 0.3368, G_B_loss: 0.3471\n",
      "Epoch [29/200], Step [1031/1067], D_A_loss: 0.0646, D_B_loss: 0.0350, G_A_loss: 0.6145, G_B_loss: 0.5462\n",
      "Epoch [29/200], Step [1041/1067], D_A_loss: 0.1352, D_B_loss: 0.0785, G_A_loss: 0.7514, G_B_loss: 0.4406\n",
      "Epoch [29/200], Step [1051/1067], D_A_loss: 0.0773, D_B_loss: 0.0602, G_A_loss: 0.6876, G_B_loss: 0.5251\n",
      "Epoch [29/200], Step [1061/1067], D_A_loss: 0.0237, D_B_loss: 0.0390, G_A_loss: 0.6259, G_B_loss: 1.1454\n",
      "Epoch [30/200], Step [1/1067], D_A_loss: 0.1270, D_B_loss: 0.1213, G_A_loss: 0.6446, G_B_loss: 0.8430\n",
      "Epoch [30/200], Step [11/1067], D_A_loss: 0.2268, D_B_loss: 0.0759, G_A_loss: 0.4640, G_B_loss: 0.3856\n",
      "Epoch [30/200], Step [21/1067], D_A_loss: 0.0284, D_B_loss: 0.0352, G_A_loss: 0.3810, G_B_loss: 0.9905\n",
      "Epoch [30/200], Step [31/1067], D_A_loss: 0.0287, D_B_loss: 0.2366, G_A_loss: 0.9100, G_B_loss: 0.6945\n",
      "Epoch [30/200], Step [41/1067], D_A_loss: 0.1864, D_B_loss: 0.1582, G_A_loss: 0.4803, G_B_loss: 0.5196\n",
      "Epoch [30/200], Step [51/1067], D_A_loss: 0.1011, D_B_loss: 0.0771, G_A_loss: 0.7699, G_B_loss: 0.4599\n",
      "Epoch [30/200], Step [61/1067], D_A_loss: 0.0351, D_B_loss: 0.0690, G_A_loss: 0.4897, G_B_loss: 0.5212\n",
      "Epoch [30/200], Step [71/1067], D_A_loss: 0.0393, D_B_loss: 0.0449, G_A_loss: 0.5641, G_B_loss: 0.8592\n",
      "Epoch [30/200], Step [81/1067], D_A_loss: 0.0413, D_B_loss: 0.0559, G_A_loss: 0.5687, G_B_loss: 0.7947\n",
      "Epoch [30/200], Step [91/1067], D_A_loss: 0.0445, D_B_loss: 0.0589, G_A_loss: 0.7291, G_B_loss: 0.8368\n",
      "Epoch [30/200], Step [101/1067], D_A_loss: 0.0850, D_B_loss: 0.0139, G_A_loss: 0.5252, G_B_loss: 0.9164\n",
      "Epoch [30/200], Step [111/1067], D_A_loss: 0.0816, D_B_loss: 0.0494, G_A_loss: 0.7366, G_B_loss: 0.6391\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [30/200], Step [121/1067], D_A_loss: 0.0427, D_B_loss: 0.0516, G_A_loss: 0.5203, G_B_loss: 0.5492\n",
      "Epoch [30/200], Step [131/1067], D_A_loss: 0.1350, D_B_loss: 0.0185, G_A_loss: 0.8715, G_B_loss: 0.3208\n",
      "Epoch [30/200], Step [141/1067], D_A_loss: 0.0756, D_B_loss: 0.0771, G_A_loss: 0.2954, G_B_loss: 0.9608\n",
      "Epoch [30/200], Step [151/1067], D_A_loss: 0.0373, D_B_loss: 0.2521, G_A_loss: 1.1029, G_B_loss: 0.3435\n",
      "Epoch [30/200], Step [161/1067], D_A_loss: 0.0504, D_B_loss: 0.0255, G_A_loss: 0.6573, G_B_loss: 0.6817\n",
      "Epoch [30/200], Step [171/1067], D_A_loss: 0.0457, D_B_loss: 0.0386, G_A_loss: 0.4798, G_B_loss: 0.8595\n",
      "Epoch [30/200], Step [181/1067], D_A_loss: 0.1213, D_B_loss: 0.0125, G_A_loss: 0.5321, G_B_loss: 0.6500\n",
      "Epoch [30/200], Step [191/1067], D_A_loss: 0.0460, D_B_loss: 0.0744, G_A_loss: 0.7508, G_B_loss: 0.6307\n",
      "Epoch [30/200], Step [201/1067], D_A_loss: 0.0803, D_B_loss: 0.0809, G_A_loss: 0.5394, G_B_loss: 0.6069\n",
      "Epoch [30/200], Step [211/1067], D_A_loss: 0.0664, D_B_loss: 0.0393, G_A_loss: 0.7445, G_B_loss: 0.5541\n",
      "Epoch [30/200], Step [221/1067], D_A_loss: 0.0504, D_B_loss: 0.0514, G_A_loss: 0.7034, G_B_loss: 0.6997\n",
      "Epoch [30/200], Step [231/1067], D_A_loss: 0.0684, D_B_loss: 0.2085, G_A_loss: 0.8568, G_B_loss: 0.6807\n",
      "Epoch [30/200], Step [241/1067], D_A_loss: 0.1487, D_B_loss: 0.0351, G_A_loss: 0.3093, G_B_loss: 0.7569\n",
      "Epoch [30/200], Step [251/1067], D_A_loss: 0.0766, D_B_loss: 0.0391, G_A_loss: 0.2635, G_B_loss: 0.8207\n",
      "Epoch [30/200], Step [261/1067], D_A_loss: 0.0527, D_B_loss: 0.0659, G_A_loss: 0.6877, G_B_loss: 0.4794\n",
      "Epoch [30/200], Step [271/1067], D_A_loss: 0.0438, D_B_loss: 0.0183, G_A_loss: 1.0126, G_B_loss: 0.5605\n",
      "Epoch [30/200], Step [281/1067], D_A_loss: 0.0999, D_B_loss: 0.1025, G_A_loss: 1.0627, G_B_loss: 0.7321\n",
      "Epoch [30/200], Step [291/1067], D_A_loss: 0.1127, D_B_loss: 0.0299, G_A_loss: 1.0880, G_B_loss: 0.3575\n",
      "Epoch [30/200], Step [301/1067], D_A_loss: 0.0547, D_B_loss: 0.0130, G_A_loss: 0.4911, G_B_loss: 0.5918\n",
      "Epoch [30/200], Step [311/1067], D_A_loss: 0.0840, D_B_loss: 0.0423, G_A_loss: 1.0613, G_B_loss: 1.2971\n",
      "Epoch [30/200], Step [321/1067], D_A_loss: 0.1139, D_B_loss: 0.0866, G_A_loss: 0.6964, G_B_loss: 0.1897\n",
      "Epoch [30/200], Step [331/1067], D_A_loss: 0.0610, D_B_loss: 0.0323, G_A_loss: 1.0001, G_B_loss: 0.6595\n",
      "Epoch [30/200], Step [341/1067], D_A_loss: 0.1862, D_B_loss: 0.0831, G_A_loss: 0.4730, G_B_loss: 0.2349\n",
      "Epoch [30/200], Step [351/1067], D_A_loss: 0.0318, D_B_loss: 0.0415, G_A_loss: 1.0317, G_B_loss: 0.7629\n",
      "Epoch [30/200], Step [361/1067], D_A_loss: 0.1562, D_B_loss: 0.0161, G_A_loss: 0.5288, G_B_loss: 0.6124\n",
      "Epoch [30/200], Step [371/1067], D_A_loss: 0.0489, D_B_loss: 0.0681, G_A_loss: 0.7136, G_B_loss: 0.6434\n",
      "Epoch [30/200], Step [381/1067], D_A_loss: 0.2703, D_B_loss: 0.0170, G_A_loss: 0.9399, G_B_loss: 0.7174\n",
      "Epoch [30/200], Step [391/1067], D_A_loss: 0.1965, D_B_loss: 0.1573, G_A_loss: 0.7373, G_B_loss: 0.8980\n",
      "Epoch [30/200], Step [401/1067], D_A_loss: 0.0942, D_B_loss: 0.0215, G_A_loss: 0.7159, G_B_loss: 0.9572\n",
      "Epoch [30/200], Step [411/1067], D_A_loss: 0.1554, D_B_loss: 0.0438, G_A_loss: 0.4002, G_B_loss: 0.8336\n",
      "Epoch [30/200], Step [421/1067], D_A_loss: 0.0866, D_B_loss: 0.0593, G_A_loss: 0.9793, G_B_loss: 0.4546\n",
      "Epoch [30/200], Step [431/1067], D_A_loss: 0.1337, D_B_loss: 0.0235, G_A_loss: 0.5603, G_B_loss: 0.5083\n",
      "Epoch [30/200], Step [441/1067], D_A_loss: 0.0960, D_B_loss: 0.0760, G_A_loss: 0.4770, G_B_loss: 0.4254\n",
      "Epoch [30/200], Step [451/1067], D_A_loss: 0.1181, D_B_loss: 0.0862, G_A_loss: 0.6454, G_B_loss: 0.2937\n",
      "Epoch [30/200], Step [461/1067], D_A_loss: 0.0224, D_B_loss: 0.0909, G_A_loss: 0.8710, G_B_loss: 0.3324\n",
      "Epoch [30/200], Step [471/1067], D_A_loss: 0.0183, D_B_loss: 0.0243, G_A_loss: 1.1375, G_B_loss: 0.7631\n",
      "Epoch [30/200], Step [481/1067], D_A_loss: 0.2014, D_B_loss: 0.0436, G_A_loss: 0.6164, G_B_loss: 0.2054\n",
      "Epoch [30/200], Step [491/1067], D_A_loss: 0.0419, D_B_loss: 0.1002, G_A_loss: 0.4400, G_B_loss: 0.4813\n",
      "Epoch [30/200], Step [501/1067], D_A_loss: 0.0400, D_B_loss: 0.1196, G_A_loss: 1.2531, G_B_loss: 0.2930\n",
      "Epoch [30/200], Step [511/1067], D_A_loss: 0.0632, D_B_loss: 0.0150, G_A_loss: 0.7406, G_B_loss: 0.7946\n",
      "Epoch [30/200], Step [521/1067], D_A_loss: 0.0325, D_B_loss: 0.0261, G_A_loss: 0.7388, G_B_loss: 0.5790\n",
      "Epoch [30/200], Step [531/1067], D_A_loss: 0.0284, D_B_loss: 0.1032, G_A_loss: 1.0465, G_B_loss: 0.5874\n",
      "Epoch [30/200], Step [541/1067], D_A_loss: 0.0562, D_B_loss: 0.0263, G_A_loss: 0.2284, G_B_loss: 0.5515\n",
      "Epoch [30/200], Step [551/1067], D_A_loss: 0.2122, D_B_loss: 0.0796, G_A_loss: 0.5194, G_B_loss: 0.1585\n",
      "Epoch [30/200], Step [561/1067], D_A_loss: 0.0855, D_B_loss: 0.0916, G_A_loss: 0.7073, G_B_loss: 0.5619\n",
      "Epoch [30/200], Step [571/1067], D_A_loss: 0.0381, D_B_loss: 0.0887, G_A_loss: 0.5526, G_B_loss: 0.8196\n",
      "Epoch [30/200], Step [581/1067], D_A_loss: 0.0593, D_B_loss: 0.0341, G_A_loss: 0.7370, G_B_loss: 0.9555\n",
      "Epoch [30/200], Step [591/1067], D_A_loss: 0.1132, D_B_loss: 0.0307, G_A_loss: 0.7558, G_B_loss: 0.7229\n",
      "Epoch [30/200], Step [601/1067], D_A_loss: 0.0489, D_B_loss: 0.0548, G_A_loss: 0.4886, G_B_loss: 0.6172\n",
      "Epoch [30/200], Step [611/1067], D_A_loss: 0.0394, D_B_loss: 0.0293, G_A_loss: 0.5530, G_B_loss: 0.4025\n",
      "Epoch [30/200], Step [621/1067], D_A_loss: 0.1486, D_B_loss: 0.0178, G_A_loss: 0.9104, G_B_loss: 0.9590\n",
      "Epoch [30/200], Step [631/1067], D_A_loss: 0.0325, D_B_loss: 0.0672, G_A_loss: 0.4802, G_B_loss: 0.6184\n",
      "Epoch [30/200], Step [641/1067], D_A_loss: 0.0321, D_B_loss: 0.0361, G_A_loss: 0.6914, G_B_loss: 0.5340\n",
      "Epoch [30/200], Step [651/1067], D_A_loss: 0.0805, D_B_loss: 0.0567, G_A_loss: 0.3523, G_B_loss: 0.5890\n",
      "Epoch [30/200], Step [661/1067], D_A_loss: 0.0906, D_B_loss: 0.1456, G_A_loss: 1.2547, G_B_loss: 0.7714\n",
      "Epoch [30/200], Step [671/1067], D_A_loss: 0.2076, D_B_loss: 0.0789, G_A_loss: 0.8999, G_B_loss: 0.2564\n",
      "Epoch [30/200], Step [681/1067], D_A_loss: 0.0181, D_B_loss: 0.0282, G_A_loss: 0.8276, G_B_loss: 0.9789\n",
      "Epoch [30/200], Step [691/1067], D_A_loss: 0.0331, D_B_loss: 0.0505, G_A_loss: 1.1012, G_B_loss: 0.6088\n",
      "Epoch [30/200], Step [701/1067], D_A_loss: 0.0444, D_B_loss: 0.0447, G_A_loss: 1.1751, G_B_loss: 0.5808\n",
      "Epoch [30/200], Step [711/1067], D_A_loss: 0.0918, D_B_loss: 0.1180, G_A_loss: 0.3522, G_B_loss: 0.4594\n",
      "Epoch [30/200], Step [721/1067], D_A_loss: 0.0282, D_B_loss: 0.0843, G_A_loss: 0.5307, G_B_loss: 1.0904\n",
      "Epoch [30/200], Step [731/1067], D_A_loss: 0.0227, D_B_loss: 0.1966, G_A_loss: 0.1769, G_B_loss: 0.7604\n",
      "Epoch [30/200], Step [741/1067], D_A_loss: 0.0410, D_B_loss: 0.1771, G_A_loss: 0.2493, G_B_loss: 0.6723\n",
      "Epoch [30/200], Step [751/1067], D_A_loss: 0.0441, D_B_loss: 0.1266, G_A_loss: 0.7490, G_B_loss: 0.5398\n",
      "Epoch [30/200], Step [761/1067], D_A_loss: 0.0749, D_B_loss: 0.0510, G_A_loss: 0.5645, G_B_loss: 0.7335\n",
      "Epoch [30/200], Step [771/1067], D_A_loss: 0.0788, D_B_loss: 0.0472, G_A_loss: 0.7134, G_B_loss: 0.3372\n",
      "Epoch [30/200], Step [781/1067], D_A_loss: 0.1035, D_B_loss: 0.0252, G_A_loss: 0.9480, G_B_loss: 0.3854\n",
      "Epoch [30/200], Step [791/1067], D_A_loss: 0.0698, D_B_loss: 0.1068, G_A_loss: 0.8558, G_B_loss: 0.4163\n",
      "Epoch [30/200], Step [801/1067], D_A_loss: 0.1091, D_B_loss: 0.0445, G_A_loss: 1.0187, G_B_loss: 1.0952\n",
      "Epoch [30/200], Step [811/1067], D_A_loss: 0.0715, D_B_loss: 0.0630, G_A_loss: 1.0220, G_B_loss: 0.3565\n",
      "Epoch [30/200], Step [821/1067], D_A_loss: 0.0327, D_B_loss: 0.1315, G_A_loss: 0.4520, G_B_loss: 1.1530\n",
      "Epoch [30/200], Step [831/1067], D_A_loss: 0.2704, D_B_loss: 0.0767, G_A_loss: 0.5307, G_B_loss: 1.0056\n",
      "Epoch [30/200], Step [841/1067], D_A_loss: 0.1496, D_B_loss: 0.1462, G_A_loss: 0.2652, G_B_loss: 0.3101\n",
      "Epoch [30/200], Step [851/1067], D_A_loss: 0.1785, D_B_loss: 0.0244, G_A_loss: 0.7602, G_B_loss: 0.2574\n",
      "Epoch [30/200], Step [861/1067], D_A_loss: 0.0667, D_B_loss: 0.0538, G_A_loss: 0.9303, G_B_loss: 0.5347\n",
      "Epoch [30/200], Step [871/1067], D_A_loss: 0.0528, D_B_loss: 0.1691, G_A_loss: 0.3520, G_B_loss: 0.6569\n",
      "Epoch [30/200], Step [881/1067], D_A_loss: 0.0330, D_B_loss: 0.0213, G_A_loss: 0.8149, G_B_loss: 0.7305\n",
      "Epoch [30/200], Step [891/1067], D_A_loss: 0.0656, D_B_loss: 0.0831, G_A_loss: 0.5304, G_B_loss: 0.6069\n",
      "Epoch [30/200], Step [901/1067], D_A_loss: 0.2912, D_B_loss: 0.0193, G_A_loss: 0.7661, G_B_loss: 0.9884\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [30/200], Step [911/1067], D_A_loss: 0.0663, D_B_loss: 0.1532, G_A_loss: 0.3836, G_B_loss: 0.7749\n",
      "Epoch [30/200], Step [921/1067], D_A_loss: 0.0539, D_B_loss: 0.1364, G_A_loss: 0.7946, G_B_loss: 0.5248\n",
      "Epoch [30/200], Step [931/1067], D_A_loss: 0.1535, D_B_loss: 0.0671, G_A_loss: 0.5526, G_B_loss: 1.1693\n",
      "Epoch [30/200], Step [941/1067], D_A_loss: 0.3163, D_B_loss: 0.0710, G_A_loss: 0.4705, G_B_loss: 0.5416\n",
      "Epoch [30/200], Step [951/1067], D_A_loss: 0.0733, D_B_loss: 0.0262, G_A_loss: 0.5128, G_B_loss: 0.4990\n",
      "Epoch [30/200], Step [961/1067], D_A_loss: 0.1726, D_B_loss: 0.0976, G_A_loss: 1.0277, G_B_loss: 0.2195\n",
      "Epoch [30/200], Step [971/1067], D_A_loss: 0.1064, D_B_loss: 0.0443, G_A_loss: 0.4727, G_B_loss: 1.1859\n",
      "Epoch [30/200], Step [981/1067], D_A_loss: 0.0994, D_B_loss: 0.0320, G_A_loss: 0.6436, G_B_loss: 0.8882\n",
      "Epoch [30/200], Step [991/1067], D_A_loss: 0.1987, D_B_loss: 0.0735, G_A_loss: 0.5981, G_B_loss: 0.8623\n",
      "Epoch [30/200], Step [1001/1067], D_A_loss: 0.1266, D_B_loss: 0.0916, G_A_loss: 0.9628, G_B_loss: 0.3672\n",
      "Epoch [30/200], Step [1011/1067], D_A_loss: 0.0399, D_B_loss: 0.0225, G_A_loss: 0.7809, G_B_loss: 1.1433\n",
      "Epoch [30/200], Step [1021/1067], D_A_loss: 0.0273, D_B_loss: 0.0154, G_A_loss: 0.6586, G_B_loss: 0.7831\n",
      "Epoch [30/200], Step [1031/1067], D_A_loss: 0.0732, D_B_loss: 0.0409, G_A_loss: 0.9327, G_B_loss: 0.4387\n",
      "Epoch [30/200], Step [1041/1067], D_A_loss: 0.0250, D_B_loss: 0.0447, G_A_loss: 0.5688, G_B_loss: 0.7479\n",
      "Epoch [30/200], Step [1051/1067], D_A_loss: 0.0572, D_B_loss: 0.0215, G_A_loss: 0.5318, G_B_loss: 0.6813\n",
      "Epoch [30/200], Step [1061/1067], D_A_loss: 0.0834, D_B_loss: 0.0940, G_A_loss: 0.5536, G_B_loss: 0.5663\n",
      "Epoch [31/200], Step [1/1067], D_A_loss: 0.0593, D_B_loss: 0.0815, G_A_loss: 0.3426, G_B_loss: 0.3262\n",
      "Epoch [31/200], Step [11/1067], D_A_loss: 0.0586, D_B_loss: 0.0191, G_A_loss: 1.1320, G_B_loss: 0.4548\n",
      "Epoch [31/200], Step [21/1067], D_A_loss: 0.0267, D_B_loss: 0.0364, G_A_loss: 0.3999, G_B_loss: 0.6306\n",
      "Epoch [31/200], Step [31/1067], D_A_loss: 0.1168, D_B_loss: 0.0531, G_A_loss: 0.7298, G_B_loss: 0.5026\n",
      "Epoch [31/200], Step [41/1067], D_A_loss: 0.0885, D_B_loss: 0.0307, G_A_loss: 0.7113, G_B_loss: 1.1259\n",
      "Epoch [31/200], Step [51/1067], D_A_loss: 0.0253, D_B_loss: 0.0367, G_A_loss: 0.6764, G_B_loss: 0.5780\n",
      "Epoch [31/200], Step [61/1067], D_A_loss: 0.0373, D_B_loss: 0.0219, G_A_loss: 0.7043, G_B_loss: 0.3389\n",
      "Epoch [31/200], Step [71/1067], D_A_loss: 0.0433, D_B_loss: 0.1297, G_A_loss: 0.8748, G_B_loss: 0.6338\n",
      "Epoch [31/200], Step [81/1067], D_A_loss: 0.1031, D_B_loss: 0.0239, G_A_loss: 0.4730, G_B_loss: 0.6802\n",
      "Epoch [31/200], Step [91/1067], D_A_loss: 0.0745, D_B_loss: 0.0248, G_A_loss: 0.5351, G_B_loss: 0.4461\n",
      "Epoch [31/200], Step [101/1067], D_A_loss: 0.0415, D_B_loss: 0.0196, G_A_loss: 0.6531, G_B_loss: 0.7748\n",
      "Epoch [31/200], Step [111/1067], D_A_loss: 0.0631, D_B_loss: 0.0536, G_A_loss: 0.6889, G_B_loss: 0.5345\n",
      "Epoch [31/200], Step [121/1067], D_A_loss: 0.0584, D_B_loss: 0.0197, G_A_loss: 0.9109, G_B_loss: 0.5844\n",
      "Epoch [31/200], Step [131/1067], D_A_loss: 0.0489, D_B_loss: 0.0136, G_A_loss: 0.5059, G_B_loss: 0.9052\n",
      "Epoch [31/200], Step [141/1067], D_A_loss: 0.0754, D_B_loss: 0.0531, G_A_loss: 1.2028, G_B_loss: 1.1568\n",
      "Epoch [31/200], Step [151/1067], D_A_loss: 0.0926, D_B_loss: 0.0275, G_A_loss: 1.0296, G_B_loss: 0.7784\n",
      "Epoch [31/200], Step [161/1067], D_A_loss: 0.1148, D_B_loss: 0.0876, G_A_loss: 0.4791, G_B_loss: 0.3447\n",
      "Epoch [31/200], Step [171/1067], D_A_loss: 0.0536, D_B_loss: 0.0638, G_A_loss: 0.5041, G_B_loss: 0.7200\n",
      "Epoch [31/200], Step [181/1067], D_A_loss: 0.0345, D_B_loss: 0.0183, G_A_loss: 0.9771, G_B_loss: 0.5114\n",
      "Epoch [31/200], Step [191/1067], D_A_loss: 0.0516, D_B_loss: 0.0173, G_A_loss: 0.9769, G_B_loss: 0.6749\n",
      "Epoch [31/200], Step [201/1067], D_A_loss: 0.0276, D_B_loss: 0.0353, G_A_loss: 0.7680, G_B_loss: 0.4482\n",
      "Epoch [31/200], Step [211/1067], D_A_loss: 0.0191, D_B_loss: 0.0804, G_A_loss: 1.2255, G_B_loss: 1.0478\n",
      "Epoch [31/200], Step [221/1067], D_A_loss: 0.0593, D_B_loss: 0.0523, G_A_loss: 1.2976, G_B_loss: 0.6178\n",
      "Epoch [31/200], Step [231/1067], D_A_loss: 0.1771, D_B_loss: 0.1029, G_A_loss: 0.4930, G_B_loss: 0.9958\n",
      "Epoch [31/200], Step [241/1067], D_A_loss: 0.0964, D_B_loss: 0.0300, G_A_loss: 0.9165, G_B_loss: 0.5379\n",
      "Epoch [31/200], Step [251/1067], D_A_loss: 0.0578, D_B_loss: 0.0229, G_A_loss: 0.8605, G_B_loss: 0.6316\n",
      "Epoch [31/200], Step [261/1067], D_A_loss: 0.0640, D_B_loss: 0.0267, G_A_loss: 0.7503, G_B_loss: 0.8825\n",
      "Epoch [31/200], Step [271/1067], D_A_loss: 0.2000, D_B_loss: 0.0202, G_A_loss: 0.3683, G_B_loss: 0.1715\n",
      "Epoch [31/200], Step [281/1067], D_A_loss: 0.1044, D_B_loss: 0.0178, G_A_loss: 0.9542, G_B_loss: 0.4610\n",
      "Epoch [31/200], Step [291/1067], D_A_loss: 0.0716, D_B_loss: 0.0393, G_A_loss: 0.8236, G_B_loss: 0.7759\n",
      "Epoch [31/200], Step [301/1067], D_A_loss: 0.0342, D_B_loss: 0.0359, G_A_loss: 1.1170, G_B_loss: 0.8705\n",
      "Epoch [31/200], Step [311/1067], D_A_loss: 0.0665, D_B_loss: 0.1114, G_A_loss: 0.3653, G_B_loss: 0.5521\n",
      "Epoch [31/200], Step [321/1067], D_A_loss: 0.0228, D_B_loss: 0.0479, G_A_loss: 0.8793, G_B_loss: 0.9205\n",
      "Epoch [31/200], Step [331/1067], D_A_loss: 0.0474, D_B_loss: 0.0825, G_A_loss: 0.9443, G_B_loss: 0.9146\n",
      "Epoch [31/200], Step [341/1067], D_A_loss: 0.0672, D_B_loss: 0.0603, G_A_loss: 0.8940, G_B_loss: 0.4536\n",
      "Epoch [31/200], Step [351/1067], D_A_loss: 0.0321, D_B_loss: 0.3480, G_A_loss: 1.3074, G_B_loss: 0.6579\n",
      "Epoch [31/200], Step [361/1067], D_A_loss: 0.1696, D_B_loss: 0.0332, G_A_loss: 0.6522, G_B_loss: 0.2406\n",
      "Epoch [31/200], Step [371/1067], D_A_loss: 0.0337, D_B_loss: 0.0582, G_A_loss: 0.5303, G_B_loss: 0.8776\n",
      "Epoch [31/200], Step [381/1067], D_A_loss: 0.0526, D_B_loss: 0.0333, G_A_loss: 0.8958, G_B_loss: 0.6430\n",
      "Epoch [31/200], Step [391/1067], D_A_loss: 0.0541, D_B_loss: 0.1445, G_A_loss: 0.7357, G_B_loss: 0.4615\n",
      "Epoch [31/200], Step [401/1067], D_A_loss: 0.1667, D_B_loss: 0.0287, G_A_loss: 0.7035, G_B_loss: 0.2243\n",
      "Epoch [31/200], Step [411/1067], D_A_loss: 0.0521, D_B_loss: 0.0377, G_A_loss: 0.3080, G_B_loss: 0.7127\n",
      "Epoch [31/200], Step [421/1067], D_A_loss: 0.1388, D_B_loss: 0.0762, G_A_loss: 0.9197, G_B_loss: 0.7733\n",
      "Epoch [31/200], Step [431/1067], D_A_loss: 0.0428, D_B_loss: 0.0999, G_A_loss: 0.6703, G_B_loss: 0.7809\n",
      "Epoch [31/200], Step [441/1067], D_A_loss: 0.0753, D_B_loss: 0.0479, G_A_loss: 0.5820, G_B_loss: 0.4467\n",
      "Epoch [31/200], Step [451/1067], D_A_loss: 0.1620, D_B_loss: 0.0318, G_A_loss: 0.6961, G_B_loss: 0.8220\n",
      "Epoch [31/200], Step [461/1067], D_A_loss: 0.0314, D_B_loss: 0.0388, G_A_loss: 0.8559, G_B_loss: 0.7074\n",
      "Epoch [31/200], Step [471/1067], D_A_loss: 0.0861, D_B_loss: 0.0791, G_A_loss: 0.9034, G_B_loss: 0.2491\n",
      "Epoch [31/200], Step [481/1067], D_A_loss: 0.0777, D_B_loss: 0.0494, G_A_loss: 0.6740, G_B_loss: 0.8808\n",
      "Epoch [31/200], Step [491/1067], D_A_loss: 0.1115, D_B_loss: 0.0401, G_A_loss: 0.7059, G_B_loss: 0.6886\n",
      "Epoch [31/200], Step [501/1067], D_A_loss: 0.1391, D_B_loss: 0.0214, G_A_loss: 0.8147, G_B_loss: 0.7732\n",
      "Epoch [31/200], Step [511/1067], D_A_loss: 0.0529, D_B_loss: 0.0706, G_A_loss: 0.9495, G_B_loss: 0.8823\n",
      "Epoch [31/200], Step [521/1067], D_A_loss: 0.0311, D_B_loss: 0.0369, G_A_loss: 1.0507, G_B_loss: 0.9364\n",
      "Epoch [31/200], Step [531/1067], D_A_loss: 0.1081, D_B_loss: 0.0269, G_A_loss: 0.7193, G_B_loss: 0.8904\n",
      "Epoch [31/200], Step [541/1067], D_A_loss: 0.0652, D_B_loss: 0.0899, G_A_loss: 1.1401, G_B_loss: 0.4357\n",
      "Epoch [31/200], Step [551/1067], D_A_loss: 0.0374, D_B_loss: 0.0720, G_A_loss: 0.5769, G_B_loss: 0.8133\n",
      "Epoch [31/200], Step [561/1067], D_A_loss: 0.0501, D_B_loss: 0.0445, G_A_loss: 0.4886, G_B_loss: 0.5883\n",
      "Epoch [31/200], Step [571/1067], D_A_loss: 0.0399, D_B_loss: 0.0785, G_A_loss: 1.1072, G_B_loss: 0.3228\n",
      "Epoch [31/200], Step [581/1067], D_A_loss: 0.0669, D_B_loss: 0.0237, G_A_loss: 1.1081, G_B_loss: 0.3656\n",
      "Epoch [31/200], Step [591/1067], D_A_loss: 0.0540, D_B_loss: 0.0811, G_A_loss: 0.7008, G_B_loss: 0.3981\n",
      "Epoch [31/200], Step [601/1067], D_A_loss: 0.0361, D_B_loss: 0.0627, G_A_loss: 0.6208, G_B_loss: 0.3377\n",
      "Epoch [31/200], Step [611/1067], D_A_loss: 0.1053, D_B_loss: 0.0720, G_A_loss: 1.1209, G_B_loss: 0.4643\n",
      "Epoch [31/200], Step [621/1067], D_A_loss: 0.0672, D_B_loss: 0.0213, G_A_loss: 0.8680, G_B_loss: 0.5105\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [31/200], Step [631/1067], D_A_loss: 0.0671, D_B_loss: 0.0522, G_A_loss: 0.7772, G_B_loss: 0.8788\n",
      "Epoch [31/200], Step [641/1067], D_A_loss: 0.0970, D_B_loss: 0.0421, G_A_loss: 1.4291, G_B_loss: 0.4648\n",
      "Epoch [31/200], Step [651/1067], D_A_loss: 0.1006, D_B_loss: 0.1051, G_A_loss: 0.5245, G_B_loss: 0.5363\n",
      "Epoch [31/200], Step [661/1067], D_A_loss: 0.0881, D_B_loss: 0.0281, G_A_loss: 0.5533, G_B_loss: 0.4152\n",
      "Epoch [31/200], Step [671/1067], D_A_loss: 0.0997, D_B_loss: 0.1031, G_A_loss: 0.7666, G_B_loss: 0.5759\n",
      "Epoch [31/200], Step [681/1067], D_A_loss: 0.0478, D_B_loss: 0.0677, G_A_loss: 0.5489, G_B_loss: 0.6001\n",
      "Epoch [31/200], Step [691/1067], D_A_loss: 0.0637, D_B_loss: 0.1009, G_A_loss: 0.4423, G_B_loss: 0.4741\n",
      "Epoch [31/200], Step [701/1067], D_A_loss: 0.0874, D_B_loss: 0.0751, G_A_loss: 0.4578, G_B_loss: 0.4088\n",
      "Epoch [31/200], Step [711/1067], D_A_loss: 0.0316, D_B_loss: 0.0133, G_A_loss: 0.8810, G_B_loss: 0.7754\n",
      "Epoch [31/200], Step [721/1067], D_A_loss: 0.0464, D_B_loss: 0.1320, G_A_loss: 0.6675, G_B_loss: 0.3182\n",
      "Epoch [31/200], Step [731/1067], D_A_loss: 0.0869, D_B_loss: 0.0264, G_A_loss: 0.5168, G_B_loss: 0.4226\n",
      "Epoch [31/200], Step [741/1067], D_A_loss: 0.0324, D_B_loss: 0.0862, G_A_loss: 0.1327, G_B_loss: 0.5278\n",
      "Epoch [31/200], Step [751/1067], D_A_loss: 0.0235, D_B_loss: 0.0438, G_A_loss: 0.7345, G_B_loss: 0.6671\n",
      "Epoch [31/200], Step [761/1067], D_A_loss: 0.1768, D_B_loss: 0.0161, G_A_loss: 0.6886, G_B_loss: 0.5557\n",
      "Epoch [31/200], Step [771/1067], D_A_loss: 0.0377, D_B_loss: 0.0536, G_A_loss: 0.7328, G_B_loss: 0.6374\n",
      "Epoch [31/200], Step [781/1067], D_A_loss: 0.0188, D_B_loss: 0.0344, G_A_loss: 0.6405, G_B_loss: 0.4649\n",
      "Epoch [31/200], Step [791/1067], D_A_loss: 0.0576, D_B_loss: 0.0470, G_A_loss: 0.9221, G_B_loss: 0.6132\n",
      "Epoch [31/200], Step [801/1067], D_A_loss: 0.0609, D_B_loss: 0.0803, G_A_loss: 0.4157, G_B_loss: 0.5602\n",
      "Epoch [31/200], Step [811/1067], D_A_loss: 0.0591, D_B_loss: 0.0168, G_A_loss: 0.8267, G_B_loss: 0.6467\n",
      "Epoch [31/200], Step [821/1067], D_A_loss: 0.0658, D_B_loss: 0.0413, G_A_loss: 0.4261, G_B_loss: 0.7617\n",
      "Epoch [31/200], Step [831/1067], D_A_loss: 0.0514, D_B_loss: 0.0126, G_A_loss: 1.0307, G_B_loss: 0.6326\n",
      "Epoch [31/200], Step [841/1067], D_A_loss: 0.0557, D_B_loss: 0.0306, G_A_loss: 0.9728, G_B_loss: 0.7727\n",
      "Epoch [31/200], Step [851/1067], D_A_loss: 0.0947, D_B_loss: 0.0289, G_A_loss: 0.8771, G_B_loss: 0.4974\n",
      "Epoch [31/200], Step [861/1067], D_A_loss: 0.0968, D_B_loss: 0.0293, G_A_loss: 0.5227, G_B_loss: 0.3126\n",
      "Epoch [31/200], Step [871/1067], D_A_loss: 0.1737, D_B_loss: 0.0602, G_A_loss: 0.5988, G_B_loss: 0.5568\n",
      "Epoch [31/200], Step [881/1067], D_A_loss: 0.0298, D_B_loss: 0.1603, G_A_loss: 0.3387, G_B_loss: 1.0141\n",
      "Epoch [31/200], Step [891/1067], D_A_loss: 0.3159, D_B_loss: 0.0601, G_A_loss: 0.5158, G_B_loss: 0.6645\n",
      "Epoch [31/200], Step [901/1067], D_A_loss: 0.0293, D_B_loss: 0.0163, G_A_loss: 0.9119, G_B_loss: 0.6467\n",
      "Epoch [31/200], Step [911/1067], D_A_loss: 0.0834, D_B_loss: 0.0155, G_A_loss: 0.6574, G_B_loss: 0.4960\n",
      "Epoch [31/200], Step [921/1067], D_A_loss: 0.0474, D_B_loss: 0.3764, G_A_loss: 0.2686, G_B_loss: 0.7660\n",
      "Epoch [31/200], Step [931/1067], D_A_loss: 0.0239, D_B_loss: 0.0604, G_A_loss: 0.7502, G_B_loss: 0.4973\n",
      "Epoch [31/200], Step [941/1067], D_A_loss: 0.0389, D_B_loss: 0.0437, G_A_loss: 0.5504, G_B_loss: 0.2752\n",
      "Epoch [31/200], Step [951/1067], D_A_loss: 0.0235, D_B_loss: 0.1521, G_A_loss: 0.3052, G_B_loss: 0.7487\n",
      "Epoch [31/200], Step [961/1067], D_A_loss: 0.1352, D_B_loss: 0.0326, G_A_loss: 0.7950, G_B_loss: 0.3798\n",
      "Epoch [31/200], Step [971/1067], D_A_loss: 0.1614, D_B_loss: 0.0510, G_A_loss: 0.8421, G_B_loss: 0.5188\n",
      "Epoch [31/200], Step [981/1067], D_A_loss: 0.0387, D_B_loss: 0.0277, G_A_loss: 0.9870, G_B_loss: 0.7165\n",
      "Epoch [31/200], Step [991/1067], D_A_loss: 0.1074, D_B_loss: 0.0540, G_A_loss: 0.6320, G_B_loss: 0.4948\n",
      "Epoch [31/200], Step [1001/1067], D_A_loss: 0.0914, D_B_loss: 0.0466, G_A_loss: 0.5929, G_B_loss: 0.4927\n",
      "Epoch [31/200], Step [1011/1067], D_A_loss: 0.1071, D_B_loss: 0.1015, G_A_loss: 0.3718, G_B_loss: 0.3971\n",
      "Epoch [31/200], Step [1021/1067], D_A_loss: 0.0766, D_B_loss: 0.0776, G_A_loss: 0.8827, G_B_loss: 0.3278\n",
      "Epoch [31/200], Step [1031/1067], D_A_loss: 0.0786, D_B_loss: 0.0643, G_A_loss: 0.2267, G_B_loss: 0.3232\n",
      "Epoch [31/200], Step [1041/1067], D_A_loss: 0.0411, D_B_loss: 0.0470, G_A_loss: 1.1520, G_B_loss: 1.1192\n",
      "Epoch [31/200], Step [1051/1067], D_A_loss: 0.1856, D_B_loss: 0.1410, G_A_loss: 0.5418, G_B_loss: 0.7399\n",
      "Epoch [31/200], Step [1061/1067], D_A_loss: 0.1543, D_B_loss: 0.0868, G_A_loss: 1.1074, G_B_loss: 0.3125\n",
      "Epoch [32/200], Step [1/1067], D_A_loss: 0.0367, D_B_loss: 0.1552, G_A_loss: 0.6656, G_B_loss: 0.6379\n",
      "Epoch [32/200], Step [11/1067], D_A_loss: 0.0684, D_B_loss: 0.2759, G_A_loss: 0.8958, G_B_loss: 0.8325\n",
      "Epoch [32/200], Step [21/1067], D_A_loss: 0.0361, D_B_loss: 0.1381, G_A_loss: 0.5547, G_B_loss: 0.8047\n",
      "Epoch [32/200], Step [31/1067], D_A_loss: 0.0671, D_B_loss: 0.0584, G_A_loss: 0.7245, G_B_loss: 0.6547\n",
      "Epoch [32/200], Step [41/1067], D_A_loss: 0.1221, D_B_loss: 0.0460, G_A_loss: 0.9176, G_B_loss: 0.3559\n",
      "Epoch [32/200], Step [51/1067], D_A_loss: 0.0328, D_B_loss: 0.0544, G_A_loss: 0.9127, G_B_loss: 0.8051\n",
      "Epoch [32/200], Step [61/1067], D_A_loss: 0.1062, D_B_loss: 0.0429, G_A_loss: 0.8204, G_B_loss: 0.7374\n",
      "Epoch [32/200], Step [71/1067], D_A_loss: 0.0743, D_B_loss: 0.0230, G_A_loss: 0.7993, G_B_loss: 0.5791\n",
      "Epoch [32/200], Step [81/1067], D_A_loss: 0.1116, D_B_loss: 0.0648, G_A_loss: 0.4941, G_B_loss: 0.4599\n",
      "Epoch [32/200], Step [91/1067], D_A_loss: 0.0425, D_B_loss: 0.1233, G_A_loss: 0.3743, G_B_loss: 0.9266\n",
      "Epoch [32/200], Step [101/1067], D_A_loss: 0.1543, D_B_loss: 0.0269, G_A_loss: 0.7139, G_B_loss: 0.3599\n",
      "Epoch [32/200], Step [111/1067], D_A_loss: 0.0546, D_B_loss: 0.0314, G_A_loss: 0.8850, G_B_loss: 0.4929\n",
      "Epoch [32/200], Step [121/1067], D_A_loss: 0.2740, D_B_loss: 0.2579, G_A_loss: 0.2913, G_B_loss: 0.8109\n",
      "Epoch [32/200], Step [131/1067], D_A_loss: 0.0596, D_B_loss: 0.0433, G_A_loss: 0.9474, G_B_loss: 0.5481\n",
      "Epoch [32/200], Step [141/1067], D_A_loss: 0.0351, D_B_loss: 0.0178, G_A_loss: 0.5004, G_B_loss: 0.9842\n",
      "Epoch [32/200], Step [151/1067], D_A_loss: 0.1316, D_B_loss: 0.0172, G_A_loss: 0.5697, G_B_loss: 0.5779\n",
      "Epoch [32/200], Step [161/1067], D_A_loss: 0.0299, D_B_loss: 0.0681, G_A_loss: 0.5822, G_B_loss: 0.6205\n",
      "Epoch [32/200], Step [171/1067], D_A_loss: 0.0935, D_B_loss: 0.0323, G_A_loss: 0.9764, G_B_loss: 0.4983\n",
      "Epoch [32/200], Step [181/1067], D_A_loss: 0.0673, D_B_loss: 0.0196, G_A_loss: 0.8103, G_B_loss: 0.4857\n",
      "Epoch [32/200], Step [191/1067], D_A_loss: 0.1220, D_B_loss: 0.0759, G_A_loss: 0.4771, G_B_loss: 0.3322\n",
      "Epoch [32/200], Step [201/1067], D_A_loss: 0.2534, D_B_loss: 0.0874, G_A_loss: 0.5215, G_B_loss: 0.7557\n",
      "Epoch [32/200], Step [211/1067], D_A_loss: 0.0618, D_B_loss: 0.1735, G_A_loss: 0.6956, G_B_loss: 0.5440\n",
      "Epoch [32/200], Step [221/1067], D_A_loss: 0.0273, D_B_loss: 0.0206, G_A_loss: 0.8493, G_B_loss: 0.9552\n",
      "Epoch [32/200], Step [231/1067], D_A_loss: 0.0682, D_B_loss: 0.0600, G_A_loss: 0.9420, G_B_loss: 0.5348\n",
      "Epoch [32/200], Step [241/1067], D_A_loss: 0.0813, D_B_loss: 0.0471, G_A_loss: 0.7019, G_B_loss: 0.6632\n",
      "Epoch [32/200], Step [251/1067], D_A_loss: 0.0269, D_B_loss: 0.0764, G_A_loss: 0.8266, G_B_loss: 0.8667\n",
      "Epoch [32/200], Step [261/1067], D_A_loss: 0.0673, D_B_loss: 0.0372, G_A_loss: 0.6734, G_B_loss: 1.2122\n",
      "Epoch [32/200], Step [271/1067], D_A_loss: 0.1030, D_B_loss: 0.0461, G_A_loss: 0.6622, G_B_loss: 0.4681\n",
      "Epoch [32/200], Step [281/1067], D_A_loss: 0.2980, D_B_loss: 0.0609, G_A_loss: 0.6908, G_B_loss: 0.7866\n",
      "Epoch [32/200], Step [291/1067], D_A_loss: 0.2975, D_B_loss: 0.0382, G_A_loss: 0.5868, G_B_loss: 0.6066\n",
      "Epoch [32/200], Step [301/1067], D_A_loss: 0.0821, D_B_loss: 0.0228, G_A_loss: 0.7557, G_B_loss: 1.3261\n",
      "Epoch [32/200], Step [311/1067], D_A_loss: 0.1880, D_B_loss: 0.0493, G_A_loss: 0.5767, G_B_loss: 0.8732\n",
      "Epoch [32/200], Step [321/1067], D_A_loss: 0.1784, D_B_loss: 0.0546, G_A_loss: 0.6927, G_B_loss: 0.5391\n",
      "Epoch [32/200], Step [331/1067], D_A_loss: 0.0486, D_B_loss: 0.0529, G_A_loss: 0.6088, G_B_loss: 0.6948\n",
      "Epoch [32/200], Step [341/1067], D_A_loss: 0.0396, D_B_loss: 0.0626, G_A_loss: 0.8224, G_B_loss: 0.5544\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [32/200], Step [351/1067], D_A_loss: 0.0834, D_B_loss: 0.0365, G_A_loss: 0.6872, G_B_loss: 0.4395\n",
      "Epoch [32/200], Step [361/1067], D_A_loss: 0.0840, D_B_loss: 0.0481, G_A_loss: 0.6771, G_B_loss: 0.6057\n",
      "Epoch [32/200], Step [371/1067], D_A_loss: 0.1518, D_B_loss: 0.0506, G_A_loss: 0.5855, G_B_loss: 0.5388\n",
      "Epoch [32/200], Step [381/1067], D_A_loss: 0.0421, D_B_loss: 0.0639, G_A_loss: 0.6948, G_B_loss: 0.3990\n",
      "Epoch [32/200], Step [391/1067], D_A_loss: 0.0670, D_B_loss: 0.0518, G_A_loss: 0.7829, G_B_loss: 0.5899\n",
      "Epoch [32/200], Step [401/1067], D_A_loss: 0.0324, D_B_loss: 0.2381, G_A_loss: 0.1931, G_B_loss: 0.3401\n",
      "Epoch [32/200], Step [411/1067], D_A_loss: 0.0795, D_B_loss: 0.0568, G_A_loss: 0.9071, G_B_loss: 0.4899\n",
      "Epoch [32/200], Step [421/1067], D_A_loss: 0.0420, D_B_loss: 0.0552, G_A_loss: 0.5502, G_B_loss: 0.3874\n",
      "Epoch [32/200], Step [431/1067], D_A_loss: 0.0631, D_B_loss: 0.0148, G_A_loss: 0.9296, G_B_loss: 0.8814\n",
      "Epoch [32/200], Step [441/1067], D_A_loss: 0.0308, D_B_loss: 0.0339, G_A_loss: 1.1196, G_B_loss: 0.8164\n",
      "Epoch [32/200], Step [451/1067], D_A_loss: 0.0481, D_B_loss: 0.0755, G_A_loss: 0.6068, G_B_loss: 0.7721\n",
      "Epoch [32/200], Step [461/1067], D_A_loss: 0.2443, D_B_loss: 0.1776, G_A_loss: 1.1926, G_B_loss: 0.4294\n",
      "Epoch [32/200], Step [471/1067], D_A_loss: 0.1389, D_B_loss: 0.0498, G_A_loss: 0.5394, G_B_loss: 0.5818\n",
      "Epoch [32/200], Step [481/1067], D_A_loss: 0.0561, D_B_loss: 0.1434, G_A_loss: 0.2794, G_B_loss: 0.5504\n",
      "Epoch [32/200], Step [491/1067], D_A_loss: 0.0624, D_B_loss: 0.0784, G_A_loss: 0.9823, G_B_loss: 0.4268\n",
      "Epoch [32/200], Step [501/1067], D_A_loss: 0.0541, D_B_loss: 0.0294, G_A_loss: 0.4795, G_B_loss: 0.8368\n",
      "Epoch [32/200], Step [511/1067], D_A_loss: 0.0392, D_B_loss: 0.0496, G_A_loss: 0.6273, G_B_loss: 0.6624\n",
      "Epoch [32/200], Step [521/1067], D_A_loss: 0.0389, D_B_loss: 0.0286, G_A_loss: 0.6221, G_B_loss: 0.4477\n",
      "Epoch [32/200], Step [531/1067], D_A_loss: 0.0369, D_B_loss: 0.0256, G_A_loss: 0.6178, G_B_loss: 0.5617\n",
      "Epoch [32/200], Step [541/1067], D_A_loss: 0.0403, D_B_loss: 0.0455, G_A_loss: 0.5831, G_B_loss: 0.8036\n",
      "Epoch [32/200], Step [551/1067], D_A_loss: 0.0796, D_B_loss: 0.0404, G_A_loss: 0.6980, G_B_loss: 0.7205\n",
      "Epoch [32/200], Step [561/1067], D_A_loss: 0.0791, D_B_loss: 0.0933, G_A_loss: 0.3865, G_B_loss: 0.2323\n",
      "Epoch [32/200], Step [571/1067], D_A_loss: 0.0480, D_B_loss: 0.0382, G_A_loss: 0.7655, G_B_loss: 0.4269\n",
      "Epoch [32/200], Step [581/1067], D_A_loss: 0.0590, D_B_loss: 0.0240, G_A_loss: 0.7911, G_B_loss: 0.6424\n",
      "Epoch [32/200], Step [591/1067], D_A_loss: 0.0433, D_B_loss: 0.0505, G_A_loss: 0.5416, G_B_loss: 1.0382\n",
      "Epoch [32/200], Step [601/1067], D_A_loss: 0.0492, D_B_loss: 0.0322, G_A_loss: 0.8442, G_B_loss: 0.8704\n",
      "Epoch [32/200], Step [611/1067], D_A_loss: 0.0532, D_B_loss: 0.0537, G_A_loss: 0.6416, G_B_loss: 0.6093\n",
      "Epoch [32/200], Step [621/1067], D_A_loss: 0.0625, D_B_loss: 0.1043, G_A_loss: 0.4418, G_B_loss: 0.5440\n",
      "Epoch [32/200], Step [631/1067], D_A_loss: 0.0395, D_B_loss: 0.0464, G_A_loss: 0.7153, G_B_loss: 0.7565\n",
      "Epoch [32/200], Step [641/1067], D_A_loss: 0.1840, D_B_loss: 0.0519, G_A_loss: 0.6832, G_B_loss: 0.3881\n",
      "Epoch [32/200], Step [651/1067], D_A_loss: 0.0603, D_B_loss: 0.0260, G_A_loss: 0.3591, G_B_loss: 0.4762\n",
      "Epoch [32/200], Step [661/1067], D_A_loss: 0.1752, D_B_loss: 0.1097, G_A_loss: 0.9692, G_B_loss: 1.0738\n",
      "Epoch [32/200], Step [671/1067], D_A_loss: 0.1088, D_B_loss: 0.0421, G_A_loss: 0.6621, G_B_loss: 0.4431\n",
      "Epoch [32/200], Step [681/1067], D_A_loss: 0.1882, D_B_loss: 0.0300, G_A_loss: 0.7685, G_B_loss: 0.9814\n",
      "Epoch [32/200], Step [691/1067], D_A_loss: 0.0338, D_B_loss: 0.2206, G_A_loss: 1.5881, G_B_loss: 0.7820\n",
      "Epoch [32/200], Step [701/1067], D_A_loss: 0.3581, D_B_loss: 0.0614, G_A_loss: 1.0693, G_B_loss: 0.8289\n",
      "Epoch [32/200], Step [711/1067], D_A_loss: 0.0838, D_B_loss: 0.0447, G_A_loss: 0.8655, G_B_loss: 0.5780\n",
      "Epoch [32/200], Step [721/1067], D_A_loss: 0.0778, D_B_loss: 0.0602, G_A_loss: 1.0215, G_B_loss: 0.5886\n",
      "Epoch [32/200], Step [731/1067], D_A_loss: 0.0135, D_B_loss: 0.0186, G_A_loss: 0.8928, G_B_loss: 0.6252\n",
      "Epoch [32/200], Step [741/1067], D_A_loss: 0.0902, D_B_loss: 0.0720, G_A_loss: 0.7673, G_B_loss: 0.5230\n",
      "Epoch [32/200], Step [751/1067], D_A_loss: 0.0451, D_B_loss: 0.0584, G_A_loss: 0.5108, G_B_loss: 0.6019\n",
      "Epoch [32/200], Step [761/1067], D_A_loss: 0.1197, D_B_loss: 0.0440, G_A_loss: 0.7237, G_B_loss: 0.5104\n",
      "Epoch [32/200], Step [771/1067], D_A_loss: 0.0481, D_B_loss: 0.0644, G_A_loss: 0.9080, G_B_loss: 0.8776\n",
      "Epoch [32/200], Step [781/1067], D_A_loss: 0.0239, D_B_loss: 0.0721, G_A_loss: 0.5650, G_B_loss: 0.3721\n",
      "Epoch [32/200], Step [791/1067], D_A_loss: 0.1863, D_B_loss: 0.0598, G_A_loss: 0.6415, G_B_loss: 0.7176\n",
      "Epoch [32/200], Step [801/1067], D_A_loss: 0.0349, D_B_loss: 0.0923, G_A_loss: 0.3991, G_B_loss: 0.7984\n",
      "Epoch [32/200], Step [811/1067], D_A_loss: 0.0963, D_B_loss: 0.0127, G_A_loss: 0.5710, G_B_loss: 0.4166\n",
      "Epoch [32/200], Step [821/1067], D_A_loss: 0.0992, D_B_loss: 0.0329, G_A_loss: 0.5165, G_B_loss: 0.4183\n",
      "Epoch [32/200], Step [831/1067], D_A_loss: 0.1714, D_B_loss: 0.0474, G_A_loss: 0.9274, G_B_loss: 0.2222\n",
      "Epoch [32/200], Step [841/1067], D_A_loss: 0.0756, D_B_loss: 0.0283, G_A_loss: 0.7313, G_B_loss: 0.6524\n",
      "Epoch [32/200], Step [851/1067], D_A_loss: 0.0470, D_B_loss: 0.1088, G_A_loss: 0.3444, G_B_loss: 0.5546\n",
      "Epoch [32/200], Step [861/1067], D_A_loss: 0.0369, D_B_loss: 0.0543, G_A_loss: 0.8374, G_B_loss: 1.1208\n",
      "Epoch [32/200], Step [871/1067], D_A_loss: 0.0707, D_B_loss: 0.0515, G_A_loss: 0.6361, G_B_loss: 0.5854\n",
      "Epoch [32/200], Step [881/1067], D_A_loss: 0.0460, D_B_loss: 0.0350, G_A_loss: 0.6190, G_B_loss: 0.7708\n",
      "Epoch [32/200], Step [891/1067], D_A_loss: 0.0583, D_B_loss: 0.0336, G_A_loss: 0.9446, G_B_loss: 0.4423\n",
      "Epoch [32/200], Step [901/1067], D_A_loss: 0.0373, D_B_loss: 0.0364, G_A_loss: 0.9967, G_B_loss: 0.6941\n",
      "Epoch [32/200], Step [911/1067], D_A_loss: 0.0355, D_B_loss: 0.0347, G_A_loss: 0.4514, G_B_loss: 0.6057\n",
      "Epoch [32/200], Step [921/1067], D_A_loss: 0.0235, D_B_loss: 0.0415, G_A_loss: 1.0303, G_B_loss: 0.4815\n",
      "Epoch [32/200], Step [931/1067], D_A_loss: 0.0295, D_B_loss: 0.0448, G_A_loss: 0.8794, G_B_loss: 0.9731\n",
      "Epoch [32/200], Step [941/1067], D_A_loss: 0.0395, D_B_loss: 0.0231, G_A_loss: 1.1215, G_B_loss: 1.4448\n",
      "Epoch [32/200], Step [951/1067], D_A_loss: 0.0594, D_B_loss: 0.0412, G_A_loss: 0.9131, G_B_loss: 0.7189\n",
      "Epoch [32/200], Step [961/1067], D_A_loss: 0.0351, D_B_loss: 0.0593, G_A_loss: 1.3553, G_B_loss: 0.4124\n",
      "Epoch [32/200], Step [971/1067], D_A_loss: 0.0157, D_B_loss: 0.0246, G_A_loss: 0.7020, G_B_loss: 0.7339\n",
      "Epoch [32/200], Step [981/1067], D_A_loss: 0.0541, D_B_loss: 0.1053, G_A_loss: 1.0263, G_B_loss: 0.8167\n",
      "Epoch [32/200], Step [991/1067], D_A_loss: 0.0300, D_B_loss: 0.0232, G_A_loss: 0.7663, G_B_loss: 0.3169\n",
      "Epoch [32/200], Step [1001/1067], D_A_loss: 0.0319, D_B_loss: 0.3033, G_A_loss: 0.9052, G_B_loss: 0.5278\n",
      "Epoch [32/200], Step [1011/1067], D_A_loss: 0.1127, D_B_loss: 0.0374, G_A_loss: 0.6757, G_B_loss: 0.3994\n",
      "Epoch [32/200], Step [1021/1067], D_A_loss: 0.0821, D_B_loss: 0.0987, G_A_loss: 0.3880, G_B_loss: 0.6883\n",
      "Epoch [32/200], Step [1031/1067], D_A_loss: 0.0273, D_B_loss: 0.0954, G_A_loss: 0.7141, G_B_loss: 0.8378\n",
      "Epoch [32/200], Step [1041/1067], D_A_loss: 0.1252, D_B_loss: 0.0156, G_A_loss: 1.1365, G_B_loss: 0.3421\n",
      "Epoch [32/200], Step [1051/1067], D_A_loss: 0.0841, D_B_loss: 0.0581, G_A_loss: 0.7423, G_B_loss: 0.9413\n",
      "Epoch [32/200], Step [1061/1067], D_A_loss: 0.4360, D_B_loss: 0.0200, G_A_loss: 0.8630, G_B_loss: 0.0632\n",
      "Epoch [33/200], Step [1/1067], D_A_loss: 0.1920, D_B_loss: 0.0241, G_A_loss: 0.2909, G_B_loss: 0.2270\n",
      "Epoch [33/200], Step [11/1067], D_A_loss: 0.0702, D_B_loss: 0.1394, G_A_loss: 0.9243, G_B_loss: 0.6838\n",
      "Epoch [33/200], Step [21/1067], D_A_loss: 0.1622, D_B_loss: 0.0215, G_A_loss: 0.4625, G_B_loss: 0.3877\n",
      "Epoch [33/200], Step [31/1067], D_A_loss: 0.0247, D_B_loss: 0.0523, G_A_loss: 1.2655, G_B_loss: 0.6449\n",
      "Epoch [33/200], Step [41/1067], D_A_loss: 0.1238, D_B_loss: 0.0233, G_A_loss: 0.7886, G_B_loss: 0.4651\n",
      "Epoch [33/200], Step [51/1067], D_A_loss: 0.0378, D_B_loss: 0.0455, G_A_loss: 0.7204, G_B_loss: 1.4238\n",
      "Epoch [33/200], Step [61/1067], D_A_loss: 0.1422, D_B_loss: 0.0886, G_A_loss: 0.4296, G_B_loss: 0.5455\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [33/200], Step [71/1067], D_A_loss: 0.2482, D_B_loss: 0.0888, G_A_loss: 0.4433, G_B_loss: 0.6875\n",
      "Epoch [33/200], Step [81/1067], D_A_loss: 0.0296, D_B_loss: 0.0324, G_A_loss: 0.7410, G_B_loss: 0.4143\n",
      "Epoch [33/200], Step [91/1067], D_A_loss: 0.0622, D_B_loss: 0.1315, G_A_loss: 0.7508, G_B_loss: 0.2179\n",
      "Epoch [33/200], Step [101/1067], D_A_loss: 0.1710, D_B_loss: 0.0864, G_A_loss: 0.5168, G_B_loss: 0.4917\n",
      "Epoch [33/200], Step [111/1067], D_A_loss: 0.0647, D_B_loss: 0.0397, G_A_loss: 0.4699, G_B_loss: 0.3777\n",
      "Epoch [33/200], Step [121/1067], D_A_loss: 0.0767, D_B_loss: 0.1082, G_A_loss: 0.3907, G_B_loss: 0.8532\n",
      "Epoch [33/200], Step [131/1067], D_A_loss: 0.1014, D_B_loss: 0.1178, G_A_loss: 0.3306, G_B_loss: 0.9053\n",
      "Epoch [33/200], Step [141/1067], D_A_loss: 0.0292, D_B_loss: 0.1627, G_A_loss: 0.3135, G_B_loss: 0.9208\n",
      "Epoch [33/200], Step [151/1067], D_A_loss: 0.1564, D_B_loss: 0.1919, G_A_loss: 0.1820, G_B_loss: 0.8042\n",
      "Epoch [33/200], Step [161/1067], D_A_loss: 0.0913, D_B_loss: 0.0160, G_A_loss: 0.8259, G_B_loss: 0.5478\n",
      "Epoch [33/200], Step [171/1067], D_A_loss: 0.0221, D_B_loss: 0.1635, G_A_loss: 0.2612, G_B_loss: 0.4986\n",
      "Epoch [33/200], Step [181/1067], D_A_loss: 0.1439, D_B_loss: 0.0790, G_A_loss: 0.6393, G_B_loss: 0.3957\n",
      "Epoch [33/200], Step [191/1067], D_A_loss: 0.0838, D_B_loss: 0.0838, G_A_loss: 0.9197, G_B_loss: 0.7816\n",
      "Epoch [33/200], Step [201/1067], D_A_loss: 0.0656, D_B_loss: 0.0175, G_A_loss: 0.9137, G_B_loss: 0.5385\n",
      "Epoch [33/200], Step [211/1067], D_A_loss: 0.0320, D_B_loss: 0.0592, G_A_loss: 1.4943, G_B_loss: 0.7711\n",
      "Epoch [33/200], Step [221/1067], D_A_loss: 0.1712, D_B_loss: 0.0421, G_A_loss: 0.7771, G_B_loss: 0.5116\n",
      "Epoch [33/200], Step [231/1067], D_A_loss: 0.0718, D_B_loss: 0.1800, G_A_loss: 0.6316, G_B_loss: 0.6572\n",
      "Epoch [33/200], Step [241/1067], D_A_loss: 0.0536, D_B_loss: 0.0507, G_A_loss: 0.8900, G_B_loss: 0.5945\n",
      "Epoch [33/200], Step [251/1067], D_A_loss: 0.0781, D_B_loss: 0.0512, G_A_loss: 0.8842, G_B_loss: 0.6859\n",
      "Epoch [33/200], Step [261/1067], D_A_loss: 0.0736, D_B_loss: 0.0771, G_A_loss: 0.9192, G_B_loss: 0.4937\n",
      "Epoch [33/200], Step [271/1067], D_A_loss: 0.2908, D_B_loss: 0.0477, G_A_loss: 0.7061, G_B_loss: 0.9703\n",
      "Epoch [33/200], Step [281/1067], D_A_loss: 0.1154, D_B_loss: 0.0251, G_A_loss: 0.7228, G_B_loss: 0.9529\n",
      "Epoch [33/200], Step [291/1067], D_A_loss: 0.0654, D_B_loss: 0.0185, G_A_loss: 0.9061, G_B_loss: 0.4993\n",
      "Epoch [33/200], Step [301/1067], D_A_loss: 0.0219, D_B_loss: 0.0631, G_A_loss: 1.0384, G_B_loss: 0.6199\n",
      "Epoch [33/200], Step [311/1067], D_A_loss: 0.1042, D_B_loss: 0.0274, G_A_loss: 1.0243, G_B_loss: 1.1483\n",
      "Epoch [33/200], Step [321/1067], D_A_loss: 0.0363, D_B_loss: 0.0768, G_A_loss: 0.3046, G_B_loss: 0.3758\n",
      "Epoch [33/200], Step [331/1067], D_A_loss: 0.0164, D_B_loss: 0.0305, G_A_loss: 0.8877, G_B_loss: 0.3593\n",
      "Epoch [33/200], Step [341/1067], D_A_loss: 0.0532, D_B_loss: 0.0267, G_A_loss: 0.6668, G_B_loss: 0.5476\n",
      "Epoch [33/200], Step [351/1067], D_A_loss: 0.1024, D_B_loss: 0.0192, G_A_loss: 0.8253, G_B_loss: 1.3760\n",
      "Epoch [33/200], Step [361/1067], D_A_loss: 0.0597, D_B_loss: 0.0235, G_A_loss: 1.1358, G_B_loss: 0.5486\n",
      "Epoch [33/200], Step [371/1067], D_A_loss: 0.0481, D_B_loss: 0.1021, G_A_loss: 0.4199, G_B_loss: 0.3634\n",
      "Epoch [33/200], Step [381/1067], D_A_loss: 0.0984, D_B_loss: 0.0985, G_A_loss: 1.1474, G_B_loss: 0.2003\n",
      "Epoch [33/200], Step [391/1067], D_A_loss: 0.0758, D_B_loss: 0.0240, G_A_loss: 0.2526, G_B_loss: 0.8869\n",
      "Epoch [33/200], Step [401/1067], D_A_loss: 0.0767, D_B_loss: 0.0348, G_A_loss: 0.6683, G_B_loss: 0.6720\n",
      "Epoch [33/200], Step [411/1067], D_A_loss: 0.0322, D_B_loss: 0.0467, G_A_loss: 0.7543, G_B_loss: 0.4129\n",
      "Epoch [33/200], Step [421/1067], D_A_loss: 0.0905, D_B_loss: 0.0590, G_A_loss: 0.5586, G_B_loss: 0.7239\n",
      "Epoch [33/200], Step [431/1067], D_A_loss: 0.0293, D_B_loss: 0.0372, G_A_loss: 0.9548, G_B_loss: 0.5995\n",
      "Epoch [33/200], Step [441/1067], D_A_loss: 0.0834, D_B_loss: 0.0557, G_A_loss: 0.8675, G_B_loss: 0.4234\n",
      "Epoch [33/200], Step [451/1067], D_A_loss: 0.0325, D_B_loss: 0.1532, G_A_loss: 1.2215, G_B_loss: 0.4586\n",
      "Epoch [33/200], Step [461/1067], D_A_loss: 0.1217, D_B_loss: 0.0790, G_A_loss: 0.6297, G_B_loss: 0.3812\n",
      "Epoch [33/200], Step [471/1067], D_A_loss: 0.0855, D_B_loss: 0.0999, G_A_loss: 1.0040, G_B_loss: 0.4862\n",
      "Epoch [33/200], Step [481/1067], D_A_loss: 0.0459, D_B_loss: 0.0405, G_A_loss: 0.9672, G_B_loss: 0.6245\n",
      "Epoch [33/200], Step [491/1067], D_A_loss: 0.0486, D_B_loss: 0.0367, G_A_loss: 0.8588, G_B_loss: 0.6304\n",
      "Epoch [33/200], Step [501/1067], D_A_loss: 0.0575, D_B_loss: 0.0683, G_A_loss: 0.5327, G_B_loss: 0.9268\n",
      "Epoch [33/200], Step [511/1067], D_A_loss: 0.0963, D_B_loss: 0.0316, G_A_loss: 1.1793, G_B_loss: 0.3947\n",
      "Epoch [33/200], Step [521/1067], D_A_loss: 0.0818, D_B_loss: 0.0161, G_A_loss: 0.2966, G_B_loss: 0.5571\n",
      "Epoch [33/200], Step [531/1067], D_A_loss: 0.0996, D_B_loss: 0.0400, G_A_loss: 0.7699, G_B_loss: 0.7752\n",
      "Epoch [33/200], Step [541/1067], D_A_loss: 0.0338, D_B_loss: 0.0217, G_A_loss: 0.8608, G_B_loss: 0.4220\n",
      "Epoch [33/200], Step [551/1067], D_A_loss: 0.0671, D_B_loss: 0.0134, G_A_loss: 0.4216, G_B_loss: 0.7525\n",
      "Epoch [33/200], Step [561/1067], D_A_loss: 0.1929, D_B_loss: 0.1193, G_A_loss: 0.2283, G_B_loss: 0.2712\n",
      "Epoch [33/200], Step [571/1067], D_A_loss: 0.0498, D_B_loss: 0.0545, G_A_loss: 0.5625, G_B_loss: 0.5130\n",
      "Epoch [33/200], Step [581/1067], D_A_loss: 0.0608, D_B_loss: 0.0427, G_A_loss: 0.6795, G_B_loss: 0.5638\n",
      "Epoch [33/200], Step [591/1067], D_A_loss: 0.0632, D_B_loss: 0.0111, G_A_loss: 0.4571, G_B_loss: 0.5930\n",
      "Epoch [33/200], Step [601/1067], D_A_loss: 0.0666, D_B_loss: 0.0305, G_A_loss: 0.7348, G_B_loss: 0.6552\n",
      "Epoch [33/200], Step [611/1067], D_A_loss: 0.0321, D_B_loss: 0.0378, G_A_loss: 0.7256, G_B_loss: 0.3595\n",
      "Epoch [33/200], Step [621/1067], D_A_loss: 0.0448, D_B_loss: 0.0515, G_A_loss: 0.6336, G_B_loss: 0.7388\n",
      "Epoch [33/200], Step [631/1067], D_A_loss: 0.0185, D_B_loss: 0.0971, G_A_loss: 0.9128, G_B_loss: 0.6269\n",
      "Epoch [33/200], Step [641/1067], D_A_loss: 0.1028, D_B_loss: 0.0251, G_A_loss: 0.9745, G_B_loss: 0.8251\n",
      "Epoch [33/200], Step [651/1067], D_A_loss: 0.0369, D_B_loss: 0.0313, G_A_loss: 0.9604, G_B_loss: 0.8062\n",
      "Epoch [33/200], Step [661/1067], D_A_loss: 0.0596, D_B_loss: 0.0524, G_A_loss: 0.7363, G_B_loss: 0.5078\n",
      "Epoch [33/200], Step [671/1067], D_A_loss: 0.0681, D_B_loss: 0.0538, G_A_loss: 0.4305, G_B_loss: 0.5463\n",
      "Epoch [33/200], Step [681/1067], D_A_loss: 0.0807, D_B_loss: 0.0621, G_A_loss: 0.5684, G_B_loss: 0.4476\n",
      "Epoch [33/200], Step [691/1067], D_A_loss: 0.0315, D_B_loss: 0.0743, G_A_loss: 1.0151, G_B_loss: 0.7169\n",
      "Epoch [33/200], Step [701/1067], D_A_loss: 0.1364, D_B_loss: 0.0500, G_A_loss: 0.4607, G_B_loss: 0.5973\n",
      "Epoch [33/200], Step [711/1067], D_A_loss: 0.0497, D_B_loss: 0.0534, G_A_loss: 0.1865, G_B_loss: 0.7163\n",
      "Epoch [33/200], Step [721/1067], D_A_loss: 0.1654, D_B_loss: 0.2538, G_A_loss: 0.7510, G_B_loss: 0.7575\n",
      "Epoch [33/200], Step [731/1067], D_A_loss: 0.0585, D_B_loss: 0.0903, G_A_loss: 0.5775, G_B_loss: 0.6034\n",
      "Epoch [33/200], Step [741/1067], D_A_loss: 0.0828, D_B_loss: 0.0234, G_A_loss: 0.6403, G_B_loss: 0.4579\n",
      "Epoch [33/200], Step [751/1067], D_A_loss: 0.1017, D_B_loss: 0.0448, G_A_loss: 0.9842, G_B_loss: 1.0956\n",
      "Epoch [33/200], Step [761/1067], D_A_loss: 0.1384, D_B_loss: 0.0862, G_A_loss: 0.4642, G_B_loss: 0.7547\n",
      "Epoch [33/200], Step [771/1067], D_A_loss: 0.0373, D_B_loss: 0.0497, G_A_loss: 0.8791, G_B_loss: 0.6442\n",
      "Epoch [33/200], Step [781/1067], D_A_loss: 0.1553, D_B_loss: 0.0786, G_A_loss: 0.8074, G_B_loss: 0.3337\n",
      "Epoch [33/200], Step [791/1067], D_A_loss: 0.0751, D_B_loss: 0.0274, G_A_loss: 0.4523, G_B_loss: 0.6588\n",
      "Epoch [33/200], Step [801/1067], D_A_loss: 0.0469, D_B_loss: 0.0490, G_A_loss: 0.6725, G_B_loss: 0.9790\n",
      "Epoch [33/200], Step [811/1067], D_A_loss: 0.0488, D_B_loss: 0.0961, G_A_loss: 0.6379, G_B_loss: 0.2054\n",
      "Epoch [33/200], Step [821/1067], D_A_loss: 0.1236, D_B_loss: 0.0330, G_A_loss: 1.2671, G_B_loss: 0.3458\n",
      "Epoch [33/200], Step [831/1067], D_A_loss: 0.0712, D_B_loss: 0.2649, G_A_loss: 0.2108, G_B_loss: 0.5442\n",
      "Epoch [33/200], Step [841/1067], D_A_loss: 0.1966, D_B_loss: 0.0447, G_A_loss: 0.8969, G_B_loss: 0.5635\n",
      "Epoch [33/200], Step [851/1067], D_A_loss: 0.0363, D_B_loss: 0.0467, G_A_loss: 0.8949, G_B_loss: 0.8935\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [33/200], Step [861/1067], D_A_loss: 0.0902, D_B_loss: 0.1592, G_A_loss: 0.4337, G_B_loss: 0.4250\n",
      "Epoch [33/200], Step [871/1067], D_A_loss: 0.1130, D_B_loss: 0.0169, G_A_loss: 0.9242, G_B_loss: 0.7023\n",
      "Epoch [33/200], Step [881/1067], D_A_loss: 0.1881, D_B_loss: 0.0448, G_A_loss: 0.6185, G_B_loss: 1.3142\n",
      "Epoch [33/200], Step [891/1067], D_A_loss: 0.0846, D_B_loss: 0.0200, G_A_loss: 0.7940, G_B_loss: 0.3177\n",
      "Epoch [33/200], Step [901/1067], D_A_loss: 0.0620, D_B_loss: 0.0254, G_A_loss: 0.4414, G_B_loss: 0.6223\n",
      "Epoch [33/200], Step [911/1067], D_A_loss: 0.0255, D_B_loss: 0.0198, G_A_loss: 1.1958, G_B_loss: 0.9193\n",
      "Epoch [33/200], Step [921/1067], D_A_loss: 0.0162, D_B_loss: 0.0426, G_A_loss: 0.6190, G_B_loss: 0.7097\n",
      "Epoch [33/200], Step [931/1067], D_A_loss: 0.0640, D_B_loss: 0.0937, G_A_loss: 1.2974, G_B_loss: 0.2971\n",
      "Epoch [33/200], Step [941/1067], D_A_loss: 0.0598, D_B_loss: 0.0271, G_A_loss: 0.5241, G_B_loss: 0.5574\n",
      "Epoch [33/200], Step [951/1067], D_A_loss: 0.0779, D_B_loss: 0.0271, G_A_loss: 0.7237, G_B_loss: 0.5085\n",
      "Epoch [33/200], Step [961/1067], D_A_loss: 0.0458, D_B_loss: 0.1000, G_A_loss: 0.8970, G_B_loss: 0.4672\n",
      "Epoch [33/200], Step [971/1067], D_A_loss: 0.0248, D_B_loss: 0.0326, G_A_loss: 0.9849, G_B_loss: 1.0791\n",
      "Epoch [33/200], Step [981/1067], D_A_loss: 0.0901, D_B_loss: 0.0269, G_A_loss: 0.6136, G_B_loss: 0.7560\n",
      "Epoch [33/200], Step [991/1067], D_A_loss: 0.0131, D_B_loss: 0.1675, G_A_loss: 1.0199, G_B_loss: 0.8349\n",
      "Epoch [33/200], Step [1001/1067], D_A_loss: 0.1227, D_B_loss: 0.0203, G_A_loss: 0.5814, G_B_loss: 0.4360\n",
      "Epoch [33/200], Step [1011/1067], D_A_loss: 0.0327, D_B_loss: 0.0892, G_A_loss: 0.6671, G_B_loss: 0.7848\n",
      "Epoch [33/200], Step [1021/1067], D_A_loss: 0.2462, D_B_loss: 0.0200, G_A_loss: 0.3714, G_B_loss: 0.3388\n",
      "Epoch [33/200], Step [1031/1067], D_A_loss: 0.0347, D_B_loss: 0.0502, G_A_loss: 0.9185, G_B_loss: 0.6650\n",
      "Epoch [33/200], Step [1041/1067], D_A_loss: 0.0448, D_B_loss: 0.0504, G_A_loss: 0.5878, G_B_loss: 0.9327\n",
      "Epoch [33/200], Step [1051/1067], D_A_loss: 0.0734, D_B_loss: 0.0451, G_A_loss: 1.1432, G_B_loss: 0.5936\n",
      "Epoch [33/200], Step [1061/1067], D_A_loss: 0.0467, D_B_loss: 0.0549, G_A_loss: 0.6999, G_B_loss: 0.5021\n",
      "Epoch [34/200], Step [1/1067], D_A_loss: 0.1453, D_B_loss: 0.0303, G_A_loss: 0.7592, G_B_loss: 0.3780\n",
      "Epoch [34/200], Step [11/1067], D_A_loss: 0.0646, D_B_loss: 0.0999, G_A_loss: 0.4170, G_B_loss: 0.7385\n",
      "Epoch [34/200], Step [21/1067], D_A_loss: 0.1464, D_B_loss: 0.0361, G_A_loss: 0.6773, G_B_loss: 0.2709\n",
      "Epoch [34/200], Step [31/1067], D_A_loss: 0.0248, D_B_loss: 0.0306, G_A_loss: 0.4825, G_B_loss: 0.4861\n",
      "Epoch [34/200], Step [41/1067], D_A_loss: 0.1181, D_B_loss: 0.0527, G_A_loss: 0.5167, G_B_loss: 0.9082\n",
      "Epoch [34/200], Step [51/1067], D_A_loss: 0.1114, D_B_loss: 0.0488, G_A_loss: 0.6683, G_B_loss: 0.7663\n",
      "Epoch [34/200], Step [61/1067], D_A_loss: 0.1131, D_B_loss: 0.0735, G_A_loss: 0.5485, G_B_loss: 0.2385\n",
      "Epoch [34/200], Step [71/1067], D_A_loss: 0.0901, D_B_loss: 0.0307, G_A_loss: 0.2322, G_B_loss: 0.4140\n",
      "Epoch [34/200], Step [81/1067], D_A_loss: 0.0404, D_B_loss: 0.0267, G_A_loss: 0.7622, G_B_loss: 0.5999\n",
      "Epoch [34/200], Step [91/1067], D_A_loss: 0.2051, D_B_loss: 0.0617, G_A_loss: 0.5092, G_B_loss: 0.7113\n",
      "Epoch [34/200], Step [101/1067], D_A_loss: 0.0594, D_B_loss: 0.1228, G_A_loss: 0.7450, G_B_loss: 0.4289\n",
      "Epoch [34/200], Step [111/1067], D_A_loss: 0.1325, D_B_loss: 0.0164, G_A_loss: 0.5141, G_B_loss: 0.2926\n",
      "Epoch [34/200], Step [121/1067], D_A_loss: 0.0650, D_B_loss: 0.0804, G_A_loss: 0.6036, G_B_loss: 0.4869\n",
      "Epoch [34/200], Step [131/1067], D_A_loss: 0.0604, D_B_loss: 0.0561, G_A_loss: 0.4320, G_B_loss: 0.5539\n",
      "Epoch [34/200], Step [141/1067], D_A_loss: 0.0991, D_B_loss: 0.0541, G_A_loss: 0.8410, G_B_loss: 0.7942\n",
      "Epoch [34/200], Step [151/1067], D_A_loss: 0.0361, D_B_loss: 0.0159, G_A_loss: 0.4674, G_B_loss: 0.5191\n",
      "Epoch [34/200], Step [161/1067], D_A_loss: 0.0550, D_B_loss: 0.0299, G_A_loss: 0.7121, G_B_loss: 0.9582\n",
      "Epoch [34/200], Step [171/1067], D_A_loss: 0.0382, D_B_loss: 0.0218, G_A_loss: 1.0016, G_B_loss: 0.6887\n",
      "Epoch [34/200], Step [181/1067], D_A_loss: 0.0319, D_B_loss: 0.0322, G_A_loss: 0.7889, G_B_loss: 0.6868\n",
      "Epoch [34/200], Step [191/1067], D_A_loss: 0.0359, D_B_loss: 0.0942, G_A_loss: 0.3838, G_B_loss: 0.7036\n",
      "Epoch [34/200], Step [201/1067], D_A_loss: 0.0562, D_B_loss: 0.0194, G_A_loss: 0.6572, G_B_loss: 0.4384\n",
      "Epoch [34/200], Step [211/1067], D_A_loss: 0.0185, D_B_loss: 0.0770, G_A_loss: 0.5161, G_B_loss: 0.5896\n",
      "Epoch [34/200], Step [221/1067], D_A_loss: 0.0696, D_B_loss: 0.0382, G_A_loss: 0.6353, G_B_loss: 0.7120\n",
      "Epoch [34/200], Step [231/1067], D_A_loss: 0.1522, D_B_loss: 0.1699, G_A_loss: 0.9308, G_B_loss: 0.7892\n",
      "Epoch [34/200], Step [241/1067], D_A_loss: 0.0309, D_B_loss: 0.1152, G_A_loss: 0.3410, G_B_loss: 0.9998\n",
      "Epoch [34/200], Step [251/1067], D_A_loss: 0.0544, D_B_loss: 0.0315, G_A_loss: 0.6992, G_B_loss: 0.2322\n",
      "Epoch [34/200], Step [261/1067], D_A_loss: 0.0490, D_B_loss: 0.0466, G_A_loss: 0.8446, G_B_loss: 0.3289\n",
      "Epoch [34/200], Step [271/1067], D_A_loss: 0.0407, D_B_loss: 0.0264, G_A_loss: 0.7345, G_B_loss: 0.5458\n",
      "Epoch [34/200], Step [281/1067], D_A_loss: 0.0349, D_B_loss: 0.0299, G_A_loss: 1.2560, G_B_loss: 0.4978\n",
      "Epoch [34/200], Step [291/1067], D_A_loss: 0.0505, D_B_loss: 0.0574, G_A_loss: 0.7969, G_B_loss: 0.4576\n",
      "Epoch [34/200], Step [301/1067], D_A_loss: 0.0935, D_B_loss: 0.0705, G_A_loss: 0.6499, G_B_loss: 0.6581\n",
      "Epoch [34/200], Step [311/1067], D_A_loss: 0.0197, D_B_loss: 0.0772, G_A_loss: 0.8495, G_B_loss: 0.9457\n",
      "Epoch [34/200], Step [321/1067], D_A_loss: 0.0330, D_B_loss: 0.0189, G_A_loss: 0.5035, G_B_loss: 0.4962\n",
      "Epoch [34/200], Step [331/1067], D_A_loss: 0.0221, D_B_loss: 0.0195, G_A_loss: 0.8429, G_B_loss: 0.8963\n",
      "Epoch [34/200], Step [341/1067], D_A_loss: 0.0615, D_B_loss: 0.0366, G_A_loss: 0.7653, G_B_loss: 0.5236\n",
      "Epoch [34/200], Step [351/1067], D_A_loss: 0.0587, D_B_loss: 0.0655, G_A_loss: 0.5643, G_B_loss: 0.5316\n",
      "Epoch [34/200], Step [361/1067], D_A_loss: 0.1945, D_B_loss: 0.0877, G_A_loss: 0.4851, G_B_loss: 0.3421\n",
      "Epoch [34/200], Step [371/1067], D_A_loss: 0.0671, D_B_loss: 0.1046, G_A_loss: 0.4792, G_B_loss: 0.8325\n",
      "Epoch [34/200], Step [381/1067], D_A_loss: 0.1294, D_B_loss: 0.0544, G_A_loss: 1.5097, G_B_loss: 0.5398\n",
      "Epoch [34/200], Step [391/1067], D_A_loss: 0.0947, D_B_loss: 0.1567, G_A_loss: 0.2364, G_B_loss: 0.4410\n",
      "Epoch [34/200], Step [401/1067], D_A_loss: 0.0285, D_B_loss: 0.0222, G_A_loss: 0.5542, G_B_loss: 0.6115\n",
      "Epoch [34/200], Step [411/1067], D_A_loss: 0.0519, D_B_loss: 0.0519, G_A_loss: 0.7350, G_B_loss: 0.5788\n",
      "Epoch [34/200], Step [421/1067], D_A_loss: 0.0957, D_B_loss: 0.0095, G_A_loss: 0.5487, G_B_loss: 0.4319\n",
      "Epoch [34/200], Step [431/1067], D_A_loss: 0.0752, D_B_loss: 0.0439, G_A_loss: 0.7339, G_B_loss: 0.4817\n",
      "Epoch [34/200], Step [441/1067], D_A_loss: 0.2477, D_B_loss: 0.0245, G_A_loss: 1.0802, G_B_loss: 0.3690\n",
      "Epoch [34/200], Step [451/1067], D_A_loss: 0.0634, D_B_loss: 0.0284, G_A_loss: 1.0344, G_B_loss: 0.4178\n",
      "Epoch [34/200], Step [461/1067], D_A_loss: 0.0309, D_B_loss: 0.0776, G_A_loss: 0.5144, G_B_loss: 0.4655\n",
      "Epoch [34/200], Step [471/1067], D_A_loss: 0.0781, D_B_loss: 0.1107, G_A_loss: 0.6284, G_B_loss: 0.4323\n",
      "Epoch [34/200], Step [481/1067], D_A_loss: 0.1176, D_B_loss: 0.1077, G_A_loss: 0.3361, G_B_loss: 0.1713\n",
      "Epoch [34/200], Step [491/1067], D_A_loss: 0.2146, D_B_loss: 0.1169, G_A_loss: 0.3231, G_B_loss: 1.1854\n",
      "Epoch [34/200], Step [501/1067], D_A_loss: 0.0689, D_B_loss: 0.0449, G_A_loss: 0.6459, G_B_loss: 0.6238\n",
      "Epoch [34/200], Step [511/1067], D_A_loss: 0.1017, D_B_loss: 0.0142, G_A_loss: 0.5525, G_B_loss: 0.4246\n",
      "Epoch [34/200], Step [521/1067], D_A_loss: 0.1214, D_B_loss: 0.1430, G_A_loss: 0.2818, G_B_loss: 0.6053\n",
      "Epoch [34/200], Step [531/1067], D_A_loss: 0.1437, D_B_loss: 0.0687, G_A_loss: 0.7466, G_B_loss: 0.5986\n",
      "Epoch [34/200], Step [541/1067], D_A_loss: 0.0418, D_B_loss: 0.0288, G_A_loss: 0.7906, G_B_loss: 0.8585\n",
      "Epoch [34/200], Step [551/1067], D_A_loss: 0.0853, D_B_loss: 0.0388, G_A_loss: 0.7420, G_B_loss: 0.4516\n",
      "Epoch [34/200], Step [561/1067], D_A_loss: 0.0503, D_B_loss: 0.0502, G_A_loss: 0.5928, G_B_loss: 0.6761\n",
      "Epoch [34/200], Step [571/1067], D_A_loss: 0.0719, D_B_loss: 0.0515, G_A_loss: 1.1757, G_B_loss: 0.6055\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [34/200], Step [581/1067], D_A_loss: 0.0555, D_B_loss: 0.0867, G_A_loss: 0.9835, G_B_loss: 1.0283\n",
      "Epoch [34/200], Step [591/1067], D_A_loss: 0.0733, D_B_loss: 0.0367, G_A_loss: 0.7946, G_B_loss: 0.4980\n",
      "Epoch [34/200], Step [601/1067], D_A_loss: 0.0285, D_B_loss: 0.0950, G_A_loss: 0.4168, G_B_loss: 0.5838\n",
      "Epoch [34/200], Step [611/1067], D_A_loss: 0.0291, D_B_loss: 0.0214, G_A_loss: 0.5123, G_B_loss: 0.7131\n",
      "Epoch [34/200], Step [621/1067], D_A_loss: 0.0750, D_B_loss: 0.0594, G_A_loss: 0.6309, G_B_loss: 0.4585\n",
      "Epoch [34/200], Step [631/1067], D_A_loss: 0.0249, D_B_loss: 0.0367, G_A_loss: 0.6853, G_B_loss: 0.8040\n",
      "Epoch [34/200], Step [641/1067], D_A_loss: 0.0666, D_B_loss: 0.0499, G_A_loss: 0.8813, G_B_loss: 0.5401\n",
      "Epoch [34/200], Step [651/1067], D_A_loss: 0.0494, D_B_loss: 0.0272, G_A_loss: 0.8253, G_B_loss: 0.5871\n",
      "Epoch [34/200], Step [661/1067], D_A_loss: 0.0325, D_B_loss: 0.0246, G_A_loss: 0.8752, G_B_loss: 0.8085\n",
      "Epoch [34/200], Step [671/1067], D_A_loss: 0.0382, D_B_loss: 0.2207, G_A_loss: 0.5126, G_B_loss: 0.6748\n",
      "Epoch [34/200], Step [681/1067], D_A_loss: 0.0396, D_B_loss: 0.1050, G_A_loss: 0.7499, G_B_loss: 0.6193\n",
      "Epoch [34/200], Step [691/1067], D_A_loss: 0.0388, D_B_loss: 0.1205, G_A_loss: 0.8763, G_B_loss: 0.6654\n",
      "Epoch [34/200], Step [701/1067], D_A_loss: 0.0334, D_B_loss: 0.0658, G_A_loss: 0.5909, G_B_loss: 0.8600\n",
      "Epoch [34/200], Step [711/1067], D_A_loss: 0.0588, D_B_loss: 0.0304, G_A_loss: 1.1509, G_B_loss: 0.6803\n",
      "Epoch [34/200], Step [721/1067], D_A_loss: 0.1423, D_B_loss: 0.0975, G_A_loss: 0.4750, G_B_loss: 0.5479\n",
      "Epoch [34/200], Step [731/1067], D_A_loss: 0.0350, D_B_loss: 0.0345, G_A_loss: 0.9461, G_B_loss: 0.7114\n",
      "Epoch [34/200], Step [741/1067], D_A_loss: 0.0652, D_B_loss: 0.0699, G_A_loss: 0.9855, G_B_loss: 0.7130\n",
      "Epoch [34/200], Step [751/1067], D_A_loss: 0.0601, D_B_loss: 0.0364, G_A_loss: 0.6349, G_B_loss: 0.5697\n",
      "Epoch [34/200], Step [761/1067], D_A_loss: 0.0669, D_B_loss: 0.0370, G_A_loss: 0.8008, G_B_loss: 0.4038\n",
      "Epoch [34/200], Step [771/1067], D_A_loss: 0.0401, D_B_loss: 0.0335, G_A_loss: 0.7150, G_B_loss: 0.6121\n",
      "Epoch [34/200], Step [781/1067], D_A_loss: 0.0624, D_B_loss: 0.0593, G_A_loss: 0.4183, G_B_loss: 0.3156\n",
      "Epoch [34/200], Step [791/1067], D_A_loss: 0.0272, D_B_loss: 0.0515, G_A_loss: 0.8312, G_B_loss: 0.8268\n",
      "Epoch [34/200], Step [801/1067], D_A_loss: 0.1238, D_B_loss: 0.0674, G_A_loss: 0.4711, G_B_loss: 0.7419\n",
      "Epoch [34/200], Step [811/1067], D_A_loss: 0.0664, D_B_loss: 0.0144, G_A_loss: 0.7205, G_B_loss: 0.5942\n",
      "Epoch [34/200], Step [821/1067], D_A_loss: 0.0291, D_B_loss: 0.0487, G_A_loss: 0.6001, G_B_loss: 0.6667\n",
      "Epoch [34/200], Step [831/1067], D_A_loss: 0.1109, D_B_loss: 0.2702, G_A_loss: 0.2703, G_B_loss: 0.5913\n",
      "Epoch [34/200], Step [841/1067], D_A_loss: 0.1362, D_B_loss: 0.0185, G_A_loss: 0.5608, G_B_loss: 0.4253\n",
      "Epoch [34/200], Step [851/1067], D_A_loss: 0.2428, D_B_loss: 0.1805, G_A_loss: 0.2005, G_B_loss: 0.4542\n",
      "Epoch [34/200], Step [861/1067], D_A_loss: 0.1153, D_B_loss: 0.0336, G_A_loss: 1.0192, G_B_loss: 1.1909\n",
      "Epoch [34/200], Step [871/1067], D_A_loss: 0.0245, D_B_loss: 0.0206, G_A_loss: 0.9088, G_B_loss: 0.7580\n",
      "Epoch [34/200], Step [881/1067], D_A_loss: 0.0618, D_B_loss: 0.1730, G_A_loss: 0.2159, G_B_loss: 0.6514\n",
      "Epoch [34/200], Step [891/1067], D_A_loss: 0.2550, D_B_loss: 0.0589, G_A_loss: 0.8526, G_B_loss: 0.8320\n",
      "Epoch [34/200], Step [901/1067], D_A_loss: 0.0318, D_B_loss: 0.0842, G_A_loss: 1.2458, G_B_loss: 0.4881\n",
      "Epoch [34/200], Step [911/1067], D_A_loss: 0.0340, D_B_loss: 0.0404, G_A_loss: 0.6696, G_B_loss: 0.7447\n",
      "Epoch [34/200], Step [921/1067], D_A_loss: 0.0292, D_B_loss: 0.0528, G_A_loss: 0.2916, G_B_loss: 0.4176\n",
      "Epoch [34/200], Step [931/1067], D_A_loss: 0.1335, D_B_loss: 0.0211, G_A_loss: 0.5666, G_B_loss: 0.7141\n",
      "Epoch [34/200], Step [941/1067], D_A_loss: 0.1151, D_B_loss: 0.0589, G_A_loss: 0.5801, G_B_loss: 0.4872\n",
      "Epoch [34/200], Step [951/1067], D_A_loss: 0.0167, D_B_loss: 0.0612, G_A_loss: 0.7146, G_B_loss: 0.5585\n",
      "Epoch [34/200], Step [961/1067], D_A_loss: 0.0803, D_B_loss: 0.0568, G_A_loss: 0.5578, G_B_loss: 0.8052\n",
      "Epoch [34/200], Step [971/1067], D_A_loss: 0.0822, D_B_loss: 0.0651, G_A_loss: 0.4736, G_B_loss: 0.9428\n",
      "Epoch [34/200], Step [981/1067], D_A_loss: 0.1942, D_B_loss: 0.0306, G_A_loss: 1.0495, G_B_loss: 0.4916\n",
      "Epoch [34/200], Step [991/1067], D_A_loss: 0.0453, D_B_loss: 0.0279, G_A_loss: 0.8314, G_B_loss: 0.5299\n",
      "Epoch [34/200], Step [1001/1067], D_A_loss: 0.1290, D_B_loss: 0.1133, G_A_loss: 0.8370, G_B_loss: 0.3710\n",
      "Epoch [34/200], Step [1011/1067], D_A_loss: 0.0818, D_B_loss: 0.3080, G_A_loss: 0.8284, G_B_loss: 0.6761\n",
      "Epoch [34/200], Step [1021/1067], D_A_loss: 0.0226, D_B_loss: 0.0480, G_A_loss: 0.6126, G_B_loss: 0.7814\n",
      "Epoch [34/200], Step [1031/1067], D_A_loss: 0.1081, D_B_loss: 0.1009, G_A_loss: 0.3724, G_B_loss: 0.8310\n",
      "Epoch [34/200], Step [1041/1067], D_A_loss: 0.2511, D_B_loss: 0.0422, G_A_loss: 0.7473, G_B_loss: 1.0678\n",
      "Epoch [34/200], Step [1051/1067], D_A_loss: 0.0247, D_B_loss: 0.0145, G_A_loss: 0.8985, G_B_loss: 0.7126\n",
      "Epoch [34/200], Step [1061/1067], D_A_loss: 0.1631, D_B_loss: 0.0905, G_A_loss: 0.4539, G_B_loss: 0.2926\n",
      "Epoch [35/200], Step [1/1067], D_A_loss: 0.0285, D_B_loss: 0.2036, G_A_loss: 0.3481, G_B_loss: 0.8095\n",
      "Epoch [35/200], Step [11/1067], D_A_loss: 0.0311, D_B_loss: 0.0449, G_A_loss: 0.7351, G_B_loss: 0.8283\n",
      "Epoch [35/200], Step [21/1067], D_A_loss: 0.0946, D_B_loss: 0.0241, G_A_loss: 0.8626, G_B_loss: 0.7048\n",
      "Epoch [35/200], Step [31/1067], D_A_loss: 0.0874, D_B_loss: 0.0253, G_A_loss: 0.6450, G_B_loss: 0.4782\n",
      "Epoch [35/200], Step [41/1067], D_A_loss: 0.0308, D_B_loss: 0.0579, G_A_loss: 0.7622, G_B_loss: 0.7253\n",
      "Epoch [35/200], Step [51/1067], D_A_loss: 0.0362, D_B_loss: 0.0307, G_A_loss: 0.6676, G_B_loss: 0.8092\n",
      "Epoch [35/200], Step [61/1067], D_A_loss: 0.0654, D_B_loss: 0.0198, G_A_loss: 0.7611, G_B_loss: 0.5109\n",
      "Epoch [35/200], Step [71/1067], D_A_loss: 0.1785, D_B_loss: 0.0352, G_A_loss: 1.2771, G_B_loss: 0.3175\n",
      "Epoch [35/200], Step [81/1067], D_A_loss: 0.0655, D_B_loss: 0.0298, G_A_loss: 0.3816, G_B_loss: 0.7438\n",
      "Epoch [35/200], Step [91/1067], D_A_loss: 0.1156, D_B_loss: 0.1379, G_A_loss: 0.3173, G_B_loss: 0.3546\n",
      "Epoch [35/200], Step [101/1067], D_A_loss: 0.0571, D_B_loss: 0.0528, G_A_loss: 0.7503, G_B_loss: 0.5905\n",
      "Epoch [35/200], Step [111/1067], D_A_loss: 0.0255, D_B_loss: 0.2302, G_A_loss: 0.1654, G_B_loss: 0.4848\n",
      "Epoch [35/200], Step [121/1067], D_A_loss: 0.1835, D_B_loss: 0.0580, G_A_loss: 0.5920, G_B_loss: 0.9635\n",
      "Epoch [35/200], Step [131/1067], D_A_loss: 0.0581, D_B_loss: 0.0603, G_A_loss: 0.5990, G_B_loss: 0.5612\n",
      "Epoch [35/200], Step [141/1067], D_A_loss: 0.0369, D_B_loss: 0.0952, G_A_loss: 0.6933, G_B_loss: 0.5948\n",
      "Epoch [35/200], Step [151/1067], D_A_loss: 0.1088, D_B_loss: 0.0986, G_A_loss: 1.5667, G_B_loss: 0.6467\n",
      "Epoch [35/200], Step [161/1067], D_A_loss: 0.2201, D_B_loss: 0.0735, G_A_loss: 0.3466, G_B_loss: 0.1840\n",
      "Epoch [35/200], Step [171/1067], D_A_loss: 0.0361, D_B_loss: 0.0162, G_A_loss: 0.5651, G_B_loss: 0.5063\n",
      "Epoch [35/200], Step [181/1067], D_A_loss: 0.0848, D_B_loss: 0.0278, G_A_loss: 1.0202, G_B_loss: 0.4952\n",
      "Epoch [35/200], Step [191/1067], D_A_loss: 0.0791, D_B_loss: 0.0374, G_A_loss: 0.8292, G_B_loss: 0.4853\n",
      "Epoch [35/200], Step [201/1067], D_A_loss: 0.1031, D_B_loss: 0.0238, G_A_loss: 0.6914, G_B_loss: 1.5979\n",
      "Epoch [35/200], Step [211/1067], D_A_loss: 0.0568, D_B_loss: 0.0167, G_A_loss: 0.5778, G_B_loss: 0.5416\n",
      "Epoch [35/200], Step [221/1067], D_A_loss: 0.0169, D_B_loss: 0.0493, G_A_loss: 1.1281, G_B_loss: 0.6821\n",
      "Epoch [35/200], Step [231/1067], D_A_loss: 0.0236, D_B_loss: 0.0217, G_A_loss: 0.7253, G_B_loss: 0.7800\n",
      "Epoch [35/200], Step [241/1067], D_A_loss: 0.0432, D_B_loss: 0.0944, G_A_loss: 1.0293, G_B_loss: 0.6909\n",
      "Epoch [35/200], Step [251/1067], D_A_loss: 0.0261, D_B_loss: 0.0248, G_A_loss: 0.7826, G_B_loss: 0.8930\n",
      "Epoch [35/200], Step [261/1067], D_A_loss: 0.0779, D_B_loss: 0.0110, G_A_loss: 1.0371, G_B_loss: 0.4982\n",
      "Epoch [35/200], Step [271/1067], D_A_loss: 0.1104, D_B_loss: 0.0183, G_A_loss: 0.6888, G_B_loss: 0.7539\n",
      "Epoch [35/200], Step [281/1067], D_A_loss: 0.0534, D_B_loss: 0.0280, G_A_loss: 0.4019, G_B_loss: 0.9462\n",
      "Epoch [35/200], Step [291/1067], D_A_loss: 0.3172, D_B_loss: 0.0248, G_A_loss: 0.4300, G_B_loss: 0.3965\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [35/200], Step [301/1067], D_A_loss: 0.0485, D_B_loss: 0.0338, G_A_loss: 0.8917, G_B_loss: 0.6923\n",
      "Epoch [35/200], Step [311/1067], D_A_loss: 0.1474, D_B_loss: 0.0235, G_A_loss: 0.8627, G_B_loss: 0.3787\n",
      "Epoch [35/200], Step [321/1067], D_A_loss: 0.0572, D_B_loss: 0.0443, G_A_loss: 0.6872, G_B_loss: 0.5674\n",
      "Epoch [35/200], Step [331/1067], D_A_loss: 0.0552, D_B_loss: 0.0661, G_A_loss: 0.9292, G_B_loss: 0.6166\n",
      "Epoch [35/200], Step [341/1067], D_A_loss: 0.0826, D_B_loss: 0.0698, G_A_loss: 0.8966, G_B_loss: 0.7364\n",
      "Epoch [35/200], Step [351/1067], D_A_loss: 0.0352, D_B_loss: 0.0378, G_A_loss: 1.0190, G_B_loss: 0.7937\n",
      "Epoch [35/200], Step [361/1067], D_A_loss: 0.0311, D_B_loss: 0.0382, G_A_loss: 0.8979, G_B_loss: 1.1949\n",
      "Epoch [35/200], Step [371/1067], D_A_loss: 0.1084, D_B_loss: 0.0426, G_A_loss: 1.0736, G_B_loss: 0.3368\n",
      "Epoch [35/200], Step [381/1067], D_A_loss: 0.0473, D_B_loss: 0.1267, G_A_loss: 0.6938, G_B_loss: 0.5116\n",
      "Epoch [35/200], Step [391/1067], D_A_loss: 0.0778, D_B_loss: 0.0358, G_A_loss: 0.6301, G_B_loss: 0.5651\n",
      "Epoch [35/200], Step [401/1067], D_A_loss: 0.0686, D_B_loss: 0.0285, G_A_loss: 0.6144, G_B_loss: 0.5058\n",
      "Epoch [35/200], Step [411/1067], D_A_loss: 0.0617, D_B_loss: 0.0779, G_A_loss: 0.7026, G_B_loss: 0.5954\n",
      "Epoch [35/200], Step [421/1067], D_A_loss: 0.2341, D_B_loss: 0.0583, G_A_loss: 0.5472, G_B_loss: 0.1395\n",
      "Epoch [35/200], Step [431/1067], D_A_loss: 0.0364, D_B_loss: 0.2712, G_A_loss: 1.3098, G_B_loss: 0.7639\n",
      "Epoch [35/200], Step [441/1067], D_A_loss: 0.0702, D_B_loss: 0.0243, G_A_loss: 0.4216, G_B_loss: 0.5453\n",
      "Epoch [35/200], Step [451/1067], D_A_loss: 0.2364, D_B_loss: 0.1292, G_A_loss: 0.3113, G_B_loss: 0.6637\n",
      "Epoch [35/200], Step [461/1067], D_A_loss: 0.0553, D_B_loss: 0.1357, G_A_loss: 0.9897, G_B_loss: 0.3712\n",
      "Epoch [35/200], Step [471/1067], D_A_loss: 0.0393, D_B_loss: 0.0690, G_A_loss: 0.5263, G_B_loss: 0.8051\n",
      "Epoch [35/200], Step [481/1067], D_A_loss: 0.0231, D_B_loss: 0.0275, G_A_loss: 0.4411, G_B_loss: 0.8124\n",
      "Epoch [35/200], Step [491/1067], D_A_loss: 0.0631, D_B_loss: 0.0209, G_A_loss: 1.0471, G_B_loss: 0.5608\n",
      "Epoch [35/200], Step [501/1067], D_A_loss: 0.1225, D_B_loss: 0.0174, G_A_loss: 0.5522, G_B_loss: 0.6040\n",
      "Epoch [35/200], Step [511/1067], D_A_loss: 0.0519, D_B_loss: 0.0619, G_A_loss: 0.8165, G_B_loss: 0.7098\n",
      "Epoch [35/200], Step [521/1067], D_A_loss: 0.0909, D_B_loss: 0.0270, G_A_loss: 0.5396, G_B_loss: 0.5108\n",
      "Epoch [35/200], Step [531/1067], D_A_loss: 0.0693, D_B_loss: 0.0190, G_A_loss: 1.1393, G_B_loss: 0.6718\n",
      "Epoch [35/200], Step [541/1067], D_A_loss: 0.0288, D_B_loss: 0.0476, G_A_loss: 0.4651, G_B_loss: 0.6065\n",
      "Epoch [35/200], Step [551/1067], D_A_loss: 0.0560, D_B_loss: 0.0299, G_A_loss: 0.7082, G_B_loss: 0.7602\n",
      "Epoch [35/200], Step [561/1067], D_A_loss: 0.2436, D_B_loss: 0.0833, G_A_loss: 0.4056, G_B_loss: 0.6980\n",
      "Epoch [35/200], Step [571/1067], D_A_loss: 0.0196, D_B_loss: 0.0707, G_A_loss: 1.2294, G_B_loss: 0.7104\n",
      "Epoch [35/200], Step [581/1067], D_A_loss: 0.0367, D_B_loss: 0.1297, G_A_loss: 0.3265, G_B_loss: 0.9876\n",
      "Epoch [35/200], Step [591/1067], D_A_loss: 0.0407, D_B_loss: 0.1164, G_A_loss: 0.3963, G_B_loss: 0.7162\n",
      "Epoch [35/200], Step [601/1067], D_A_loss: 0.0844, D_B_loss: 0.2337, G_A_loss: 0.6370, G_B_loss: 0.6802\n",
      "Epoch [35/200], Step [611/1067], D_A_loss: 0.0905, D_B_loss: 0.0311, G_A_loss: 0.9630, G_B_loss: 1.0573\n",
      "Epoch [35/200], Step [621/1067], D_A_loss: 0.0608, D_B_loss: 0.0731, G_A_loss: 1.2363, G_B_loss: 0.2557\n",
      "Epoch [35/200], Step [631/1067], D_A_loss: 0.1033, D_B_loss: 0.0557, G_A_loss: 0.5955, G_B_loss: 0.7546\n",
      "Epoch [35/200], Step [641/1067], D_A_loss: 0.1696, D_B_loss: 0.0386, G_A_loss: 0.6779, G_B_loss: 0.2503\n",
      "Epoch [35/200], Step [651/1067], D_A_loss: 0.2438, D_B_loss: 0.0593, G_A_loss: 0.7305, G_B_loss: 0.6297\n",
      "Epoch [35/200], Step [661/1067], D_A_loss: 0.3603, D_B_loss: 0.0369, G_A_loss: 0.6912, G_B_loss: 0.1477\n",
      "Epoch [35/200], Step [671/1067], D_A_loss: 0.1269, D_B_loss: 0.2776, G_A_loss: 0.2212, G_B_loss: 0.6798\n",
      "Epoch [35/200], Step [681/1067], D_A_loss: 0.0414, D_B_loss: 0.1384, G_A_loss: 1.1605, G_B_loss: 0.9963\n",
      "Epoch [35/200], Step [691/1067], D_A_loss: 0.0657, D_B_loss: 0.0320, G_A_loss: 0.8054, G_B_loss: 1.1468\n",
      "Epoch [35/200], Step [701/1067], D_A_loss: 0.0715, D_B_loss: 0.1434, G_A_loss: 0.8358, G_B_loss: 1.0427\n",
      "Epoch [35/200], Step [711/1067], D_A_loss: 0.0280, D_B_loss: 0.0220, G_A_loss: 0.7807, G_B_loss: 0.6468\n",
      "Epoch [35/200], Step [721/1067], D_A_loss: 0.1057, D_B_loss: 0.0311, G_A_loss: 0.7913, G_B_loss: 0.4428\n",
      "Epoch [35/200], Step [731/1067], D_A_loss: 0.0668, D_B_loss: 0.0114, G_A_loss: 0.9411, G_B_loss: 0.5659\n",
      "Epoch [35/200], Step [741/1067], D_A_loss: 0.0327, D_B_loss: 0.0822, G_A_loss: 0.6922, G_B_loss: 0.6403\n",
      "Epoch [35/200], Step [751/1067], D_A_loss: 0.0559, D_B_loss: 0.0505, G_A_loss: 0.7739, G_B_loss: 0.6250\n",
      "Epoch [35/200], Step [761/1067], D_A_loss: 0.0415, D_B_loss: 0.0222, G_A_loss: 0.8955, G_B_loss: 0.6911\n",
      "Epoch [35/200], Step [771/1067], D_A_loss: 0.1779, D_B_loss: 0.1618, G_A_loss: 0.6360, G_B_loss: 0.2959\n",
      "Epoch [35/200], Step [781/1067], D_A_loss: 0.0597, D_B_loss: 0.0139, G_A_loss: 0.7557, G_B_loss: 0.5115\n",
      "Epoch [35/200], Step [791/1067], D_A_loss: 0.0712, D_B_loss: 0.0186, G_A_loss: 0.7914, G_B_loss: 0.5379\n",
      "Epoch [35/200], Step [801/1067], D_A_loss: 0.1346, D_B_loss: 0.0264, G_A_loss: 0.4264, G_B_loss: 0.3188\n",
      "Epoch [35/200], Step [811/1067], D_A_loss: 0.0247, D_B_loss: 0.0311, G_A_loss: 0.7476, G_B_loss: 0.6536\n",
      "Epoch [35/200], Step [821/1067], D_A_loss: 0.0686, D_B_loss: 0.0669, G_A_loss: 0.5700, G_B_loss: 1.0032\n",
      "Epoch [35/200], Step [831/1067], D_A_loss: 0.1455, D_B_loss: 0.0169, G_A_loss: 0.6649, G_B_loss: 0.4494\n",
      "Epoch [35/200], Step [841/1067], D_A_loss: 0.0674, D_B_loss: 0.0131, G_A_loss: 0.5181, G_B_loss: 0.8597\n",
      "Epoch [35/200], Step [851/1067], D_A_loss: 0.0697, D_B_loss: 0.0402, G_A_loss: 0.2018, G_B_loss: 0.4880\n",
      "Epoch [35/200], Step [861/1067], D_A_loss: 0.0242, D_B_loss: 0.1434, G_A_loss: 0.8774, G_B_loss: 0.4653\n",
      "Epoch [35/200], Step [871/1067], D_A_loss: 0.1391, D_B_loss: 0.0986, G_A_loss: 0.5637, G_B_loss: 0.2164\n",
      "Epoch [35/200], Step [881/1067], D_A_loss: 0.0213, D_B_loss: 0.0210, G_A_loss: 0.5821, G_B_loss: 0.8886\n",
      "Epoch [35/200], Step [891/1067], D_A_loss: 0.1407, D_B_loss: 0.1093, G_A_loss: 0.5842, G_B_loss: 0.4546\n",
      "Epoch [35/200], Step [901/1067], D_A_loss: 0.1021, D_B_loss: 0.0201, G_A_loss: 1.1706, G_B_loss: 0.5614\n",
      "Epoch [35/200], Step [911/1067], D_A_loss: 0.0643, D_B_loss: 0.0576, G_A_loss: 0.6226, G_B_loss: 1.0085\n",
      "Epoch [35/200], Step [921/1067], D_A_loss: 0.0421, D_B_loss: 0.0326, G_A_loss: 0.8162, G_B_loss: 0.7228\n",
      "Epoch [35/200], Step [931/1067], D_A_loss: 0.0555, D_B_loss: 0.0186, G_A_loss: 0.8379, G_B_loss: 0.5271\n",
      "Epoch [35/200], Step [941/1067], D_A_loss: 0.0524, D_B_loss: 0.0547, G_A_loss: 0.6829, G_B_loss: 0.5467\n",
      "Epoch [35/200], Step [951/1067], D_A_loss: 0.0581, D_B_loss: 0.0218, G_A_loss: 0.7152, G_B_loss: 1.0082\n",
      "Epoch [35/200], Step [961/1067], D_A_loss: 0.0539, D_B_loss: 0.0510, G_A_loss: 1.0322, G_B_loss: 0.9761\n",
      "Epoch [35/200], Step [971/1067], D_A_loss: 0.0485, D_B_loss: 0.0489, G_A_loss: 1.3532, G_B_loss: 1.1406\n",
      "Epoch [35/200], Step [981/1067], D_A_loss: 0.1266, D_B_loss: 0.0648, G_A_loss: 0.5141, G_B_loss: 0.7036\n",
      "Epoch [35/200], Step [991/1067], D_A_loss: 0.0544, D_B_loss: 0.0487, G_A_loss: 0.5537, G_B_loss: 0.6057\n",
      "Epoch [35/200], Step [1001/1067], D_A_loss: 0.2079, D_B_loss: 0.0333, G_A_loss: 1.1544, G_B_loss: 1.0807\n",
      "Epoch [35/200], Step [1011/1067], D_A_loss: 0.0696, D_B_loss: 0.0470, G_A_loss: 0.6904, G_B_loss: 1.0185\n",
      "Epoch [35/200], Step [1021/1067], D_A_loss: 0.1009, D_B_loss: 0.0547, G_A_loss: 0.6009, G_B_loss: 0.3702\n",
      "Epoch [35/200], Step [1031/1067], D_A_loss: 0.0341, D_B_loss: 0.0906, G_A_loss: 1.1527, G_B_loss: 0.7323\n",
      "Epoch [35/200], Step [1041/1067], D_A_loss: 0.0140, D_B_loss: 0.0493, G_A_loss: 0.6693, G_B_loss: 0.3448\n",
      "Epoch [35/200], Step [1051/1067], D_A_loss: 0.0241, D_B_loss: 0.0336, G_A_loss: 0.8398, G_B_loss: 0.4556\n",
      "Epoch [35/200], Step [1061/1067], D_A_loss: 0.0380, D_B_loss: 0.1360, G_A_loss: 0.9162, G_B_loss: 0.4997\n",
      "Epoch [36/200], Step [1/1067], D_A_loss: 0.1167, D_B_loss: 0.0463, G_A_loss: 0.9801, G_B_loss: 0.3299\n",
      "Epoch [36/200], Step [11/1067], D_A_loss: 0.1352, D_B_loss: 0.0690, G_A_loss: 0.5432, G_B_loss: 0.7951\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [36/200], Step [21/1067], D_A_loss: 0.0729, D_B_loss: 0.1195, G_A_loss: 0.2879, G_B_loss: 0.5593\n",
      "Epoch [36/200], Step [31/1067], D_A_loss: 0.1127, D_B_loss: 0.0318, G_A_loss: 0.3265, G_B_loss: 0.3987\n",
      "Epoch [36/200], Step [41/1067], D_A_loss: 0.0667, D_B_loss: 0.0421, G_A_loss: 0.8229, G_B_loss: 0.4317\n",
      "Epoch [36/200], Step [51/1067], D_A_loss: 0.0231, D_B_loss: 0.1029, G_A_loss: 0.8717, G_B_loss: 1.0508\n",
      "Epoch [36/200], Step [61/1067], D_A_loss: 0.0318, D_B_loss: 0.0434, G_A_loss: 1.2439, G_B_loss: 0.7657\n",
      "Epoch [36/200], Step [71/1067], D_A_loss: 0.4652, D_B_loss: 0.0412, G_A_loss: 0.8067, G_B_loss: 0.9631\n",
      "Epoch [36/200], Step [81/1067], D_A_loss: 0.0482, D_B_loss: 0.0375, G_A_loss: 0.7786, G_B_loss: 0.3667\n",
      "Epoch [36/200], Step [91/1067], D_A_loss: 0.0225, D_B_loss: 0.0291, G_A_loss: 0.3550, G_B_loss: 0.8584\n",
      "Epoch [36/200], Step [101/1067], D_A_loss: 0.0298, D_B_loss: 0.0880, G_A_loss: 0.1370, G_B_loss: 0.7902\n",
      "Epoch [36/200], Step [111/1067], D_A_loss: 0.0432, D_B_loss: 0.1115, G_A_loss: 0.6360, G_B_loss: 0.6785\n",
      "Epoch [36/200], Step [121/1067], D_A_loss: 0.0282, D_B_loss: 0.0362, G_A_loss: 0.8900, G_B_loss: 0.8910\n",
      "Epoch [36/200], Step [131/1067], D_A_loss: 0.0381, D_B_loss: 0.0773, G_A_loss: 1.1411, G_B_loss: 0.7230\n",
      "Epoch [36/200], Step [141/1067], D_A_loss: 0.0525, D_B_loss: 0.0522, G_A_loss: 0.4202, G_B_loss: 0.7604\n",
      "Epoch [36/200], Step [151/1067], D_A_loss: 0.0592, D_B_loss: 0.0315, G_A_loss: 0.1579, G_B_loss: 0.7070\n",
      "Epoch [36/200], Step [161/1067], D_A_loss: 0.0843, D_B_loss: 0.0474, G_A_loss: 0.6395, G_B_loss: 0.5893\n",
      "Epoch [36/200], Step [171/1067], D_A_loss: 0.0820, D_B_loss: 0.0471, G_A_loss: 0.3776, G_B_loss: 1.2194\n",
      "Epoch [36/200], Step [181/1067], D_A_loss: 0.1032, D_B_loss: 0.0791, G_A_loss: 0.3868, G_B_loss: 0.4890\n",
      "Epoch [36/200], Step [191/1067], D_A_loss: 0.0557, D_B_loss: 0.0442, G_A_loss: 0.8802, G_B_loss: 0.7418\n",
      "Epoch [36/200], Step [201/1067], D_A_loss: 0.0408, D_B_loss: 0.1203, G_A_loss: 0.4438, G_B_loss: 0.7743\n",
      "Epoch [36/200], Step [211/1067], D_A_loss: 0.0419, D_B_loss: 0.0262, G_A_loss: 0.6140, G_B_loss: 0.7297\n",
      "Epoch [36/200], Step [221/1067], D_A_loss: 0.0405, D_B_loss: 0.0490, G_A_loss: 0.9730, G_B_loss: 0.5171\n",
      "Epoch [36/200], Step [231/1067], D_A_loss: 0.0477, D_B_loss: 0.0210, G_A_loss: 0.7162, G_B_loss: 0.3101\n",
      "Epoch [36/200], Step [241/1067], D_A_loss: 0.0909, D_B_loss: 0.0359, G_A_loss: 1.2139, G_B_loss: 0.4346\n",
      "Epoch [36/200], Step [251/1067], D_A_loss: 0.0799, D_B_loss: 0.0245, G_A_loss: 1.1264, G_B_loss: 0.2412\n",
      "Epoch [36/200], Step [261/1067], D_A_loss: 0.0339, D_B_loss: 0.0411, G_A_loss: 1.1090, G_B_loss: 0.8540\n",
      "Epoch [36/200], Step [271/1067], D_A_loss: 0.1979, D_B_loss: 0.0717, G_A_loss: 0.4327, G_B_loss: 0.2174\n",
      "Epoch [36/200], Step [281/1067], D_A_loss: 0.0744, D_B_loss: 0.0556, G_A_loss: 0.5601, G_B_loss: 0.5140\n",
      "Epoch [36/200], Step [291/1067], D_A_loss: 0.0384, D_B_loss: 0.0369, G_A_loss: 0.4540, G_B_loss: 0.7902\n",
      "Epoch [36/200], Step [301/1067], D_A_loss: 0.3516, D_B_loss: 0.0563, G_A_loss: 0.6270, G_B_loss: 1.0224\n",
      "Epoch [36/200], Step [311/1067], D_A_loss: 0.0351, D_B_loss: 0.0239, G_A_loss: 0.7364, G_B_loss: 0.5246\n",
      "Epoch [36/200], Step [321/1067], D_A_loss: 0.0741, D_B_loss: 0.0432, G_A_loss: 0.5378, G_B_loss: 0.6313\n",
      "Epoch [36/200], Step [331/1067], D_A_loss: 0.0558, D_B_loss: 0.0587, G_A_loss: 0.9212, G_B_loss: 0.9847\n",
      "Epoch [36/200], Step [341/1067], D_A_loss: 0.1212, D_B_loss: 0.0338, G_A_loss: 0.6936, G_B_loss: 0.5440\n",
      "Epoch [36/200], Step [351/1067], D_A_loss: 0.1141, D_B_loss: 0.1081, G_A_loss: 0.4412, G_B_loss: 0.4967\n",
      "Epoch [36/200], Step [361/1067], D_A_loss: 0.0406, D_B_loss: 0.0176, G_A_loss: 0.8763, G_B_loss: 0.4803\n",
      "Epoch [36/200], Step [371/1067], D_A_loss: 0.0729, D_B_loss: 0.0160, G_A_loss: 1.0298, G_B_loss: 0.4958\n",
      "Epoch [36/200], Step [381/1067], D_A_loss: 0.0245, D_B_loss: 0.0097, G_A_loss: 0.9313, G_B_loss: 0.5588\n",
      "Epoch [36/200], Step [391/1067], D_A_loss: 0.0705, D_B_loss: 0.0862, G_A_loss: 0.8662, G_B_loss: 0.4928\n",
      "Epoch [36/200], Step [401/1067], D_A_loss: 0.0743, D_B_loss: 0.0185, G_A_loss: 0.7984, G_B_loss: 0.4901\n",
      "Epoch [36/200], Step [411/1067], D_A_loss: 0.1490, D_B_loss: 0.0177, G_A_loss: 0.7592, G_B_loss: 0.8831\n",
      "Epoch [36/200], Step [421/1067], D_A_loss: 0.1576, D_B_loss: 0.0599, G_A_loss: 0.5107, G_B_loss: 0.4943\n",
      "Epoch [36/200], Step [431/1067], D_A_loss: 0.0406, D_B_loss: 0.0785, G_A_loss: 0.4101, G_B_loss: 0.7079\n",
      "Epoch [36/200], Step [441/1067], D_A_loss: 0.0403, D_B_loss: 0.0402, G_A_loss: 0.9181, G_B_loss: 0.6674\n",
      "Epoch [36/200], Step [451/1067], D_A_loss: 0.1090, D_B_loss: 0.0119, G_A_loss: 0.8694, G_B_loss: 0.4243\n",
      "Epoch [36/200], Step [461/1067], D_A_loss: 0.0985, D_B_loss: 0.1554, G_A_loss: 1.0401, G_B_loss: 1.1203\n",
      "Epoch [36/200], Step [471/1067], D_A_loss: 0.0507, D_B_loss: 0.0525, G_A_loss: 0.6943, G_B_loss: 0.2205\n",
      "Epoch [36/200], Step [481/1067], D_A_loss: 0.0431, D_B_loss: 0.0133, G_A_loss: 1.0342, G_B_loss: 0.7420\n",
      "Epoch [36/200], Step [491/1067], D_A_loss: 0.1037, D_B_loss: 0.0434, G_A_loss: 0.7278, G_B_loss: 0.5103\n",
      "Epoch [36/200], Step [501/1067], D_A_loss: 0.1808, D_B_loss: 0.0298, G_A_loss: 0.9805, G_B_loss: 0.1470\n",
      "Epoch [36/200], Step [511/1067], D_A_loss: 0.0571, D_B_loss: 0.0209, G_A_loss: 0.4807, G_B_loss: 0.5667\n",
      "Epoch [36/200], Step [521/1067], D_A_loss: 0.1197, D_B_loss: 0.0634, G_A_loss: 0.9779, G_B_loss: 0.4527\n",
      "Epoch [36/200], Step [531/1067], D_A_loss: 0.0442, D_B_loss: 0.0146, G_A_loss: 1.0482, G_B_loss: 0.6248\n",
      "Epoch [36/200], Step [541/1067], D_A_loss: 0.0223, D_B_loss: 0.0469, G_A_loss: 0.6384, G_B_loss: 0.4892\n",
      "Epoch [36/200], Step [551/1067], D_A_loss: 0.0346, D_B_loss: 0.0403, G_A_loss: 0.6624, G_B_loss: 0.3485\n",
      "Epoch [36/200], Step [561/1067], D_A_loss: 0.0365, D_B_loss: 0.0198, G_A_loss: 0.7882, G_B_loss: 0.3334\n",
      "Epoch [36/200], Step [571/1067], D_A_loss: 0.0759, D_B_loss: 0.0179, G_A_loss: 0.8249, G_B_loss: 0.4401\n",
      "Epoch [36/200], Step [581/1067], D_A_loss: 0.0241, D_B_loss: 0.0178, G_A_loss: 0.8743, G_B_loss: 0.5304\n",
      "Epoch [36/200], Step [591/1067], D_A_loss: 0.0312, D_B_loss: 0.0458, G_A_loss: 0.6001, G_B_loss: 0.9792\n",
      "Epoch [36/200], Step [601/1067], D_A_loss: 0.0774, D_B_loss: 0.0471, G_A_loss: 0.7817, G_B_loss: 0.5138\n",
      "Epoch [36/200], Step [611/1067], D_A_loss: 0.0214, D_B_loss: 0.2602, G_A_loss: 1.4336, G_B_loss: 0.8426\n",
      "Epoch [36/200], Step [621/1067], D_A_loss: 0.0248, D_B_loss: 0.0155, G_A_loss: 0.4445, G_B_loss: 1.0234\n",
      "Epoch [36/200], Step [631/1067], D_A_loss: 0.0507, D_B_loss: 0.0117, G_A_loss: 0.5989, G_B_loss: 0.9298\n",
      "Epoch [36/200], Step [641/1067], D_A_loss: 0.0858, D_B_loss: 0.2366, G_A_loss: 0.4436, G_B_loss: 0.4201\n",
      "Epoch [36/200], Step [651/1067], D_A_loss: 0.0294, D_B_loss: 0.0477, G_A_loss: 1.0764, G_B_loss: 0.5476\n",
      "Epoch [36/200], Step [661/1067], D_A_loss: 0.0405, D_B_loss: 0.0207, G_A_loss: 0.9130, G_B_loss: 1.1521\n",
      "Epoch [36/200], Step [671/1067], D_A_loss: 0.0258, D_B_loss: 0.0412, G_A_loss: 0.9555, G_B_loss: 0.7142\n",
      "Epoch [36/200], Step [681/1067], D_A_loss: 0.0613, D_B_loss: 0.0217, G_A_loss: 0.8176, G_B_loss: 0.5292\n",
      "Epoch [36/200], Step [691/1067], D_A_loss: 0.1575, D_B_loss: 0.0254, G_A_loss: 0.7037, G_B_loss: 0.6826\n",
      "Epoch [36/200], Step [701/1067], D_A_loss: 0.0293, D_B_loss: 0.0212, G_A_loss: 1.1479, G_B_loss: 0.7476\n",
      "Epoch [36/200], Step [711/1067], D_A_loss: 0.1015, D_B_loss: 0.2160, G_A_loss: 0.2676, G_B_loss: 0.4751\n",
      "Epoch [36/200], Step [721/1067], D_A_loss: 0.0527, D_B_loss: 0.0833, G_A_loss: 0.2957, G_B_loss: 0.6077\n",
      "Epoch [36/200], Step [731/1067], D_A_loss: 0.1005, D_B_loss: 0.1847, G_A_loss: 0.4960, G_B_loss: 0.5350\n",
      "Epoch [36/200], Step [741/1067], D_A_loss: 0.0272, D_B_loss: 0.1695, G_A_loss: 0.7927, G_B_loss: 0.3332\n",
      "Epoch [36/200], Step [751/1067], D_A_loss: 0.0704, D_B_loss: 0.0145, G_A_loss: 0.6245, G_B_loss: 0.4906\n",
      "Epoch [36/200], Step [761/1067], D_A_loss: 0.0821, D_B_loss: 0.1500, G_A_loss: 1.2575, G_B_loss: 0.6505\n",
      "Epoch [36/200], Step [771/1067], D_A_loss: 0.0318, D_B_loss: 0.0819, G_A_loss: 0.5643, G_B_loss: 0.6994\n",
      "Epoch [36/200], Step [781/1067], D_A_loss: 0.0510, D_B_loss: 0.0283, G_A_loss: 0.5548, G_B_loss: 0.5383\n",
      "Epoch [36/200], Step [791/1067], D_A_loss: 0.0171, D_B_loss: 0.0387, G_A_loss: 0.7155, G_B_loss: 0.6412\n",
      "Epoch [36/200], Step [801/1067], D_A_loss: 0.0518, D_B_loss: 0.0178, G_A_loss: 0.6170, G_B_loss: 0.8020\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [36/200], Step [811/1067], D_A_loss: 0.0173, D_B_loss: 0.0277, G_A_loss: 0.6927, G_B_loss: 1.0269\n",
      "Epoch [36/200], Step [821/1067], D_A_loss: 0.0478, D_B_loss: 0.0416, G_A_loss: 1.1233, G_B_loss: 0.2435\n",
      "Epoch [36/200], Step [831/1067], D_A_loss: 0.0737, D_B_loss: 0.1387, G_A_loss: 1.2563, G_B_loss: 0.8113\n",
      "Epoch [36/200], Step [841/1067], D_A_loss: 0.0617, D_B_loss: 0.0372, G_A_loss: 0.9561, G_B_loss: 0.6018\n",
      "Epoch [36/200], Step [851/1067], D_A_loss: 0.0604, D_B_loss: 0.0473, G_A_loss: 0.6978, G_B_loss: 0.6498\n",
      "Epoch [36/200], Step [861/1067], D_A_loss: 0.0314, D_B_loss: 0.0679, G_A_loss: 0.5815, G_B_loss: 0.7454\n",
      "Epoch [36/200], Step [871/1067], D_A_loss: 0.1163, D_B_loss: 0.0946, G_A_loss: 1.0834, G_B_loss: 0.3437\n",
      "Epoch [36/200], Step [881/1067], D_A_loss: 0.1508, D_B_loss: 0.0693, G_A_loss: 0.6289, G_B_loss: 0.4623\n",
      "Epoch [36/200], Step [891/1067], D_A_loss: 0.0286, D_B_loss: 0.1579, G_A_loss: 1.1706, G_B_loss: 0.8044\n",
      "Epoch [36/200], Step [901/1067], D_A_loss: 0.0306, D_B_loss: 0.0871, G_A_loss: 1.0838, G_B_loss: 0.6844\n",
      "Epoch [36/200], Step [911/1067], D_A_loss: 0.0420, D_B_loss: 0.1472, G_A_loss: 0.9547, G_B_loss: 0.6037\n",
      "Epoch [36/200], Step [921/1067], D_A_loss: 0.0330, D_B_loss: 0.0120, G_A_loss: 0.5991, G_B_loss: 0.2953\n",
      "Epoch [36/200], Step [931/1067], D_A_loss: 0.0503, D_B_loss: 0.0235, G_A_loss: 0.6634, G_B_loss: 0.8581\n",
      "Epoch [36/200], Step [941/1067], D_A_loss: 0.0426, D_B_loss: 0.0154, G_A_loss: 0.6149, G_B_loss: 0.6446\n",
      "Epoch [36/200], Step [951/1067], D_A_loss: 0.0726, D_B_loss: 0.0547, G_A_loss: 0.5758, G_B_loss: 0.5639\n",
      "Epoch [36/200], Step [961/1067], D_A_loss: 0.0290, D_B_loss: 0.0286, G_A_loss: 0.3490, G_B_loss: 0.6280\n",
      "Epoch [36/200], Step [971/1067], D_A_loss: 0.0726, D_B_loss: 0.0789, G_A_loss: 1.1906, G_B_loss: 0.4518\n",
      "Epoch [36/200], Step [981/1067], D_A_loss: 0.0902, D_B_loss: 0.0171, G_A_loss: 0.4734, G_B_loss: 0.9602\n",
      "Epoch [36/200], Step [991/1067], D_A_loss: 0.1723, D_B_loss: 0.0302, G_A_loss: 0.6729, G_B_loss: 0.9003\n",
      "Epoch [36/200], Step [1001/1067], D_A_loss: 0.0794, D_B_loss: 0.0177, G_A_loss: 0.7980, G_B_loss: 0.7232\n",
      "Epoch [36/200], Step [1011/1067], D_A_loss: 0.0909, D_B_loss: 0.0308, G_A_loss: 0.6947, G_B_loss: 0.3958\n",
      "Epoch [36/200], Step [1021/1067], D_A_loss: 0.1124, D_B_loss: 0.0159, G_A_loss: 0.5803, G_B_loss: 0.7205\n",
      "Epoch [36/200], Step [1031/1067], D_A_loss: 0.0750, D_B_loss: 0.0225, G_A_loss: 0.7596, G_B_loss: 0.8660\n",
      "Epoch [36/200], Step [1041/1067], D_A_loss: 0.0694, D_B_loss: 0.0346, G_A_loss: 0.5647, G_B_loss: 0.4754\n",
      "Epoch [36/200], Step [1051/1067], D_A_loss: 0.0863, D_B_loss: 0.1177, G_A_loss: 0.4118, G_B_loss: 0.4098\n",
      "Epoch [36/200], Step [1061/1067], D_A_loss: 0.0660, D_B_loss: 0.0495, G_A_loss: 0.5637, G_B_loss: 0.6570\n",
      "Epoch [37/200], Step [1/1067], D_A_loss: 0.0805, D_B_loss: 0.0731, G_A_loss: 0.7900, G_B_loss: 0.4752\n",
      "Epoch [37/200], Step [11/1067], D_A_loss: 0.0219, D_B_loss: 0.1152, G_A_loss: 0.6611, G_B_loss: 1.1831\n",
      "Epoch [37/200], Step [21/1067], D_A_loss: 0.0558, D_B_loss: 0.0732, G_A_loss: 0.8782, G_B_loss: 0.5977\n",
      "Epoch [37/200], Step [31/1067], D_A_loss: 0.0548, D_B_loss: 0.0630, G_A_loss: 0.6202, G_B_loss: 0.7602\n",
      "Epoch [37/200], Step [41/1067], D_A_loss: 0.0704, D_B_loss: 0.1357, G_A_loss: 0.7742, G_B_loss: 0.6735\n",
      "Epoch [37/200], Step [51/1067], D_A_loss: 0.1861, D_B_loss: 0.0764, G_A_loss: 0.4344, G_B_loss: 0.2817\n",
      "Epoch [37/200], Step [61/1067], D_A_loss: 0.0811, D_B_loss: 0.0371, G_A_loss: 0.7689, G_B_loss: 0.5146\n",
      "Epoch [37/200], Step [71/1067], D_A_loss: 0.0841, D_B_loss: 0.0707, G_A_loss: 0.5936, G_B_loss: 0.5084\n",
      "Epoch [37/200], Step [81/1067], D_A_loss: 0.0586, D_B_loss: 0.1733, G_A_loss: 0.2904, G_B_loss: 0.7362\n",
      "Epoch [37/200], Step [91/1067], D_A_loss: 0.0165, D_B_loss: 0.0387, G_A_loss: 0.6369, G_B_loss: 0.6869\n",
      "Epoch [37/200], Step [101/1067], D_A_loss: 0.1895, D_B_loss: 0.0516, G_A_loss: 0.5371, G_B_loss: 0.2056\n",
      "Epoch [37/200], Step [111/1067], D_A_loss: 0.1302, D_B_loss: 0.0498, G_A_loss: 0.9629, G_B_loss: 1.1031\n",
      "Epoch [37/200], Step [121/1067], D_A_loss: 0.1893, D_B_loss: 0.0457, G_A_loss: 0.8513, G_B_loss: 0.5008\n",
      "Epoch [37/200], Step [131/1067], D_A_loss: 0.0368, D_B_loss: 0.1480, G_A_loss: 0.5413, G_B_loss: 0.4549\n",
      "Epoch [37/200], Step [141/1067], D_A_loss: 0.0529, D_B_loss: 0.0765, G_A_loss: 0.6164, G_B_loss: 1.4684\n",
      "Epoch [37/200], Step [151/1067], D_A_loss: 0.0970, D_B_loss: 0.0331, G_A_loss: 1.1553, G_B_loss: 0.4383\n",
      "Epoch [37/200], Step [161/1067], D_A_loss: 0.0599, D_B_loss: 0.0683, G_A_loss: 0.3277, G_B_loss: 0.9964\n",
      "Epoch [37/200], Step [171/1067], D_A_loss: 0.0256, D_B_loss: 0.0212, G_A_loss: 1.0240, G_B_loss: 0.4466\n",
      "Epoch [37/200], Step [181/1067], D_A_loss: 0.0634, D_B_loss: 0.0424, G_A_loss: 0.3850, G_B_loss: 0.7987\n",
      "Epoch [37/200], Step [191/1067], D_A_loss: 0.1448, D_B_loss: 0.0931, G_A_loss: 0.7509, G_B_loss: 0.2877\n",
      "Epoch [37/200], Step [201/1067], D_A_loss: 0.1523, D_B_loss: 0.0343, G_A_loss: 0.6649, G_B_loss: 0.7889\n",
      "Epoch [37/200], Step [211/1067], D_A_loss: 0.0327, D_B_loss: 0.0341, G_A_loss: 0.7519, G_B_loss: 0.7904\n",
      "Epoch [37/200], Step [221/1067], D_A_loss: 0.0343, D_B_loss: 0.0643, G_A_loss: 0.8063, G_B_loss: 0.7842\n",
      "Epoch [37/200], Step [231/1067], D_A_loss: 0.0218, D_B_loss: 0.0386, G_A_loss: 0.7007, G_B_loss: 0.5224\n",
      "Epoch [37/200], Step [241/1067], D_A_loss: 0.0384, D_B_loss: 0.0603, G_A_loss: 0.6556, G_B_loss: 0.7603\n",
      "Epoch [37/200], Step [251/1067], D_A_loss: 0.0644, D_B_loss: 0.0229, G_A_loss: 1.0493, G_B_loss: 0.4464\n",
      "Epoch [37/200], Step [261/1067], D_A_loss: 0.0196, D_B_loss: 0.0142, G_A_loss: 1.0522, G_B_loss: 0.9866\n",
      "Epoch [37/200], Step [271/1067], D_A_loss: 0.0569, D_B_loss: 0.0382, G_A_loss: 0.8014, G_B_loss: 0.8451\n",
      "Epoch [37/200], Step [281/1067], D_A_loss: 0.3693, D_B_loss: 0.0433, G_A_loss: 0.9394, G_B_loss: 0.5496\n",
      "Epoch [37/200], Step [291/1067], D_A_loss: 0.0441, D_B_loss: 0.0680, G_A_loss: 0.7599, G_B_loss: 0.7104\n",
      "Epoch [37/200], Step [301/1067], D_A_loss: 0.0404, D_B_loss: 0.0463, G_A_loss: 0.4211, G_B_loss: 0.9006\n",
      "Epoch [37/200], Step [311/1067], D_A_loss: 0.0458, D_B_loss: 0.0464, G_A_loss: 0.8819, G_B_loss: 1.0588\n",
      "Epoch [37/200], Step [321/1067], D_A_loss: 0.1132, D_B_loss: 0.0529, G_A_loss: 0.6518, G_B_loss: 1.0087\n",
      "Epoch [37/200], Step [331/1067], D_A_loss: 0.0263, D_B_loss: 0.2067, G_A_loss: 1.1524, G_B_loss: 0.8799\n",
      "Epoch [37/200], Step [341/1067], D_A_loss: 0.0588, D_B_loss: 0.0440, G_A_loss: 1.0590, G_B_loss: 0.9087\n",
      "Epoch [37/200], Step [351/1067], D_A_loss: 0.0247, D_B_loss: 0.1284, G_A_loss: 1.1505, G_B_loss: 0.5964\n",
      "Epoch [37/200], Step [361/1067], D_A_loss: 0.0174, D_B_loss: 0.0786, G_A_loss: 0.4442, G_B_loss: 0.7730\n",
      "Epoch [37/200], Step [371/1067], D_A_loss: 0.0418, D_B_loss: 0.0423, G_A_loss: 0.5686, G_B_loss: 0.7544\n",
      "Epoch [37/200], Step [381/1067], D_A_loss: 0.1239, D_B_loss: 0.0904, G_A_loss: 0.5849, G_B_loss: 1.1418\n",
      "Epoch [37/200], Step [391/1067], D_A_loss: 0.0520, D_B_loss: 0.0518, G_A_loss: 0.4609, G_B_loss: 0.5096\n",
      "Epoch [37/200], Step [401/1067], D_A_loss: 0.0813, D_B_loss: 0.0230, G_A_loss: 0.7854, G_B_loss: 0.4212\n",
      "Epoch [37/200], Step [411/1067], D_A_loss: 0.2419, D_B_loss: 0.0225, G_A_loss: 0.9514, G_B_loss: 0.6981\n",
      "Epoch [37/200], Step [421/1067], D_A_loss: 0.0384, D_B_loss: 0.0637, G_A_loss: 0.4796, G_B_loss: 0.4451\n",
      "Epoch [37/200], Step [431/1067], D_A_loss: 0.1551, D_B_loss: 0.0161, G_A_loss: 0.6265, G_B_loss: 0.3455\n",
      "Epoch [37/200], Step [441/1067], D_A_loss: 0.0636, D_B_loss: 0.0567, G_A_loss: 0.7266, G_B_loss: 0.6975\n",
      "Epoch [37/200], Step [451/1067], D_A_loss: 0.0683, D_B_loss: 0.0754, G_A_loss: 0.9163, G_B_loss: 0.5022\n",
      "Epoch [37/200], Step [461/1067], D_A_loss: 0.1982, D_B_loss: 0.1951, G_A_loss: 0.7797, G_B_loss: 0.7052\n",
      "Epoch [37/200], Step [471/1067], D_A_loss: 0.0287, D_B_loss: 0.0120, G_A_loss: 1.1473, G_B_loss: 0.3433\n",
      "Epoch [37/200], Step [481/1067], D_A_loss: 0.0567, D_B_loss: 0.0404, G_A_loss: 0.6834, G_B_loss: 1.0385\n",
      "Epoch [37/200], Step [491/1067], D_A_loss: 0.0422, D_B_loss: 0.0338, G_A_loss: 0.7904, G_B_loss: 0.8126\n",
      "Epoch [37/200], Step [501/1067], D_A_loss: 0.1985, D_B_loss: 0.0277, G_A_loss: 0.6891, G_B_loss: 0.2764\n",
      "Epoch [37/200], Step [511/1067], D_A_loss: 0.0411, D_B_loss: 0.0162, G_A_loss: 0.6546, G_B_loss: 0.8398\n",
      "Epoch [37/200], Step [521/1067], D_A_loss: 0.0649, D_B_loss: 0.0887, G_A_loss: 0.4213, G_B_loss: 0.7506\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [37/200], Step [531/1067], D_A_loss: 0.1149, D_B_loss: 0.0200, G_A_loss: 0.3265, G_B_loss: 0.4838\n",
      "Epoch [37/200], Step [541/1067], D_A_loss: 0.0248, D_B_loss: 0.0669, G_A_loss: 0.4717, G_B_loss: 0.5226\n",
      "Epoch [37/200], Step [551/1067], D_A_loss: 0.0871, D_B_loss: 0.0462, G_A_loss: 0.9049, G_B_loss: 0.4436\n",
      "Epoch [37/200], Step [561/1067], D_A_loss: 0.1729, D_B_loss: 0.1686, G_A_loss: 1.0139, G_B_loss: 0.7613\n",
      "Epoch [37/200], Step [571/1067], D_A_loss: 0.0724, D_B_loss: 0.1511, G_A_loss: 0.6322, G_B_loss: 0.5548\n",
      "Epoch [37/200], Step [581/1067], D_A_loss: 0.0548, D_B_loss: 0.0368, G_A_loss: 1.1373, G_B_loss: 1.1320\n",
      "Epoch [37/200], Step [591/1067], D_A_loss: 0.0497, D_B_loss: 0.0802, G_A_loss: 0.6426, G_B_loss: 0.6403\n",
      "Epoch [37/200], Step [601/1067], D_A_loss: 0.0595, D_B_loss: 0.0309, G_A_loss: 0.6857, G_B_loss: 0.8320\n",
      "Epoch [37/200], Step [611/1067], D_A_loss: 0.0260, D_B_loss: 0.1198, G_A_loss: 0.7946, G_B_loss: 0.2237\n",
      "Epoch [37/200], Step [621/1067], D_A_loss: 0.0776, D_B_loss: 0.0887, G_A_loss: 0.6920, G_B_loss: 0.6344\n",
      "Epoch [37/200], Step [631/1067], D_A_loss: 0.0357, D_B_loss: 0.0430, G_A_loss: 0.6536, G_B_loss: 0.7913\n",
      "Epoch [37/200], Step [641/1067], D_A_loss: 0.1320, D_B_loss: 0.0340, G_A_loss: 0.9491, G_B_loss: 1.3232\n",
      "Epoch [37/200], Step [651/1067], D_A_loss: 0.0223, D_B_loss: 0.0290, G_A_loss: 0.5552, G_B_loss: 0.7510\n",
      "Epoch [37/200], Step [661/1067], D_A_loss: 0.0487, D_B_loss: 0.0208, G_A_loss: 1.0869, G_B_loss: 0.5694\n",
      "Epoch [37/200], Step [671/1067], D_A_loss: 0.0387, D_B_loss: 0.2162, G_A_loss: 0.8985, G_B_loss: 0.3138\n",
      "Epoch [37/200], Step [681/1067], D_A_loss: 0.0563, D_B_loss: 0.0350, G_A_loss: 0.6450, G_B_loss: 0.8613\n",
      "Epoch [37/200], Step [691/1067], D_A_loss: 0.0401, D_B_loss: 0.1102, G_A_loss: 0.5884, G_B_loss: 0.6814\n",
      "Epoch [37/200], Step [701/1067], D_A_loss: 0.1290, D_B_loss: 0.0216, G_A_loss: 0.5116, G_B_loss: 0.3518\n",
      "Epoch [37/200], Step [711/1067], D_A_loss: 0.0866, D_B_loss: 0.0219, G_A_loss: 0.7007, G_B_loss: 0.6817\n",
      "Epoch [37/200], Step [721/1067], D_A_loss: 0.0685, D_B_loss: 0.0176, G_A_loss: 0.9509, G_B_loss: 0.6284\n",
      "Epoch [37/200], Step [731/1067], D_A_loss: 0.0537, D_B_loss: 0.0989, G_A_loss: 0.5668, G_B_loss: 0.5941\n",
      "Epoch [37/200], Step [741/1067], D_A_loss: 0.0171, D_B_loss: 0.0924, G_A_loss: 0.7356, G_B_loss: 0.6675\n",
      "Epoch [37/200], Step [751/1067], D_A_loss: 0.0427, D_B_loss: 0.0194, G_A_loss: 0.4863, G_B_loss: 1.1313\n",
      "Epoch [37/200], Step [761/1067], D_A_loss: 0.0547, D_B_loss: 0.0552, G_A_loss: 0.8423, G_B_loss: 0.5583\n",
      "Epoch [37/200], Step [771/1067], D_A_loss: 0.1691, D_B_loss: 0.0454, G_A_loss: 0.7715, G_B_loss: 0.9750\n",
      "Epoch [37/200], Step [781/1067], D_A_loss: 0.0612, D_B_loss: 0.1355, G_A_loss: 1.4067, G_B_loss: 0.5191\n",
      "Epoch [37/200], Step [791/1067], D_A_loss: 0.1043, D_B_loss: 0.0155, G_A_loss: 0.7798, G_B_loss: 0.8391\n",
      "Epoch [37/200], Step [801/1067], D_A_loss: 0.1117, D_B_loss: 0.0501, G_A_loss: 0.5522, G_B_loss: 0.7517\n",
      "Epoch [37/200], Step [811/1067], D_A_loss: 0.0463, D_B_loss: 0.0490, G_A_loss: 0.6147, G_B_loss: 0.6121\n",
      "Epoch [37/200], Step [821/1067], D_A_loss: 0.0292, D_B_loss: 0.1912, G_A_loss: 1.6021, G_B_loss: 0.8951\n",
      "Epoch [37/200], Step [831/1067], D_A_loss: 0.0634, D_B_loss: 0.0361, G_A_loss: 0.7893, G_B_loss: 0.5552\n",
      "Epoch [37/200], Step [841/1067], D_A_loss: 0.0312, D_B_loss: 0.0485, G_A_loss: 0.5761, G_B_loss: 1.0077\n",
      "Epoch [37/200], Step [851/1067], D_A_loss: 0.1483, D_B_loss: 0.0690, G_A_loss: 0.3596, G_B_loss: 0.6033\n",
      "Epoch [37/200], Step [861/1067], D_A_loss: 0.0594, D_B_loss: 0.0541, G_A_loss: 1.0600, G_B_loss: 0.4476\n",
      "Epoch [37/200], Step [871/1067], D_A_loss: 0.0478, D_B_loss: 0.0454, G_A_loss: 0.6982, G_B_loss: 0.6237\n",
      "Epoch [37/200], Step [881/1067], D_A_loss: 0.0577, D_B_loss: 0.0479, G_A_loss: 0.6567, G_B_loss: 0.5809\n",
      "Epoch [37/200], Step [891/1067], D_A_loss: 0.0388, D_B_loss: 0.0946, G_A_loss: 0.7229, G_B_loss: 0.6818\n",
      "Epoch [37/200], Step [901/1067], D_A_loss: 0.2026, D_B_loss: 0.0751, G_A_loss: 0.8396, G_B_loss: 0.2852\n",
      "Epoch [37/200], Step [911/1067], D_A_loss: 0.0668, D_B_loss: 0.2504, G_A_loss: 0.9782, G_B_loss: 0.6115\n",
      "Epoch [37/200], Step [921/1067], D_A_loss: 0.0672, D_B_loss: 0.0167, G_A_loss: 0.4672, G_B_loss: 0.5951\n",
      "Epoch [37/200], Step [931/1067], D_A_loss: 0.1427, D_B_loss: 0.0589, G_A_loss: 0.5420, G_B_loss: 1.0350\n",
      "Epoch [37/200], Step [941/1067], D_A_loss: 0.0506, D_B_loss: 0.0235, G_A_loss: 0.8153, G_B_loss: 0.4285\n",
      "Epoch [37/200], Step [951/1067], D_A_loss: 0.0223, D_B_loss: 0.0207, G_A_loss: 0.4785, G_B_loss: 0.6024\n",
      "Epoch [37/200], Step [961/1067], D_A_loss: 0.0711, D_B_loss: 0.0258, G_A_loss: 0.7825, G_B_loss: 0.4821\n",
      "Epoch [37/200], Step [971/1067], D_A_loss: 0.0875, D_B_loss: 0.0680, G_A_loss: 1.0247, G_B_loss: 0.7754\n",
      "Epoch [37/200], Step [981/1067], D_A_loss: 0.1574, D_B_loss: 0.0401, G_A_loss: 0.6295, G_B_loss: 0.2767\n",
      "Epoch [37/200], Step [991/1067], D_A_loss: 0.0291, D_B_loss: 0.0334, G_A_loss: 1.1295, G_B_loss: 0.7508\n",
      "Epoch [37/200], Step [1001/1067], D_A_loss: 0.1261, D_B_loss: 0.0361, G_A_loss: 0.6736, G_B_loss: 0.8153\n",
      "Epoch [37/200], Step [1011/1067], D_A_loss: 0.0556, D_B_loss: 0.0381, G_A_loss: 0.5545, G_B_loss: 0.8967\n",
      "Epoch [37/200], Step [1021/1067], D_A_loss: 0.1139, D_B_loss: 0.0547, G_A_loss: 0.5697, G_B_loss: 0.3943\n",
      "Epoch [37/200], Step [1031/1067], D_A_loss: 0.0399, D_B_loss: 0.0901, G_A_loss: 0.7138, G_B_loss: 0.2385\n",
      "Epoch [37/200], Step [1041/1067], D_A_loss: 0.0733, D_B_loss: 0.0974, G_A_loss: 1.2078, G_B_loss: 0.7462\n",
      "Epoch [37/200], Step [1051/1067], D_A_loss: 0.0707, D_B_loss: 0.0206, G_A_loss: 0.7816, G_B_loss: 0.6049\n",
      "Epoch [37/200], Step [1061/1067], D_A_loss: 0.0834, D_B_loss: 0.0276, G_A_loss: 1.3460, G_B_loss: 0.7888\n",
      "Epoch [38/200], Step [1/1067], D_A_loss: 0.0833, D_B_loss: 0.0336, G_A_loss: 1.0406, G_B_loss: 0.6111\n",
      "Epoch [38/200], Step [11/1067], D_A_loss: 0.1195, D_B_loss: 0.1723, G_A_loss: 0.7026, G_B_loss: 0.4022\n",
      "Epoch [38/200], Step [21/1067], D_A_loss: 0.0379, D_B_loss: 0.0717, G_A_loss: 0.4713, G_B_loss: 0.6218\n",
      "Epoch [38/200], Step [31/1067], D_A_loss: 0.0933, D_B_loss: 0.0373, G_A_loss: 1.3038, G_B_loss: 0.6868\n",
      "Epoch [38/200], Step [41/1067], D_A_loss: 0.0951, D_B_loss: 0.0351, G_A_loss: 0.9557, G_B_loss: 0.6491\n",
      "Epoch [38/200], Step [51/1067], D_A_loss: 0.0340, D_B_loss: 0.1057, G_A_loss: 1.1206, G_B_loss: 0.6607\n",
      "Epoch [38/200], Step [61/1067], D_A_loss: 0.0296, D_B_loss: 0.0352, G_A_loss: 0.6556, G_B_loss: 0.8778\n",
      "Epoch [38/200], Step [71/1067], D_A_loss: 0.0298, D_B_loss: 0.0578, G_A_loss: 0.6157, G_B_loss: 0.4833\n",
      "Epoch [38/200], Step [81/1067], D_A_loss: 0.0870, D_B_loss: 0.0135, G_A_loss: 0.8086, G_B_loss: 0.5700\n",
      "Epoch [38/200], Step [91/1067], D_A_loss: 0.1186, D_B_loss: 0.0327, G_A_loss: 0.9659, G_B_loss: 1.1356\n",
      "Epoch [38/200], Step [101/1067], D_A_loss: 0.1272, D_B_loss: 0.0308, G_A_loss: 0.9131, G_B_loss: 0.4458\n",
      "Epoch [38/200], Step [111/1067], D_A_loss: 0.0557, D_B_loss: 0.1517, G_A_loss: 0.8881, G_B_loss: 0.3904\n",
      "Epoch [38/200], Step [121/1067], D_A_loss: 0.0630, D_B_loss: 0.0667, G_A_loss: 0.9000, G_B_loss: 0.6561\n",
      "Epoch [38/200], Step [131/1067], D_A_loss: 0.0291, D_B_loss: 0.0365, G_A_loss: 0.6707, G_B_loss: 0.7805\n",
      "Epoch [38/200], Step [141/1067], D_A_loss: 0.0523, D_B_loss: 0.0182, G_A_loss: 0.8306, G_B_loss: 0.6500\n",
      "Epoch [38/200], Step [151/1067], D_A_loss: 0.1970, D_B_loss: 0.0173, G_A_loss: 0.6827, G_B_loss: 0.2003\n",
      "Epoch [38/200], Step [161/1067], D_A_loss: 0.0321, D_B_loss: 0.0199, G_A_loss: 1.0089, G_B_loss: 0.6839\n",
      "Epoch [38/200], Step [171/1067], D_A_loss: 0.0881, D_B_loss: 0.0227, G_A_loss: 0.7649, G_B_loss: 0.4325\n",
      "Epoch [38/200], Step [181/1067], D_A_loss: 0.0517, D_B_loss: 0.0441, G_A_loss: 0.5748, G_B_loss: 0.6189\n",
      "Epoch [38/200], Step [191/1067], D_A_loss: 0.0904, D_B_loss: 0.0670, G_A_loss: 0.6781, G_B_loss: 0.4174\n",
      "Epoch [38/200], Step [201/1067], D_A_loss: 0.0868, D_B_loss: 0.0410, G_A_loss: 0.6350, G_B_loss: 1.0566\n",
      "Epoch [38/200], Step [211/1067], D_A_loss: 0.0686, D_B_loss: 0.0194, G_A_loss: 0.7966, G_B_loss: 1.1716\n",
      "Epoch [38/200], Step [221/1067], D_A_loss: 0.0494, D_B_loss: 0.0451, G_A_loss: 0.7965, G_B_loss: 0.6666\n",
      "Epoch [38/200], Step [231/1067], D_A_loss: 0.0215, D_B_loss: 0.0362, G_A_loss: 0.7476, G_B_loss: 0.6084\n",
      "Epoch [38/200], Step [241/1067], D_A_loss: 0.0158, D_B_loss: 0.0187, G_A_loss: 1.0945, G_B_loss: 0.4206\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [38/200], Step [251/1067], D_A_loss: 0.0493, D_B_loss: 0.0490, G_A_loss: 0.7433, G_B_loss: 0.6206\n",
      "Epoch [38/200], Step [261/1067], D_A_loss: 0.0619, D_B_loss: 0.0340, G_A_loss: 0.8350, G_B_loss: 0.5126\n",
      "Epoch [38/200], Step [271/1067], D_A_loss: 0.0512, D_B_loss: 0.0593, G_A_loss: 1.4848, G_B_loss: 0.6589\n",
      "Epoch [38/200], Step [281/1067], D_A_loss: 0.0270, D_B_loss: 0.1062, G_A_loss: 0.3695, G_B_loss: 0.4606\n",
      "Epoch [38/200], Step [291/1067], D_A_loss: 0.0868, D_B_loss: 0.1137, G_A_loss: 0.9102, G_B_loss: 0.4716\n",
      "Epoch [38/200], Step [301/1067], D_A_loss: 0.0414, D_B_loss: 0.0337, G_A_loss: 0.5490, G_B_loss: 0.4476\n",
      "Epoch [38/200], Step [311/1067], D_A_loss: 0.0526, D_B_loss: 0.1165, G_A_loss: 0.8916, G_B_loss: 0.7134\n",
      "Epoch [38/200], Step [321/1067], D_A_loss: 0.0423, D_B_loss: 0.0256, G_A_loss: 0.8546, G_B_loss: 0.6633\n",
      "Epoch [38/200], Step [331/1067], D_A_loss: 0.0998, D_B_loss: 0.1090, G_A_loss: 0.3280, G_B_loss: 0.4118\n",
      "Epoch [38/200], Step [341/1067], D_A_loss: 0.2095, D_B_loss: 0.0264, G_A_loss: 0.8736, G_B_loss: 0.9650\n",
      "Epoch [38/200], Step [351/1067], D_A_loss: 0.0240, D_B_loss: 0.0181, G_A_loss: 0.3620, G_B_loss: 0.7041\n",
      "Epoch [38/200], Step [361/1067], D_A_loss: 0.0335, D_B_loss: 0.1556, G_A_loss: 0.5376, G_B_loss: 0.6657\n",
      "Epoch [38/200], Step [371/1067], D_A_loss: 0.1024, D_B_loss: 0.0281, G_A_loss: 0.9379, G_B_loss: 0.5319\n",
      "Epoch [38/200], Step [381/1067], D_A_loss: 0.1425, D_B_loss: 0.0706, G_A_loss: 0.4344, G_B_loss: 1.4639\n",
      "Epoch [38/200], Step [391/1067], D_A_loss: 0.0406, D_B_loss: 0.0513, G_A_loss: 1.1110, G_B_loss: 1.1701\n",
      "Epoch [38/200], Step [401/1067], D_A_loss: 0.0470, D_B_loss: 0.0195, G_A_loss: 0.8035, G_B_loss: 0.9053\n",
      "Epoch [38/200], Step [411/1067], D_A_loss: 0.2447, D_B_loss: 0.1733, G_A_loss: 0.7369, G_B_loss: 0.4637\n",
      "Epoch [38/200], Step [421/1067], D_A_loss: 0.0808, D_B_loss: 0.0410, G_A_loss: 1.0166, G_B_loss: 0.4847\n",
      "Epoch [38/200], Step [431/1067], D_A_loss: 0.0548, D_B_loss: 0.0411, G_A_loss: 0.3017, G_B_loss: 0.7165\n",
      "Epoch [38/200], Step [441/1067], D_A_loss: 0.0402, D_B_loss: 0.3715, G_A_loss: 0.9146, G_B_loss: 0.9079\n",
      "Epoch [38/200], Step [451/1067], D_A_loss: 0.0353, D_B_loss: 0.0305, G_A_loss: 0.6137, G_B_loss: 0.6779\n",
      "Epoch [38/200], Step [461/1067], D_A_loss: 0.0195, D_B_loss: 0.0842, G_A_loss: 0.6287, G_B_loss: 0.4673\n",
      "Epoch [38/200], Step [471/1067], D_A_loss: 0.1075, D_B_loss: 0.0413, G_A_loss: 0.6938, G_B_loss: 0.7486\n",
      "Epoch [38/200], Step [481/1067], D_A_loss: 0.0451, D_B_loss: 0.0801, G_A_loss: 1.1710, G_B_loss: 0.7683\n",
      "Epoch [38/200], Step [491/1067], D_A_loss: 0.0468, D_B_loss: 0.0380, G_A_loss: 0.6154, G_B_loss: 0.6463\n",
      "Epoch [38/200], Step [501/1067], D_A_loss: 0.1472, D_B_loss: 0.1492, G_A_loss: 0.4860, G_B_loss: 0.8079\n",
      "Epoch [38/200], Step [511/1067], D_A_loss: 0.1101, D_B_loss: 0.0444, G_A_loss: 0.5960, G_B_loss: 0.8025\n",
      "Epoch [38/200], Step [521/1067], D_A_loss: 0.0833, D_B_loss: 0.0205, G_A_loss: 0.9843, G_B_loss: 0.4997\n",
      "Epoch [38/200], Step [531/1067], D_A_loss: 0.0799, D_B_loss: 0.0512, G_A_loss: 0.7128, G_B_loss: 0.8041\n",
      "Epoch [38/200], Step [541/1067], D_A_loss: 0.0446, D_B_loss: 0.1838, G_A_loss: 0.4317, G_B_loss: 0.8473\n",
      "Epoch [38/200], Step [551/1067], D_A_loss: 0.0569, D_B_loss: 0.0685, G_A_loss: 0.9784, G_B_loss: 0.7149\n",
      "Epoch [38/200], Step [561/1067], D_A_loss: 0.0661, D_B_loss: 0.1884, G_A_loss: 0.2943, G_B_loss: 0.9309\n",
      "Epoch [38/200], Step [571/1067], D_A_loss: 0.0707, D_B_loss: 0.0237, G_A_loss: 0.4498, G_B_loss: 0.5062\n",
      "Epoch [38/200], Step [581/1067], D_A_loss: 0.0625, D_B_loss: 0.0654, G_A_loss: 0.7982, G_B_loss: 0.5091\n",
      "Epoch [38/200], Step [591/1067], D_A_loss: 0.0359, D_B_loss: 0.0716, G_A_loss: 0.6206, G_B_loss: 0.3480\n",
      "Epoch [38/200], Step [601/1067], D_A_loss: 0.0829, D_B_loss: 0.0582, G_A_loss: 0.8500, G_B_loss: 0.7412\n",
      "Epoch [38/200], Step [611/1067], D_A_loss: 0.1619, D_B_loss: 0.0310, G_A_loss: 0.7331, G_B_loss: 0.2040\n",
      "Epoch [38/200], Step [621/1067], D_A_loss: 0.0945, D_B_loss: 0.0281, G_A_loss: 0.9060, G_B_loss: 0.4147\n",
      "Epoch [38/200], Step [631/1067], D_A_loss: 0.0331, D_B_loss: 0.0310, G_A_loss: 0.8882, G_B_loss: 0.5091\n",
      "Epoch [38/200], Step [641/1067], D_A_loss: 0.0636, D_B_loss: 0.0879, G_A_loss: 0.3636, G_B_loss: 0.7177\n",
      "Epoch [38/200], Step [651/1067], D_A_loss: 0.0677, D_B_loss: 0.0186, G_A_loss: 0.9480, G_B_loss: 0.5271\n",
      "Epoch [38/200], Step [661/1067], D_A_loss: 0.0240, D_B_loss: 0.0341, G_A_loss: 0.5749, G_B_loss: 0.8512\n",
      "Epoch [38/200], Step [671/1067], D_A_loss: 0.0348, D_B_loss: 0.0391, G_A_loss: 0.6312, G_B_loss: 0.9932\n",
      "Epoch [38/200], Step [681/1067], D_A_loss: 0.0326, D_B_loss: 0.0110, G_A_loss: 0.8404, G_B_loss: 0.5134\n",
      "Epoch [38/200], Step [691/1067], D_A_loss: 0.0719, D_B_loss: 0.0252, G_A_loss: 0.8235, G_B_loss: 0.3362\n",
      "Epoch [38/200], Step [701/1067], D_A_loss: 0.0894, D_B_loss: 0.0556, G_A_loss: 0.8095, G_B_loss: 0.5114\n",
      "Epoch [38/200], Step [711/1067], D_A_loss: 0.1617, D_B_loss: 0.0687, G_A_loss: 0.7399, G_B_loss: 0.5198\n",
      "Epoch [38/200], Step [721/1067], D_A_loss: 0.0939, D_B_loss: 0.0442, G_A_loss: 0.7443, G_B_loss: 0.4253\n",
      "Epoch [38/200], Step [731/1067], D_A_loss: 0.0355, D_B_loss: 0.0309, G_A_loss: 0.8628, G_B_loss: 0.8327\n",
      "Epoch [38/200], Step [741/1067], D_A_loss: 0.1599, D_B_loss: 0.0152, G_A_loss: 0.9123, G_B_loss: 0.2837\n",
      "Epoch [38/200], Step [751/1067], D_A_loss: 0.0527, D_B_loss: 0.0572, G_A_loss: 1.1223, G_B_loss: 0.6587\n",
      "Epoch [38/200], Step [761/1067], D_A_loss: 0.0397, D_B_loss: 0.1294, G_A_loss: 0.7016, G_B_loss: 1.0539\n",
      "Epoch [38/200], Step [771/1067], D_A_loss: 0.1118, D_B_loss: 0.2326, G_A_loss: 1.1482, G_B_loss: 0.2599\n",
      "Epoch [38/200], Step [781/1067], D_A_loss: 0.0338, D_B_loss: 0.1249, G_A_loss: 0.4261, G_B_loss: 0.5047\n",
      "Epoch [38/200], Step [791/1067], D_A_loss: 0.1127, D_B_loss: 0.1200, G_A_loss: 0.3732, G_B_loss: 0.9952\n",
      "Epoch [38/200], Step [801/1067], D_A_loss: 0.0473, D_B_loss: 0.0119, G_A_loss: 0.8795, G_B_loss: 0.6057\n",
      "Epoch [38/200], Step [811/1067], D_A_loss: 0.0355, D_B_loss: 0.0428, G_A_loss: 0.9322, G_B_loss: 0.6437\n",
      "Epoch [38/200], Step [821/1067], D_A_loss: 0.1835, D_B_loss: 0.0292, G_A_loss: 0.7953, G_B_loss: 0.7802\n",
      "Epoch [38/200], Step [831/1067], D_A_loss: 0.1259, D_B_loss: 0.0286, G_A_loss: 0.7113, G_B_loss: 0.4631\n",
      "Epoch [38/200], Step [841/1067], D_A_loss: 0.1677, D_B_loss: 0.0647, G_A_loss: 1.1952, G_B_loss: 0.2384\n",
      "Epoch [38/200], Step [851/1067], D_A_loss: 0.1170, D_B_loss: 0.0790, G_A_loss: 0.8768, G_B_loss: 0.8369\n",
      "Epoch [38/200], Step [861/1067], D_A_loss: 0.0868, D_B_loss: 0.1878, G_A_loss: 0.7467, G_B_loss: 0.9386\n",
      "Epoch [38/200], Step [871/1067], D_A_loss: 0.1271, D_B_loss: 0.0201, G_A_loss: 0.6806, G_B_loss: 0.3468\n",
      "Epoch [38/200], Step [881/1067], D_A_loss: 0.1089, D_B_loss: 0.1379, G_A_loss: 0.2644, G_B_loss: 0.3376\n",
      "Epoch [38/200], Step [891/1067], D_A_loss: 0.0475, D_B_loss: 0.0474, G_A_loss: 0.6667, G_B_loss: 0.4807\n",
      "Epoch [38/200], Step [901/1067], D_A_loss: 0.0640, D_B_loss: 0.0621, G_A_loss: 1.0772, G_B_loss: 0.5300\n",
      "Epoch [38/200], Step [911/1067], D_A_loss: 0.1260, D_B_loss: 0.0274, G_A_loss: 0.4177, G_B_loss: 0.3018\n",
      "Epoch [38/200], Step [921/1067], D_A_loss: 0.0377, D_B_loss: 0.1203, G_A_loss: 0.3268, G_B_loss: 0.5456\n",
      "Epoch [38/200], Step [931/1067], D_A_loss: 0.0901, D_B_loss: 0.0148, G_A_loss: 0.6330, G_B_loss: 0.6849\n",
      "Epoch [38/200], Step [941/1067], D_A_loss: 0.0807, D_B_loss: 0.0567, G_A_loss: 0.9942, G_B_loss: 0.4900\n",
      "Epoch [38/200], Step [951/1067], D_A_loss: 0.1179, D_B_loss: 0.0590, G_A_loss: 0.5791, G_B_loss: 0.3333\n",
      "Epoch [38/200], Step [961/1067], D_A_loss: 0.0591, D_B_loss: 0.0310, G_A_loss: 0.8897, G_B_loss: 0.6252\n",
      "Epoch [38/200], Step [971/1067], D_A_loss: 0.0913, D_B_loss: 0.1284, G_A_loss: 0.3773, G_B_loss: 0.3914\n",
      "Epoch [38/200], Step [981/1067], D_A_loss: 0.0768, D_B_loss: 0.0379, G_A_loss: 0.6863, G_B_loss: 0.3069\n",
      "Epoch [38/200], Step [991/1067], D_A_loss: 0.0268, D_B_loss: 0.1311, G_A_loss: 0.2590, G_B_loss: 0.5489\n",
      "Epoch [38/200], Step [1001/1067], D_A_loss: 0.0673, D_B_loss: 0.0662, G_A_loss: 1.0977, G_B_loss: 0.5244\n",
      "Epoch [38/200], Step [1011/1067], D_A_loss: 0.2310, D_B_loss: 0.0219, G_A_loss: 0.9561, G_B_loss: 0.2350\n",
      "Epoch [38/200], Step [1021/1067], D_A_loss: 0.1560, D_B_loss: 0.0204, G_A_loss: 0.8231, G_B_loss: 0.2541\n",
      "Epoch [38/200], Step [1031/1067], D_A_loss: 0.1614, D_B_loss: 0.0403, G_A_loss: 0.8431, G_B_loss: 0.2984\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [38/200], Step [1041/1067], D_A_loss: 0.0719, D_B_loss: 0.0164, G_A_loss: 0.9021, G_B_loss: 1.2257\n",
      "Epoch [38/200], Step [1051/1067], D_A_loss: 0.0909, D_B_loss: 0.0469, G_A_loss: 0.6340, G_B_loss: 0.4303\n",
      "Epoch [38/200], Step [1061/1067], D_A_loss: 0.0811, D_B_loss: 0.1727, G_A_loss: 0.8681, G_B_loss: 0.4728\n",
      "Epoch [39/200], Step [1/1067], D_A_loss: 0.1505, D_B_loss: 0.0664, G_A_loss: 0.8984, G_B_loss: 0.4226\n",
      "Epoch [39/200], Step [11/1067], D_A_loss: 0.1268, D_B_loss: 0.0864, G_A_loss: 0.3604, G_B_loss: 0.3349\n",
      "Epoch [39/200], Step [21/1067], D_A_loss: 0.0314, D_B_loss: 0.0154, G_A_loss: 0.7638, G_B_loss: 0.7524\n",
      "Epoch [39/200], Step [31/1067], D_A_loss: 0.0582, D_B_loss: 0.1150, G_A_loss: 0.4827, G_B_loss: 0.9549\n",
      "Epoch [39/200], Step [41/1067], D_A_loss: 0.0781, D_B_loss: 0.0162, G_A_loss: 0.6612, G_B_loss: 0.3268\n",
      "Epoch [39/200], Step [51/1067], D_A_loss: 0.0613, D_B_loss: 0.2602, G_A_loss: 1.0111, G_B_loss: 0.5806\n",
      "Epoch [39/200], Step [61/1067], D_A_loss: 0.1435, D_B_loss: 0.0413, G_A_loss: 0.7718, G_B_loss: 0.7757\n",
      "Epoch [39/200], Step [71/1067], D_A_loss: 0.2001, D_B_loss: 0.0861, G_A_loss: 0.8390, G_B_loss: 0.3926\n",
      "Epoch [39/200], Step [81/1067], D_A_loss: 0.0423, D_B_loss: 0.0219, G_A_loss: 0.3508, G_B_loss: 0.4451\n",
      "Epoch [39/200], Step [91/1067], D_A_loss: 0.1210, D_B_loss: 0.0523, G_A_loss: 0.8106, G_B_loss: 0.6703\n",
      "Epoch [39/200], Step [101/1067], D_A_loss: 0.0847, D_B_loss: 0.0259, G_A_loss: 0.8562, G_B_loss: 0.3039\n",
      "Epoch [39/200], Step [111/1067], D_A_loss: 0.0575, D_B_loss: 0.0284, G_A_loss: 0.8939, G_B_loss: 0.2395\n",
      "Epoch [39/200], Step [121/1067], D_A_loss: 0.1259, D_B_loss: 0.0329, G_A_loss: 0.9470, G_B_loss: 0.3877\n",
      "Epoch [39/200], Step [131/1067], D_A_loss: 0.0561, D_B_loss: 0.0287, G_A_loss: 0.7219, G_B_loss: 0.4651\n",
      "Epoch [39/200], Step [141/1067], D_A_loss: 0.0604, D_B_loss: 0.0985, G_A_loss: 0.4981, G_B_loss: 0.2013\n",
      "Epoch [39/200], Step [151/1067], D_A_loss: 0.0730, D_B_loss: 0.0220, G_A_loss: 0.7889, G_B_loss: 0.4503\n",
      "Epoch [39/200], Step [161/1067], D_A_loss: 0.1299, D_B_loss: 0.0297, G_A_loss: 1.1831, G_B_loss: 0.3141\n",
      "Epoch [39/200], Step [171/1067], D_A_loss: 0.1244, D_B_loss: 0.0909, G_A_loss: 0.7948, G_B_loss: 0.4496\n",
      "Epoch [39/200], Step [181/1067], D_A_loss: 0.0244, D_B_loss: 0.0159, G_A_loss: 0.5341, G_B_loss: 0.7766\n",
      "Epoch [39/200], Step [191/1067], D_A_loss: 0.0266, D_B_loss: 0.0516, G_A_loss: 0.7596, G_B_loss: 0.3574\n",
      "Epoch [39/200], Step [201/1067], D_A_loss: 0.3652, D_B_loss: 0.0668, G_A_loss: 1.2116, G_B_loss: 0.0766\n",
      "Epoch [39/200], Step [211/1067], D_A_loss: 0.1016, D_B_loss: 0.0202, G_A_loss: 0.8038, G_B_loss: 0.5745\n",
      "Epoch [39/200], Step [221/1067], D_A_loss: 0.1090, D_B_loss: 0.0684, G_A_loss: 0.5097, G_B_loss: 0.7155\n",
      "Epoch [39/200], Step [231/1067], D_A_loss: 0.0846, D_B_loss: 0.0714, G_A_loss: 0.5301, G_B_loss: 0.1682\n",
      "Epoch [39/200], Step [241/1067], D_A_loss: 0.1044, D_B_loss: 0.1033, G_A_loss: 0.4119, G_B_loss: 0.7986\n",
      "Epoch [39/200], Step [251/1067], D_A_loss: 0.0481, D_B_loss: 0.0309, G_A_loss: 1.0767, G_B_loss: 0.4711\n",
      "Epoch [39/200], Step [261/1067], D_A_loss: 0.0451, D_B_loss: 0.0362, G_A_loss: 0.7190, G_B_loss: 0.5491\n",
      "Epoch [39/200], Step [271/1067], D_A_loss: 0.0378, D_B_loss: 0.1345, G_A_loss: 0.8544, G_B_loss: 0.5085\n",
      "Epoch [39/200], Step [281/1067], D_A_loss: 0.0681, D_B_loss: 0.0327, G_A_loss: 1.0103, G_B_loss: 0.7193\n",
      "Epoch [39/200], Step [291/1067], D_A_loss: 0.0452, D_B_loss: 0.1471, G_A_loss: 1.0352, G_B_loss: 0.3618\n",
      "Epoch [39/200], Step [301/1067], D_A_loss: 0.0637, D_B_loss: 0.1168, G_A_loss: 0.6359, G_B_loss: 0.7428\n",
      "Epoch [39/200], Step [311/1067], D_A_loss: 0.0640, D_B_loss: 0.0288, G_A_loss: 0.2118, G_B_loss: 0.8633\n",
      "Epoch [39/200], Step [321/1067], D_A_loss: 0.0911, D_B_loss: 0.0458, G_A_loss: 0.8120, G_B_loss: 0.7749\n",
      "Epoch [39/200], Step [331/1067], D_A_loss: 0.1105, D_B_loss: 0.0560, G_A_loss: 0.7593, G_B_loss: 0.6288\n",
      "Epoch [39/200], Step [341/1067], D_A_loss: 0.1025, D_B_loss: 0.0616, G_A_loss: 0.5055, G_B_loss: 0.4636\n",
      "Epoch [39/200], Step [351/1067], D_A_loss: 0.0424, D_B_loss: 0.0862, G_A_loss: 0.2693, G_B_loss: 0.7564\n",
      "Epoch [39/200], Step [361/1067], D_A_loss: 0.0430, D_B_loss: 0.0237, G_A_loss: 0.9032, G_B_loss: 0.4674\n",
      "Epoch [39/200], Step [371/1067], D_A_loss: 0.0816, D_B_loss: 0.1051, G_A_loss: 0.5693, G_B_loss: 0.4639\n",
      "Epoch [39/200], Step [381/1067], D_A_loss: 0.0450, D_B_loss: 0.0266, G_A_loss: 0.9950, G_B_loss: 0.4970\n",
      "Epoch [39/200], Step [391/1067], D_A_loss: 0.0744, D_B_loss: 0.0443, G_A_loss: 0.6020, G_B_loss: 0.5424\n",
      "Epoch [39/200], Step [401/1067], D_A_loss: 0.0689, D_B_loss: 0.0629, G_A_loss: 0.5095, G_B_loss: 0.4931\n",
      "Epoch [39/200], Step [411/1067], D_A_loss: 0.0589, D_B_loss: 0.0455, G_A_loss: 0.3274, G_B_loss: 0.5725\n",
      "Epoch [39/200], Step [421/1067], D_A_loss: 0.0653, D_B_loss: 0.0932, G_A_loss: 0.7406, G_B_loss: 0.7924\n",
      "Epoch [39/200], Step [431/1067], D_A_loss: 0.1296, D_B_loss: 0.0669, G_A_loss: 0.6511, G_B_loss: 0.4796\n",
      "Epoch [39/200], Step [441/1067], D_A_loss: 0.2416, D_B_loss: 0.0228, G_A_loss: 0.8850, G_B_loss: 1.0676\n",
      "Epoch [39/200], Step [451/1067], D_A_loss: 0.1795, D_B_loss: 0.0158, G_A_loss: 0.8246, G_B_loss: 0.6163\n",
      "Epoch [39/200], Step [461/1067], D_A_loss: 0.0320, D_B_loss: 0.0525, G_A_loss: 0.5550, G_B_loss: 0.7215\n",
      "Epoch [39/200], Step [471/1067], D_A_loss: 0.0607, D_B_loss: 0.1035, G_A_loss: 0.4459, G_B_loss: 0.2630\n",
      "Epoch [39/200], Step [481/1067], D_A_loss: 0.1264, D_B_loss: 0.0458, G_A_loss: 0.6228, G_B_loss: 0.6124\n",
      "Epoch [39/200], Step [491/1067], D_A_loss: 0.0293, D_B_loss: 0.0439, G_A_loss: 0.8894, G_B_loss: 0.3441\n",
      "Epoch [39/200], Step [501/1067], D_A_loss: 0.1416, D_B_loss: 0.0570, G_A_loss: 0.5454, G_B_loss: 0.6204\n",
      "Epoch [39/200], Step [511/1067], D_A_loss: 0.1517, D_B_loss: 0.0740, G_A_loss: 0.5227, G_B_loss: 0.3493\n",
      "Epoch [39/200], Step [521/1067], D_A_loss: 0.1927, D_B_loss: 0.0254, G_A_loss: 0.9142, G_B_loss: 0.2113\n",
      "Epoch [39/200], Step [531/1067], D_A_loss: 0.1336, D_B_loss: 0.0164, G_A_loss: 0.4261, G_B_loss: 0.3906\n",
      "Epoch [39/200], Step [541/1067], D_A_loss: 0.0691, D_B_loss: 0.0111, G_A_loss: 1.2248, G_B_loss: 0.5122\n",
      "Epoch [39/200], Step [551/1067], D_A_loss: 0.1967, D_B_loss: 0.0193, G_A_loss: 1.0555, G_B_loss: 0.2231\n",
      "Epoch [39/200], Step [561/1067], D_A_loss: 0.2043, D_B_loss: 0.0558, G_A_loss: 0.2670, G_B_loss: 0.4944\n",
      "Epoch [39/200], Step [571/1067], D_A_loss: 0.0988, D_B_loss: 0.0100, G_A_loss: 1.0744, G_B_loss: 0.8899\n",
      "Epoch [39/200], Step [581/1067], D_A_loss: 0.1368, D_B_loss: 0.0756, G_A_loss: 1.2204, G_B_loss: 0.4177\n",
      "Epoch [39/200], Step [591/1067], D_A_loss: 0.0704, D_B_loss: 0.2062, G_A_loss: 0.9030, G_B_loss: 0.5039\n",
      "Epoch [39/200], Step [601/1067], D_A_loss: 0.0446, D_B_loss: 0.1380, G_A_loss: 0.4702, G_B_loss: 0.3533\n",
      "Epoch [39/200], Step [611/1067], D_A_loss: 0.0945, D_B_loss: 0.0706, G_A_loss: 0.5486, G_B_loss: 0.4310\n",
      "Epoch [39/200], Step [621/1067], D_A_loss: 0.1571, D_B_loss: 0.0150, G_A_loss: 0.7492, G_B_loss: 0.4965\n",
      "Epoch [39/200], Step [631/1067], D_A_loss: 0.2852, D_B_loss: 0.0446, G_A_loss: 0.7306, G_B_loss: 0.5398\n",
      "Epoch [39/200], Step [641/1067], D_A_loss: 0.1265, D_B_loss: 0.1354, G_A_loss: 0.3664, G_B_loss: 0.3055\n",
      "Epoch [39/200], Step [651/1067], D_A_loss: 0.0229, D_B_loss: 0.0387, G_A_loss: 0.8248, G_B_loss: 0.3204\n",
      "Epoch [39/200], Step [661/1067], D_A_loss: 0.1094, D_B_loss: 0.0386, G_A_loss: 0.8760, G_B_loss: 0.3917\n",
      "Epoch [39/200], Step [671/1067], D_A_loss: 0.1579, D_B_loss: 0.0298, G_A_loss: 0.8707, G_B_loss: 0.4401\n",
      "Epoch [39/200], Step [681/1067], D_A_loss: 0.0867, D_B_loss: 0.0139, G_A_loss: 0.7811, G_B_loss: 0.3769\n",
      "Epoch [39/200], Step [691/1067], D_A_loss: 0.1910, D_B_loss: 0.1071, G_A_loss: 0.3437, G_B_loss: 0.2236\n",
      "Epoch [39/200], Step [701/1067], D_A_loss: 0.3960, D_B_loss: 0.0358, G_A_loss: 0.7001, G_B_loss: 0.0479\n",
      "Epoch [39/200], Step [711/1067], D_A_loss: 0.0590, D_B_loss: 0.0265, G_A_loss: 0.9120, G_B_loss: 0.5273\n",
      "Epoch [39/200], Step [721/1067], D_A_loss: 0.0851, D_B_loss: 0.0299, G_A_loss: 0.7292, G_B_loss: 0.6094\n",
      "Epoch [39/200], Step [731/1067], D_A_loss: 0.0996, D_B_loss: 0.1263, G_A_loss: 0.2994, G_B_loss: 0.3321\n",
      "Epoch [39/200], Step [741/1067], D_A_loss: 0.0259, D_B_loss: 0.0582, G_A_loss: 0.5339, G_B_loss: 0.4279\n",
      "Epoch [39/200], Step [751/1067], D_A_loss: 0.1628, D_B_loss: 0.1107, G_A_loss: 0.4725, G_B_loss: 0.4812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [39/200], Step [761/1067], D_A_loss: 0.1185, D_B_loss: 0.1037, G_A_loss: 0.4017, G_B_loss: 0.3612\n",
      "Epoch [39/200], Step [771/1067], D_A_loss: 0.1725, D_B_loss: 0.0735, G_A_loss: 0.5643, G_B_loss: 0.2191\n",
      "Epoch [39/200], Step [781/1067], D_A_loss: 0.0713, D_B_loss: 0.0805, G_A_loss: 0.6832, G_B_loss: 0.5061\n",
      "Epoch [39/200], Step [791/1067], D_A_loss: 0.0572, D_B_loss: 0.0614, G_A_loss: 0.2439, G_B_loss: 0.5756\n",
      "Epoch [39/200], Step [801/1067], D_A_loss: 0.1732, D_B_loss: 0.0571, G_A_loss: 0.5620, G_B_loss: 0.4161\n",
      "Epoch [39/200], Step [811/1067], D_A_loss: 0.0968, D_B_loss: 0.1449, G_A_loss: 0.2995, G_B_loss: 0.7278\n",
      "Epoch [39/200], Step [821/1067], D_A_loss: 0.0528, D_B_loss: 0.0468, G_A_loss: 0.7477, G_B_loss: 0.3152\n",
      "Epoch [39/200], Step [831/1067], D_A_loss: 0.2046, D_B_loss: 0.0937, G_A_loss: 0.4329, G_B_loss: 0.1842\n",
      "Epoch [39/200], Step [841/1067], D_A_loss: 0.0788, D_B_loss: 0.0288, G_A_loss: 1.0139, G_B_loss: 0.2869\n",
      "Epoch [39/200], Step [851/1067], D_A_loss: 0.0780, D_B_loss: 0.0200, G_A_loss: 1.0119, G_B_loss: 0.3487\n",
      "Epoch [39/200], Step [861/1067], D_A_loss: 0.0650, D_B_loss: 0.0492, G_A_loss: 0.6644, G_B_loss: 0.6459\n",
      "Epoch [39/200], Step [871/1067], D_A_loss: 0.0951, D_B_loss: 0.0540, G_A_loss: 0.6932, G_B_loss: 0.4521\n",
      "Epoch [39/200], Step [881/1067], D_A_loss: 0.0582, D_B_loss: 0.0274, G_A_loss: 0.7249, G_B_loss: 0.3962\n",
      "Epoch [39/200], Step [891/1067], D_A_loss: 0.1409, D_B_loss: 0.0676, G_A_loss: 0.7322, G_B_loss: 0.3275\n",
      "Epoch [39/200], Step [901/1067], D_A_loss: 0.1344, D_B_loss: 0.0476, G_A_loss: 0.3708, G_B_loss: 0.2752\n",
      "Epoch [39/200], Step [911/1067], D_A_loss: 0.0218, D_B_loss: 0.0759, G_A_loss: 1.0514, G_B_loss: 0.6475\n",
      "Epoch [39/200], Step [921/1067], D_A_loss: 0.1140, D_B_loss: 0.1013, G_A_loss: 1.0708, G_B_loss: 0.8882\n",
      "Epoch [39/200], Step [931/1067], D_A_loss: 0.1282, D_B_loss: 0.0848, G_A_loss: 0.5242, G_B_loss: 0.7822\n",
      "Epoch [39/200], Step [941/1067], D_A_loss: 0.0971, D_B_loss: 0.1025, G_A_loss: 0.4047, G_B_loss: 0.5930\n",
      "Epoch [39/200], Step [951/1067], D_A_loss: 0.2532, D_B_loss: 0.0563, G_A_loss: 0.7746, G_B_loss: 0.1461\n",
      "Epoch [39/200], Step [961/1067], D_A_loss: 0.0906, D_B_loss: 0.0353, G_A_loss: 0.8190, G_B_loss: 0.4946\n",
      "Epoch [39/200], Step [971/1067], D_A_loss: 0.0345, D_B_loss: 0.4171, G_A_loss: 0.8837, G_B_loss: 0.7693\n",
      "Epoch [39/200], Step [981/1067], D_A_loss: 0.2173, D_B_loss: 0.0726, G_A_loss: 0.7165, G_B_loss: 0.8417\n",
      "Epoch [39/200], Step [991/1067], D_A_loss: 0.1230, D_B_loss: 0.0273, G_A_loss: 0.9806, G_B_loss: 0.8663\n",
      "Epoch [39/200], Step [1001/1067], D_A_loss: 0.0894, D_B_loss: 0.0782, G_A_loss: 1.2389, G_B_loss: 0.5813\n",
      "Epoch [39/200], Step [1011/1067], D_A_loss: 0.0413, D_B_loss: 0.0269, G_A_loss: 0.7056, G_B_loss: 0.4791\n",
      "Epoch [39/200], Step [1021/1067], D_A_loss: 0.0892, D_B_loss: 0.0245, G_A_loss: 0.7254, G_B_loss: 0.2882\n",
      "Epoch [39/200], Step [1031/1067], D_A_loss: 0.0590, D_B_loss: 0.0151, G_A_loss: 0.6502, G_B_loss: 0.4830\n",
      "Epoch [39/200], Step [1041/1067], D_A_loss: 0.0936, D_B_loss: 0.0231, G_A_loss: 0.8526, G_B_loss: 0.3976\n",
      "Epoch [39/200], Step [1051/1067], D_A_loss: 0.1021, D_B_loss: 0.0662, G_A_loss: 0.3645, G_B_loss: 0.2928\n",
      "Epoch [39/200], Step [1061/1067], D_A_loss: 0.1767, D_B_loss: 0.0493, G_A_loss: 0.7439, G_B_loss: 0.7811\n",
      "Epoch [40/200], Step [1/1067], D_A_loss: 0.1051, D_B_loss: 0.0397, G_A_loss: 1.3930, G_B_loss: 0.6555\n",
      "Epoch [40/200], Step [11/1067], D_A_loss: 0.0332, D_B_loss: 0.0911, G_A_loss: 1.2282, G_B_loss: 0.5928\n",
      "Epoch [40/200], Step [21/1067], D_A_loss: 0.0521, D_B_loss: 0.0225, G_A_loss: 0.7424, G_B_loss: 0.3044\n",
      "Epoch [40/200], Step [31/1067], D_A_loss: 0.1481, D_B_loss: 0.1486, G_A_loss: 0.3480, G_B_loss: 0.6877\n",
      "Epoch [40/200], Step [41/1067], D_A_loss: 0.0777, D_B_loss: 0.0692, G_A_loss: 0.4388, G_B_loss: 0.5967\n",
      "Epoch [40/200], Step [51/1067], D_A_loss: 0.0260, D_B_loss: 0.0684, G_A_loss: 0.4990, G_B_loss: 0.3390\n",
      "Epoch [40/200], Step [61/1067], D_A_loss: 0.0593, D_B_loss: 0.0206, G_A_loss: 0.6831, G_B_loss: 0.6706\n",
      "Epoch [40/200], Step [71/1067], D_A_loss: 0.2295, D_B_loss: 0.0138, G_A_loss: 0.6289, G_B_loss: 0.5164\n",
      "Epoch [40/200], Step [81/1067], D_A_loss: 0.0632, D_B_loss: 0.0359, G_A_loss: 0.6434, G_B_loss: 0.5113\n",
      "Epoch [40/200], Step [91/1067], D_A_loss: 0.0920, D_B_loss: 0.0684, G_A_loss: 0.6064, G_B_loss: 0.3010\n",
      "Epoch [40/200], Step [101/1067], D_A_loss: 0.0553, D_B_loss: 0.0162, G_A_loss: 0.8635, G_B_loss: 0.3824\n",
      "Epoch [40/200], Step [111/1067], D_A_loss: 0.1246, D_B_loss: 0.0821, G_A_loss: 1.3711, G_B_loss: 0.4904\n",
      "Epoch [40/200], Step [121/1067], D_A_loss: 0.0957, D_B_loss: 0.0179, G_A_loss: 0.8441, G_B_loss: 0.4532\n",
      "Epoch [40/200], Step [131/1067], D_A_loss: 0.1287, D_B_loss: 0.0465, G_A_loss: 0.6938, G_B_loss: 0.5678\n",
      "Epoch [40/200], Step [141/1067], D_A_loss: 0.0301, D_B_loss: 0.0588, G_A_loss: 0.9540, G_B_loss: 0.2779\n",
      "Epoch [40/200], Step [151/1067], D_A_loss: 0.1052, D_B_loss: 0.0252, G_A_loss: 0.8366, G_B_loss: 0.7356\n",
      "Epoch [40/200], Step [161/1067], D_A_loss: 0.2609, D_B_loss: 0.0454, G_A_loss: 0.7070, G_B_loss: 0.6058\n",
      "Epoch [40/200], Step [171/1067], D_A_loss: 0.1395, D_B_loss: 0.0743, G_A_loss: 0.6238, G_B_loss: 0.2598\n",
      "Epoch [40/200], Step [181/1067], D_A_loss: 0.0256, D_B_loss: 0.0357, G_A_loss: 0.6820, G_B_loss: 1.2185\n",
      "Epoch [40/200], Step [191/1067], D_A_loss: 0.1441, D_B_loss: 0.0490, G_A_loss: 0.8459, G_B_loss: 0.3922\n",
      "Epoch [40/200], Step [201/1067], D_A_loss: 0.1119, D_B_loss: 0.0179, G_A_loss: 0.9566, G_B_loss: 0.3554\n",
      "Epoch [40/200], Step [211/1067], D_A_loss: 0.0425, D_B_loss: 0.0458, G_A_loss: 0.6193, G_B_loss: 0.6345\n",
      "Epoch [40/200], Step [221/1067], D_A_loss: 0.1333, D_B_loss: 0.0301, G_A_loss: 0.8944, G_B_loss: 0.5584\n",
      "Epoch [40/200], Step [231/1067], D_A_loss: 0.0453, D_B_loss: 0.0173, G_A_loss: 0.8667, G_B_loss: 0.5527\n",
      "Epoch [40/200], Step [241/1067], D_A_loss: 0.1225, D_B_loss: 0.0533, G_A_loss: 1.1561, G_B_loss: 0.6295\n",
      "Epoch [40/200], Step [251/1067], D_A_loss: 0.1130, D_B_loss: 0.0252, G_A_loss: 0.7704, G_B_loss: 0.4096\n",
      "Epoch [40/200], Step [261/1067], D_A_loss: 0.1478, D_B_loss: 0.0318, G_A_loss: 0.6607, G_B_loss: 0.5658\n",
      "Epoch [40/200], Step [271/1067], D_A_loss: 0.1476, D_B_loss: 0.0565, G_A_loss: 0.6199, G_B_loss: 0.5857\n",
      "Epoch [40/200], Step [281/1067], D_A_loss: 0.1156, D_B_loss: 0.0931, G_A_loss: 1.0251, G_B_loss: 0.4759\n",
      "Epoch [40/200], Step [291/1067], D_A_loss: 0.0498, D_B_loss: 0.1132, G_A_loss: 0.3789, G_B_loss: 0.3027\n",
      "Epoch [40/200], Step [301/1067], D_A_loss: 0.0153, D_B_loss: 0.0133, G_A_loss: 0.6777, G_B_loss: 0.7959\n",
      "Epoch [40/200], Step [311/1067], D_A_loss: 0.0951, D_B_loss: 0.0332, G_A_loss: 0.6387, G_B_loss: 0.6554\n",
      "Epoch [40/200], Step [321/1067], D_A_loss: 0.0876, D_B_loss: 0.0273, G_A_loss: 0.4501, G_B_loss: 0.5916\n",
      "Epoch [40/200], Step [331/1067], D_A_loss: 0.1181, D_B_loss: 0.0119, G_A_loss: 0.8546, G_B_loss: 0.3832\n",
      "Epoch [40/200], Step [341/1067], D_A_loss: 0.0571, D_B_loss: 0.1179, G_A_loss: 0.3790, G_B_loss: 0.6476\n",
      "Epoch [40/200], Step [351/1067], D_A_loss: 0.0837, D_B_loss: 0.1275, G_A_loss: 1.4272, G_B_loss: 1.1677\n",
      "Epoch [40/200], Step [361/1067], D_A_loss: 0.0931, D_B_loss: 0.1433, G_A_loss: 0.6537, G_B_loss: 0.4015\n",
      "Epoch [40/200], Step [371/1067], D_A_loss: 0.0565, D_B_loss: 0.0432, G_A_loss: 0.6688, G_B_loss: 0.6960\n",
      "Epoch [40/200], Step [381/1067], D_A_loss: 0.0668, D_B_loss: 0.0169, G_A_loss: 0.7780, G_B_loss: 0.5094\n",
      "Epoch [40/200], Step [391/1067], D_A_loss: 0.1070, D_B_loss: 0.0371, G_A_loss: 0.3300, G_B_loss: 0.4539\n",
      "Epoch [40/200], Step [401/1067], D_A_loss: 0.1272, D_B_loss: 0.0421, G_A_loss: 0.6128, G_B_loss: 0.3354\n",
      "Epoch [40/200], Step [411/1067], D_A_loss: 0.0671, D_B_loss: 0.0386, G_A_loss: 0.4533, G_B_loss: 0.7666\n",
      "Epoch [40/200], Step [421/1067], D_A_loss: 0.0471, D_B_loss: 0.0229, G_A_loss: 1.1171, G_B_loss: 0.4437\n",
      "Epoch [40/200], Step [431/1067], D_A_loss: 0.0440, D_B_loss: 0.0218, G_A_loss: 0.6513, G_B_loss: 0.6706\n",
      "Epoch [40/200], Step [441/1067], D_A_loss: 0.1249, D_B_loss: 0.0419, G_A_loss: 1.2619, G_B_loss: 0.6970\n",
      "Epoch [40/200], Step [451/1067], D_A_loss: 0.0739, D_B_loss: 0.0297, G_A_loss: 0.5337, G_B_loss: 0.5469\n",
      "Epoch [40/200], Step [461/1067], D_A_loss: 0.1048, D_B_loss: 0.0162, G_A_loss: 0.5072, G_B_loss: 0.1617\n",
      "Epoch [40/200], Step [471/1067], D_A_loss: 0.0587, D_B_loss: 0.1813, G_A_loss: 0.2841, G_B_loss: 0.7026\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [40/200], Step [481/1067], D_A_loss: 0.0675, D_B_loss: 0.0638, G_A_loss: 0.5988, G_B_loss: 0.6434\n",
      "Epoch [40/200], Step [491/1067], D_A_loss: 0.0373, D_B_loss: 0.1421, G_A_loss: 0.4355, G_B_loss: 0.9177\n",
      "Epoch [40/200], Step [501/1067], D_A_loss: 0.1042, D_B_loss: 0.0688, G_A_loss: 1.1014, G_B_loss: 0.7012\n",
      "Epoch [40/200], Step [511/1067], D_A_loss: 0.0372, D_B_loss: 0.0298, G_A_loss: 0.8360, G_B_loss: 0.7956\n",
      "Epoch [40/200], Step [521/1067], D_A_loss: 0.1500, D_B_loss: 0.0356, G_A_loss: 1.3965, G_B_loss: 0.3064\n",
      "Epoch [40/200], Step [531/1067], D_A_loss: 0.0287, D_B_loss: 0.0316, G_A_loss: 0.8442, G_B_loss: 0.7730\n",
      "Epoch [40/200], Step [541/1067], D_A_loss: 0.0834, D_B_loss: 0.0644, G_A_loss: 1.0437, G_B_loss: 0.5710\n",
      "Epoch [40/200], Step [551/1067], D_A_loss: 0.0681, D_B_loss: 0.0312, G_A_loss: 0.6479, G_B_loss: 0.5125\n",
      "Epoch [40/200], Step [561/1067], D_A_loss: 0.1124, D_B_loss: 0.1180, G_A_loss: 0.3158, G_B_loss: 0.3844\n",
      "Epoch [40/200], Step [571/1067], D_A_loss: 0.0644, D_B_loss: 0.0584, G_A_loss: 0.5379, G_B_loss: 0.8827\n",
      "Epoch [40/200], Step [581/1067], D_A_loss: 0.1227, D_B_loss: 0.0366, G_A_loss: 0.7630, G_B_loss: 0.6286\n",
      "Epoch [40/200], Step [591/1067], D_A_loss: 0.0340, D_B_loss: 0.0140, G_A_loss: 0.8673, G_B_loss: 0.1952\n",
      "Epoch [40/200], Step [601/1067], D_A_loss: 0.0690, D_B_loss: 0.0207, G_A_loss: 0.7346, G_B_loss: 0.7138\n",
      "Epoch [40/200], Step [611/1067], D_A_loss: 0.0959, D_B_loss: 0.0256, G_A_loss: 0.5999, G_B_loss: 0.4818\n",
      "Epoch [40/200], Step [621/1067], D_A_loss: 0.0599, D_B_loss: 0.0365, G_A_loss: 0.7069, G_B_loss: 0.4034\n",
      "Epoch [40/200], Step [631/1067], D_A_loss: 0.1095, D_B_loss: 0.1033, G_A_loss: 0.3795, G_B_loss: 0.6795\n",
      "Epoch [40/200], Step [641/1067], D_A_loss: 0.0227, D_B_loss: 0.0392, G_A_loss: 0.6374, G_B_loss: 0.6466\n",
      "Epoch [40/200], Step [651/1067], D_A_loss: 0.1945, D_B_loss: 0.0745, G_A_loss: 0.4699, G_B_loss: 0.2305\n",
      "Epoch [40/200], Step [661/1067], D_A_loss: 0.1710, D_B_loss: 0.0214, G_A_loss: 0.9065, G_B_loss: 1.0368\n",
      "Epoch [40/200], Step [671/1067], D_A_loss: 0.2600, D_B_loss: 0.0225, G_A_loss: 0.8799, G_B_loss: 0.9075\n",
      "Epoch [40/200], Step [681/1067], D_A_loss: 0.0484, D_B_loss: 0.0301, G_A_loss: 0.4812, G_B_loss: 0.5251\n",
      "Epoch [40/200], Step [691/1067], D_A_loss: 0.1065, D_B_loss: 0.1123, G_A_loss: 0.6410, G_B_loss: 0.4898\n",
      "Epoch [40/200], Step [701/1067], D_A_loss: 0.0827, D_B_loss: 0.0802, G_A_loss: 0.5885, G_B_loss: 0.5844\n",
      "Epoch [40/200], Step [711/1067], D_A_loss: 0.1493, D_B_loss: 0.0208, G_A_loss: 0.8871, G_B_loss: 0.2961\n",
      "Epoch [40/200], Step [721/1067], D_A_loss: 0.0244, D_B_loss: 0.0298, G_A_loss: 1.0241, G_B_loss: 0.7475\n",
      "Epoch [40/200], Step [731/1067], D_A_loss: 0.0257, D_B_loss: 0.0249, G_A_loss: 0.8737, G_B_loss: 0.9146\n",
      "Epoch [40/200], Step [741/1067], D_A_loss: 0.0374, D_B_loss: 0.0150, G_A_loss: 1.1305, G_B_loss: 0.5195\n",
      "Epoch [40/200], Step [751/1067], D_A_loss: 0.0770, D_B_loss: 0.0639, G_A_loss: 0.5140, G_B_loss: 0.9699\n",
      "Epoch [40/200], Step [761/1067], D_A_loss: 0.0815, D_B_loss: 0.0355, G_A_loss: 0.7824, G_B_loss: 0.4798\n",
      "Epoch [40/200], Step [771/1067], D_A_loss: 0.0819, D_B_loss: 0.0324, G_A_loss: 0.4752, G_B_loss: 0.4538\n",
      "Epoch [40/200], Step [781/1067], D_A_loss: 0.1345, D_B_loss: 0.0446, G_A_loss: 0.6895, G_B_loss: 0.4372\n",
      "Epoch [40/200], Step [791/1067], D_A_loss: 0.0356, D_B_loss: 0.0474, G_A_loss: 0.5567, G_B_loss: 0.5801\n",
      "Epoch [40/200], Step [801/1067], D_A_loss: 0.0328, D_B_loss: 0.0836, G_A_loss: 0.9505, G_B_loss: 0.6407\n",
      "Epoch [40/200], Step [811/1067], D_A_loss: 0.1990, D_B_loss: 0.0285, G_A_loss: 1.1102, G_B_loss: 0.1535\n",
      "Epoch [40/200], Step [821/1067], D_A_loss: 0.1057, D_B_loss: 0.0447, G_A_loss: 0.5448, G_B_loss: 0.3857\n",
      "Epoch [40/200], Step [831/1067], D_A_loss: 0.0582, D_B_loss: 0.0109, G_A_loss: 0.5231, G_B_loss: 0.5701\n",
      "Epoch [40/200], Step [841/1067], D_A_loss: 0.1641, D_B_loss: 0.0517, G_A_loss: 0.7621, G_B_loss: 0.4587\n",
      "Epoch [40/200], Step [851/1067], D_A_loss: 0.0640, D_B_loss: 0.0213, G_A_loss: 0.5610, G_B_loss: 0.5361\n",
      "Epoch [40/200], Step [861/1067], D_A_loss: 0.0509, D_B_loss: 0.0502, G_A_loss: 0.5521, G_B_loss: 0.5794\n",
      "Epoch [40/200], Step [871/1067], D_A_loss: 0.0379, D_B_loss: 0.0140, G_A_loss: 1.0888, G_B_loss: 0.3587\n",
      "Epoch [40/200], Step [881/1067], D_A_loss: 0.1300, D_B_loss: 0.0573, G_A_loss: 1.1127, G_B_loss: 0.3504\n",
      "Epoch [40/200], Step [891/1067], D_A_loss: 0.0223, D_B_loss: 0.0711, G_A_loss: 0.4421, G_B_loss: 0.7038\n",
      "Epoch [40/200], Step [901/1067], D_A_loss: 0.0687, D_B_loss: 0.0232, G_A_loss: 0.9069, G_B_loss: 0.5424\n",
      "Epoch [40/200], Step [911/1067], D_A_loss: 0.1748, D_B_loss: 0.1103, G_A_loss: 1.0727, G_B_loss: 0.9226\n",
      "Epoch [40/200], Step [921/1067], D_A_loss: 0.0709, D_B_loss: 0.0955, G_A_loss: 0.6440, G_B_loss: 0.6225\n",
      "Epoch [40/200], Step [931/1067], D_A_loss: 0.0553, D_B_loss: 0.0187, G_A_loss: 0.9581, G_B_loss: 0.9417\n",
      "Epoch [40/200], Step [941/1067], D_A_loss: 0.0548, D_B_loss: 0.0204, G_A_loss: 0.8019, G_B_loss: 1.0218\n",
      "Epoch [40/200], Step [951/1067], D_A_loss: 0.0396, D_B_loss: 0.0277, G_A_loss: 0.8334, G_B_loss: 0.9335\n",
      "Epoch [40/200], Step [961/1067], D_A_loss: 0.0737, D_B_loss: 0.0865, G_A_loss: 0.9381, G_B_loss: 0.5151\n",
      "Epoch [40/200], Step [971/1067], D_A_loss: 0.0811, D_B_loss: 0.2428, G_A_loss: 0.3441, G_B_loss: 0.4886\n",
      "Epoch [40/200], Step [981/1067], D_A_loss: 0.1637, D_B_loss: 0.0313, G_A_loss: 0.5163, G_B_loss: 0.7445\n",
      "Epoch [40/200], Step [991/1067], D_A_loss: 0.0366, D_B_loss: 0.0704, G_A_loss: 0.5183, G_B_loss: 0.2461\n",
      "Epoch [40/200], Step [1001/1067], D_A_loss: 0.0806, D_B_loss: 0.0423, G_A_loss: 0.6754, G_B_loss: 0.3472\n",
      "Epoch [40/200], Step [1011/1067], D_A_loss: 0.0733, D_B_loss: 0.0195, G_A_loss: 0.5744, G_B_loss: 0.5801\n",
      "Epoch [40/200], Step [1021/1067], D_A_loss: 0.1496, D_B_loss: 0.0267, G_A_loss: 0.9562, G_B_loss: 0.3479\n",
      "Epoch [40/200], Step [1031/1067], D_A_loss: 0.1002, D_B_loss: 0.0633, G_A_loss: 0.3349, G_B_loss: 0.3894\n",
      "Epoch [40/200], Step [1041/1067], D_A_loss: 0.0964, D_B_loss: 0.0348, G_A_loss: 1.4040, G_B_loss: 0.3900\n",
      "Epoch [40/200], Step [1051/1067], D_A_loss: 0.0599, D_B_loss: 0.0709, G_A_loss: 0.4859, G_B_loss: 0.7413\n",
      "Epoch [40/200], Step [1061/1067], D_A_loss: 0.0222, D_B_loss: 0.0644, G_A_loss: 0.4656, G_B_loss: 0.2495\n",
      "Epoch [41/200], Step [1/1067], D_A_loss: 0.0689, D_B_loss: 0.0366, G_A_loss: 0.9962, G_B_loss: 0.5830\n",
      "Epoch [41/200], Step [11/1067], D_A_loss: 0.0684, D_B_loss: 0.0763, G_A_loss: 0.9341, G_B_loss: 0.5088\n",
      "Epoch [41/200], Step [21/1067], D_A_loss: 0.0186, D_B_loss: 0.1172, G_A_loss: 0.8194, G_B_loss: 0.5366\n",
      "Epoch [41/200], Step [31/1067], D_A_loss: 0.0726, D_B_loss: 0.0479, G_A_loss: 0.6714, G_B_loss: 0.5195\n",
      "Epoch [41/200], Step [41/1067], D_A_loss: 0.1758, D_B_loss: 0.0116, G_A_loss: 0.9166, G_B_loss: 0.2438\n",
      "Epoch [41/200], Step [51/1067], D_A_loss: 0.1309, D_B_loss: 0.0200, G_A_loss: 0.8001, G_B_loss: 0.7580\n",
      "Epoch [41/200], Step [61/1067], D_A_loss: 0.0308, D_B_loss: 0.0299, G_A_loss: 0.6940, G_B_loss: 0.8136\n",
      "Epoch [41/200], Step [71/1067], D_A_loss: 0.1218, D_B_loss: 0.0163, G_A_loss: 0.8145, G_B_loss: 0.7068\n",
      "Epoch [41/200], Step [81/1067], D_A_loss: 0.2658, D_B_loss: 0.1992, G_A_loss: 0.1858, G_B_loss: 0.6988\n",
      "Epoch [41/200], Step [91/1067], D_A_loss: 0.0286, D_B_loss: 0.0346, G_A_loss: 1.2438, G_B_loss: 0.6300\n",
      "Epoch [41/200], Step [101/1067], D_A_loss: 0.0309, D_B_loss: 0.0316, G_A_loss: 0.4249, G_B_loss: 0.4588\n",
      "Epoch [41/200], Step [111/1067], D_A_loss: 0.1172, D_B_loss: 0.0974, G_A_loss: 0.7774, G_B_loss: 0.2493\n",
      "Epoch [41/200], Step [121/1067], D_A_loss: 0.2217, D_B_loss: 0.0410, G_A_loss: 0.5657, G_B_loss: 0.2242\n",
      "Epoch [41/200], Step [131/1067], D_A_loss: 0.1773, D_B_loss: 0.1142, G_A_loss: 0.5724, G_B_loss: 0.2699\n",
      "Epoch [41/200], Step [141/1067], D_A_loss: 0.0720, D_B_loss: 0.0291, G_A_loss: 0.8361, G_B_loss: 0.6367\n",
      "Epoch [41/200], Step [151/1067], D_A_loss: 0.0778, D_B_loss: 0.0219, G_A_loss: 0.8233, G_B_loss: 0.6087\n",
      "Epoch [41/200], Step [161/1067], D_A_loss: 0.1772, D_B_loss: 0.0423, G_A_loss: 0.7055, G_B_loss: 0.3905\n",
      "Epoch [41/200], Step [171/1067], D_A_loss: 0.0254, D_B_loss: 0.0265, G_A_loss: 0.8208, G_B_loss: 0.4446\n",
      "Epoch [41/200], Step [181/1067], D_A_loss: 0.1569, D_B_loss: 0.0352, G_A_loss: 0.3580, G_B_loss: 0.2657\n",
      "Epoch [41/200], Step [191/1067], D_A_loss: 0.0175, D_B_loss: 0.0142, G_A_loss: 1.0030, G_B_loss: 0.7050\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [41/200], Step [201/1067], D_A_loss: 0.2026, D_B_loss: 0.1518, G_A_loss: 0.7359, G_B_loss: 0.2535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [90/200], Step [371/1067], D_A_loss: 0.0852, D_B_loss: 0.0324, G_A_loss: 0.7278, G_B_loss: 0.5105\n",
      "Epoch [90/200], Step [381/1067], D_A_loss: 0.0920, D_B_loss: 0.0260, G_A_loss: 0.9498, G_B_loss: 0.6364\n",
      "Epoch [90/200], Step [391/1067], D_A_loss: 0.1493, D_B_loss: 0.0251, G_A_loss: 0.8083, G_B_loss: 0.3682\n",
      "Epoch [90/200], Step [401/1067], D_A_loss: 0.2392, D_B_loss: 0.0844, G_A_loss: 0.4449, G_B_loss: 0.5453\n",
      "Epoch [90/200], Step [411/1067], D_A_loss: 0.0455, D_B_loss: 0.0213, G_A_loss: 0.8309, G_B_loss: 0.3711\n",
      "Epoch [90/200], Step [421/1067], D_A_loss: 0.1680, D_B_loss: 0.0222, G_A_loss: 0.9697, G_B_loss: 0.6859\n",
      "Epoch [90/200], Step [431/1067], D_A_loss: 0.0436, D_B_loss: 0.0233, G_A_loss: 0.8440, G_B_loss: 0.6141\n",
      "Epoch [90/200], Step [441/1067], D_A_loss: 0.0366, D_B_loss: 0.0379, G_A_loss: 0.5862, G_B_loss: 0.6523\n",
      "Epoch [90/200], Step [451/1067], D_A_loss: 0.1244, D_B_loss: 0.0572, G_A_loss: 0.5883, G_B_loss: 0.3638\n",
      "Epoch [90/200], Step [461/1067], D_A_loss: 0.1101, D_B_loss: 0.0310, G_A_loss: 0.8352, G_B_loss: 0.5735\n",
      "Epoch [90/200], Step [471/1067], D_A_loss: 0.1046, D_B_loss: 0.0343, G_A_loss: 1.3845, G_B_loss: 0.4754\n",
      "Epoch [90/200], Step [481/1067], D_A_loss: 0.0234, D_B_loss: 0.0481, G_A_loss: 1.0001, G_B_loss: 0.7144\n",
      "Epoch [90/200], Step [491/1067], D_A_loss: 0.0566, D_B_loss: 0.0289, G_A_loss: 0.7331, G_B_loss: 0.6571\n",
      "Epoch [90/200], Step [501/1067], D_A_loss: 0.1891, D_B_loss: 0.0158, G_A_loss: 0.5305, G_B_loss: 0.3573\n",
      "Epoch [90/200], Step [511/1067], D_A_loss: 0.0597, D_B_loss: 0.0461, G_A_loss: 1.4697, G_B_loss: 0.6222\n",
      "Epoch [90/200], Step [521/1067], D_A_loss: 0.1488, D_B_loss: 0.0508, G_A_loss: 0.4371, G_B_loss: 1.1080\n",
      "Epoch [90/200], Step [531/1067], D_A_loss: 0.0553, D_B_loss: 0.0701, G_A_loss: 0.6891, G_B_loss: 0.6909\n",
      "Epoch [90/200], Step [541/1067], D_A_loss: 0.0683, D_B_loss: 0.0186, G_A_loss: 0.6279, G_B_loss: 0.3837\n",
      "Epoch [90/200], Step [551/1067], D_A_loss: 0.1234, D_B_loss: 0.0160, G_A_loss: 0.8870, G_B_loss: 0.8767\n",
      "Epoch [90/200], Step [561/1067], D_A_loss: 0.2217, D_B_loss: 0.0110, G_A_loss: 0.9172, G_B_loss: 0.5409\n",
      "Epoch [90/200], Step [571/1067], D_A_loss: 0.1031, D_B_loss: 0.0644, G_A_loss: 0.7394, G_B_loss: 0.5015\n",
      "Epoch [90/200], Step [581/1067], D_A_loss: 0.1353, D_B_loss: 0.0296, G_A_loss: 1.2010, G_B_loss: 0.6210\n",
      "Epoch [90/200], Step [591/1067], D_A_loss: 0.0758, D_B_loss: 0.0140, G_A_loss: 1.4347, G_B_loss: 0.3366\n",
      "Epoch [90/200], Step [601/1067], D_A_loss: 0.1131, D_B_loss: 0.0359, G_A_loss: 1.0977, G_B_loss: 0.3293\n",
      "Epoch [90/200], Step [611/1067], D_A_loss: 0.0874, D_B_loss: 0.0450, G_A_loss: 0.6338, G_B_loss: 0.4623\n",
      "Epoch [90/200], Step [621/1067], D_A_loss: 0.0929, D_B_loss: 0.0200, G_A_loss: 0.6418, G_B_loss: 0.3180\n",
      "Epoch [90/200], Step [631/1067], D_A_loss: 0.0287, D_B_loss: 0.0447, G_A_loss: 0.8151, G_B_loss: 0.4037\n",
      "Epoch [90/200], Step [641/1067], D_A_loss: 0.2338, D_B_loss: 0.0201, G_A_loss: 1.1575, G_B_loss: 0.4378\n",
      "Epoch [90/200], Step [651/1067], D_A_loss: 0.1391, D_B_loss: 0.0623, G_A_loss: 1.1138, G_B_loss: 0.4073\n",
      "Epoch [90/200], Step [661/1067], D_A_loss: 0.0742, D_B_loss: 0.0471, G_A_loss: 0.5861, G_B_loss: 0.3891\n",
      "Epoch [90/200], Step [671/1067], D_A_loss: 0.1403, D_B_loss: 0.0438, G_A_loss: 0.8604, G_B_loss: 0.2901\n",
      "Epoch [90/200], Step [681/1067], D_A_loss: 0.2197, D_B_loss: 0.0230, G_A_loss: 1.0589, G_B_loss: 0.2591\n",
      "Epoch [90/200], Step [691/1067], D_A_loss: 0.0628, D_B_loss: 0.0200, G_A_loss: 0.7749, G_B_loss: 0.2973\n",
      "Epoch [90/200], Step [701/1067], D_A_loss: 0.0447, D_B_loss: 0.0204, G_A_loss: 0.8053, G_B_loss: 0.3138\n",
      "Epoch [90/200], Step [711/1067], D_A_loss: 0.1071, D_B_loss: 0.0717, G_A_loss: 0.9615, G_B_loss: 0.5586\n",
      "Epoch [90/200], Step [721/1067], D_A_loss: 0.1129, D_B_loss: 0.0092, G_A_loss: 0.7443, G_B_loss: 0.6305\n",
      "Epoch [90/200], Step [731/1067], D_A_loss: 0.0206, D_B_loss: 0.0116, G_A_loss: 0.8798, G_B_loss: 0.6563\n",
      "Epoch [90/200], Step [741/1067], D_A_loss: 0.2194, D_B_loss: 0.0259, G_A_loss: 0.5573, G_B_loss: 0.4678\n",
      "Epoch [90/200], Step [751/1067], D_A_loss: 0.0427, D_B_loss: 0.0172, G_A_loss: 0.7774, G_B_loss: 0.8806\n",
      "Epoch [90/200], Step [761/1067], D_A_loss: 0.0521, D_B_loss: 0.0749, G_A_loss: 0.5940, G_B_loss: 0.6466\n",
      "Epoch [90/200], Step [771/1067], D_A_loss: 0.1132, D_B_loss: 0.2951, G_A_loss: 1.2601, G_B_loss: 0.5183\n",
      "Epoch [90/200], Step [781/1067], D_A_loss: 0.0985, D_B_loss: 0.0148, G_A_loss: 0.9569, G_B_loss: 0.4860\n",
      "Epoch [90/200], Step [791/1067], D_A_loss: 0.0610, D_B_loss: 0.0122, G_A_loss: 1.0498, G_B_loss: 0.5434\n",
      "Epoch [90/200], Step [801/1067], D_A_loss: 0.1183, D_B_loss: 0.0901, G_A_loss: 0.5623, G_B_loss: 0.4358\n",
      "Epoch [90/200], Step [811/1067], D_A_loss: 0.0574, D_B_loss: 0.0728, G_A_loss: 0.4493, G_B_loss: 0.7687\n",
      "Epoch [90/200], Step [821/1067], D_A_loss: 0.0750, D_B_loss: 0.0356, G_A_loss: 0.6530, G_B_loss: 0.7717\n",
      "Epoch [90/200], Step [831/1067], D_A_loss: 0.1528, D_B_loss: 0.0652, G_A_loss: 0.6896, G_B_loss: 0.4275\n",
      "Epoch [90/200], Step [841/1067], D_A_loss: 0.1300, D_B_loss: 0.0403, G_A_loss: 0.6671, G_B_loss: 0.5141\n",
      "Epoch [90/200], Step [851/1067], D_A_loss: 0.2221, D_B_loss: 0.0319, G_A_loss: 0.7599, G_B_loss: 0.1870\n",
      "Epoch [90/200], Step [861/1067], D_A_loss: 0.0419, D_B_loss: 0.0333, G_A_loss: 0.6569, G_B_loss: 0.9633\n",
      "Epoch [90/200], Step [871/1067], D_A_loss: 0.1329, D_B_loss: 0.0253, G_A_loss: 0.9368, G_B_loss: 0.4130\n",
      "Epoch [90/200], Step [881/1067], D_A_loss: 0.0922, D_B_loss: 0.0145, G_A_loss: 0.7837, G_B_loss: 0.9793\n",
      "Epoch [90/200], Step [891/1067], D_A_loss: 0.0749, D_B_loss: 0.0107, G_A_loss: 0.9049, G_B_loss: 1.1982\n",
      "Epoch [90/200], Step [901/1067], D_A_loss: 0.0812, D_B_loss: 0.0196, G_A_loss: 0.7013, G_B_loss: 0.4771\n",
      "Epoch [90/200], Step [911/1067], D_A_loss: 0.0449, D_B_loss: 0.0327, G_A_loss: 1.1473, G_B_loss: 0.8195\n",
      "Epoch [90/200], Step [921/1067], D_A_loss: 0.1258, D_B_loss: 0.0672, G_A_loss: 0.8652, G_B_loss: 0.5610\n",
      "Epoch [90/200], Step [931/1067], D_A_loss: 0.0539, D_B_loss: 0.0128, G_A_loss: 1.0549, G_B_loss: 0.6548\n",
      "Epoch [90/200], Step [941/1067], D_A_loss: 0.0420, D_B_loss: 0.0364, G_A_loss: 0.6891, G_B_loss: 0.6758\n",
      "Epoch [90/200], Step [951/1067], D_A_loss: 0.1098, D_B_loss: 0.0312, G_A_loss: 0.7834, G_B_loss: 0.3666\n",
      "Epoch [90/200], Step [961/1067], D_A_loss: 0.0371, D_B_loss: 0.0124, G_A_loss: 0.8986, G_B_loss: 1.0223\n",
      "Epoch [90/200], Step [971/1067], D_A_loss: 0.0514, D_B_loss: 0.0225, G_A_loss: 0.8685, G_B_loss: 1.1208\n",
      "Epoch [90/200], Step [981/1067], D_A_loss: 0.1160, D_B_loss: 0.0182, G_A_loss: 0.8679, G_B_loss: 0.7238\n",
      "Epoch [90/200], Step [991/1067], D_A_loss: 0.1824, D_B_loss: 0.0944, G_A_loss: 1.3225, G_B_loss: 0.5052\n",
      "Epoch [90/200], Step [1001/1067], D_A_loss: 0.0359, D_B_loss: 0.0758, G_A_loss: 0.9668, G_B_loss: 0.5256\n",
      "Epoch [90/200], Step [1011/1067], D_A_loss: 0.0637, D_B_loss: 0.0231, G_A_loss: 0.4304, G_B_loss: 0.5490\n",
      "Epoch [90/200], Step [1021/1067], D_A_loss: 0.0701, D_B_loss: 0.0438, G_A_loss: 0.7894, G_B_loss: 0.2691\n",
      "Epoch [90/200], Step [1031/1067], D_A_loss: 0.1258, D_B_loss: 0.0160, G_A_loss: 1.2188, G_B_loss: 0.3273\n",
      "Epoch [90/200], Step [1041/1067], D_A_loss: 0.0899, D_B_loss: 0.0225, G_A_loss: 0.9415, G_B_loss: 0.7377\n",
      "Epoch [90/200], Step [1051/1067], D_A_loss: 0.2317, D_B_loss: 0.0227, G_A_loss: 0.9328, G_B_loss: 0.7303\n",
      "Epoch [90/200], Step [1061/1067], D_A_loss: 0.0729, D_B_loss: 0.0185, G_A_loss: 0.7698, G_B_loss: 0.5077\n",
      "Epoch [91/200], Step [1/1067], D_A_loss: 0.0218, D_B_loss: 0.0559, G_A_loss: 0.6904, G_B_loss: 0.6085\n",
      "Epoch [91/200], Step [11/1067], D_A_loss: 0.1465, D_B_loss: 0.0112, G_A_loss: 0.9068, G_B_loss: 1.0093\n",
      "Epoch [91/200], Step [21/1067], D_A_loss: 0.1527, D_B_loss: 0.0277, G_A_loss: 0.6780, G_B_loss: 0.6396\n",
      "Epoch [91/200], Step [31/1067], D_A_loss: 0.1627, D_B_loss: 0.0273, G_A_loss: 0.7662, G_B_loss: 0.2448\n",
      "Epoch [91/200], Step [41/1067], D_A_loss: 0.0450, D_B_loss: 0.0381, G_A_loss: 0.6295, G_B_loss: 0.6091\n",
      "Epoch [91/200], Step [51/1067], D_A_loss: 0.1124, D_B_loss: 0.0643, G_A_loss: 0.6817, G_B_loss: 0.6619\n",
      "Epoch [91/200], Step [61/1067], D_A_loss: 0.0531, D_B_loss: 0.0592, G_A_loss: 0.5388, G_B_loss: 0.3428\n",
      "Epoch [91/200], Step [71/1067], D_A_loss: 0.1440, D_B_loss: 0.0739, G_A_loss: 0.9540, G_B_loss: 0.6213\n",
      "Epoch [91/200], Step [81/1067], D_A_loss: 0.1526, D_B_loss: 0.0365, G_A_loss: 0.7638, G_B_loss: 0.5753\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [91/200], Step [91/1067], D_A_loss: 0.0685, D_B_loss: 0.0326, G_A_loss: 0.7773, G_B_loss: 0.7935\n",
      "Epoch [91/200], Step [101/1067], D_A_loss: 0.0335, D_B_loss: 0.1132, G_A_loss: 0.4131, G_B_loss: 0.5762\n",
      "Epoch [91/200], Step [111/1067], D_A_loss: 0.0958, D_B_loss: 0.1625, G_A_loss: 1.6294, G_B_loss: 0.4917\n",
      "Epoch [91/200], Step [121/1067], D_A_loss: 0.2842, D_B_loss: 0.0133, G_A_loss: 0.7018, G_B_loss: 0.9177\n",
      "Epoch [91/200], Step [131/1067], D_A_loss: 0.1659, D_B_loss: 0.0227, G_A_loss: 0.6358, G_B_loss: 0.2370\n",
      "Epoch [91/200], Step [141/1067], D_A_loss: 0.1469, D_B_loss: 0.0171, G_A_loss: 0.5369, G_B_loss: 0.7373\n",
      "Epoch [91/200], Step [151/1067], D_A_loss: 0.0482, D_B_loss: 0.0181, G_A_loss: 1.1683, G_B_loss: 0.2219\n",
      "Epoch [91/200], Step [161/1067], D_A_loss: 0.1628, D_B_loss: 0.0394, G_A_loss: 0.7809, G_B_loss: 0.2923\n",
      "Epoch [91/200], Step [171/1067], D_A_loss: 0.0322, D_B_loss: 0.0545, G_A_loss: 0.5181, G_B_loss: 0.7439\n",
      "Epoch [91/200], Step [181/1067], D_A_loss: 0.1172, D_B_loss: 0.0267, G_A_loss: 0.8251, G_B_loss: 0.4376\n",
      "Epoch [91/200], Step [191/1067], D_A_loss: 0.0604, D_B_loss: 0.0089, G_A_loss: 0.9217, G_B_loss: 0.2634\n",
      "Epoch [91/200], Step [201/1067], D_A_loss: 0.0655, D_B_loss: 0.0419, G_A_loss: 0.5990, G_B_loss: 0.2723\n",
      "Epoch [91/200], Step [211/1067], D_A_loss: 0.0793, D_B_loss: 0.0464, G_A_loss: 0.5739, G_B_loss: 0.4675\n",
      "Epoch [91/200], Step [221/1067], D_A_loss: 0.1085, D_B_loss: 0.0570, G_A_loss: 0.8580, G_B_loss: 0.7851\n",
      "Epoch [91/200], Step [231/1067], D_A_loss: 0.2072, D_B_loss: 0.0099, G_A_loss: 1.0051, G_B_loss: 0.2058\n",
      "Epoch [91/200], Step [241/1067], D_A_loss: 0.0371, D_B_loss: 0.0195, G_A_loss: 0.4640, G_B_loss: 0.6686\n",
      "Epoch [91/200], Step [251/1067], D_A_loss: 0.1956, D_B_loss: 0.0550, G_A_loss: 0.6424, G_B_loss: 0.9594\n",
      "Epoch [91/200], Step [261/1067], D_A_loss: 0.1694, D_B_loss: 0.1431, G_A_loss: 1.1746, G_B_loss: 0.2609\n",
      "Epoch [91/200], Step [271/1067], D_A_loss: 0.1037, D_B_loss: 0.0468, G_A_loss: 1.3647, G_B_loss: 0.5602\n",
      "Epoch [91/200], Step [281/1067], D_A_loss: 0.0465, D_B_loss: 0.0543, G_A_loss: 0.7625, G_B_loss: 0.4317\n",
      "Epoch [91/200], Step [291/1067], D_A_loss: 0.0587, D_B_loss: 0.0111, G_A_loss: 0.9053, G_B_loss: 0.6957\n",
      "Epoch [91/200], Step [301/1067], D_A_loss: 0.1583, D_B_loss: 0.0159, G_A_loss: 0.9895, G_B_loss: 0.8775\n",
      "Epoch [91/200], Step [311/1067], D_A_loss: 0.1122, D_B_loss: 0.1006, G_A_loss: 1.4065, G_B_loss: 0.3592\n",
      "Epoch [91/200], Step [321/1067], D_A_loss: 0.1643, D_B_loss: 0.0378, G_A_loss: 0.9314, G_B_loss: 0.5168\n",
      "Epoch [91/200], Step [331/1067], D_A_loss: 0.1609, D_B_loss: 0.0160, G_A_loss: 0.8210, G_B_loss: 0.3614\n",
      "Epoch [91/200], Step [341/1067], D_A_loss: 0.1446, D_B_loss: 0.0271, G_A_loss: 0.5649, G_B_loss: 0.9200\n",
      "Epoch [91/200], Step [351/1067], D_A_loss: 0.1244, D_B_loss: 0.0314, G_A_loss: 0.6643, G_B_loss: 0.4759\n",
      "Epoch [91/200], Step [361/1067], D_A_loss: 0.1821, D_B_loss: 0.0202, G_A_loss: 0.8301, G_B_loss: 1.1134\n",
      "Epoch [91/200], Step [371/1067], D_A_loss: 0.2207, D_B_loss: 0.0488, G_A_loss: 0.8861, G_B_loss: 0.3029\n",
      "Epoch [91/200], Step [381/1067], D_A_loss: 0.1191, D_B_loss: 0.0319, G_A_loss: 0.7653, G_B_loss: 0.9384\n",
      "Epoch [91/200], Step [391/1067], D_A_loss: 0.1862, D_B_loss: 0.0952, G_A_loss: 0.8065, G_B_loss: 0.4328\n",
      "Epoch [91/200], Step [401/1067], D_A_loss: 0.1126, D_B_loss: 0.0502, G_A_loss: 0.5112, G_B_loss: 0.3686\n",
      "Epoch [91/200], Step [411/1067], D_A_loss: 0.0516, D_B_loss: 0.0179, G_A_loss: 0.4640, G_B_loss: 0.2703\n",
      "Epoch [91/200], Step [421/1067], D_A_loss: 0.1301, D_B_loss: 0.1013, G_A_loss: 0.7000, G_B_loss: 0.4140\n",
      "Epoch [91/200], Step [431/1067], D_A_loss: 0.0883, D_B_loss: 0.0764, G_A_loss: 0.4142, G_B_loss: 0.7708\n",
      "Epoch [91/200], Step [441/1067], D_A_loss: 0.0346, D_B_loss: 0.0202, G_A_loss: 0.6675, G_B_loss: 0.4654\n",
      "Epoch [91/200], Step [451/1067], D_A_loss: 0.1289, D_B_loss: 0.0193, G_A_loss: 1.0341, G_B_loss: 0.4099\n",
      "Epoch [91/200], Step [461/1067], D_A_loss: 0.2460, D_B_loss: 0.0744, G_A_loss: 1.0587, G_B_loss: 0.9889\n",
      "Epoch [91/200], Step [471/1067], D_A_loss: 0.1080, D_B_loss: 0.0190, G_A_loss: 0.8847, G_B_loss: 0.6709\n",
      "Epoch [91/200], Step [481/1067], D_A_loss: 0.1225, D_B_loss: 0.0596, G_A_loss: 0.8116, G_B_loss: 0.4262\n",
      "Epoch [91/200], Step [491/1067], D_A_loss: 0.2241, D_B_loss: 0.0340, G_A_loss: 0.8882, G_B_loss: 0.5264\n",
      "Epoch [91/200], Step [501/1067], D_A_loss: 0.1150, D_B_loss: 0.0129, G_A_loss: 0.9267, G_B_loss: 0.4680\n",
      "Epoch [91/200], Step [511/1067], D_A_loss: 0.1747, D_B_loss: 0.0463, G_A_loss: 0.4537, G_B_loss: 0.5966\n",
      "Epoch [91/200], Step [521/1067], D_A_loss: 0.0581, D_B_loss: 0.0176, G_A_loss: 0.7316, G_B_loss: 0.7392\n",
      "Epoch [91/200], Step [531/1067], D_A_loss: 0.2584, D_B_loss: 0.0261, G_A_loss: 0.5122, G_B_loss: 0.1183\n",
      "Epoch [91/200], Step [541/1067], D_A_loss: 0.1631, D_B_loss: 0.0417, G_A_loss: 0.3888, G_B_loss: 0.2516\n",
      "Epoch [91/200], Step [551/1067], D_A_loss: 0.1228, D_B_loss: 0.0152, G_A_loss: 0.5645, G_B_loss: 0.4832\n",
      "Epoch [91/200], Step [561/1067], D_A_loss: 0.0779, D_B_loss: 0.0561, G_A_loss: 1.0798, G_B_loss: 0.4400\n",
      "Epoch [91/200], Step [571/1067], D_A_loss: 0.1573, D_B_loss: 0.0661, G_A_loss: 0.6091, G_B_loss: 0.3267\n",
      "Epoch [91/200], Step [581/1067], D_A_loss: 0.0812, D_B_loss: 0.0240, G_A_loss: 0.9813, G_B_loss: 0.7787\n",
      "Epoch [91/200], Step [591/1067], D_A_loss: 0.0524, D_B_loss: 0.0346, G_A_loss: 0.7790, G_B_loss: 0.4803\n",
      "Epoch [91/200], Step [601/1067], D_A_loss: 0.0432, D_B_loss: 0.2466, G_A_loss: 1.1724, G_B_loss: 0.4906\n",
      "Epoch [91/200], Step [611/1067], D_A_loss: 0.1333, D_B_loss: 0.0388, G_A_loss: 0.6791, G_B_loss: 0.9441\n",
      "Epoch [91/200], Step [621/1067], D_A_loss: 0.0515, D_B_loss: 0.0766, G_A_loss: 0.6451, G_B_loss: 0.5963\n",
      "Epoch [91/200], Step [631/1067], D_A_loss: 0.0273, D_B_loss: 0.0271, G_A_loss: 0.5852, G_B_loss: 0.4790\n",
      "Epoch [91/200], Step [641/1067], D_A_loss: 0.1287, D_B_loss: 0.0125, G_A_loss: 0.4346, G_B_loss: 0.3918\n",
      "Epoch [91/200], Step [651/1067], D_A_loss: 0.1034, D_B_loss: 0.0152, G_A_loss: 0.7898, G_B_loss: 0.5071\n",
      "Epoch [91/200], Step [661/1067], D_A_loss: 0.1440, D_B_loss: 0.2253, G_A_loss: 0.8557, G_B_loss: 0.8467\n",
      "Epoch [91/200], Step [671/1067], D_A_loss: 0.0995, D_B_loss: 0.0511, G_A_loss: 0.5526, G_B_loss: 0.6224\n",
      "Epoch [91/200], Step [681/1067], D_A_loss: 0.0860, D_B_loss: 0.0134, G_A_loss: 1.1204, G_B_loss: 0.2838\n",
      "Epoch [91/200], Step [691/1067], D_A_loss: 0.0829, D_B_loss: 0.0638, G_A_loss: 0.8239, G_B_loss: 0.6799\n",
      "Epoch [91/200], Step [701/1067], D_A_loss: 0.1566, D_B_loss: 0.0243, G_A_loss: 0.6829, G_B_loss: 0.4675\n",
      "Epoch [91/200], Step [711/1067], D_A_loss: 0.0902, D_B_loss: 0.1291, G_A_loss: 0.6666, G_B_loss: 0.4871\n",
      "Epoch [91/200], Step [721/1067], D_A_loss: 0.0843, D_B_loss: 0.0145, G_A_loss: 0.4623, G_B_loss: 0.7713\n",
      "Epoch [91/200], Step [731/1067], D_A_loss: 0.1339, D_B_loss: 0.0138, G_A_loss: 0.6185, G_B_loss: 0.4116\n",
      "Epoch [91/200], Step [741/1067], D_A_loss: 0.1620, D_B_loss: 0.0231, G_A_loss: 0.8624, G_B_loss: 0.6704\n",
      "Epoch [91/200], Step [751/1067], D_A_loss: 0.1276, D_B_loss: 0.0219, G_A_loss: 1.1295, G_B_loss: 0.5473\n",
      "Epoch [91/200], Step [761/1067], D_A_loss: 0.1851, D_B_loss: 0.0286, G_A_loss: 1.3624, G_B_loss: 0.7218\n",
      "Epoch [91/200], Step [771/1067], D_A_loss: 0.0523, D_B_loss: 0.0254, G_A_loss: 0.7973, G_B_loss: 0.3185\n",
      "Epoch [91/200], Step [781/1067], D_A_loss: 0.0249, D_B_loss: 0.0185, G_A_loss: 0.9852, G_B_loss: 0.1395\n",
      "Epoch [91/200], Step [791/1067], D_A_loss: 0.1214, D_B_loss: 0.0371, G_A_loss: 0.5825, G_B_loss: 0.5027\n",
      "Epoch [91/200], Step [801/1067], D_A_loss: 0.0503, D_B_loss: 0.0125, G_A_loss: 1.3244, G_B_loss: 1.0152\n",
      "Epoch [91/200], Step [811/1067], D_A_loss: 0.0705, D_B_loss: 0.0277, G_A_loss: 0.7384, G_B_loss: 0.3057\n",
      "Epoch [91/200], Step [821/1067], D_A_loss: 0.0713, D_B_loss: 0.0676, G_A_loss: 0.4004, G_B_loss: 0.4338\n",
      "Epoch [91/200], Step [831/1067], D_A_loss: 0.0633, D_B_loss: 0.0449, G_A_loss: 0.6074, G_B_loss: 1.0290\n",
      "Epoch [91/200], Step [841/1067], D_A_loss: 0.0487, D_B_loss: 0.0316, G_A_loss: 1.2156, G_B_loss: 0.1993\n",
      "Epoch [91/200], Step [851/1067], D_A_loss: 0.1708, D_B_loss: 0.1194, G_A_loss: 0.3490, G_B_loss: 0.3797\n",
      "Epoch [91/200], Step [861/1067], D_A_loss: 0.1189, D_B_loss: 0.0316, G_A_loss: 0.5231, G_B_loss: 0.7985\n",
      "Epoch [91/200], Step [871/1067], D_A_loss: 0.1849, D_B_loss: 0.0334, G_A_loss: 1.1126, G_B_loss: 0.2334\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [91/200], Step [881/1067], D_A_loss: 0.0455, D_B_loss: 0.0099, G_A_loss: 0.4617, G_B_loss: 0.8674\n",
      "Epoch [91/200], Step [891/1067], D_A_loss: 0.0567, D_B_loss: 0.0388, G_A_loss: 0.7119, G_B_loss: 0.2732\n",
      "Epoch [91/200], Step [901/1067], D_A_loss: 0.0441, D_B_loss: 0.0541, G_A_loss: 1.2627, G_B_loss: 0.7442\n",
      "Epoch [91/200], Step [911/1067], D_A_loss: 0.0526, D_B_loss: 0.0668, G_A_loss: 0.6924, G_B_loss: 0.6320\n",
      "Epoch [91/200], Step [921/1067], D_A_loss: 0.1300, D_B_loss: 0.0402, G_A_loss: 0.6540, G_B_loss: 0.4794\n",
      "Epoch [91/200], Step [931/1067], D_A_loss: 0.1521, D_B_loss: 0.0209, G_A_loss: 0.7812, G_B_loss: 0.2479\n",
      "Epoch [91/200], Step [941/1067], D_A_loss: 0.1547, D_B_loss: 0.0114, G_A_loss: 1.1697, G_B_loss: 0.2727\n",
      "Epoch [91/200], Step [951/1067], D_A_loss: 0.0284, D_B_loss: 0.0457, G_A_loss: 1.5292, G_B_loss: 0.1824\n",
      "Epoch [91/200], Step [961/1067], D_A_loss: 0.0799, D_B_loss: 0.0122, G_A_loss: 0.7707, G_B_loss: 0.1409\n",
      "Epoch [91/200], Step [971/1067], D_A_loss: 0.0530, D_B_loss: 0.0523, G_A_loss: 0.6189, G_B_loss: 0.6576\n",
      "Epoch [91/200], Step [981/1067], D_A_loss: 0.1292, D_B_loss: 0.0190, G_A_loss: 1.6661, G_B_loss: 0.5545\n",
      "Epoch [91/200], Step [991/1067], D_A_loss: 0.1891, D_B_loss: 0.0573, G_A_loss: 0.5466, G_B_loss: 0.2147\n",
      "Epoch [91/200], Step [1001/1067], D_A_loss: 0.1393, D_B_loss: 0.1150, G_A_loss: 0.5552, G_B_loss: 0.7967\n",
      "Epoch [91/200], Step [1011/1067], D_A_loss: 0.0586, D_B_loss: 0.0285, G_A_loss: 0.8428, G_B_loss: 0.6849\n",
      "Epoch [91/200], Step [1021/1067], D_A_loss: 0.0986, D_B_loss: 0.0250, G_A_loss: 0.7278, G_B_loss: 0.4846\n",
      "Epoch [91/200], Step [1031/1067], D_A_loss: 0.0303, D_B_loss: 0.0373, G_A_loss: 0.6366, G_B_loss: 0.7218\n",
      "Epoch [91/200], Step [1041/1067], D_A_loss: 0.0882, D_B_loss: 0.0092, G_A_loss: 1.0165, G_B_loss: 0.3722\n",
      "Epoch [91/200], Step [1051/1067], D_A_loss: 0.1309, D_B_loss: 0.0409, G_A_loss: 0.6377, G_B_loss: 0.5139\n",
      "Epoch [91/200], Step [1061/1067], D_A_loss: 0.0194, D_B_loss: 0.0188, G_A_loss: 0.8267, G_B_loss: 0.3535\n",
      "Epoch [92/200], Step [1/1067], D_A_loss: 0.1650, D_B_loss: 0.0221, G_A_loss: 0.4997, G_B_loss: 0.2811\n",
      "Epoch [92/200], Step [11/1067], D_A_loss: 0.1610, D_B_loss: 0.0557, G_A_loss: 0.3903, G_B_loss: 0.4723\n",
      "Epoch [92/200], Step [21/1067], D_A_loss: 0.1059, D_B_loss: 0.0099, G_A_loss: 1.0164, G_B_loss: 0.4565\n",
      "Epoch [92/200], Step [31/1067], D_A_loss: 0.1647, D_B_loss: 0.0146, G_A_loss: 0.6895, G_B_loss: 0.8399\n",
      "Epoch [92/200], Step [41/1067], D_A_loss: 0.1437, D_B_loss: 0.0222, G_A_loss: 0.6443, G_B_loss: 0.6353\n",
      "Epoch [92/200], Step [51/1067], D_A_loss: 0.0479, D_B_loss: 0.0230, G_A_loss: 0.9641, G_B_loss: 1.0332\n",
      "Epoch [92/200], Step [61/1067], D_A_loss: 0.0719, D_B_loss: 0.0303, G_A_loss: 1.0374, G_B_loss: 0.5647\n",
      "Epoch [92/200], Step [71/1067], D_A_loss: 0.0336, D_B_loss: 0.0498, G_A_loss: 0.7883, G_B_loss: 0.6943\n",
      "Epoch [92/200], Step [81/1067], D_A_loss: 0.2860, D_B_loss: 0.0607, G_A_loss: 0.9590, G_B_loss: 0.5942\n",
      "Epoch [92/200], Step [91/1067], D_A_loss: 0.1750, D_B_loss: 0.0505, G_A_loss: 0.5426, G_B_loss: 0.2347\n",
      "Epoch [92/200], Step [101/1067], D_A_loss: 0.0299, D_B_loss: 0.0405, G_A_loss: 0.8292, G_B_loss: 0.7352\n",
      "Epoch [92/200], Step [111/1067], D_A_loss: 0.0988, D_B_loss: 0.0728, G_A_loss: 0.9727, G_B_loss: 0.3577\n",
      "Epoch [92/200], Step [121/1067], D_A_loss: 0.0785, D_B_loss: 0.0257, G_A_loss: 1.0936, G_B_loss: 0.4900\n",
      "Epoch [92/200], Step [131/1067], D_A_loss: 0.0963, D_B_loss: 0.0420, G_A_loss: 1.0101, G_B_loss: 1.1788\n",
      "Epoch [92/200], Step [141/1067], D_A_loss: 0.0908, D_B_loss: 0.0289, G_A_loss: 0.9720, G_B_loss: 0.5127\n",
      "Epoch [92/200], Step [151/1067], D_A_loss: 0.0873, D_B_loss: 0.0270, G_A_loss: 0.7818, G_B_loss: 0.6280\n",
      "Epoch [92/200], Step [161/1067], D_A_loss: 0.0477, D_B_loss: 0.0523, G_A_loss: 0.7768, G_B_loss: 0.4085\n",
      "Epoch [92/200], Step [171/1067], D_A_loss: 0.0534, D_B_loss: 0.0110, G_A_loss: 0.6698, G_B_loss: 0.6627\n",
      "Epoch [92/200], Step [181/1067], D_A_loss: 0.0770, D_B_loss: 0.0148, G_A_loss: 0.9915, G_B_loss: 0.7980\n",
      "Epoch [92/200], Step [191/1067], D_A_loss: 0.0268, D_B_loss: 0.0193, G_A_loss: 1.0990, G_B_loss: 1.2103\n",
      "Epoch [92/200], Step [201/1067], D_A_loss: 0.0641, D_B_loss: 0.0260, G_A_loss: 0.8642, G_B_loss: 0.8089\n",
      "Epoch [92/200], Step [211/1067], D_A_loss: 0.0730, D_B_loss: 0.0237, G_A_loss: 0.8887, G_B_loss: 1.0047\n",
      "Epoch [92/200], Step [221/1067], D_A_loss: 0.0509, D_B_loss: 0.0388, G_A_loss: 0.6250, G_B_loss: 1.0217\n",
      "Epoch [92/200], Step [231/1067], D_A_loss: 0.0817, D_B_loss: 0.0328, G_A_loss: 0.5564, G_B_loss: 0.5361\n",
      "Epoch [92/200], Step [241/1067], D_A_loss: 0.0872, D_B_loss: 0.0252, G_A_loss: 0.5477, G_B_loss: 0.4589\n",
      "Epoch [92/200], Step [251/1067], D_A_loss: 0.1286, D_B_loss: 0.0192, G_A_loss: 0.7669, G_B_loss: 0.5440\n",
      "Epoch [92/200], Step [261/1067], D_A_loss: 0.2786, D_B_loss: 0.0192, G_A_loss: 0.9175, G_B_loss: 0.2617\n",
      "Epoch [92/200], Step [271/1067], D_A_loss: 0.2847, D_B_loss: 0.0511, G_A_loss: 0.2726, G_B_loss: 0.4309\n",
      "Epoch [92/200], Step [281/1067], D_A_loss: 0.0491, D_B_loss: 0.0298, G_A_loss: 0.9385, G_B_loss: 0.5027\n",
      "Epoch [92/200], Step [291/1067], D_A_loss: 0.1507, D_B_loss: 0.0381, G_A_loss: 0.7730, G_B_loss: 0.4031\n",
      "Epoch [92/200], Step [301/1067], D_A_loss: 0.0250, D_B_loss: 0.0131, G_A_loss: 0.7751, G_B_loss: 0.7009\n",
      "Epoch [92/200], Step [311/1067], D_A_loss: 0.1668, D_B_loss: 0.0656, G_A_loss: 0.8868, G_B_loss: 1.2098\n",
      "Epoch [92/200], Step [321/1067], D_A_loss: 0.0362, D_B_loss: 0.0555, G_A_loss: 0.6597, G_B_loss: 0.3392\n",
      "Epoch [92/200], Step [331/1067], D_A_loss: 0.0405, D_B_loss: 0.0223, G_A_loss: 1.1034, G_B_loss: 0.5785\n",
      "Epoch [92/200], Step [341/1067], D_A_loss: 0.2997, D_B_loss: 0.1530, G_A_loss: 0.6557, G_B_loss: 0.5768\n",
      "Epoch [92/200], Step [351/1067], D_A_loss: 0.2523, D_B_loss: 0.0180, G_A_loss: 0.8190, G_B_loss: 0.8435\n",
      "Epoch [92/200], Step [361/1067], D_A_loss: 0.1570, D_B_loss: 0.0409, G_A_loss: 0.5495, G_B_loss: 0.5172\n",
      "Epoch [92/200], Step [371/1067], D_A_loss: 0.0443, D_B_loss: 0.0307, G_A_loss: 1.1349, G_B_loss: 0.6573\n",
      "Epoch [92/200], Step [381/1067], D_A_loss: 0.2740, D_B_loss: 0.0481, G_A_loss: 0.9262, G_B_loss: 0.1249\n",
      "Epoch [92/200], Step [391/1067], D_A_loss: 0.1153, D_B_loss: 0.0318, G_A_loss: 0.7090, G_B_loss: 0.4663\n",
      "Epoch [92/200], Step [401/1067], D_A_loss: 0.2010, D_B_loss: 0.0289, G_A_loss: 0.7093, G_B_loss: 0.6556\n",
      "Epoch [92/200], Step [411/1067], D_A_loss: 0.0623, D_B_loss: 0.0129, G_A_loss: 0.9524, G_B_loss: 0.7125\n",
      "Epoch [92/200], Step [421/1067], D_A_loss: 0.0988, D_B_loss: 0.0860, G_A_loss: 0.9191, G_B_loss: 0.3790\n",
      "Epoch [92/200], Step [431/1067], D_A_loss: 0.0517, D_B_loss: 0.0195, G_A_loss: 0.8524, G_B_loss: 0.3069\n",
      "Epoch [92/200], Step [441/1067], D_A_loss: 0.0643, D_B_loss: 0.0922, G_A_loss: 0.6913, G_B_loss: 0.5610\n",
      "Epoch [92/200], Step [451/1067], D_A_loss: 0.0448, D_B_loss: 0.0430, G_A_loss: 0.5769, G_B_loss: 0.3307\n",
      "Epoch [92/200], Step [461/1067], D_A_loss: 0.2159, D_B_loss: 0.1834, G_A_loss: 0.2510, G_B_loss: 0.6862\n",
      "Epoch [92/200], Step [471/1067], D_A_loss: 0.0405, D_B_loss: 0.0295, G_A_loss: 0.7297, G_B_loss: 0.9858\n",
      "Epoch [92/200], Step [481/1067], D_A_loss: 0.2328, D_B_loss: 0.0125, G_A_loss: 0.9382, G_B_loss: 0.2670\n",
      "Epoch [92/200], Step [491/1067], D_A_loss: 0.0515, D_B_loss: 0.0313, G_A_loss: 1.3767, G_B_loss: 0.7230\n",
      "Epoch [92/200], Step [501/1067], D_A_loss: 0.0907, D_B_loss: 0.0223, G_A_loss: 0.9208, G_B_loss: 0.5143\n",
      "Epoch [92/200], Step [511/1067], D_A_loss: 0.0602, D_B_loss: 0.0523, G_A_loss: 0.8188, G_B_loss: 0.2921\n",
      "Epoch [92/200], Step [521/1067], D_A_loss: 0.2585, D_B_loss: 0.0212, G_A_loss: 0.9763, G_B_loss: 0.1877\n",
      "Epoch [92/200], Step [531/1067], D_A_loss: 0.0550, D_B_loss: 0.0426, G_A_loss: 0.7674, G_B_loss: 0.6795\n",
      "Epoch [92/200], Step [541/1067], D_A_loss: 0.0836, D_B_loss: 0.0232, G_A_loss: 0.4944, G_B_loss: 0.4419\n",
      "Epoch [92/200], Step [551/1067], D_A_loss: 0.0896, D_B_loss: 0.0309, G_A_loss: 0.7275, G_B_loss: 0.3059\n",
      "Epoch [92/200], Step [561/1067], D_A_loss: 0.1082, D_B_loss: 0.0248, G_A_loss: 0.9524, G_B_loss: 0.6555\n",
      "Epoch [92/200], Step [571/1067], D_A_loss: 0.1329, D_B_loss: 0.0343, G_A_loss: 0.8076, G_B_loss: 0.3098\n",
      "Epoch [92/200], Step [581/1067], D_A_loss: 0.0503, D_B_loss: 0.0281, G_A_loss: 0.7532, G_B_loss: 0.6183\n",
      "Epoch [92/200], Step [591/1067], D_A_loss: 0.1514, D_B_loss: 0.0491, G_A_loss: 0.5911, G_B_loss: 0.2818\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [92/200], Step [601/1067], D_A_loss: 0.3312, D_B_loss: 0.0375, G_A_loss: 1.0759, G_B_loss: 0.0793\n",
      "Epoch [92/200], Step [611/1067], D_A_loss: 0.0341, D_B_loss: 0.0191, G_A_loss: 0.7756, G_B_loss: 0.4928\n",
      "Epoch [92/200], Step [621/1067], D_A_loss: 0.1703, D_B_loss: 0.0164, G_A_loss: 1.2874, G_B_loss: 0.9838\n",
      "Epoch [92/200], Step [631/1067], D_A_loss: 0.1635, D_B_loss: 0.0241, G_A_loss: 0.4790, G_B_loss: 0.2684\n",
      "Epoch [92/200], Step [641/1067], D_A_loss: 0.0225, D_B_loss: 0.0715, G_A_loss: 0.4827, G_B_loss: 0.7185\n",
      "Epoch [92/200], Step [651/1067], D_A_loss: 0.0829, D_B_loss: 0.0251, G_A_loss: 1.0165, G_B_loss: 0.3925\n",
      "Epoch [92/200], Step [661/1067], D_A_loss: 0.0470, D_B_loss: 0.0422, G_A_loss: 0.6105, G_B_loss: 0.7722\n",
      "Epoch [92/200], Step [671/1067], D_A_loss: 0.0423, D_B_loss: 0.0325, G_A_loss: 0.8760, G_B_loss: 0.2441\n",
      "Epoch [92/200], Step [681/1067], D_A_loss: 0.0280, D_B_loss: 0.0114, G_A_loss: 0.8287, G_B_loss: 0.6676\n",
      "Epoch [92/200], Step [691/1067], D_A_loss: 0.0762, D_B_loss: 0.0365, G_A_loss: 0.7495, G_B_loss: 0.8943\n",
      "Epoch [92/200], Step [701/1067], D_A_loss: 0.2520, D_B_loss: 0.0608, G_A_loss: 1.0068, G_B_loss: 0.8291\n",
      "Epoch [92/200], Step [711/1067], D_A_loss: 0.1321, D_B_loss: 0.0306, G_A_loss: 0.7586, G_B_loss: 0.5185\n",
      "Epoch [92/200], Step [721/1067], D_A_loss: 0.1056, D_B_loss: 0.0413, G_A_loss: 0.4513, G_B_loss: 0.4647\n",
      "Epoch [92/200], Step [731/1067], D_A_loss: 0.0702, D_B_loss: 0.0717, G_A_loss: 0.6316, G_B_loss: 1.0575\n",
      "Epoch [92/200], Step [741/1067], D_A_loss: 0.0869, D_B_loss: 0.0243, G_A_loss: 0.7912, G_B_loss: 0.2380\n",
      "Epoch [92/200], Step [751/1067], D_A_loss: 0.0909, D_B_loss: 0.0287, G_A_loss: 0.6120, G_B_loss: 0.4435\n",
      "Epoch [92/200], Step [761/1067], D_A_loss: 0.0884, D_B_loss: 0.0718, G_A_loss: 0.6730, G_B_loss: 0.5278\n",
      "Epoch [92/200], Step [771/1067], D_A_loss: 0.0856, D_B_loss: 0.0463, G_A_loss: 1.1763, G_B_loss: 0.3442\n",
      "Epoch [92/200], Step [781/1067], D_A_loss: 0.1336, D_B_loss: 0.1080, G_A_loss: 1.0015, G_B_loss: 0.7490\n",
      "Epoch [92/200], Step [791/1067], D_A_loss: 0.0425, D_B_loss: 0.0297, G_A_loss: 0.3549, G_B_loss: 0.4674\n",
      "Epoch [92/200], Step [801/1067], D_A_loss: 0.0358, D_B_loss: 0.0464, G_A_loss: 0.8450, G_B_loss: 0.8502\n",
      "Epoch [92/200], Step [811/1067], D_A_loss: 0.2249, D_B_loss: 0.0852, G_A_loss: 1.2054, G_B_loss: 0.6238\n",
      "Epoch [92/200], Step [821/1067], D_A_loss: 0.0973, D_B_loss: 0.0526, G_A_loss: 0.8326, G_B_loss: 0.6152\n",
      "Epoch [92/200], Step [831/1067], D_A_loss: 0.1599, D_B_loss: 0.0664, G_A_loss: 0.3377, G_B_loss: 0.9748\n",
      "Epoch [92/200], Step [841/1067], D_A_loss: 0.1105, D_B_loss: 0.0668, G_A_loss: 0.9293, G_B_loss: 0.4081\n",
      "Epoch [92/200], Step [851/1067], D_A_loss: 0.0677, D_B_loss: 0.0376, G_A_loss: 0.6042, G_B_loss: 0.5780\n",
      "Epoch [92/200], Step [861/1067], D_A_loss: 0.0211, D_B_loss: 0.0480, G_A_loss: 0.5519, G_B_loss: 0.2184\n",
      "Epoch [92/200], Step [871/1067], D_A_loss: 0.0375, D_B_loss: 0.0570, G_A_loss: 0.9920, G_B_loss: 0.4108\n",
      "Epoch [92/200], Step [881/1067], D_A_loss: 0.1388, D_B_loss: 0.0191, G_A_loss: 0.8308, G_B_loss: 0.1734\n",
      "Epoch [92/200], Step [891/1067], D_A_loss: 0.0969, D_B_loss: 0.0227, G_A_loss: 0.6317, G_B_loss: 0.9138\n",
      "Epoch [92/200], Step [901/1067], D_A_loss: 0.0217, D_B_loss: 0.0144, G_A_loss: 0.7745, G_B_loss: 0.4639\n",
      "Epoch [92/200], Step [911/1067], D_A_loss: 0.1695, D_B_loss: 0.0192, G_A_loss: 0.7192, G_B_loss: 0.2735\n",
      "Epoch [92/200], Step [921/1067], D_A_loss: 0.1065, D_B_loss: 0.0631, G_A_loss: 0.9716, G_B_loss: 0.3687\n",
      "Epoch [92/200], Step [931/1067], D_A_loss: 0.1582, D_B_loss: 0.0212, G_A_loss: 0.8454, G_B_loss: 0.2723\n",
      "Epoch [92/200], Step [941/1067], D_A_loss: 0.0304, D_B_loss: 0.0536, G_A_loss: 0.6514, G_B_loss: 0.7080\n",
      "Epoch [92/200], Step [951/1067], D_A_loss: 0.1144, D_B_loss: 0.1136, G_A_loss: 0.8280, G_B_loss: 0.3313\n",
      "Epoch [92/200], Step [961/1067], D_A_loss: 0.1041, D_B_loss: 0.0187, G_A_loss: 0.7392, G_B_loss: 0.4105\n",
      "Epoch [92/200], Step [971/1067], D_A_loss: 0.1416, D_B_loss: 0.0522, G_A_loss: 0.5472, G_B_loss: 0.4530\n",
      "Epoch [92/200], Step [981/1067], D_A_loss: 0.0823, D_B_loss: 0.0375, G_A_loss: 0.6549, G_B_loss: 0.3141\n",
      "Epoch [92/200], Step [991/1067], D_A_loss: 0.2051, D_B_loss: 0.0306, G_A_loss: 0.5206, G_B_loss: 0.5817\n",
      "Epoch [92/200], Step [1001/1067], D_A_loss: 0.0966, D_B_loss: 0.0789, G_A_loss: 1.0729, G_B_loss: 0.4419\n",
      "Epoch [92/200], Step [1011/1067], D_A_loss: 0.0904, D_B_loss: 0.0138, G_A_loss: 1.3331, G_B_loss: 0.7284\n",
      "Epoch [92/200], Step [1021/1067], D_A_loss: 0.0526, D_B_loss: 0.0246, G_A_loss: 0.8339, G_B_loss: 0.5353\n",
      "Epoch [92/200], Step [1031/1067], D_A_loss: 0.0518, D_B_loss: 0.1666, G_A_loss: 0.9474, G_B_loss: 0.1994\n",
      "Epoch [92/200], Step [1041/1067], D_A_loss: 0.1050, D_B_loss: 0.1111, G_A_loss: 1.5253, G_B_loss: 0.3164\n",
      "Epoch [92/200], Step [1051/1067], D_A_loss: 0.1390, D_B_loss: 0.0213, G_A_loss: 0.6652, G_B_loss: 0.4404\n",
      "Epoch [92/200], Step [1061/1067], D_A_loss: 0.0710, D_B_loss: 0.0347, G_A_loss: 0.9959, G_B_loss: 0.6389\n",
      "Epoch [93/200], Step [1/1067], D_A_loss: 0.0432, D_B_loss: 0.1133, G_A_loss: 0.7420, G_B_loss: 0.8352\n",
      "Epoch [93/200], Step [11/1067], D_A_loss: 0.0268, D_B_loss: 0.0198, G_A_loss: 0.7840, G_B_loss: 0.8214\n",
      "Epoch [93/200], Step [21/1067], D_A_loss: 0.1389, D_B_loss: 0.0693, G_A_loss: 1.2184, G_B_loss: 0.6860\n",
      "Epoch [93/200], Step [31/1067], D_A_loss: 0.2132, D_B_loss: 0.0200, G_A_loss: 0.8761, G_B_loss: 0.6177\n",
      "Epoch [93/200], Step [41/1067], D_A_loss: 0.0658, D_B_loss: 0.0110, G_A_loss: 0.8987, G_B_loss: 0.5735\n",
      "Epoch [93/200], Step [51/1067], D_A_loss: 0.0395, D_B_loss: 0.0177, G_A_loss: 0.8859, G_B_loss: 0.3734\n",
      "Epoch [93/200], Step [61/1067], D_A_loss: 0.0343, D_B_loss: 0.0821, G_A_loss: 0.8426, G_B_loss: 0.3502\n",
      "Epoch [93/200], Step [71/1067], D_A_loss: 0.2250, D_B_loss: 0.0277, G_A_loss: 0.5963, G_B_loss: 0.2293\n",
      "Epoch [93/200], Step [81/1067], D_A_loss: 0.1594, D_B_loss: 0.0545, G_A_loss: 1.1924, G_B_loss: 1.0229\n",
      "Epoch [93/200], Step [91/1067], D_A_loss: 0.1143, D_B_loss: 0.3047, G_A_loss: 0.8912, G_B_loss: 0.5726\n",
      "Epoch [93/200], Step [101/1067], D_A_loss: 0.2279, D_B_loss: 0.0928, G_A_loss: 0.7189, G_B_loss: 0.6121\n",
      "Epoch [93/200], Step [111/1067], D_A_loss: 0.1244, D_B_loss: 0.0348, G_A_loss: 1.4046, G_B_loss: 0.7294\n",
      "Epoch [93/200], Step [121/1067], D_A_loss: 0.0533, D_B_loss: 0.0438, G_A_loss: 1.0269, G_B_loss: 0.5421\n",
      "Epoch [93/200], Step [131/1067], D_A_loss: 0.1790, D_B_loss: 0.0658, G_A_loss: 0.5937, G_B_loss: 0.2837\n",
      "Epoch [93/200], Step [141/1067], D_A_loss: 0.1141, D_B_loss: 0.0185, G_A_loss: 0.7321, G_B_loss: 0.7993\n",
      "Epoch [93/200], Step [151/1067], D_A_loss: 0.1801, D_B_loss: 0.0251, G_A_loss: 1.0580, G_B_loss: 0.3194\n",
      "Epoch [93/200], Step [161/1067], D_A_loss: 0.1204, D_B_loss: 0.0197, G_A_loss: 0.7698, G_B_loss: 0.5174\n",
      "Epoch [93/200], Step [171/1067], D_A_loss: 0.0982, D_B_loss: 0.0137, G_A_loss: 0.8240, G_B_loss: 0.5824\n",
      "Epoch [93/200], Step [181/1067], D_A_loss: 0.1518, D_B_loss: 0.0302, G_A_loss: 0.6830, G_B_loss: 0.2998\n",
      "Epoch [93/200], Step [191/1067], D_A_loss: 0.0774, D_B_loss: 0.0367, G_A_loss: 0.6033, G_B_loss: 0.8143\n",
      "Epoch [93/200], Step [201/1067], D_A_loss: 0.1293, D_B_loss: 0.1073, G_A_loss: 0.3492, G_B_loss: 0.6370\n",
      "Epoch [93/200], Step [211/1067], D_A_loss: 0.3385, D_B_loss: 0.0155, G_A_loss: 0.8937, G_B_loss: 0.5943\n",
      "Epoch [93/200], Step [221/1067], D_A_loss: 0.1021, D_B_loss: 0.1000, G_A_loss: 0.8091, G_B_loss: 0.1825\n",
      "Epoch [93/200], Step [231/1067], D_A_loss: 0.1493, D_B_loss: 0.0523, G_A_loss: 0.8435, G_B_loss: 0.2655\n",
      "Epoch [93/200], Step [241/1067], D_A_loss: 0.0470, D_B_loss: 0.0161, G_A_loss: 0.9050, G_B_loss: 0.9526\n",
      "Epoch [93/200], Step [251/1067], D_A_loss: 0.0813, D_B_loss: 0.0233, G_A_loss: 0.6357, G_B_loss: 0.9533\n",
      "Epoch [93/200], Step [261/1067], D_A_loss: 0.0452, D_B_loss: 0.0233, G_A_loss: 1.0384, G_B_loss: 0.2178\n",
      "Epoch [93/200], Step [271/1067], D_A_loss: 0.1498, D_B_loss: 0.0308, G_A_loss: 0.8542, G_B_loss: 0.3061\n",
      "Epoch [93/200], Step [281/1067], D_A_loss: 0.0502, D_B_loss: 0.0153, G_A_loss: 0.8685, G_B_loss: 0.6502\n",
      "Epoch [93/200], Step [291/1067], D_A_loss: 0.1093, D_B_loss: 0.0518, G_A_loss: 0.2990, G_B_loss: 0.3397\n",
      "Epoch [93/200], Step [301/1067], D_A_loss: 0.0328, D_B_loss: 0.0702, G_A_loss: 0.3184, G_B_loss: 0.5790\n",
      "Epoch [93/200], Step [311/1067], D_A_loss: 0.0305, D_B_loss: 0.0505, G_A_loss: 0.7070, G_B_loss: 0.4999\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [93/200], Step [321/1067], D_A_loss: 0.0942, D_B_loss: 0.0199, G_A_loss: 0.4467, G_B_loss: 0.5191\n",
      "Epoch [93/200], Step [331/1067], D_A_loss: 0.0614, D_B_loss: 0.0200, G_A_loss: 0.9291, G_B_loss: 0.5395\n",
      "Epoch [93/200], Step [341/1067], D_A_loss: 0.0714, D_B_loss: 0.0363, G_A_loss: 0.6179, G_B_loss: 0.4415\n",
      "Epoch [93/200], Step [351/1067], D_A_loss: 0.1607, D_B_loss: 0.0133, G_A_loss: 0.8882, G_B_loss: 0.7705\n",
      "Epoch [93/200], Step [361/1067], D_A_loss: 0.0657, D_B_loss: 0.0274, G_A_loss: 0.7722, G_B_loss: 0.7996\n",
      "Epoch [93/200], Step [371/1067], D_A_loss: 0.1034, D_B_loss: 0.0182, G_A_loss: 1.1387, G_B_loss: 0.4434\n",
      "Epoch [93/200], Step [381/1067], D_A_loss: 0.2019, D_B_loss: 0.0978, G_A_loss: 0.4566, G_B_loss: 0.2988\n",
      "Epoch [93/200], Step [391/1067], D_A_loss: 0.1688, D_B_loss: 0.0193, G_A_loss: 0.7474, G_B_loss: 0.8060\n",
      "Epoch [93/200], Step [401/1067], D_A_loss: 0.0564, D_B_loss: 0.0287, G_A_loss: 0.6330, G_B_loss: 0.6005\n",
      "Epoch [93/200], Step [411/1067], D_A_loss: 0.0930, D_B_loss: 0.0675, G_A_loss: 0.4998, G_B_loss: 0.5649\n",
      "Epoch [93/200], Step [421/1067], D_A_loss: 0.0295, D_B_loss: 0.0122, G_A_loss: 0.8410, G_B_loss: 1.2158\n",
      "Epoch [93/200], Step [431/1067], D_A_loss: 0.1051, D_B_loss: 0.0473, G_A_loss: 0.6384, G_B_loss: 0.2611\n",
      "Epoch [93/200], Step [441/1067], D_A_loss: 0.1687, D_B_loss: 0.0707, G_A_loss: 0.6509, G_B_loss: 0.8042\n",
      "Epoch [93/200], Step [451/1067], D_A_loss: 0.0995, D_B_loss: 0.0556, G_A_loss: 0.8166, G_B_loss: 0.5880\n",
      "Epoch [93/200], Step [461/1067], D_A_loss: 0.3305, D_B_loss: 0.0452, G_A_loss: 1.0648, G_B_loss: 0.9528\n",
      "Epoch [93/200], Step [471/1067], D_A_loss: 0.0194, D_B_loss: 0.0417, G_A_loss: 1.4835, G_B_loss: 0.4299\n",
      "Epoch [93/200], Step [481/1067], D_A_loss: 0.2053, D_B_loss: 0.0447, G_A_loss: 1.0300, G_B_loss: 0.4184\n",
      "Epoch [93/200], Step [491/1067], D_A_loss: 0.0775, D_B_loss: 0.0232, G_A_loss: 0.8651, G_B_loss: 0.4631\n",
      "Epoch [93/200], Step [501/1067], D_A_loss: 0.0624, D_B_loss: 0.0330, G_A_loss: 0.7743, G_B_loss: 0.7664\n",
      "Epoch [93/200], Step [511/1067], D_A_loss: 0.0900, D_B_loss: 0.0082, G_A_loss: 1.1813, G_B_loss: 0.7147\n",
      "Epoch [93/200], Step [521/1067], D_A_loss: 0.1021, D_B_loss: 0.0189, G_A_loss: 0.7848, G_B_loss: 0.4326\n",
      "Epoch [93/200], Step [531/1067], D_A_loss: 0.0491, D_B_loss: 0.0347, G_A_loss: 0.9656, G_B_loss: 0.5485\n",
      "Epoch [93/200], Step [541/1067], D_A_loss: 0.0277, D_B_loss: 0.0202, G_A_loss: 0.7308, G_B_loss: 0.2067\n",
      "Epoch [93/200], Step [551/1067], D_A_loss: 0.0557, D_B_loss: 0.0553, G_A_loss: 0.5668, G_B_loss: 0.6831\n",
      "Epoch [93/200], Step [561/1067], D_A_loss: 0.1307, D_B_loss: 0.0184, G_A_loss: 0.9687, G_B_loss: 0.5582\n",
      "Epoch [93/200], Step [571/1067], D_A_loss: 0.1487, D_B_loss: 0.0224, G_A_loss: 0.6239, G_B_loss: 0.5919\n",
      "Epoch [93/200], Step [581/1067], D_A_loss: 0.1124, D_B_loss: 0.0520, G_A_loss: 0.4969, G_B_loss: 0.6873\n",
      "Epoch [93/200], Step [591/1067], D_A_loss: 0.0730, D_B_loss: 0.0156, G_A_loss: 1.0901, G_B_loss: 0.7931\n",
      "Epoch [93/200], Step [601/1067], D_A_loss: 0.0315, D_B_loss: 0.0195, G_A_loss: 0.8460, G_B_loss: 0.9014\n",
      "Epoch [93/200], Step [611/1067], D_A_loss: 0.0506, D_B_loss: 0.1039, G_A_loss: 1.0569, G_B_loss: 0.4722\n",
      "Epoch [93/200], Step [621/1067], D_A_loss: 0.1887, D_B_loss: 0.0889, G_A_loss: 0.4314, G_B_loss: 0.5007\n",
      "Epoch [93/200], Step [631/1067], D_A_loss: 0.0153, D_B_loss: 0.0316, G_A_loss: 1.0072, G_B_loss: 0.6579\n",
      "Epoch [93/200], Step [641/1067], D_A_loss: 0.1677, D_B_loss: 0.0280, G_A_loss: 0.8686, G_B_loss: 0.2543\n",
      "Epoch [93/200], Step [651/1067], D_A_loss: 0.0865, D_B_loss: 0.0362, G_A_loss: 1.1166, G_B_loss: 1.0805\n",
      "Epoch [93/200], Step [661/1067], D_A_loss: 0.1621, D_B_loss: 0.0363, G_A_loss: 0.6293, G_B_loss: 0.2785\n",
      "Epoch [93/200], Step [671/1067], D_A_loss: 0.0998, D_B_loss: 0.0220, G_A_loss: 0.7357, G_B_loss: 0.4615\n",
      "Epoch [93/200], Step [681/1067], D_A_loss: 0.1054, D_B_loss: 0.0671, G_A_loss: 0.9953, G_B_loss: 0.3812\n",
      "Epoch [93/200], Step [691/1067], D_A_loss: 0.1627, D_B_loss: 0.0257, G_A_loss: 0.6119, G_B_loss: 0.6863\n",
      "Epoch [93/200], Step [701/1067], D_A_loss: 0.0988, D_B_loss: 0.0467, G_A_loss: 1.0257, G_B_loss: 0.5682\n",
      "Epoch [93/200], Step [711/1067], D_A_loss: 0.1165, D_B_loss: 0.0378, G_A_loss: 0.8694, G_B_loss: 0.5055\n",
      "Epoch [93/200], Step [721/1067], D_A_loss: 0.0840, D_B_loss: 0.0419, G_A_loss: 0.5720, G_B_loss: 0.6390\n",
      "Epoch [93/200], Step [731/1067], D_A_loss: 0.1492, D_B_loss: 0.0270, G_A_loss: 0.4940, G_B_loss: 0.2666\n",
      "Epoch [93/200], Step [741/1067], D_A_loss: 0.1519, D_B_loss: 0.0134, G_A_loss: 1.0328, G_B_loss: 0.2690\n",
      "Epoch [93/200], Step [751/1067], D_A_loss: 0.1325, D_B_loss: 0.0502, G_A_loss: 0.4287, G_B_loss: 0.6358\n",
      "Epoch [93/200], Step [761/1067], D_A_loss: 0.1171, D_B_loss: 0.0154, G_A_loss: 1.1457, G_B_loss: 0.4457\n",
      "Epoch [93/200], Step [771/1067], D_A_loss: 0.1026, D_B_loss: 0.0282, G_A_loss: 0.9163, G_B_loss: 0.3889\n",
      "Epoch [93/200], Step [781/1067], D_A_loss: 0.2207, D_B_loss: 0.0136, G_A_loss: 0.9107, G_B_loss: 0.1696\n",
      "Epoch [93/200], Step [791/1067], D_A_loss: 0.1744, D_B_loss: 0.0257, G_A_loss: 1.4238, G_B_loss: 0.6733\n",
      "Epoch [93/200], Step [801/1067], D_A_loss: 0.1461, D_B_loss: 0.0573, G_A_loss: 0.5779, G_B_loss: 0.5830\n",
      "Epoch [93/200], Step [811/1067], D_A_loss: 0.1747, D_B_loss: 0.0238, G_A_loss: 0.6968, G_B_loss: 0.8420\n",
      "Epoch [93/200], Step [821/1067], D_A_loss: 0.0491, D_B_loss: 0.0278, G_A_loss: 1.3042, G_B_loss: 0.3738\n",
      "Epoch [93/200], Step [831/1067], D_A_loss: 0.0768, D_B_loss: 0.1337, G_A_loss: 0.5630, G_B_loss: 0.6810\n",
      "Epoch [93/200], Step [841/1067], D_A_loss: 0.1162, D_B_loss: 0.0717, G_A_loss: 0.8874, G_B_loss: 0.4680\n",
      "Epoch [93/200], Step [851/1067], D_A_loss: 0.1159, D_B_loss: 0.0443, G_A_loss: 0.7185, G_B_loss: 0.3692\n",
      "Epoch [93/200], Step [861/1067], D_A_loss: 0.1966, D_B_loss: 0.0187, G_A_loss: 1.0670, G_B_loss: 0.6386\n",
      "Epoch [93/200], Step [871/1067], D_A_loss: 0.0792, D_B_loss: 0.0770, G_A_loss: 0.9846, G_B_loss: 0.3186\n",
      "Epoch [93/200], Step [881/1067], D_A_loss: 0.0945, D_B_loss: 0.0146, G_A_loss: 0.8017, G_B_loss: 0.4443\n",
      "Epoch [93/200], Step [891/1067], D_A_loss: 0.0559, D_B_loss: 0.0121, G_A_loss: 1.0231, G_B_loss: 0.7668\n",
      "Epoch [93/200], Step [901/1067], D_A_loss: 0.1067, D_B_loss: 0.2444, G_A_loss: 0.9999, G_B_loss: 0.5356\n",
      "Epoch [93/200], Step [911/1067], D_A_loss: 0.0487, D_B_loss: 0.0618, G_A_loss: 1.0354, G_B_loss: 0.6389\n",
      "Epoch [93/200], Step [921/1067], D_A_loss: 0.0279, D_B_loss: 0.0430, G_A_loss: 1.2579, G_B_loss: 0.7552\n",
      "Epoch [93/200], Step [931/1067], D_A_loss: 0.2081, D_B_loss: 0.0205, G_A_loss: 0.9439, G_B_loss: 0.2522\n",
      "Epoch [93/200], Step [941/1067], D_A_loss: 0.1028, D_B_loss: 0.1603, G_A_loss: 0.8585, G_B_loss: 0.4772\n",
      "Epoch [93/200], Step [951/1067], D_A_loss: 0.0712, D_B_loss: 0.0267, G_A_loss: 0.6768, G_B_loss: 0.5323\n",
      "Epoch [93/200], Step [961/1067], D_A_loss: 0.0878, D_B_loss: 0.0394, G_A_loss: 0.7739, G_B_loss: 0.4696\n",
      "Epoch [93/200], Step [971/1067], D_A_loss: 0.1525, D_B_loss: 0.0794, G_A_loss: 0.4441, G_B_loss: 0.7959\n",
      "Epoch [93/200], Step [981/1067], D_A_loss: 0.1809, D_B_loss: 0.0763, G_A_loss: 0.3311, G_B_loss: 1.0448\n",
      "Epoch [93/200], Step [991/1067], D_A_loss: 0.1647, D_B_loss: 0.0647, G_A_loss: 0.6068, G_B_loss: 1.1222\n",
      "Epoch [93/200], Step [1001/1067], D_A_loss: 0.0937, D_B_loss: 0.0260, G_A_loss: 1.3195, G_B_loss: 0.4827\n",
      "Epoch [93/200], Step [1011/1067], D_A_loss: 0.0862, D_B_loss: 0.0207, G_A_loss: 0.9113, G_B_loss: 0.2862\n",
      "Epoch [93/200], Step [1021/1067], D_A_loss: 0.1788, D_B_loss: 0.0320, G_A_loss: 0.6193, G_B_loss: 0.5260\n",
      "Epoch [93/200], Step [1031/1067], D_A_loss: 0.0472, D_B_loss: 0.0978, G_A_loss: 0.7100, G_B_loss: 0.4747\n",
      "Epoch [93/200], Step [1041/1067], D_A_loss: 0.1181, D_B_loss: 0.0373, G_A_loss: 0.6478, G_B_loss: 0.4023\n",
      "Epoch [93/200], Step [1051/1067], D_A_loss: 0.0515, D_B_loss: 0.0324, G_A_loss: 0.8911, G_B_loss: 0.5528\n",
      "Epoch [93/200], Step [1061/1067], D_A_loss: 0.1027, D_B_loss: 0.0196, G_A_loss: 1.1514, G_B_loss: 0.4675\n",
      "Epoch [94/200], Step [1/1067], D_A_loss: 0.0436, D_B_loss: 0.0171, G_A_loss: 0.9342, G_B_loss: 0.7315\n",
      "Epoch [94/200], Step [11/1067], D_A_loss: 0.0626, D_B_loss: 0.0355, G_A_loss: 0.4265, G_B_loss: 0.6157\n",
      "Epoch [94/200], Step [21/1067], D_A_loss: 0.2203, D_B_loss: 0.0225, G_A_loss: 0.8809, G_B_loss: 0.7644\n",
      "Epoch [94/200], Step [31/1067], D_A_loss: 0.0743, D_B_loss: 0.0837, G_A_loss: 0.6131, G_B_loss: 0.0327\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [94/200], Step [41/1067], D_A_loss: 0.0862, D_B_loss: 0.0774, G_A_loss: 1.1809, G_B_loss: 0.4070\n",
      "Epoch [94/200], Step [51/1067], D_A_loss: 0.0763, D_B_loss: 0.0787, G_A_loss: 0.9581, G_B_loss: 0.5682\n",
      "Epoch [94/200], Step [61/1067], D_A_loss: 0.2880, D_B_loss: 0.0170, G_A_loss: 1.0571, G_B_loss: 1.2315\n",
      "Epoch [94/200], Step [71/1067], D_A_loss: 0.2153, D_B_loss: 0.0121, G_A_loss: 0.7891, G_B_loss: 0.1861\n",
      "Epoch [94/200], Step [81/1067], D_A_loss: 0.0586, D_B_loss: 0.0554, G_A_loss: 0.4837, G_B_loss: 0.6969\n",
      "Epoch [94/200], Step [91/1067], D_A_loss: 0.0717, D_B_loss: 0.0233, G_A_loss: 0.5719, G_B_loss: 0.6104\n",
      "Epoch [94/200], Step [101/1067], D_A_loss: 0.0604, D_B_loss: 0.0517, G_A_loss: 0.8918, G_B_loss: 0.5284\n",
      "Epoch [94/200], Step [111/1067], D_A_loss: 0.1367, D_B_loss: 0.0242, G_A_loss: 0.7238, G_B_loss: 0.3083\n",
      "Epoch [94/200], Step [121/1067], D_A_loss: 0.1427, D_B_loss: 0.0167, G_A_loss: 0.7623, G_B_loss: 0.3883\n",
      "Epoch [94/200], Step [131/1067], D_A_loss: 0.1558, D_B_loss: 0.0138, G_A_loss: 0.8354, G_B_loss: 0.7253\n",
      "Epoch [94/200], Step [141/1067], D_A_loss: 0.0394, D_B_loss: 0.0126, G_A_loss: 0.9422, G_B_loss: 0.3914\n",
      "Epoch [94/200], Step [151/1067], D_A_loss: 0.1046, D_B_loss: 0.0175, G_A_loss: 1.0432, G_B_loss: 0.5090\n",
      "Epoch [94/200], Step [161/1067], D_A_loss: 0.0674, D_B_loss: 0.0654, G_A_loss: 1.1627, G_B_loss: 0.6918\n",
      "Epoch [94/200], Step [171/1067], D_A_loss: 0.1987, D_B_loss: 0.0211, G_A_loss: 0.8883, G_B_loss: 0.2402\n",
      "Epoch [94/200], Step [181/1067], D_A_loss: 0.2097, D_B_loss: 0.0211, G_A_loss: 0.6319, G_B_loss: 0.5928\n",
      "Epoch [94/200], Step [191/1067], D_A_loss: 0.1247, D_B_loss: 0.0147, G_A_loss: 0.9001, G_B_loss: 0.3648\n",
      "Epoch [94/200], Step [201/1067], D_A_loss: 0.1180, D_B_loss: 0.0893, G_A_loss: 0.3859, G_B_loss: 0.8820\n",
      "Epoch [94/200], Step [211/1067], D_A_loss: 0.1300, D_B_loss: 0.0392, G_A_loss: 0.8247, G_B_loss: 0.2646\n",
      "Epoch [94/200], Step [221/1067], D_A_loss: 0.0329, D_B_loss: 0.0449, G_A_loss: 1.2925, G_B_loss: 0.9259\n",
      "Epoch [94/200], Step [231/1067], D_A_loss: 0.1613, D_B_loss: 0.0218, G_A_loss: 0.7934, G_B_loss: 0.3116\n",
      "Epoch [94/200], Step [241/1067], D_A_loss: 0.1211, D_B_loss: 0.0679, G_A_loss: 0.4896, G_B_loss: 0.6798\n",
      "Epoch [94/200], Step [251/1067], D_A_loss: 0.1468, D_B_loss: 0.0400, G_A_loss: 0.8397, G_B_loss: 0.5330\n",
      "Epoch [94/200], Step [261/1067], D_A_loss: 0.0481, D_B_loss: 0.0249, G_A_loss: 0.9197, G_B_loss: 0.9286\n",
      "Epoch [94/200], Step [271/1067], D_A_loss: 0.0968, D_B_loss: 0.0593, G_A_loss: 0.6346, G_B_loss: 0.5424\n",
      "Epoch [94/200], Step [281/1067], D_A_loss: 0.0330, D_B_loss: 0.0144, G_A_loss: 1.1512, G_B_loss: 0.6668\n",
      "Epoch [94/200], Step [291/1067], D_A_loss: 0.1218, D_B_loss: 0.0114, G_A_loss: 0.9671, G_B_loss: 0.3620\n",
      "Epoch [94/200], Step [301/1067], D_A_loss: 0.0830, D_B_loss: 0.0180, G_A_loss: 0.7451, G_B_loss: 0.5050\n",
      "Epoch [94/200], Step [311/1067], D_A_loss: 0.1913, D_B_loss: 0.0695, G_A_loss: 1.3106, G_B_loss: 0.7320\n",
      "Epoch [94/200], Step [321/1067], D_A_loss: 0.1758, D_B_loss: 0.0098, G_A_loss: 1.0300, G_B_loss: 0.2671\n",
      "Epoch [94/200], Step [331/1067], D_A_loss: 0.1583, D_B_loss: 0.0213, G_A_loss: 0.5689, G_B_loss: 0.4560\n",
      "Epoch [94/200], Step [341/1067], D_A_loss: 0.3286, D_B_loss: 0.1066, G_A_loss: 0.3480, G_B_loss: 1.2269\n",
      "Epoch [94/200], Step [351/1067], D_A_loss: 0.3944, D_B_loss: 0.0270, G_A_loss: 0.8531, G_B_loss: 0.5669\n",
      "Epoch [94/200], Step [361/1067], D_A_loss: 0.1064, D_B_loss: 0.0322, G_A_loss: 1.0528, G_B_loss: 0.4691\n",
      "Epoch [94/200], Step [371/1067], D_A_loss: 0.0476, D_B_loss: 0.0416, G_A_loss: 0.3699, G_B_loss: 0.3525\n",
      "Epoch [94/200], Step [381/1067], D_A_loss: 0.0598, D_B_loss: 0.0134, G_A_loss: 0.7677, G_B_loss: 0.7343\n",
      "Epoch [94/200], Step [391/1067], D_A_loss: 0.1762, D_B_loss: 0.0147, G_A_loss: 0.7332, G_B_loss: 0.6095\n",
      "Epoch [94/200], Step [401/1067], D_A_loss: 0.0964, D_B_loss: 0.0420, G_A_loss: 0.7569, G_B_loss: 0.4514\n",
      "Epoch [94/200], Step [411/1067], D_A_loss: 0.1598, D_B_loss: 0.0164, G_A_loss: 1.0847, G_B_loss: 0.3157\n",
      "Epoch [94/200], Step [421/1067], D_A_loss: 0.0401, D_B_loss: 0.0785, G_A_loss: 1.1611, G_B_loss: 0.3094\n",
      "Epoch [94/200], Step [431/1067], D_A_loss: 0.0947, D_B_loss: 0.0790, G_A_loss: 0.6006, G_B_loss: 0.4140\n",
      "Epoch [94/200], Step [441/1067], D_A_loss: 0.1503, D_B_loss: 0.0194, G_A_loss: 0.6022, G_B_loss: 0.4559\n",
      "Epoch [94/200], Step [451/1067], D_A_loss: 0.0535, D_B_loss: 0.0329, G_A_loss: 0.5980, G_B_loss: 0.6517\n",
      "Epoch [94/200], Step [461/1067], D_A_loss: 0.0462, D_B_loss: 0.0174, G_A_loss: 1.1558, G_B_loss: 0.5510\n",
      "Epoch [94/200], Step [471/1067], D_A_loss: 0.0871, D_B_loss: 0.0814, G_A_loss: 0.5643, G_B_loss: 0.2337\n",
      "Epoch [94/200], Step [481/1067], D_A_loss: 0.0902, D_B_loss: 0.0238, G_A_loss: 0.5294, G_B_loss: 0.5045\n",
      "Epoch [94/200], Step [491/1067], D_A_loss: 0.1845, D_B_loss: 0.0356, G_A_loss: 0.5173, G_B_loss: 0.8915\n",
      "Epoch [94/200], Step [501/1067], D_A_loss: 0.0298, D_B_loss: 0.0239, G_A_loss: 0.8348, G_B_loss: 0.3245\n",
      "Epoch [94/200], Step [511/1067], D_A_loss: 0.0763, D_B_loss: 0.0182, G_A_loss: 0.7590, G_B_loss: 0.3601\n",
      "Epoch [94/200], Step [521/1067], D_A_loss: 0.0536, D_B_loss: 0.0510, G_A_loss: 0.5381, G_B_loss: 0.3434\n",
      "Epoch [94/200], Step [531/1067], D_A_loss: 0.1176, D_B_loss: 0.0263, G_A_loss: 0.8121, G_B_loss: 0.4404\n",
      "Epoch [94/200], Step [541/1067], D_A_loss: 0.0937, D_B_loss: 0.0200, G_A_loss: 0.8469, G_B_loss: 0.1057\n",
      "Epoch [94/200], Step [551/1067], D_A_loss: 0.1195, D_B_loss: 0.0424, G_A_loss: 0.6965, G_B_loss: 0.1568\n",
      "Epoch [94/200], Step [561/1067], D_A_loss: 0.0987, D_B_loss: 0.0424, G_A_loss: 0.5694, G_B_loss: 0.5610\n",
      "Epoch [94/200], Step [571/1067], D_A_loss: 0.1119, D_B_loss: 0.0285, G_A_loss: 0.8973, G_B_loss: 0.8220\n",
      "Epoch [94/200], Step [581/1067], D_A_loss: 0.0758, D_B_loss: 0.1581, G_A_loss: 0.2783, G_B_loss: 0.6771\n",
      "Epoch [94/200], Step [591/1067], D_A_loss: 0.0533, D_B_loss: 0.1012, G_A_loss: 0.4125, G_B_loss: 0.7763\n",
      "Epoch [94/200], Step [601/1067], D_A_loss: 0.2781, D_B_loss: 0.0410, G_A_loss: 0.5905, G_B_loss: 0.3272\n",
      "Epoch [94/200], Step [611/1067], D_A_loss: 0.1116, D_B_loss: 0.0388, G_A_loss: 0.8952, G_B_loss: 0.4488\n",
      "Epoch [94/200], Step [621/1067], D_A_loss: 0.0498, D_B_loss: 0.1206, G_A_loss: 1.1960, G_B_loss: 0.6460\n",
      "Epoch [94/200], Step [631/1067], D_A_loss: 0.0390, D_B_loss: 0.0557, G_A_loss: 0.6834, G_B_loss: 0.8246\n",
      "Epoch [94/200], Step [641/1067], D_A_loss: 0.1284, D_B_loss: 0.0223, G_A_loss: 1.1526, G_B_loss: 0.3184\n",
      "Epoch [94/200], Step [651/1067], D_A_loss: 0.2236, D_B_loss: 0.0159, G_A_loss: 0.8054, G_B_loss: 0.6487\n",
      "Epoch [94/200], Step [661/1067], D_A_loss: 0.0773, D_B_loss: 0.0145, G_A_loss: 0.7903, G_B_loss: 0.4980\n",
      "Epoch [94/200], Step [671/1067], D_A_loss: 0.0464, D_B_loss: 0.0319, G_A_loss: 0.7298, G_B_loss: 0.7992\n",
      "Epoch [94/200], Step [681/1067], D_A_loss: 0.0184, D_B_loss: 0.0397, G_A_loss: 1.0272, G_B_loss: 0.1679\n",
      "Epoch [94/200], Step [691/1067], D_A_loss: 0.0437, D_B_loss: 0.0384, G_A_loss: 0.9472, G_B_loss: 0.4277\n",
      "Epoch [94/200], Step [701/1067], D_A_loss: 0.0981, D_B_loss: 0.0228, G_A_loss: 0.7423, G_B_loss: 0.4449\n",
      "Epoch [94/200], Step [711/1067], D_A_loss: 0.1352, D_B_loss: 0.0926, G_A_loss: 0.6578, G_B_loss: 0.4501\n",
      "Epoch [94/200], Step [721/1067], D_A_loss: 0.0428, D_B_loss: 0.2235, G_A_loss: 0.6954, G_B_loss: 0.1424\n",
      "Epoch [94/200], Step [731/1067], D_A_loss: 0.1308, D_B_loss: 0.0720, G_A_loss: 0.6757, G_B_loss: 0.7533\n",
      "Epoch [94/200], Step [741/1067], D_A_loss: 0.0321, D_B_loss: 0.0428, G_A_loss: 0.5812, G_B_loss: 0.2131\n",
      "Epoch [94/200], Step [751/1067], D_A_loss: 0.2032, D_B_loss: 0.0503, G_A_loss: 0.8750, G_B_loss: 0.4751\n",
      "Epoch [94/200], Step [761/1067], D_A_loss: 0.0869, D_B_loss: 0.0086, G_A_loss: 0.8949, G_B_loss: 0.3739\n",
      "Epoch [94/200], Step [771/1067], D_A_loss: 0.1011, D_B_loss: 0.0240, G_A_loss: 0.6901, G_B_loss: 0.7206\n",
      "Epoch [94/200], Step [781/1067], D_A_loss: 0.0636, D_B_loss: 0.0669, G_A_loss: 0.8398, G_B_loss: 0.3475\n",
      "Epoch [94/200], Step [791/1067], D_A_loss: 0.1434, D_B_loss: 0.0890, G_A_loss: 0.7415, G_B_loss: 0.5494\n",
      "Epoch [94/200], Step [801/1067], D_A_loss: 0.0732, D_B_loss: 0.0405, G_A_loss: 1.0721, G_B_loss: 0.3890\n",
      "Epoch [94/200], Step [811/1067], D_A_loss: 0.2016, D_B_loss: 0.0418, G_A_loss: 1.0479, G_B_loss: 0.7155\n",
      "Epoch [94/200], Step [821/1067], D_A_loss: 0.0668, D_B_loss: 0.0276, G_A_loss: 0.8089, G_B_loss: 0.3088\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [94/200], Step [831/1067], D_A_loss: 0.1410, D_B_loss: 0.1359, G_A_loss: 0.2719, G_B_loss: 0.3287\n",
      "Epoch [94/200], Step [841/1067], D_A_loss: 0.0287, D_B_loss: 0.0307, G_A_loss: 0.8501, G_B_loss: 0.4813\n",
      "Epoch [94/200], Step [851/1067], D_A_loss: 0.1828, D_B_loss: 0.0138, G_A_loss: 0.9124, G_B_loss: 0.5385\n",
      "Epoch [94/200], Step [861/1067], D_A_loss: 0.3111, D_B_loss: 0.0575, G_A_loss: 0.4305, G_B_loss: 1.2501\n",
      "Epoch [94/200], Step [871/1067], D_A_loss: 0.0658, D_B_loss: 0.0327, G_A_loss: 1.1594, G_B_loss: 0.5743\n",
      "Epoch [94/200], Step [881/1067], D_A_loss: 0.1880, D_B_loss: 0.0273, G_A_loss: 0.7738, G_B_loss: 0.2678\n",
      "Epoch [94/200], Step [891/1067], D_A_loss: 0.0507, D_B_loss: 0.1589, G_A_loss: 1.1710, G_B_loss: 0.1292\n",
      "Epoch [94/200], Step [901/1067], D_A_loss: 0.2876, D_B_loss: 0.1443, G_A_loss: 0.3425, G_B_loss: 1.1657\n",
      "Epoch [94/200], Step [911/1067], D_A_loss: 0.2664, D_B_loss: 0.0516, G_A_loss: 0.6911, G_B_loss: 0.1448\n",
      "Epoch [94/200], Step [921/1067], D_A_loss: 0.0466, D_B_loss: 0.0262, G_A_loss: 0.7142, G_B_loss: 0.7654\n",
      "Epoch [94/200], Step [931/1067], D_A_loss: 0.1972, D_B_loss: 0.0140, G_A_loss: 0.7353, G_B_loss: 0.3468\n",
      "Epoch [94/200], Step [941/1067], D_A_loss: 0.0459, D_B_loss: 0.0162, G_A_loss: 0.9530, G_B_loss: 0.5260\n",
      "Epoch [94/200], Step [951/1067], D_A_loss: 0.0776, D_B_loss: 0.0163, G_A_loss: 0.6809, G_B_loss: 0.5250\n",
      "Epoch [94/200], Step [961/1067], D_A_loss: 0.0398, D_B_loss: 0.0158, G_A_loss: 0.4283, G_B_loss: 0.7180\n",
      "Epoch [94/200], Step [971/1067], D_A_loss: 0.0403, D_B_loss: 0.0668, G_A_loss: 0.5037, G_B_loss: 0.6450\n",
      "Epoch [94/200], Step [981/1067], D_A_loss: 0.0764, D_B_loss: 0.0722, G_A_loss: 0.6117, G_B_loss: 0.5534\n",
      "Epoch [94/200], Step [991/1067], D_A_loss: 0.0331, D_B_loss: 0.0213, G_A_loss: 0.8916, G_B_loss: 0.5027\n",
      "Epoch [94/200], Step [1001/1067], D_A_loss: 0.0371, D_B_loss: 0.0128, G_A_loss: 0.8553, G_B_loss: 0.4809\n",
      "Epoch [94/200], Step [1011/1067], D_A_loss: 0.1140, D_B_loss: 0.0215, G_A_loss: 0.7074, G_B_loss: 0.6017\n",
      "Epoch [94/200], Step [1021/1067], D_A_loss: 0.0648, D_B_loss: 0.0567, G_A_loss: 1.0027, G_B_loss: 1.3534\n",
      "Epoch [94/200], Step [1031/1067], D_A_loss: 0.1811, D_B_loss: 0.0186, G_A_loss: 0.4619, G_B_loss: 0.7960\n",
      "Epoch [94/200], Step [1041/1067], D_A_loss: 0.0552, D_B_loss: 0.0534, G_A_loss: 0.6676, G_B_loss: 0.2668\n",
      "Epoch [94/200], Step [1051/1067], D_A_loss: 0.0539, D_B_loss: 0.0130, G_A_loss: 0.5268, G_B_loss: 0.4593\n",
      "Epoch [94/200], Step [1061/1067], D_A_loss: 0.0627, D_B_loss: 0.0454, G_A_loss: 1.0995, G_B_loss: 0.7831\n",
      "Epoch [95/200], Step [1/1067], D_A_loss: 0.0279, D_B_loss: 0.0692, G_A_loss: 0.5353, G_B_loss: 0.5040\n",
      "Epoch [95/200], Step [11/1067], D_A_loss: 0.0389, D_B_loss: 0.0304, G_A_loss: 0.7622, G_B_loss: 0.9730\n",
      "Epoch [95/200], Step [21/1067], D_A_loss: 0.1016, D_B_loss: 0.0547, G_A_loss: 0.7849, G_B_loss: 0.3570\n",
      "Epoch [95/200], Step [31/1067], D_A_loss: 0.1328, D_B_loss: 0.0514, G_A_loss: 0.5665, G_B_loss: 0.7036\n",
      "Epoch [95/200], Step [41/1067], D_A_loss: 0.0459, D_B_loss: 0.0237, G_A_loss: 1.1571, G_B_loss: 0.6719\n",
      "Epoch [95/200], Step [51/1067], D_A_loss: 0.0597, D_B_loss: 0.0339, G_A_loss: 0.7058, G_B_loss: 1.3965\n",
      "Epoch [95/200], Step [61/1067], D_A_loss: 0.0861, D_B_loss: 0.0256, G_A_loss: 0.6655, G_B_loss: 0.3379\n",
      "Epoch [95/200], Step [71/1067], D_A_loss: 0.1409, D_B_loss: 0.0429, G_A_loss: 0.4033, G_B_loss: 0.4035\n",
      "Epoch [95/200], Step [81/1067], D_A_loss: 0.1587, D_B_loss: 0.0863, G_A_loss: 0.3843, G_B_loss: 0.3419\n",
      "Epoch [95/200], Step [91/1067], D_A_loss: 0.1698, D_B_loss: 0.0569, G_A_loss: 0.8888, G_B_loss: 0.5472\n",
      "Epoch [95/200], Step [101/1067], D_A_loss: 0.0260, D_B_loss: 0.0567, G_A_loss: 0.5772, G_B_loss: 0.3560\n",
      "Epoch [95/200], Step [111/1067], D_A_loss: 0.0739, D_B_loss: 0.0979, G_A_loss: 0.8943, G_B_loss: 0.8330\n",
      "Epoch [95/200], Step [121/1067], D_A_loss: 0.0893, D_B_loss: 0.0391, G_A_loss: 0.9568, G_B_loss: 0.5384\n",
      "Epoch [95/200], Step [131/1067], D_A_loss: 0.1144, D_B_loss: 0.0199, G_A_loss: 0.9874, G_B_loss: 0.4717\n",
      "Epoch [95/200], Step [141/1067], D_A_loss: 0.0458, D_B_loss: 0.0166, G_A_loss: 1.0248, G_B_loss: 0.7084\n",
      "Epoch [95/200], Step [151/1067], D_A_loss: 0.1512, D_B_loss: 0.0107, G_A_loss: 0.9527, G_B_loss: 0.6350\n",
      "Epoch [95/200], Step [161/1067], D_A_loss: 0.1345, D_B_loss: 0.0515, G_A_loss: 0.8428, G_B_loss: 0.4181\n",
      "Epoch [95/200], Step [171/1067], D_A_loss: 0.0900, D_B_loss: 0.0270, G_A_loss: 1.1261, G_B_loss: 0.6607\n",
      "Epoch [95/200], Step [181/1067], D_A_loss: 0.0906, D_B_loss: 0.0162, G_A_loss: 0.4732, G_B_loss: 0.5958\n",
      "Epoch [95/200], Step [191/1067], D_A_loss: 0.0553, D_B_loss: 0.0249, G_A_loss: 1.0480, G_B_loss: 0.3335\n",
      "Epoch [95/200], Step [201/1067], D_A_loss: 0.1126, D_B_loss: 0.0086, G_A_loss: 1.4206, G_B_loss: 0.7905\n",
      "Epoch [95/200], Step [211/1067], D_A_loss: 0.0746, D_B_loss: 0.0286, G_A_loss: 0.6223, G_B_loss: 0.3028\n",
      "Epoch [95/200], Step [221/1067], D_A_loss: 0.1125, D_B_loss: 0.0168, G_A_loss: 1.2010, G_B_loss: 0.4926\n",
      "Epoch [95/200], Step [231/1067], D_A_loss: 0.1811, D_B_loss: 0.0136, G_A_loss: 0.7969, G_B_loss: 1.0000\n",
      "Epoch [95/200], Step [241/1067], D_A_loss: 0.0657, D_B_loss: 0.0386, G_A_loss: 0.6799, G_B_loss: 0.4785\n",
      "Epoch [95/200], Step [251/1067], D_A_loss: 0.0965, D_B_loss: 0.0523, G_A_loss: 0.3004, G_B_loss: 0.4736\n",
      "Epoch [95/200], Step [261/1067], D_A_loss: 0.1931, D_B_loss: 0.0354, G_A_loss: 0.6879, G_B_loss: 0.4177\n",
      "Epoch [95/200], Step [271/1067], D_A_loss: 0.1051, D_B_loss: 0.0577, G_A_loss: 0.8358, G_B_loss: 0.4235\n",
      "Epoch [95/200], Step [281/1067], D_A_loss: 0.0279, D_B_loss: 0.0095, G_A_loss: 1.0316, G_B_loss: 0.5228\n",
      "Epoch [95/200], Step [291/1067], D_A_loss: 0.2420, D_B_loss: 0.0248, G_A_loss: 1.2326, G_B_loss: 0.2733\n",
      "Epoch [95/200], Step [301/1067], D_A_loss: 0.2061, D_B_loss: 0.0163, G_A_loss: 1.0560, G_B_loss: 0.8683\n",
      "Epoch [95/200], Step [311/1067], D_A_loss: 0.1921, D_B_loss: 0.0219, G_A_loss: 0.7276, G_B_loss: 0.1358\n",
      "Epoch [95/200], Step [321/1067], D_A_loss: 0.1115, D_B_loss: 0.0405, G_A_loss: 0.3668, G_B_loss: 0.5981\n",
      "Epoch [95/200], Step [331/1067], D_A_loss: 0.0939, D_B_loss: 0.0205, G_A_loss: 0.6948, G_B_loss: 0.7852\n",
      "Epoch [95/200], Step [341/1067], D_A_loss: 0.2074, D_B_loss: 0.0184, G_A_loss: 0.8712, G_B_loss: 0.6157\n",
      "Epoch [95/200], Step [351/1067], D_A_loss: 0.1959, D_B_loss: 0.0809, G_A_loss: 0.9668, G_B_loss: 0.2151\n",
      "Epoch [95/200], Step [361/1067], D_A_loss: 0.1486, D_B_loss: 0.0403, G_A_loss: 0.7087, G_B_loss: 0.6946\n",
      "Epoch [95/200], Step [371/1067], D_A_loss: 0.1097, D_B_loss: 0.0135, G_A_loss: 0.8185, G_B_loss: 0.3471\n",
      "Epoch [95/200], Step [381/1067], D_A_loss: 0.0946, D_B_loss: 0.0396, G_A_loss: 0.6014, G_B_loss: 0.5453\n",
      "Epoch [95/200], Step [391/1067], D_A_loss: 0.0614, D_B_loss: 0.0387, G_A_loss: 1.0403, G_B_loss: 0.6260\n",
      "Epoch [95/200], Step [401/1067], D_A_loss: 0.0790, D_B_loss: 0.0697, G_A_loss: 0.5347, G_B_loss: 0.4390\n",
      "Epoch [95/200], Step [411/1067], D_A_loss: 0.0481, D_B_loss: 0.0154, G_A_loss: 0.7017, G_B_loss: 0.5805\n",
      "Epoch [95/200], Step [421/1067], D_A_loss: 0.1231, D_B_loss: 0.0381, G_A_loss: 0.7400, G_B_loss: 0.3116\n",
      "Epoch [95/200], Step [431/1067], D_A_loss: 0.0913, D_B_loss: 0.0223, G_A_loss: 0.8031, G_B_loss: 0.4513\n",
      "Epoch [95/200], Step [441/1067], D_A_loss: 0.0714, D_B_loss: 0.0722, G_A_loss: 0.5194, G_B_loss: 0.5609\n",
      "Epoch [95/200], Step [451/1067], D_A_loss: 0.1424, D_B_loss: 0.0200, G_A_loss: 0.7844, G_B_loss: 0.5544\n",
      "Epoch [95/200], Step [461/1067], D_A_loss: 0.2432, D_B_loss: 0.0131, G_A_loss: 0.8787, G_B_loss: 0.4071\n",
      "Epoch [95/200], Step [471/1067], D_A_loss: 0.1399, D_B_loss: 0.0571, G_A_loss: 1.6400, G_B_loss: 0.6161\n",
      "Epoch [95/200], Step [481/1067], D_A_loss: 0.1115, D_B_loss: 0.0941, G_A_loss: 0.4393, G_B_loss: 0.5053\n",
      "Epoch [95/200], Step [491/1067], D_A_loss: 0.1734, D_B_loss: 0.2386, G_A_loss: 0.6311, G_B_loss: 0.5202\n",
      "Epoch [95/200], Step [501/1067], D_A_loss: 0.0571, D_B_loss: 0.0398, G_A_loss: 1.1743, G_B_loss: 0.7402\n",
      "Epoch [95/200], Step [511/1067], D_A_loss: 0.0657, D_B_loss: 0.0442, G_A_loss: 0.6356, G_B_loss: 0.4513\n",
      "Epoch [95/200], Step [521/1067], D_A_loss: 0.1134, D_B_loss: 0.0167, G_A_loss: 0.6130, G_B_loss: 0.7276\n",
      "Epoch [95/200], Step [531/1067], D_A_loss: 0.1923, D_B_loss: 0.0202, G_A_loss: 0.9565, G_B_loss: 0.3702\n",
      "Epoch [95/200], Step [541/1067], D_A_loss: 0.0403, D_B_loss: 0.0297, G_A_loss: 0.9804, G_B_loss: 0.4965\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [95/200], Step [551/1067], D_A_loss: 0.0967, D_B_loss: 0.1720, G_A_loss: 0.7886, G_B_loss: 0.4278\n",
      "Epoch [95/200], Step [561/1067], D_A_loss: 0.2469, D_B_loss: 0.0211, G_A_loss: 0.5009, G_B_loss: 0.4778\n",
      "Epoch [95/200], Step [571/1067], D_A_loss: 0.0279, D_B_loss: 0.0256, G_A_loss: 0.7043, G_B_loss: 0.3992\n",
      "Epoch [95/200], Step [581/1067], D_A_loss: 0.0962, D_B_loss: 0.0321, G_A_loss: 0.9042, G_B_loss: 0.4738\n",
      "Epoch [95/200], Step [591/1067], D_A_loss: 0.0844, D_B_loss: 0.0837, G_A_loss: 1.1542, G_B_loss: 0.3378\n",
      "Epoch [95/200], Step [601/1067], D_A_loss: 0.0686, D_B_loss: 0.0181, G_A_loss: 0.7805, G_B_loss: 0.5140\n",
      "Epoch [95/200], Step [611/1067], D_A_loss: 0.0888, D_B_loss: 0.0177, G_A_loss: 0.9437, G_B_loss: 0.4060\n",
      "Epoch [95/200], Step [621/1067], D_A_loss: 0.0762, D_B_loss: 0.0203, G_A_loss: 0.9578, G_B_loss: 0.8628\n",
      "Epoch [95/200], Step [631/1067], D_A_loss: 0.0899, D_B_loss: 0.0334, G_A_loss: 0.8207, G_B_loss: 0.4805\n",
      "Epoch [95/200], Step [641/1067], D_A_loss: 0.0720, D_B_loss: 0.0138, G_A_loss: 1.0972, G_B_loss: 0.3160\n",
      "Epoch [95/200], Step [651/1067], D_A_loss: 0.1001, D_B_loss: 0.0137, G_A_loss: 1.2351, G_B_loss: 0.5599\n",
      "Epoch [95/200], Step [661/1067], D_A_loss: 0.0510, D_B_loss: 0.0388, G_A_loss: 0.9699, G_B_loss: 0.6320\n",
      "Epoch [95/200], Step [671/1067], D_A_loss: 0.0986, D_B_loss: 0.0643, G_A_loss: 0.5429, G_B_loss: 0.4532\n",
      "Epoch [95/200], Step [681/1067], D_A_loss: 0.0583, D_B_loss: 0.0914, G_A_loss: 0.7776, G_B_loss: 0.2729\n",
      "Epoch [95/200], Step [691/1067], D_A_loss: 0.0703, D_B_loss: 0.0550, G_A_loss: 1.0342, G_B_loss: 0.7453\n",
      "Epoch [95/200], Step [701/1067], D_A_loss: 0.1979, D_B_loss: 0.0366, G_A_loss: 0.6857, G_B_loss: 0.2664\n",
      "Epoch [95/200], Step [711/1067], D_A_loss: 0.1490, D_B_loss: 0.0240, G_A_loss: 0.9031, G_B_loss: 0.3335\n",
      "Epoch [95/200], Step [721/1067], D_A_loss: 0.1153, D_B_loss: 0.0138, G_A_loss: 0.9558, G_B_loss: 1.0005\n",
      "Epoch [95/200], Step [731/1067], D_A_loss: 0.0762, D_B_loss: 0.0799, G_A_loss: 0.6854, G_B_loss: 0.5090\n",
      "Epoch [95/200], Step [741/1067], D_A_loss: 0.1660, D_B_loss: 0.0197, G_A_loss: 1.0192, G_B_loss: 0.2446\n",
      "Epoch [95/200], Step [751/1067], D_A_loss: 0.1419, D_B_loss: 0.0983, G_A_loss: 0.3682, G_B_loss: 0.3392\n",
      "Epoch [95/200], Step [761/1067], D_A_loss: 0.1412, D_B_loss: 0.0403, G_A_loss: 0.6066, G_B_loss: 0.1851\n",
      "Epoch [95/200], Step [771/1067], D_A_loss: 0.0346, D_B_loss: 0.0429, G_A_loss: 0.7765, G_B_loss: 0.5305\n",
      "Epoch [95/200], Step [781/1067], D_A_loss: 0.1731, D_B_loss: 0.0263, G_A_loss: 0.7261, G_B_loss: 0.4886\n",
      "Epoch [95/200], Step [791/1067], D_A_loss: 0.0377, D_B_loss: 0.0200, G_A_loss: 0.6692, G_B_loss: 0.2347\n",
      "Epoch [95/200], Step [801/1067], D_A_loss: 0.0223, D_B_loss: 0.0230, G_A_loss: 0.8809, G_B_loss: 0.1956\n",
      "Epoch [95/200], Step [811/1067], D_A_loss: 0.0918, D_B_loss: 0.0322, G_A_loss: 0.7772, G_B_loss: 0.6031\n",
      "Epoch [95/200], Step [821/1067], D_A_loss: 0.1387, D_B_loss: 0.0322, G_A_loss: 0.4397, G_B_loss: 0.9887\n",
      "Epoch [95/200], Step [831/1067], D_A_loss: 0.1624, D_B_loss: 0.0306, G_A_loss: 0.8218, G_B_loss: 0.7527\n",
      "Epoch [95/200], Step [841/1067], D_A_loss: 0.0478, D_B_loss: 0.0111, G_A_loss: 0.8302, G_B_loss: 0.9218\n",
      "Epoch [95/200], Step [851/1067], D_A_loss: 0.0756, D_B_loss: 0.0236, G_A_loss: 0.6845, G_B_loss: 0.5561\n",
      "Epoch [95/200], Step [861/1067], D_A_loss: 0.0781, D_B_loss: 0.0081, G_A_loss: 0.9684, G_B_loss: 0.6785\n",
      "Epoch [95/200], Step [871/1067], D_A_loss: 0.0499, D_B_loss: 0.0163, G_A_loss: 0.6221, G_B_loss: 0.6336\n",
      "Epoch [95/200], Step [881/1067], D_A_loss: 0.0402, D_B_loss: 0.0405, G_A_loss: 0.7159, G_B_loss: 0.9221\n",
      "Epoch [95/200], Step [891/1067], D_A_loss: 0.1524, D_B_loss: 0.0422, G_A_loss: 1.0686, G_B_loss: 0.8539\n",
      "Epoch [95/200], Step [901/1067], D_A_loss: 0.3240, D_B_loss: 0.0305, G_A_loss: 0.6246, G_B_loss: 0.0957\n",
      "Epoch [95/200], Step [911/1067], D_A_loss: 0.1602, D_B_loss: 0.0139, G_A_loss: 0.5900, G_B_loss: 0.4484\n",
      "Epoch [95/200], Step [921/1067], D_A_loss: 0.0347, D_B_loss: 0.1158, G_A_loss: 0.4050, G_B_loss: 0.5362\n",
      "Epoch [95/200], Step [931/1067], D_A_loss: 0.2211, D_B_loss: 0.0390, G_A_loss: 0.7029, G_B_loss: 0.2727\n",
      "Epoch [95/200], Step [941/1067], D_A_loss: 0.1594, D_B_loss: 0.0363, G_A_loss: 0.5675, G_B_loss: 0.2470\n",
      "Epoch [95/200], Step [951/1067], D_A_loss: 0.1478, D_B_loss: 0.0334, G_A_loss: 0.7717, G_B_loss: 0.2757\n",
      "Epoch [95/200], Step [961/1067], D_A_loss: 0.3289, D_B_loss: 0.0522, G_A_loss: 1.0583, G_B_loss: 0.2949\n",
      "Epoch [95/200], Step [971/1067], D_A_loss: 0.1314, D_B_loss: 0.0515, G_A_loss: 0.7964, G_B_loss: 0.3833\n",
      "Epoch [95/200], Step [981/1067], D_A_loss: 0.1160, D_B_loss: 0.0187, G_A_loss: 0.8542, G_B_loss: 0.1975\n",
      "Epoch [95/200], Step [991/1067], D_A_loss: 0.0930, D_B_loss: 0.0576, G_A_loss: 0.5177, G_B_loss: 0.4774\n",
      "Epoch [95/200], Step [1001/1067], D_A_loss: 0.1418, D_B_loss: 0.1966, G_A_loss: 0.8719, G_B_loss: 0.3287\n",
      "Epoch [95/200], Step [1011/1067], D_A_loss: 0.3030, D_B_loss: 0.0290, G_A_loss: 0.5735, G_B_loss: 0.8866\n",
      "Epoch [95/200], Step [1021/1067], D_A_loss: 0.1171, D_B_loss: 0.0241, G_A_loss: 0.3140, G_B_loss: 0.4870\n",
      "Epoch [95/200], Step [1031/1067], D_A_loss: 0.1471, D_B_loss: 0.0650, G_A_loss: 0.7448, G_B_loss: 0.5589\n",
      "Epoch [95/200], Step [1041/1067], D_A_loss: 0.0535, D_B_loss: 0.0128, G_A_loss: 0.7002, G_B_loss: 0.7514\n",
      "Epoch [95/200], Step [1051/1067], D_A_loss: 0.1361, D_B_loss: 0.0157, G_A_loss: 0.9221, G_B_loss: 0.4403\n",
      "Epoch [95/200], Step [1061/1067], D_A_loss: 0.1378, D_B_loss: 0.0640, G_A_loss: 1.1191, G_B_loss: 0.4366\n",
      "Epoch [96/200], Step [1/1067], D_A_loss: 0.0814, D_B_loss: 0.0181, G_A_loss: 0.9261, G_B_loss: 0.7805\n",
      "Epoch [96/200], Step [11/1067], D_A_loss: 0.3371, D_B_loss: 0.0256, G_A_loss: 0.7789, G_B_loss: 0.7541\n",
      "Epoch [96/200], Step [21/1067], D_A_loss: 0.1655, D_B_loss: 0.0462, G_A_loss: 0.9116, G_B_loss: 1.0315\n",
      "Epoch [96/200], Step [31/1067], D_A_loss: 0.1858, D_B_loss: 0.0504, G_A_loss: 0.6014, G_B_loss: 0.4166\n",
      "Epoch [96/200], Step [41/1067], D_A_loss: 0.0382, D_B_loss: 0.1204, G_A_loss: 0.8238, G_B_loss: 0.2382\n",
      "Epoch [96/200], Step [51/1067], D_A_loss: 0.0759, D_B_loss: 0.0291, G_A_loss: 1.0921, G_B_loss: 0.4918\n",
      "Epoch [96/200], Step [61/1067], D_A_loss: 0.0873, D_B_loss: 0.0397, G_A_loss: 1.0928, G_B_loss: 0.5345\n",
      "Epoch [96/200], Step [71/1067], D_A_loss: 0.2004, D_B_loss: 0.0189, G_A_loss: 1.0144, G_B_loss: 0.9678\n",
      "Epoch [96/200], Step [81/1067], D_A_loss: 0.0732, D_B_loss: 0.0077, G_A_loss: 0.9773, G_B_loss: 0.4073\n",
      "Epoch [96/200], Step [91/1067], D_A_loss: 0.1004, D_B_loss: 0.0330, G_A_loss: 1.2962, G_B_loss: 0.6641\n",
      "Epoch [96/200], Step [101/1067], D_A_loss: 0.0534, D_B_loss: 0.0865, G_A_loss: 0.7054, G_B_loss: 0.5700\n",
      "Epoch [96/200], Step [111/1067], D_A_loss: 0.2212, D_B_loss: 0.0440, G_A_loss: 0.8737, G_B_loss: 0.2506\n",
      "Epoch [96/200], Step [121/1067], D_A_loss: 0.0965, D_B_loss: 0.0203, G_A_loss: 0.9386, G_B_loss: 0.7465\n",
      "Epoch [96/200], Step [131/1067], D_A_loss: 0.0678, D_B_loss: 0.0207, G_A_loss: 0.7211, G_B_loss: 0.5571\n",
      "Epoch [96/200], Step [141/1067], D_A_loss: 0.1192, D_B_loss: 0.0426, G_A_loss: 0.5722, G_B_loss: 0.2038\n",
      "Epoch [96/200], Step [151/1067], D_A_loss: 0.0986, D_B_loss: 0.0154, G_A_loss: 0.9805, G_B_loss: 0.5869\n",
      "Epoch [96/200], Step [161/1067], D_A_loss: 0.0711, D_B_loss: 0.0652, G_A_loss: 0.6062, G_B_loss: 0.5505\n",
      "Epoch [96/200], Step [171/1067], D_A_loss: 0.0841, D_B_loss: 0.0468, G_A_loss: 0.9490, G_B_loss: 0.5602\n",
      "Epoch [96/200], Step [181/1067], D_A_loss: 0.0747, D_B_loss: 0.0297, G_A_loss: 0.7640, G_B_loss: 0.4942\n",
      "Epoch [96/200], Step [191/1067], D_A_loss: 0.0359, D_B_loss: 0.0163, G_A_loss: 1.3564, G_B_loss: 0.2468\n",
      "Epoch [96/200], Step [201/1067], D_A_loss: 0.1755, D_B_loss: 0.0258, G_A_loss: 0.7499, G_B_loss: 0.7314\n",
      "Epoch [96/200], Step [211/1067], D_A_loss: 0.1284, D_B_loss: 0.0457, G_A_loss: 0.7282, G_B_loss: 0.7049\n",
      "Epoch [96/200], Step [221/1067], D_A_loss: 0.1679, D_B_loss: 0.0184, G_A_loss: 0.7141, G_B_loss: 0.5387\n",
      "Epoch [96/200], Step [231/1067], D_A_loss: 0.1892, D_B_loss: 0.0382, G_A_loss: 1.1582, G_B_loss: 0.3998\n",
      "Epoch [96/200], Step [241/1067], D_A_loss: 0.0549, D_B_loss: 0.0768, G_A_loss: 0.5377, G_B_loss: 0.7795\n",
      "Epoch [96/200], Step [251/1067], D_A_loss: 0.0817, D_B_loss: 0.0566, G_A_loss: 0.5676, G_B_loss: 0.2023\n",
      "Epoch [96/200], Step [261/1067], D_A_loss: 0.0474, D_B_loss: 0.0217, G_A_loss: 0.7366, G_B_loss: 0.8509\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [96/200], Step [271/1067], D_A_loss: 0.1962, D_B_loss: 0.0146, G_A_loss: 0.8285, G_B_loss: 0.2783\n",
      "Epoch [96/200], Step [281/1067], D_A_loss: 0.2050, D_B_loss: 0.0361, G_A_loss: 0.7110, G_B_loss: 0.8416\n",
      "Epoch [96/200], Step [291/1067], D_A_loss: 0.0842, D_B_loss: 0.0312, G_A_loss: 0.8120, G_B_loss: 0.5051\n",
      "Epoch [96/200], Step [301/1067], D_A_loss: 0.0713, D_B_loss: 0.0528, G_A_loss: 1.1762, G_B_loss: 0.4740\n",
      "Epoch [96/200], Step [311/1067], D_A_loss: 0.0793, D_B_loss: 0.0402, G_A_loss: 0.6284, G_B_loss: 0.4626\n",
      "Epoch [96/200], Step [321/1067], D_A_loss: 0.0655, D_B_loss: 0.0266, G_A_loss: 0.8174, G_B_loss: 0.2789\n",
      "Epoch [96/200], Step [331/1067], D_A_loss: 0.2543, D_B_loss: 0.0256, G_A_loss: 0.7469, G_B_loss: 0.1196\n",
      "Epoch [96/200], Step [341/1067], D_A_loss: 0.1031, D_B_loss: 0.0144, G_A_loss: 1.0850, G_B_loss: 0.4033\n",
      "Epoch [96/200], Step [351/1067], D_A_loss: 0.0896, D_B_loss: 0.0802, G_A_loss: 1.1551, G_B_loss: 0.3135\n",
      "Epoch [96/200], Step [361/1067], D_A_loss: 0.0979, D_B_loss: 0.0278, G_A_loss: 0.9515, G_B_loss: 0.4371\n",
      "Epoch [96/200], Step [371/1067], D_A_loss: 0.0320, D_B_loss: 0.0266, G_A_loss: 0.8298, G_B_loss: 0.2088\n",
      "Epoch [96/200], Step [381/1067], D_A_loss: 0.0445, D_B_loss: 0.0448, G_A_loss: 0.6051, G_B_loss: 0.7355\n",
      "Epoch [96/200], Step [391/1067], D_A_loss: 0.0883, D_B_loss: 0.0362, G_A_loss: 0.6287, G_B_loss: 0.5470\n",
      "Epoch [96/200], Step [401/1067], D_A_loss: 0.1492, D_B_loss: 0.0581, G_A_loss: 1.0341, G_B_loss: 0.8802\n",
      "Epoch [96/200], Step [411/1067], D_A_loss: 0.0766, D_B_loss: 0.0154, G_A_loss: 0.6681, G_B_loss: 0.2978\n",
      "Epoch [96/200], Step [421/1067], D_A_loss: 0.0569, D_B_loss: 0.0190, G_A_loss: 0.9264, G_B_loss: 0.6307\n",
      "Epoch [96/200], Step [431/1067], D_A_loss: 0.0412, D_B_loss: 0.0154, G_A_loss: 0.9223, G_B_loss: 0.6084\n",
      "Epoch [96/200], Step [441/1067], D_A_loss: 0.1705, D_B_loss: 0.0337, G_A_loss: 0.6506, G_B_loss: 0.7090\n",
      "Epoch [96/200], Step [451/1067], D_A_loss: 0.3587, D_B_loss: 0.0318, G_A_loss: 0.6455, G_B_loss: 0.0943\n",
      "Epoch [96/200], Step [461/1067], D_A_loss: 0.0862, D_B_loss: 0.1620, G_A_loss: 0.3779, G_B_loss: 0.4623\n",
      "Epoch [96/200], Step [471/1067], D_A_loss: 0.1455, D_B_loss: 0.0276, G_A_loss: 1.1446, G_B_loss: 0.3362\n",
      "Epoch [96/200], Step [481/1067], D_A_loss: 0.0183, D_B_loss: 0.0392, G_A_loss: 0.5638, G_B_loss: 0.5073\n",
      "Epoch [96/200], Step [491/1067], D_A_loss: 0.0542, D_B_loss: 0.0201, G_A_loss: 0.9051, G_B_loss: 0.5982\n",
      "Epoch [96/200], Step [501/1067], D_A_loss: 0.2018, D_B_loss: 0.0292, G_A_loss: 0.6322, G_B_loss: 0.3791\n",
      "Epoch [96/200], Step [511/1067], D_A_loss: 0.0208, D_B_loss: 0.0205, G_A_loss: 0.7565, G_B_loss: 0.6409\n",
      "Epoch [96/200], Step [521/1067], D_A_loss: 0.1107, D_B_loss: 0.0168, G_A_loss: 0.9293, G_B_loss: 0.4127\n",
      "Epoch [96/200], Step [531/1067], D_A_loss: 0.1450, D_B_loss: 0.0326, G_A_loss: 1.1345, G_B_loss: 0.4597\n",
      "Epoch [96/200], Step [541/1067], D_A_loss: 0.0398, D_B_loss: 0.0513, G_A_loss: 0.9827, G_B_loss: 0.3736\n",
      "Epoch [96/200], Step [551/1067], D_A_loss: 0.1501, D_B_loss: 0.0210, G_A_loss: 0.9306, G_B_loss: 0.5367\n",
      "Epoch [96/200], Step [561/1067], D_A_loss: 0.1889, D_B_loss: 0.0153, G_A_loss: 1.0930, G_B_loss: 0.5790\n",
      "Epoch [96/200], Step [571/1067], D_A_loss: 0.2290, D_B_loss: 0.0441, G_A_loss: 0.6621, G_B_loss: 1.4775\n",
      "Epoch [96/200], Step [581/1067], D_A_loss: 0.0839, D_B_loss: 0.0200, G_A_loss: 0.9501, G_B_loss: 0.7960\n",
      "Epoch [96/200], Step [591/1067], D_A_loss: 0.0697, D_B_loss: 0.0220, G_A_loss: 0.7831, G_B_loss: 0.6784\n",
      "Epoch [96/200], Step [601/1067], D_A_loss: 0.2141, D_B_loss: 0.0136, G_A_loss: 1.2144, G_B_loss: 0.3574\n",
      "Epoch [96/200], Step [611/1067], D_A_loss: 0.1147, D_B_loss: 0.0171, G_A_loss: 0.7367, G_B_loss: 0.5696\n",
      "Epoch [96/200], Step [621/1067], D_A_loss: 0.0719, D_B_loss: 0.0293, G_A_loss: 0.6831, G_B_loss: 0.6143\n",
      "Epoch [96/200], Step [631/1067], D_A_loss: 0.1844, D_B_loss: 0.0547, G_A_loss: 0.5355, G_B_loss: 0.2564\n",
      "Epoch [96/200], Step [641/1067], D_A_loss: 0.0858, D_B_loss: 0.0643, G_A_loss: 1.5699, G_B_loss: 0.4178\n",
      "Epoch [96/200], Step [651/1067], D_A_loss: 0.0596, D_B_loss: 0.0773, G_A_loss: 0.5291, G_B_loss: 0.1988\n",
      "Epoch [96/200], Step [661/1067], D_A_loss: 0.0289, D_B_loss: 0.0508, G_A_loss: 0.7275, G_B_loss: 0.8669\n",
      "Epoch [96/200], Step [671/1067], D_A_loss: 0.1542, D_B_loss: 0.0689, G_A_loss: 1.0191, G_B_loss: 0.3654\n",
      "Epoch [96/200], Step [681/1067], D_A_loss: 0.0427, D_B_loss: 0.0235, G_A_loss: 1.2212, G_B_loss: 0.6296\n",
      "Epoch [96/200], Step [691/1067], D_A_loss: 0.1071, D_B_loss: 0.0286, G_A_loss: 0.9683, G_B_loss: 0.4053\n",
      "Epoch [96/200], Step [701/1067], D_A_loss: 0.0571, D_B_loss: 0.0776, G_A_loss: 0.5206, G_B_loss: 0.2982\n",
      "Epoch [96/200], Step [711/1067], D_A_loss: 0.0849, D_B_loss: 0.0398, G_A_loss: 0.6421, G_B_loss: 0.1874\n",
      "Epoch [96/200], Step [721/1067], D_A_loss: 0.1627, D_B_loss: 0.0470, G_A_loss: 0.7362, G_B_loss: 0.2539\n",
      "Epoch [96/200], Step [731/1067], D_A_loss: 0.0820, D_B_loss: 0.0424, G_A_loss: 1.0285, G_B_loss: 0.4420\n",
      "Epoch [96/200], Step [741/1067], D_A_loss: 0.0502, D_B_loss: 0.0400, G_A_loss: 1.2388, G_B_loss: 0.5422\n",
      "Epoch [96/200], Step [751/1067], D_A_loss: 0.2011, D_B_loss: 0.0304, G_A_loss: 0.7320, G_B_loss: 0.5296\n",
      "Epoch [96/200], Step [761/1067], D_A_loss: 0.0415, D_B_loss: 0.0495, G_A_loss: 0.5940, G_B_loss: 0.4296\n",
      "Epoch [96/200], Step [771/1067], D_A_loss: 0.0609, D_B_loss: 0.0078, G_A_loss: 1.1962, G_B_loss: 0.6949\n",
      "Epoch [96/200], Step [781/1067], D_A_loss: 0.1276, D_B_loss: 0.0350, G_A_loss: 0.6614, G_B_loss: 0.6769\n",
      "Epoch [96/200], Step [791/1067], D_A_loss: 0.0536, D_B_loss: 0.0411, G_A_loss: 0.5691, G_B_loss: 0.2552\n",
      "Epoch [96/200], Step [801/1067], D_A_loss: 0.0862, D_B_loss: 0.0672, G_A_loss: 0.4976, G_B_loss: 0.4082\n",
      "Epoch [96/200], Step [811/1067], D_A_loss: 0.0474, D_B_loss: 0.0280, G_A_loss: 1.0847, G_B_loss: 0.8743\n",
      "Epoch [96/200], Step [821/1067], D_A_loss: 0.1785, D_B_loss: 0.0470, G_A_loss: 0.6069, G_B_loss: 0.4060\n",
      "Epoch [96/200], Step [831/1067], D_A_loss: 0.0270, D_B_loss: 0.0192, G_A_loss: 0.8447, G_B_loss: 0.9882\n",
      "Epoch [96/200], Step [841/1067], D_A_loss: 0.0763, D_B_loss: 0.0283, G_A_loss: 0.9295, G_B_loss: 0.7928\n",
      "Epoch [96/200], Step [851/1067], D_A_loss: 0.0491, D_B_loss: 0.0234, G_A_loss: 0.5925, G_B_loss: 0.6147\n",
      "Epoch [96/200], Step [861/1067], D_A_loss: 0.1118, D_B_loss: 0.0359, G_A_loss: 0.8648, G_B_loss: 0.8213\n",
      "Epoch [96/200], Step [871/1067], D_A_loss: 0.0609, D_B_loss: 0.0128, G_A_loss: 0.7260, G_B_loss: 0.7426\n",
      "Epoch [96/200], Step [881/1067], D_A_loss: 0.0198, D_B_loss: 0.0299, G_A_loss: 0.8879, G_B_loss: 0.7164\n",
      "Epoch [96/200], Step [891/1067], D_A_loss: 0.1131, D_B_loss: 0.0110, G_A_loss: 0.9869, G_B_loss: 1.2290\n",
      "Epoch [96/200], Step [901/1067], D_A_loss: 0.0993, D_B_loss: 0.0260, G_A_loss: 0.7158, G_B_loss: 0.5578\n",
      "Epoch [96/200], Step [911/1067], D_A_loss: 0.0351, D_B_loss: 0.0297, G_A_loss: 0.8892, G_B_loss: 0.3589\n",
      "Epoch [96/200], Step [921/1067], D_A_loss: 0.1078, D_B_loss: 0.0240, G_A_loss: 0.9920, G_B_loss: 0.3949\n",
      "Epoch [96/200], Step [931/1067], D_A_loss: 0.1235, D_B_loss: 0.0776, G_A_loss: 0.4128, G_B_loss: 0.6598\n",
      "Epoch [96/200], Step [941/1067], D_A_loss: 0.1649, D_B_loss: 0.0335, G_A_loss: 0.8204, G_B_loss: 0.8538\n",
      "Epoch [96/200], Step [951/1067], D_A_loss: 0.0620, D_B_loss: 0.0165, G_A_loss: 0.8459, G_B_loss: 0.8009\n",
      "Epoch [96/200], Step [961/1067], D_A_loss: 0.1707, D_B_loss: 0.0221, G_A_loss: 0.3850, G_B_loss: 0.5305\n",
      "Epoch [96/200], Step [971/1067], D_A_loss: 0.0219, D_B_loss: 0.0310, G_A_loss: 0.8458, G_B_loss: 0.5006\n",
      "Epoch [96/200], Step [981/1067], D_A_loss: 0.0836, D_B_loss: 0.0078, G_A_loss: 0.9072, G_B_loss: 0.7266\n",
      "Epoch [96/200], Step [991/1067], D_A_loss: 0.2003, D_B_loss: 0.0137, G_A_loss: 1.1119, G_B_loss: 0.2035\n",
      "Epoch [96/200], Step [1001/1067], D_A_loss: 0.1089, D_B_loss: 0.1099, G_A_loss: 1.1901, G_B_loss: 0.4566\n",
      "Epoch [96/200], Step [1011/1067], D_A_loss: 0.0447, D_B_loss: 0.0643, G_A_loss: 0.8261, G_B_loss: 0.4730\n",
      "Epoch [96/200], Step [1021/1067], D_A_loss: 0.1360, D_B_loss: 0.1186, G_A_loss: 1.8217, G_B_loss: 0.7739\n",
      "Epoch [96/200], Step [1031/1067], D_A_loss: 0.0570, D_B_loss: 0.0770, G_A_loss: 0.6562, G_B_loss: 0.7807\n",
      "Epoch [96/200], Step [1041/1067], D_A_loss: 0.2404, D_B_loss: 0.1185, G_A_loss: 0.2809, G_B_loss: 0.6437\n",
      "Epoch [96/200], Step [1051/1067], D_A_loss: 0.0971, D_B_loss: 0.0222, G_A_loss: 0.8964, G_B_loss: 0.4078\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [96/200], Step [1061/1067], D_A_loss: 0.1595, D_B_loss: 0.0766, G_A_loss: 0.5042, G_B_loss: 0.6004\n",
      "Epoch [97/200], Step [1/1067], D_A_loss: 0.0337, D_B_loss: 0.0205, G_A_loss: 0.7477, G_B_loss: 0.4776\n",
      "Epoch [97/200], Step [11/1067], D_A_loss: 0.0790, D_B_loss: 0.0105, G_A_loss: 0.9632, G_B_loss: 0.6101\n",
      "Epoch [97/200], Step [21/1067], D_A_loss: 0.1108, D_B_loss: 0.0153, G_A_loss: 0.6871, G_B_loss: 1.0715\n",
      "Epoch [97/200], Step [31/1067], D_A_loss: 0.1080, D_B_loss: 0.1804, G_A_loss: 0.2518, G_B_loss: 0.4772\n",
      "Epoch [97/200], Step [41/1067], D_A_loss: 0.1545, D_B_loss: 0.0659, G_A_loss: 0.4517, G_B_loss: 0.4346\n",
      "Epoch [97/200], Step [51/1067], D_A_loss: 0.0835, D_B_loss: 0.0287, G_A_loss: 0.7375, G_B_loss: 0.5019\n",
      "Epoch [97/200], Step [61/1067], D_A_loss: 0.0789, D_B_loss: 0.0602, G_A_loss: 0.8369, G_B_loss: 0.8252\n",
      "Epoch [97/200], Step [71/1067], D_A_loss: 0.0825, D_B_loss: 0.0219, G_A_loss: 0.7315, G_B_loss: 0.6223\n",
      "Epoch [97/200], Step [81/1067], D_A_loss: 0.0519, D_B_loss: 0.0097, G_A_loss: 0.5073, G_B_loss: 0.3590\n",
      "Epoch [97/200], Step [91/1067], D_A_loss: 0.0717, D_B_loss: 0.1148, G_A_loss: 0.8834, G_B_loss: 0.6062\n",
      "Epoch [97/200], Step [101/1067], D_A_loss: 0.0858, D_B_loss: 0.0227, G_A_loss: 0.7701, G_B_loss: 0.2748\n",
      "Epoch [97/200], Step [111/1067], D_A_loss: 0.1555, D_B_loss: 0.0227, G_A_loss: 0.8194, G_B_loss: 0.5112\n",
      "Epoch [97/200], Step [121/1067], D_A_loss: 0.0736, D_B_loss: 0.0386, G_A_loss: 0.6942, G_B_loss: 0.4332\n",
      "Epoch [97/200], Step [131/1067], D_A_loss: 0.0765, D_B_loss: 0.0469, G_A_loss: 0.5511, G_B_loss: 0.4568\n",
      "Epoch [97/200], Step [141/1067], D_A_loss: 0.0997, D_B_loss: 0.0199, G_A_loss: 0.7706, G_B_loss: 0.4799\n",
      "Epoch [97/200], Step [151/1067], D_A_loss: 0.2062, D_B_loss: 0.0266, G_A_loss: 0.9060, G_B_loss: 0.3722\n",
      "Epoch [97/200], Step [161/1067], D_A_loss: 0.0839, D_B_loss: 0.0232, G_A_loss: 0.8282, G_B_loss: 0.7679\n",
      "Epoch [97/200], Step [171/1067], D_A_loss: 0.0946, D_B_loss: 0.0153, G_A_loss: 0.6312, G_B_loss: 0.4874\n",
      "Epoch [97/200], Step [181/1067], D_A_loss: 0.1265, D_B_loss: 0.0908, G_A_loss: 0.3751, G_B_loss: 0.4859\n",
      "Epoch [97/200], Step [191/1067], D_A_loss: 0.1290, D_B_loss: 0.0179, G_A_loss: 0.6221, G_B_loss: 0.5473\n",
      "Epoch [97/200], Step [201/1067], D_A_loss: 0.1245, D_B_loss: 0.0700, G_A_loss: 0.8178, G_B_loss: 0.3470\n",
      "Epoch [97/200], Step [211/1067], D_A_loss: 0.1229, D_B_loss: 0.0170, G_A_loss: 1.0394, G_B_loss: 0.5858\n",
      "Epoch [97/200], Step [221/1067], D_A_loss: 0.2006, D_B_loss: 0.0699, G_A_loss: 0.4892, G_B_loss: 0.8529\n",
      "Epoch [97/200], Step [231/1067], D_A_loss: 0.0999, D_B_loss: 0.0275, G_A_loss: 0.7334, G_B_loss: 0.4073\n",
      "Epoch [97/200], Step [241/1067], D_A_loss: 0.1399, D_B_loss: 0.0259, G_A_loss: 0.7534, G_B_loss: 0.4892\n",
      "Epoch [97/200], Step [251/1067], D_A_loss: 0.0425, D_B_loss: 0.0602, G_A_loss: 1.1758, G_B_loss: 0.3766\n",
      "Epoch [97/200], Step [261/1067], D_A_loss: 0.0782, D_B_loss: 0.0086, G_A_loss: 1.0666, G_B_loss: 0.6316\n",
      "Epoch [97/200], Step [271/1067], D_A_loss: 0.0846, D_B_loss: 0.0078, G_A_loss: 0.9056, G_B_loss: 0.4826\n",
      "Epoch [97/200], Step [281/1067], D_A_loss: 0.0767, D_B_loss: 0.0156, G_A_loss: 0.8313, G_B_loss: 0.6991\n",
      "Epoch [97/200], Step [291/1067], D_A_loss: 0.0891, D_B_loss: 0.0256, G_A_loss: 0.8873, G_B_loss: 0.5313\n",
      "Epoch [97/200], Step [301/1067], D_A_loss: 0.1544, D_B_loss: 0.0107, G_A_loss: 0.6313, G_B_loss: 0.3209\n",
      "Epoch [97/200], Step [311/1067], D_A_loss: 0.0832, D_B_loss: 0.0381, G_A_loss: 0.6191, G_B_loss: 0.4663\n",
      "Epoch [97/200], Step [321/1067], D_A_loss: 0.0842, D_B_loss: 0.0092, G_A_loss: 1.0176, G_B_loss: 0.4805\n",
      "Epoch [97/200], Step [331/1067], D_A_loss: 0.0482, D_B_loss: 0.0153, G_A_loss: 0.8089, G_B_loss: 0.6382\n",
      "Epoch [97/200], Step [341/1067], D_A_loss: 0.0586, D_B_loss: 0.0258, G_A_loss: 0.3421, G_B_loss: 0.4001\n",
      "Epoch [97/200], Step [351/1067], D_A_loss: 0.0387, D_B_loss: 0.0242, G_A_loss: 0.7224, G_B_loss: 0.7851\n",
      "Epoch [97/200], Step [361/1067], D_A_loss: 0.0286, D_B_loss: 0.0205, G_A_loss: 1.0944, G_B_loss: 0.5214\n",
      "Epoch [97/200], Step [371/1067], D_A_loss: 0.1592, D_B_loss: 0.0229, G_A_loss: 1.0501, G_B_loss: 0.4114\n",
      "Epoch [97/200], Step [381/1067], D_A_loss: 0.0467, D_B_loss: 0.0299, G_A_loss: 0.7872, G_B_loss: 0.7324\n",
      "Epoch [97/200], Step [391/1067], D_A_loss: 0.0895, D_B_loss: 0.0236, G_A_loss: 0.7064, G_B_loss: 0.5559\n",
      "Epoch [97/200], Step [401/1067], D_A_loss: 0.0878, D_B_loss: 0.0840, G_A_loss: 0.5662, G_B_loss: 0.4932\n",
      "Epoch [97/200], Step [411/1067], D_A_loss: 0.0276, D_B_loss: 0.0532, G_A_loss: 0.6291, G_B_loss: 0.4070\n",
      "Epoch [97/200], Step [421/1067], D_A_loss: 0.2150, D_B_loss: 0.0787, G_A_loss: 0.4980, G_B_loss: 0.1630\n",
      "Epoch [97/200], Step [431/1067], D_A_loss: 0.0622, D_B_loss: 0.0508, G_A_loss: 0.8373, G_B_loss: 0.6977\n",
      "Epoch [97/200], Step [441/1067], D_A_loss: 0.0367, D_B_loss: 0.0160, G_A_loss: 0.4894, G_B_loss: 0.8084\n",
      "Epoch [97/200], Step [451/1067], D_A_loss: 0.0944, D_B_loss: 0.0219, G_A_loss: 0.8254, G_B_loss: 0.4013\n",
      "Epoch [97/200], Step [461/1067], D_A_loss: 0.0796, D_B_loss: 0.0275, G_A_loss: 0.5972, G_B_loss: 0.6643\n",
      "Epoch [97/200], Step [471/1067], D_A_loss: 0.0934, D_B_loss: 0.0255, G_A_loss: 0.6903, G_B_loss: 0.4194\n",
      "Epoch [97/200], Step [481/1067], D_A_loss: 0.0899, D_B_loss: 0.0351, G_A_loss: 1.5311, G_B_loss: 0.8645\n",
      "Epoch [97/200], Step [491/1067], D_A_loss: 0.0609, D_B_loss: 0.0210, G_A_loss: 0.9190, G_B_loss: 0.5120\n",
      "Epoch [97/200], Step [501/1067], D_A_loss: 0.0373, D_B_loss: 0.0441, G_A_loss: 0.8524, G_B_loss: 0.3964\n",
      "Epoch [97/200], Step [511/1067], D_A_loss: 0.0362, D_B_loss: 0.0183, G_A_loss: 1.0283, G_B_loss: 0.3435\n",
      "Epoch [97/200], Step [521/1067], D_A_loss: 0.0992, D_B_loss: 0.1005, G_A_loss: 0.7392, G_B_loss: 0.3993\n",
      "Epoch [97/200], Step [531/1067], D_A_loss: 0.0587, D_B_loss: 0.0585, G_A_loss: 1.0994, G_B_loss: 0.4600\n",
      "Epoch [97/200], Step [541/1067], D_A_loss: 0.0726, D_B_loss: 0.0215, G_A_loss: 0.7875, G_B_loss: 0.3046\n",
      "Epoch [97/200], Step [551/1067], D_A_loss: 0.0537, D_B_loss: 0.0397, G_A_loss: 0.7122, G_B_loss: 0.2950\n",
      "Epoch [97/200], Step [561/1067], D_A_loss: 0.0275, D_B_loss: 0.0455, G_A_loss: 0.6523, G_B_loss: 0.6587\n",
      "Epoch [97/200], Step [571/1067], D_A_loss: 0.0613, D_B_loss: 0.0434, G_A_loss: 0.7805, G_B_loss: 0.5822\n",
      "Epoch [97/200], Step [581/1067], D_A_loss: 0.2376, D_B_loss: 0.0201, G_A_loss: 1.1505, G_B_loss: 0.4658\n",
      "Epoch [97/200], Step [591/1067], D_A_loss: 0.1597, D_B_loss: 0.0082, G_A_loss: 1.1033, G_B_loss: 0.2867\n",
      "Epoch [97/200], Step [601/1067], D_A_loss: 0.1176, D_B_loss: 0.0270, G_A_loss: 0.8022, G_B_loss: 0.1671\n",
      "Epoch [97/200], Step [611/1067], D_A_loss: 0.2214, D_B_loss: 0.0092, G_A_loss: 1.0070, G_B_loss: 0.4352\n",
      "Epoch [97/200], Step [621/1067], D_A_loss: 0.0405, D_B_loss: 0.0249, G_A_loss: 0.4583, G_B_loss: 0.3140\n",
      "Epoch [97/200], Step [631/1067], D_A_loss: 0.0743, D_B_loss: 0.0103, G_A_loss: 0.8773, G_B_loss: 0.4023\n",
      "Epoch [97/200], Step [641/1067], D_A_loss: 0.0745, D_B_loss: 0.0175, G_A_loss: 0.7320, G_B_loss: 0.9082\n",
      "Epoch [97/200], Step [651/1067], D_A_loss: 0.0337, D_B_loss: 0.0212, G_A_loss: 0.7409, G_B_loss: 0.4557\n",
      "Epoch [97/200], Step [661/1067], D_A_loss: 0.0671, D_B_loss: 0.0960, G_A_loss: 0.4694, G_B_loss: 0.8167\n",
      "Epoch [97/200], Step [671/1067], D_A_loss: 0.1448, D_B_loss: 0.0374, G_A_loss: 0.5989, G_B_loss: 0.7146\n",
      "Epoch [97/200], Step [681/1067], D_A_loss: 0.0495, D_B_loss: 0.0160, G_A_loss: 0.8736, G_B_loss: 0.7805\n",
      "Epoch [97/200], Step [691/1067], D_A_loss: 0.1209, D_B_loss: 0.0283, G_A_loss: 1.0158, G_B_loss: 0.3340\n",
      "Epoch [97/200], Step [701/1067], D_A_loss: 0.1612, D_B_loss: 0.0315, G_A_loss: 0.7504, G_B_loss: 0.8834\n",
      "Epoch [97/200], Step [711/1067], D_A_loss: 0.1455, D_B_loss: 0.0165, G_A_loss: 0.8467, G_B_loss: 0.7295\n",
      "Epoch [97/200], Step [721/1067], D_A_loss: 0.1253, D_B_loss: 0.0473, G_A_loss: 0.6131, G_B_loss: 0.5250\n",
      "Epoch [97/200], Step [731/1067], D_A_loss: 0.0692, D_B_loss: 0.0428, G_A_loss: 0.8394, G_B_loss: 0.5917\n",
      "Epoch [97/200], Step [741/1067], D_A_loss: 0.0615, D_B_loss: 0.0114, G_A_loss: 0.7798, G_B_loss: 0.0549\n",
      "Epoch [97/200], Step [751/1067], D_A_loss: 0.0583, D_B_loss: 0.0401, G_A_loss: 0.4701, G_B_loss: 0.3866\n",
      "Epoch [97/200], Step [761/1067], D_A_loss: 0.1647, D_B_loss: 0.0988, G_A_loss: 1.0911, G_B_loss: 0.6487\n",
      "Epoch [97/200], Step [771/1067], D_A_loss: 0.1392, D_B_loss: 0.0603, G_A_loss: 1.4858, G_B_loss: 0.5808\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [97/200], Step [781/1067], D_A_loss: 0.1177, D_B_loss: 0.0541, G_A_loss: 0.8263, G_B_loss: 0.4717\n",
      "Epoch [97/200], Step [791/1067], D_A_loss: 0.1257, D_B_loss: 0.0395, G_A_loss: 0.6193, G_B_loss: 0.7071\n",
      "Epoch [97/200], Step [801/1067], D_A_loss: 0.0437, D_B_loss: 0.0471, G_A_loss: 1.4533, G_B_loss: 0.7883\n",
      "Epoch [97/200], Step [811/1067], D_A_loss: 0.1532, D_B_loss: 0.0150, G_A_loss: 0.8166, G_B_loss: 0.4078\n",
      "Epoch [97/200], Step [821/1067], D_A_loss: 0.1508, D_B_loss: 0.0114, G_A_loss: 0.8994, G_B_loss: 0.4767\n",
      "Epoch [97/200], Step [831/1067], D_A_loss: 0.0537, D_B_loss: 0.0357, G_A_loss: 0.6840, G_B_loss: 0.2526\n",
      "Epoch [97/200], Step [841/1067], D_A_loss: 0.1016, D_B_loss: 0.0366, G_A_loss: 0.6968, G_B_loss: 0.4397\n",
      "Epoch [97/200], Step [851/1067], D_A_loss: 0.0717, D_B_loss: 0.0570, G_A_loss: 0.4932, G_B_loss: 0.3801\n",
      "Epoch [97/200], Step [861/1067], D_A_loss: 0.2839, D_B_loss: 0.0353, G_A_loss: 0.7114, G_B_loss: 0.1865\n",
      "Epoch [97/200], Step [871/1067], D_A_loss: 0.1407, D_B_loss: 0.0490, G_A_loss: 0.6163, G_B_loss: 0.5224\n",
      "Epoch [97/200], Step [881/1067], D_A_loss: 0.1880, D_B_loss: 0.0466, G_A_loss: 1.2576, G_B_loss: 0.3927\n",
      "Epoch [97/200], Step [891/1067], D_A_loss: 0.1490, D_B_loss: 0.0282, G_A_loss: 0.5094, G_B_loss: 0.2888\n",
      "Epoch [97/200], Step [901/1067], D_A_loss: 0.0803, D_B_loss: 0.0318, G_A_loss: 0.7894, G_B_loss: 0.5895\n",
      "Epoch [97/200], Step [911/1067], D_A_loss: 0.0607, D_B_loss: 0.0693, G_A_loss: 0.4775, G_B_loss: 0.7399\n",
      "Epoch [97/200], Step [921/1067], D_A_loss: 0.0545, D_B_loss: 0.0566, G_A_loss: 1.0471, G_B_loss: 0.3316\n",
      "Epoch [97/200], Step [931/1067], D_A_loss: 0.1001, D_B_loss: 0.0140, G_A_loss: 0.9498, G_B_loss: 0.6649\n",
      "Epoch [97/200], Step [941/1067], D_A_loss: 0.1235, D_B_loss: 0.0125, G_A_loss: 0.4795, G_B_loss: 1.1028\n",
      "Epoch [97/200], Step [951/1067], D_A_loss: 0.1462, D_B_loss: 0.0369, G_A_loss: 0.7757, G_B_loss: 0.9771\n",
      "Epoch [97/200], Step [961/1067], D_A_loss: 0.2716, D_B_loss: 0.0540, G_A_loss: 0.6379, G_B_loss: 0.9304\n",
      "Epoch [97/200], Step [971/1067], D_A_loss: 0.1783, D_B_loss: 0.0176, G_A_loss: 0.9870, G_B_loss: 0.5837\n",
      "Epoch [97/200], Step [981/1067], D_A_loss: 0.2308, D_B_loss: 0.0288, G_A_loss: 1.2879, G_B_loss: 0.1764\n",
      "Epoch [97/200], Step [991/1067], D_A_loss: 0.2281, D_B_loss: 0.0322, G_A_loss: 1.0666, G_B_loss: 0.5378\n",
      "Epoch [97/200], Step [1001/1067], D_A_loss: 0.2600, D_B_loss: 0.0671, G_A_loss: 0.6179, G_B_loss: 0.6493\n",
      "Epoch [97/200], Step [1011/1067], D_A_loss: 0.1183, D_B_loss: 0.0412, G_A_loss: 0.7255, G_B_loss: 0.4272\n",
      "Epoch [97/200], Step [1021/1067], D_A_loss: 0.0381, D_B_loss: 0.0188, G_A_loss: 0.8474, G_B_loss: 0.1506\n",
      "Epoch [97/200], Step [1031/1067], D_A_loss: 0.0239, D_B_loss: 0.0106, G_A_loss: 0.9081, G_B_loss: 0.5295\n",
      "Epoch [97/200], Step [1041/1067], D_A_loss: 0.0489, D_B_loss: 0.0166, G_A_loss: 0.7976, G_B_loss: 0.4309\n",
      "Epoch [97/200], Step [1051/1067], D_A_loss: 0.0302, D_B_loss: 0.0119, G_A_loss: 0.7696, G_B_loss: 0.4549\n",
      "Epoch [97/200], Step [1061/1067], D_A_loss: 0.1286, D_B_loss: 0.0292, G_A_loss: 0.6128, G_B_loss: 0.8286\n",
      "Epoch [98/200], Step [1/1067], D_A_loss: 0.1759, D_B_loss: 0.0237, G_A_loss: 0.5303, G_B_loss: 0.6386\n",
      "Epoch [98/200], Step [11/1067], D_A_loss: 0.0961, D_B_loss: 0.0347, G_A_loss: 1.1075, G_B_loss: 0.6782\n",
      "Epoch [98/200], Step [21/1067], D_A_loss: 0.0785, D_B_loss: 0.0175, G_A_loss: 0.7894, G_B_loss: 0.8104\n",
      "Epoch [98/200], Step [31/1067], D_A_loss: 0.1900, D_B_loss: 0.0582, G_A_loss: 0.5766, G_B_loss: 0.5803\n",
      "Epoch [98/200], Step [41/1067], D_A_loss: 0.1732, D_B_loss: 0.0268, G_A_loss: 0.8615, G_B_loss: 0.8825\n",
      "Epoch [98/200], Step [51/1067], D_A_loss: 0.0747, D_B_loss: 0.1182, G_A_loss: 0.5336, G_B_loss: 0.5203\n",
      "Epoch [98/200], Step [61/1067], D_A_loss: 0.1085, D_B_loss: 0.0338, G_A_loss: 1.0216, G_B_loss: 0.3769\n",
      "Epoch [98/200], Step [71/1067], D_A_loss: 0.1397, D_B_loss: 0.0421, G_A_loss: 0.6802, G_B_loss: 0.7524\n",
      "Epoch [98/200], Step [81/1067], D_A_loss: 0.1096, D_B_loss: 0.0321, G_A_loss: 0.7469, G_B_loss: 0.5055\n",
      "Epoch [98/200], Step [91/1067], D_A_loss: 0.1362, D_B_loss: 0.0473, G_A_loss: 0.9505, G_B_loss: 0.3511\n",
      "Epoch [98/200], Step [101/1067], D_A_loss: 0.2395, D_B_loss: 0.0835, G_A_loss: 1.0636, G_B_loss: 0.3898\n",
      "Epoch [98/200], Step [111/1067], D_A_loss: 0.0244, D_B_loss: 0.0765, G_A_loss: 0.7728, G_B_loss: 0.4161\n",
      "Epoch [98/200], Step [121/1067], D_A_loss: 0.1622, D_B_loss: 0.0494, G_A_loss: 0.6282, G_B_loss: 0.2527\n",
      "Epoch [98/200], Step [131/1067], D_A_loss: 0.0550, D_B_loss: 0.0114, G_A_loss: 0.8884, G_B_loss: 0.4384\n",
      "Epoch [98/200], Step [141/1067], D_A_loss: 0.1787, D_B_loss: 0.0834, G_A_loss: 0.5488, G_B_loss: 0.3195\n",
      "Epoch [98/200], Step [151/1067], D_A_loss: 0.0732, D_B_loss: 0.0132, G_A_loss: 1.0803, G_B_loss: 0.2609\n",
      "Epoch [98/200], Step [161/1067], D_A_loss: 0.0786, D_B_loss: 0.0302, G_A_loss: 0.7335, G_B_loss: 0.5490\n",
      "Epoch [98/200], Step [171/1067], D_A_loss: 0.2700, D_B_loss: 0.0152, G_A_loss: 0.8430, G_B_loss: 0.4597\n",
      "Epoch [98/200], Step [181/1067], D_A_loss: 0.2851, D_B_loss: 0.0142, G_A_loss: 0.5921, G_B_loss: 0.2369\n",
      "Epoch [98/200], Step [191/1067], D_A_loss: 0.1056, D_B_loss: 0.0531, G_A_loss: 0.3815, G_B_loss: 0.7174\n",
      "Epoch [98/200], Step [201/1067], D_A_loss: 0.0884, D_B_loss: 0.0299, G_A_loss: 0.7397, G_B_loss: 0.8012\n",
      "Epoch [98/200], Step [211/1067], D_A_loss: 0.0379, D_B_loss: 0.0422, G_A_loss: 0.4453, G_B_loss: 0.3950\n",
      "Epoch [98/200], Step [221/1067], D_A_loss: 0.1235, D_B_loss: 0.0216, G_A_loss: 0.7832, G_B_loss: 0.5556\n",
      "Epoch [98/200], Step [231/1067], D_A_loss: 0.1106, D_B_loss: 0.0231, G_A_loss: 0.8783, G_B_loss: 0.4971\n",
      "Epoch [98/200], Step [241/1067], D_A_loss: 0.0285, D_B_loss: 0.0169, G_A_loss: 0.8330, G_B_loss: 0.4484\n",
      "Epoch [98/200], Step [251/1067], D_A_loss: 0.2000, D_B_loss: 0.0210, G_A_loss: 0.3249, G_B_loss: 0.2724\n",
      "Epoch [98/200], Step [261/1067], D_A_loss: 0.0495, D_B_loss: 0.0356, G_A_loss: 0.6533, G_B_loss: 0.5786\n",
      "Epoch [98/200], Step [271/1067], D_A_loss: 0.0795, D_B_loss: 0.0986, G_A_loss: 1.0364, G_B_loss: 0.6094\n",
      "Epoch [98/200], Step [281/1067], D_A_loss: 0.2694, D_B_loss: 0.0121, G_A_loss: 0.9523, G_B_loss: 0.1766\n",
      "Epoch [98/200], Step [291/1067], D_A_loss: 0.0872, D_B_loss: 0.0471, G_A_loss: 0.7776, G_B_loss: 0.4285\n",
      "Epoch [98/200], Step [301/1067], D_A_loss: 0.0316, D_B_loss: 0.0167, G_A_loss: 0.7560, G_B_loss: 0.3162\n",
      "Epoch [98/200], Step [311/1067], D_A_loss: 0.0706, D_B_loss: 0.1082, G_A_loss: 0.5705, G_B_loss: 0.5774\n",
      "Epoch [98/200], Step [321/1067], D_A_loss: 0.0932, D_B_loss: 0.0525, G_A_loss: 0.5044, G_B_loss: 0.3970\n",
      "Epoch [98/200], Step [331/1067], D_A_loss: 0.0366, D_B_loss: 0.0290, G_A_loss: 0.5005, G_B_loss: 0.1763\n",
      "Epoch [98/200], Step [341/1067], D_A_loss: 0.0648, D_B_loss: 0.0267, G_A_loss: 1.0023, G_B_loss: 0.5201\n",
      "Epoch [98/200], Step [351/1067], D_A_loss: 0.0989, D_B_loss: 0.0111, G_A_loss: 0.9914, G_B_loss: 0.4615\n",
      "Epoch [98/200], Step [361/1067], D_A_loss: 0.1146, D_B_loss: 0.0467, G_A_loss: 1.0178, G_B_loss: 0.4274\n",
      "Epoch [98/200], Step [371/1067], D_A_loss: 0.1546, D_B_loss: 0.0434, G_A_loss: 0.5677, G_B_loss: 0.5749\n",
      "Epoch [98/200], Step [381/1067], D_A_loss: 0.0704, D_B_loss: 0.0325, G_A_loss: 0.9453, G_B_loss: 0.9872\n",
      "Epoch [98/200], Step [391/1067], D_A_loss: 0.1416, D_B_loss: 0.0388, G_A_loss: 0.6471, G_B_loss: 0.9572\n",
      "Epoch [98/200], Step [401/1067], D_A_loss: 0.0289, D_B_loss: 0.0250, G_A_loss: 0.9129, G_B_loss: 1.0089\n",
      "Epoch [98/200], Step [411/1067], D_A_loss: 0.1050, D_B_loss: 0.0306, G_A_loss: 0.6653, G_B_loss: 0.9853\n",
      "Epoch [98/200], Step [421/1067], D_A_loss: 0.2865, D_B_loss: 0.0703, G_A_loss: 1.1231, G_B_loss: 0.4686\n",
      "Epoch [98/200], Step [431/1067], D_A_loss: 0.0712, D_B_loss: 0.0743, G_A_loss: 0.8460, G_B_loss: 0.2290\n",
      "Epoch [98/200], Step [441/1067], D_A_loss: 0.0317, D_B_loss: 0.0220, G_A_loss: 0.9479, G_B_loss: 1.0151\n",
      "Epoch [98/200], Step [451/1067], D_A_loss: 0.0781, D_B_loss: 0.0214, G_A_loss: 0.7854, G_B_loss: 0.3188\n",
      "Epoch [98/200], Step [461/1067], D_A_loss: 0.0381, D_B_loss: 0.1365, G_A_loss: 0.5186, G_B_loss: 0.2091\n",
      "Epoch [98/200], Step [471/1067], D_A_loss: 0.1497, D_B_loss: 0.0170, G_A_loss: 0.8379, G_B_loss: 0.2413\n",
      "Epoch [98/200], Step [481/1067], D_A_loss: 0.0405, D_B_loss: 0.0185, G_A_loss: 0.9194, G_B_loss: 0.7214\n",
      "Epoch [98/200], Step [491/1067], D_A_loss: 0.2281, D_B_loss: 0.0260, G_A_loss: 1.0373, G_B_loss: 0.2740\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [98/200], Step [501/1067], D_A_loss: 0.3343, D_B_loss: 0.0192, G_A_loss: 1.2195, G_B_loss: 0.1826\n",
      "Epoch [98/200], Step [511/1067], D_A_loss: 0.2727, D_B_loss: 0.0352, G_A_loss: 0.5825, G_B_loss: 0.5219\n",
      "Epoch [98/200], Step [521/1067], D_A_loss: 0.0672, D_B_loss: 0.0216, G_A_loss: 0.7781, G_B_loss: 0.5997\n",
      "Epoch [98/200], Step [531/1067], D_A_loss: 0.2430, D_B_loss: 0.0680, G_A_loss: 0.4861, G_B_loss: 0.1794\n",
      "Epoch [98/200], Step [541/1067], D_A_loss: 0.0728, D_B_loss: 0.0160, G_A_loss: 1.1996, G_B_loss: 0.5522\n",
      "Epoch [98/200], Step [551/1067], D_A_loss: 0.0197, D_B_loss: 0.0384, G_A_loss: 0.4266, G_B_loss: 1.0042\n",
      "Epoch [98/200], Step [561/1067], D_A_loss: 0.0298, D_B_loss: 0.0444, G_A_loss: 1.1429, G_B_loss: 0.8641\n",
      "Epoch [98/200], Step [571/1067], D_A_loss: 0.0970, D_B_loss: 0.0299, G_A_loss: 0.6676, G_B_loss: 0.4771\n",
      "Epoch [98/200], Step [581/1067], D_A_loss: 0.1543, D_B_loss: 0.0880, G_A_loss: 0.9417, G_B_loss: 0.2908\n",
      "Epoch [98/200], Step [591/1067], D_A_loss: 0.1083, D_B_loss: 0.0277, G_A_loss: 0.8662, G_B_loss: 0.4602\n",
      "Epoch [98/200], Step [601/1067], D_A_loss: 0.0629, D_B_loss: 0.0598, G_A_loss: 0.5163, G_B_loss: 0.5205\n",
      "Epoch [98/200], Step [611/1067], D_A_loss: 0.0845, D_B_loss: 0.0724, G_A_loss: 0.6440, G_B_loss: 0.5824\n",
      "Epoch [98/200], Step [621/1067], D_A_loss: 0.1274, D_B_loss: 0.0255, G_A_loss: 0.5502, G_B_loss: 0.5096\n",
      "Epoch [98/200], Step [631/1067], D_A_loss: 0.0585, D_B_loss: 0.0289, G_A_loss: 0.7791, G_B_loss: 0.5582\n",
      "Epoch [98/200], Step [641/1067], D_A_loss: 0.2895, D_B_loss: 0.0139, G_A_loss: 0.9644, G_B_loss: 0.9936\n",
      "Epoch [98/200], Step [651/1067], D_A_loss: 0.1377, D_B_loss: 0.0100, G_A_loss: 1.0947, G_B_loss: 0.4112\n",
      "Epoch [98/200], Step [661/1067], D_A_loss: 0.0665, D_B_loss: 0.0496, G_A_loss: 0.5103, G_B_loss: 0.7790\n",
      "Epoch [98/200], Step [671/1067], D_A_loss: 0.1119, D_B_loss: 0.0586, G_A_loss: 0.5393, G_B_loss: 0.4355\n",
      "Epoch [98/200], Step [681/1067], D_A_loss: 0.0422, D_B_loss: 0.0210, G_A_loss: 0.7903, G_B_loss: 0.3038\n",
      "Epoch [98/200], Step [691/1067], D_A_loss: 0.0268, D_B_loss: 0.0209, G_A_loss: 0.9023, G_B_loss: 0.3242\n",
      "Epoch [98/200], Step [701/1067], D_A_loss: 0.1307, D_B_loss: 0.0218, G_A_loss: 1.2565, G_B_loss: 0.3605\n",
      "Epoch [98/200], Step [711/1067], D_A_loss: 0.0708, D_B_loss: 0.0168, G_A_loss: 1.1953, G_B_loss: 0.5534\n",
      "Epoch [98/200], Step [721/1067], D_A_loss: 0.0712, D_B_loss: 0.0271, G_A_loss: 0.7523, G_B_loss: 0.1872\n",
      "Epoch [98/200], Step [731/1067], D_A_loss: 0.1511, D_B_loss: 0.0222, G_A_loss: 0.8487, G_B_loss: 0.5419\n",
      "Epoch [98/200], Step [741/1067], D_A_loss: 0.0555, D_B_loss: 0.0125, G_A_loss: 0.9905, G_B_loss: 0.5847\n",
      "Epoch [98/200], Step [751/1067], D_A_loss: 0.0570, D_B_loss: 0.0109, G_A_loss: 0.8656, G_B_loss: 0.6089\n",
      "Epoch [98/200], Step [761/1067], D_A_loss: 0.1101, D_B_loss: 0.0217, G_A_loss: 0.7725, G_B_loss: 0.5372\n",
      "Epoch [98/200], Step [771/1067], D_A_loss: 0.0590, D_B_loss: 0.0239, G_A_loss: 1.0341, G_B_loss: 0.6059\n",
      "Epoch [98/200], Step [781/1067], D_A_loss: 0.1358, D_B_loss: 0.0145, G_A_loss: 0.9398, G_B_loss: 0.3917\n",
      "Epoch [98/200], Step [791/1067], D_A_loss: 0.0735, D_B_loss: 0.1845, G_A_loss: 0.2948, G_B_loss: 0.2988\n",
      "Epoch [98/200], Step [801/1067], D_A_loss: 0.1731, D_B_loss: 0.0309, G_A_loss: 0.8140, G_B_loss: 0.2429\n",
      "Epoch [98/200], Step [811/1067], D_A_loss: 0.1635, D_B_loss: 0.0232, G_A_loss: 0.6769, G_B_loss: 0.3625\n",
      "Epoch [98/200], Step [821/1067], D_A_loss: 0.2801, D_B_loss: 0.0273, G_A_loss: 0.8354, G_B_loss: 0.3051\n",
      "Epoch [98/200], Step [831/1067], D_A_loss: 0.1196, D_B_loss: 0.0106, G_A_loss: 0.3994, G_B_loss: 0.4263\n",
      "Epoch [98/200], Step [841/1067], D_A_loss: 0.0900, D_B_loss: 0.0232, G_A_loss: 0.6716, G_B_loss: 0.6160\n",
      "Epoch [98/200], Step [851/1067], D_A_loss: 0.0510, D_B_loss: 0.0128, G_A_loss: 1.1313, G_B_loss: 0.4044\n",
      "Epoch [98/200], Step [861/1067], D_A_loss: 0.1075, D_B_loss: 0.0321, G_A_loss: 0.9240, G_B_loss: 0.7391\n",
      "Epoch [98/200], Step [871/1067], D_A_loss: 0.0631, D_B_loss: 0.1170, G_A_loss: 0.4432, G_B_loss: 0.6714\n",
      "Epoch [98/200], Step [881/1067], D_A_loss: 0.1263, D_B_loss: 0.0450, G_A_loss: 1.2223, G_B_loss: 0.7537\n",
      "Epoch [98/200], Step [891/1067], D_A_loss: 0.0530, D_B_loss: 0.0129, G_A_loss: 0.6141, G_B_loss: 0.9095\n",
      "Epoch [98/200], Step [901/1067], D_A_loss: 0.0367, D_B_loss: 0.0229, G_A_loss: 0.7915, G_B_loss: 0.3598\n",
      "Epoch [98/200], Step [911/1067], D_A_loss: 0.1049, D_B_loss: 0.0210, G_A_loss: 0.8777, G_B_loss: 0.5999\n",
      "Epoch [98/200], Step [921/1067], D_A_loss: 0.2314, D_B_loss: 0.0472, G_A_loss: 0.5668, G_B_loss: 0.2429\n",
      "Epoch [98/200], Step [931/1067], D_A_loss: 0.1378, D_B_loss: 0.0303, G_A_loss: 0.5863, G_B_loss: 0.4308\n",
      "Epoch [98/200], Step [941/1067], D_A_loss: 0.0959, D_B_loss: 0.0312, G_A_loss: 0.8701, G_B_loss: 0.5159\n",
      "Epoch [98/200], Step [951/1067], D_A_loss: 0.2696, D_B_loss: 0.0973, G_A_loss: 1.0568, G_B_loss: 0.1270\n",
      "Epoch [98/200], Step [961/1067], D_A_loss: 0.1973, D_B_loss: 0.0275, G_A_loss: 0.8374, G_B_loss: 0.9531\n",
      "Epoch [98/200], Step [971/1067], D_A_loss: 0.0553, D_B_loss: 0.0278, G_A_loss: 0.7651, G_B_loss: 0.3787\n",
      "Epoch [98/200], Step [981/1067], D_A_loss: 0.2736, D_B_loss: 0.0117, G_A_loss: 1.0832, G_B_loss: 0.1272\n",
      "Epoch [98/200], Step [991/1067], D_A_loss: 0.0552, D_B_loss: 0.1085, G_A_loss: 0.9701, G_B_loss: 0.5944\n",
      "Epoch [98/200], Step [1001/1067], D_A_loss: 0.0385, D_B_loss: 0.0167, G_A_loss: 0.7594, G_B_loss: 0.5489\n",
      "Epoch [98/200], Step [1011/1067], D_A_loss: 0.1680, D_B_loss: 0.0397, G_A_loss: 0.7206, G_B_loss: 0.4660\n",
      "Epoch [98/200], Step [1021/1067], D_A_loss: 0.0478, D_B_loss: 0.0121, G_A_loss: 0.8343, G_B_loss: 0.7669\n",
      "Epoch [98/200], Step [1031/1067], D_A_loss: 0.0672, D_B_loss: 0.0091, G_A_loss: 0.7065, G_B_loss: 0.5777\n",
      "Epoch [98/200], Step [1041/1067], D_A_loss: 0.1182, D_B_loss: 0.0455, G_A_loss: 0.9481, G_B_loss: 0.3786\n",
      "Epoch [98/200], Step [1051/1067], D_A_loss: 0.0201, D_B_loss: 0.0149, G_A_loss: 0.7917, G_B_loss: 0.6053\n",
      "Epoch [98/200], Step [1061/1067], D_A_loss: 0.0556, D_B_loss: 0.1566, G_A_loss: 0.6060, G_B_loss: 0.6154\n",
      "Epoch [99/200], Step [1/1067], D_A_loss: 0.1477, D_B_loss: 0.0080, G_A_loss: 0.5340, G_B_loss: 0.3290\n",
      "Epoch [99/200], Step [11/1067], D_A_loss: 0.0509, D_B_loss: 0.0213, G_A_loss: 0.8240, G_B_loss: 0.7882\n",
      "Epoch [99/200], Step [21/1067], D_A_loss: 0.0433, D_B_loss: 0.0129, G_A_loss: 0.7879, G_B_loss: 0.6627\n",
      "Epoch [99/200], Step [31/1067], D_A_loss: 0.2456, D_B_loss: 0.0850, G_A_loss: 0.5132, G_B_loss: 0.1652\n",
      "Epoch [99/200], Step [41/1067], D_A_loss: 0.1978, D_B_loss: 0.0427, G_A_loss: 0.6723, G_B_loss: 1.0346\n",
      "Epoch [99/200], Step [51/1067], D_A_loss: 0.0423, D_B_loss: 0.0433, G_A_loss: 1.0358, G_B_loss: 0.6958\n",
      "Epoch [99/200], Step [61/1067], D_A_loss: 0.0532, D_B_loss: 0.0435, G_A_loss: 0.5755, G_B_loss: 0.4404\n",
      "Epoch [99/200], Step [71/1067], D_A_loss: 0.0741, D_B_loss: 0.0508, G_A_loss: 0.5548, G_B_loss: 0.5293\n",
      "Epoch [99/200], Step [81/1067], D_A_loss: 0.1144, D_B_loss: 0.0700, G_A_loss: 0.5256, G_B_loss: 0.2914\n",
      "Epoch [99/200], Step [91/1067], D_A_loss: 0.0373, D_B_loss: 0.0731, G_A_loss: 0.5077, G_B_loss: 0.2785\n",
      "Epoch [99/200], Step [101/1067], D_A_loss: 0.0615, D_B_loss: 0.0142, G_A_loss: 0.8865, G_B_loss: 0.3641\n",
      "Epoch [99/200], Step [111/1067], D_A_loss: 0.0629, D_B_loss: 0.0199, G_A_loss: 0.9641, G_B_loss: 0.8035\n",
      "Epoch [99/200], Step [121/1067], D_A_loss: 0.0493, D_B_loss: 0.0780, G_A_loss: 0.6170, G_B_loss: 0.6872\n",
      "Epoch [99/200], Step [131/1067], D_A_loss: 0.1060, D_B_loss: 0.0491, G_A_loss: 0.5510, G_B_loss: 0.1783\n",
      "Epoch [99/200], Step [141/1067], D_A_loss: 0.1453, D_B_loss: 0.0149, G_A_loss: 0.9723, G_B_loss: 0.8142\n",
      "Epoch [99/200], Step [151/1067], D_A_loss: 0.0143, D_B_loss: 0.1353, G_A_loss: 1.2402, G_B_loss: 0.0963\n",
      "Epoch [99/200], Step [161/1067], D_A_loss: 0.2294, D_B_loss: 0.0317, G_A_loss: 0.6728, G_B_loss: 0.7690\n",
      "Epoch [99/200], Step [171/1067], D_A_loss: 0.1310, D_B_loss: 0.0232, G_A_loss: 0.8863, G_B_loss: 0.8418\n",
      "Epoch [99/200], Step [181/1067], D_A_loss: 0.0465, D_B_loss: 0.0217, G_A_loss: 1.0712, G_B_loss: 0.9668\n",
      "Epoch [99/200], Step [191/1067], D_A_loss: 0.0376, D_B_loss: 0.0442, G_A_loss: 0.5663, G_B_loss: 0.2597\n",
      "Epoch [99/200], Step [201/1067], D_A_loss: 0.0343, D_B_loss: 0.0182, G_A_loss: 0.7521, G_B_loss: 1.0844\n",
      "Epoch [99/200], Step [211/1067], D_A_loss: 0.0454, D_B_loss: 0.1229, G_A_loss: 0.4394, G_B_loss: 0.3812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [99/200], Step [221/1067], D_A_loss: 0.2773, D_B_loss: 0.0196, G_A_loss: 0.7291, G_B_loss: 0.1661\n",
      "Epoch [99/200], Step [231/1067], D_A_loss: 0.1929, D_B_loss: 0.0254, G_A_loss: 0.9754, G_B_loss: 0.8115\n",
      "Epoch [99/200], Step [241/1067], D_A_loss: 0.0383, D_B_loss: 0.0130, G_A_loss: 0.8993, G_B_loss: 0.8225\n",
      "Epoch [99/200], Step [251/1067], D_A_loss: 0.0584, D_B_loss: 0.1564, G_A_loss: 1.0303, G_B_loss: 0.8136\n",
      "Epoch [99/200], Step [261/1067], D_A_loss: 0.1636, D_B_loss: 0.0483, G_A_loss: 0.8387, G_B_loss: 0.2762\n",
      "Epoch [99/200], Step [271/1067], D_A_loss: 0.0573, D_B_loss: 0.0222, G_A_loss: 1.2234, G_B_loss: 0.3864\n",
      "Epoch [99/200], Step [281/1067], D_A_loss: 0.1444, D_B_loss: 0.0791, G_A_loss: 0.9187, G_B_loss: 0.3172\n",
      "Epoch [99/200], Step [291/1067], D_A_loss: 0.1136, D_B_loss: 0.1094, G_A_loss: 0.7044, G_B_loss: 0.6285\n",
      "Epoch [99/200], Step [301/1067], D_A_loss: 0.0941, D_B_loss: 0.0293, G_A_loss: 0.6699, G_B_loss: 0.5708\n",
      "Epoch [99/200], Step [311/1067], D_A_loss: 0.1125, D_B_loss: 0.0855, G_A_loss: 1.3291, G_B_loss: 0.4660\n",
      "Epoch [99/200], Step [321/1067], D_A_loss: 0.0312, D_B_loss: 0.0143, G_A_loss: 0.8674, G_B_loss: 0.5870\n",
      "Epoch [99/200], Step [331/1067], D_A_loss: 0.1035, D_B_loss: 0.0378, G_A_loss: 0.3697, G_B_loss: 0.4922\n",
      "Epoch [99/200], Step [341/1067], D_A_loss: 0.0593, D_B_loss: 0.0711, G_A_loss: 0.9544, G_B_loss: 0.3574\n",
      "Epoch [99/200], Step [351/1067], D_A_loss: 0.1148, D_B_loss: 0.0116, G_A_loss: 0.7059, G_B_loss: 0.3966\n",
      "Epoch [99/200], Step [361/1067], D_A_loss: 0.0664, D_B_loss: 0.0382, G_A_loss: 0.9229, G_B_loss: 0.5026\n",
      "Epoch [99/200], Step [371/1067], D_A_loss: 0.0228, D_B_loss: 0.0485, G_A_loss: 0.5171, G_B_loss: 0.4619\n",
      "Epoch [99/200], Step [381/1067], D_A_loss: 0.2911, D_B_loss: 0.0338, G_A_loss: 0.6709, G_B_loss: 0.2153\n",
      "Epoch [99/200], Step [391/1067], D_A_loss: 0.0564, D_B_loss: 0.0197, G_A_loss: 0.8838, G_B_loss: 0.6419\n",
      "Epoch [99/200], Step [401/1067], D_A_loss: 0.1999, D_B_loss: 0.0304, G_A_loss: 1.0739, G_B_loss: 0.3609\n",
      "Epoch [99/200], Step [411/1067], D_A_loss: 0.1106, D_B_loss: 0.0197, G_A_loss: 0.7609, G_B_loss: 1.1513\n",
      "Epoch [99/200], Step [421/1067], D_A_loss: 0.2528, D_B_loss: 0.0351, G_A_loss: 0.8629, G_B_loss: 0.1467\n",
      "Epoch [99/200], Step [431/1067], D_A_loss: 0.0508, D_B_loss: 0.0571, G_A_loss: 0.5205, G_B_loss: 0.5472\n",
      "Epoch [99/200], Step [441/1067], D_A_loss: 0.0702, D_B_loss: 0.0213, G_A_loss: 0.7970, G_B_loss: 0.4999\n",
      "Epoch [99/200], Step [451/1067], D_A_loss: 0.1238, D_B_loss: 0.0396, G_A_loss: 0.6908, G_B_loss: 0.8523\n",
      "Epoch [99/200], Step [461/1067], D_A_loss: 0.0625, D_B_loss: 0.0817, G_A_loss: 1.6588, G_B_loss: 0.3868\n",
      "Epoch [99/200], Step [471/1067], D_A_loss: 0.1102, D_B_loss: 0.3104, G_A_loss: 1.1088, G_B_loss: 0.4282\n",
      "Epoch [99/200], Step [481/1067], D_A_loss: 0.0779, D_B_loss: 0.0546, G_A_loss: 0.8739, G_B_loss: 0.6614\n",
      "Epoch [99/200], Step [491/1067], D_A_loss: 0.1329, D_B_loss: 0.1347, G_A_loss: 0.3425, G_B_loss: 0.6078\n",
      "Epoch [99/200], Step [501/1067], D_A_loss: 0.0834, D_B_loss: 0.0716, G_A_loss: 0.6274, G_B_loss: 0.5053\n",
      "Epoch [99/200], Step [511/1067], D_A_loss: 0.0542, D_B_loss: 0.0408, G_A_loss: 0.8949, G_B_loss: 0.5842\n",
      "Epoch [99/200], Step [521/1067], D_A_loss: 0.2664, D_B_loss: 0.0205, G_A_loss: 0.7583, G_B_loss: 0.1728\n",
      "Epoch [99/200], Step [531/1067], D_A_loss: 0.0669, D_B_loss: 0.0202, G_A_loss: 1.1649, G_B_loss: 0.3235\n",
      "Epoch [99/200], Step [541/1067], D_A_loss: 0.1396, D_B_loss: 0.0332, G_A_loss: 1.2182, G_B_loss: 1.1613\n",
      "Epoch [99/200], Step [551/1067], D_A_loss: 0.0215, D_B_loss: 0.0200, G_A_loss: 1.3170, G_B_loss: 0.4644\n",
      "Epoch [99/200], Step [561/1067], D_A_loss: 0.0780, D_B_loss: 0.0146, G_A_loss: 0.9659, G_B_loss: 0.4260\n",
      "Epoch [99/200], Step [571/1067], D_A_loss: 0.1447, D_B_loss: 0.0620, G_A_loss: 0.5294, G_B_loss: 0.8596\n",
      "Epoch [99/200], Step [581/1067], D_A_loss: 0.1346, D_B_loss: 0.0241, G_A_loss: 0.5424, G_B_loss: 0.4626\n",
      "Epoch [99/200], Step [591/1067], D_A_loss: 0.1921, D_B_loss: 0.0563, G_A_loss: 1.2320, G_B_loss: 0.4098\n",
      "Epoch [99/200], Step [601/1067], D_A_loss: 0.2805, D_B_loss: 0.0268, G_A_loss: 1.1312, G_B_loss: 0.1535\n",
      "Epoch [99/200], Step [611/1067], D_A_loss: 0.1476, D_B_loss: 0.0195, G_A_loss: 0.8399, G_B_loss: 0.5912\n",
      "Epoch [99/200], Step [621/1067], D_A_loss: 0.1580, D_B_loss: 0.0214, G_A_loss: 1.0399, G_B_loss: 0.2795\n",
      "Epoch [99/200], Step [631/1067], D_A_loss: 0.1472, D_B_loss: 0.0171, G_A_loss: 0.8341, G_B_loss: 0.3596\n",
      "Epoch [99/200], Step [641/1067], D_A_loss: 0.0381, D_B_loss: 0.0124, G_A_loss: 0.5869, G_B_loss: 0.9603\n",
      "Epoch [99/200], Step [651/1067], D_A_loss: 0.0754, D_B_loss: 0.0180, G_A_loss: 0.7923, G_B_loss: 0.9550\n",
      "Epoch [99/200], Step [661/1067], D_A_loss: 0.3357, D_B_loss: 0.0336, G_A_loss: 0.8189, G_B_loss: 0.9230\n",
      "Epoch [99/200], Step [671/1067], D_A_loss: 0.1206, D_B_loss: 0.0314, G_A_loss: 0.3161, G_B_loss: 0.3513\n",
      "Epoch [99/200], Step [681/1067], D_A_loss: 0.0492, D_B_loss: 0.0205, G_A_loss: 0.6234, G_B_loss: 0.7167\n",
      "Epoch [99/200], Step [691/1067], D_A_loss: 0.0977, D_B_loss: 0.0227, G_A_loss: 0.8177, G_B_loss: 0.7662\n",
      "Epoch [99/200], Step [701/1067], D_A_loss: 0.0574, D_B_loss: 0.0511, G_A_loss: 0.5697, G_B_loss: 0.7881\n",
      "Epoch [99/200], Step [711/1067], D_A_loss: 0.1048, D_B_loss: 0.1135, G_A_loss: 0.6383, G_B_loss: 0.4538\n",
      "Epoch [99/200], Step [721/1067], D_A_loss: 0.0581, D_B_loss: 0.0354, G_A_loss: 0.6138, G_B_loss: 0.6908\n",
      "Epoch [99/200], Step [731/1067], D_A_loss: 0.0715, D_B_loss: 0.0841, G_A_loss: 0.4177, G_B_loss: 0.5313\n",
      "Epoch [99/200], Step [741/1067], D_A_loss: 0.1522, D_B_loss: 0.0235, G_A_loss: 0.7690, G_B_loss: 0.8830\n",
      "Epoch [99/200], Step [751/1067], D_A_loss: 0.1100, D_B_loss: 0.0137, G_A_loss: 0.8424, G_B_loss: 0.4976\n",
      "Epoch [99/200], Step [761/1067], D_A_loss: 0.2910, D_B_loss: 0.0411, G_A_loss: 1.2150, G_B_loss: 0.2190\n",
      "Epoch [99/200], Step [771/1067], D_A_loss: 0.1127, D_B_loss: 0.0234, G_A_loss: 0.9758, G_B_loss: 0.4060\n",
      "Epoch [99/200], Step [781/1067], D_A_loss: 0.2337, D_B_loss: 0.0370, G_A_loss: 0.4815, G_B_loss: 1.0829\n",
      "Epoch [99/200], Step [791/1067], D_A_loss: 0.0393, D_B_loss: 0.0235, G_A_loss: 1.0700, G_B_loss: 0.6120\n",
      "Epoch [99/200], Step [801/1067], D_A_loss: 0.0664, D_B_loss: 0.0148, G_A_loss: 0.8519, G_B_loss: 0.5951\n",
      "Epoch [99/200], Step [811/1067], D_A_loss: 0.1479, D_B_loss: 0.1166, G_A_loss: 1.0739, G_B_loss: 0.3715\n",
      "Epoch [99/200], Step [821/1067], D_A_loss: 0.0989, D_B_loss: 0.0144, G_A_loss: 0.5315, G_B_loss: 0.7602\n",
      "Epoch [99/200], Step [831/1067], D_A_loss: 0.0970, D_B_loss: 0.0088, G_A_loss: 0.8842, G_B_loss: 0.3987\n",
      "Epoch [99/200], Step [841/1067], D_A_loss: 0.1257, D_B_loss: 0.0234, G_A_loss: 0.7373, G_B_loss: 0.3365\n",
      "Epoch [99/200], Step [851/1067], D_A_loss: 0.0493, D_B_loss: 0.0142, G_A_loss: 0.9522, G_B_loss: 0.8834\n",
      "Epoch [99/200], Step [861/1067], D_A_loss: 0.0414, D_B_loss: 0.0172, G_A_loss: 0.8037, G_B_loss: 0.2789\n",
      "Epoch [99/200], Step [871/1067], D_A_loss: 0.1469, D_B_loss: 0.0140, G_A_loss: 1.3150, G_B_loss: 0.5734\n",
      "Epoch [99/200], Step [881/1067], D_A_loss: 0.0342, D_B_loss: 0.0403, G_A_loss: 0.9346, G_B_loss: 0.2564\n",
      "Epoch [99/200], Step [891/1067], D_A_loss: 0.1827, D_B_loss: 0.0393, G_A_loss: 0.4702, G_B_loss: 0.5173\n",
      "Epoch [99/200], Step [901/1067], D_A_loss: 0.0521, D_B_loss: 0.0371, G_A_loss: 0.5887, G_B_loss: 0.4847\n",
      "Epoch [99/200], Step [911/1067], D_A_loss: 0.0547, D_B_loss: 0.1267, G_A_loss: 0.7245, G_B_loss: 0.6276\n",
      "Epoch [99/200], Step [921/1067], D_A_loss: 0.0569, D_B_loss: 0.0070, G_A_loss: 0.9479, G_B_loss: 0.4610\n",
      "Epoch [99/200], Step [931/1067], D_A_loss: 0.3611, D_B_loss: 0.1205, G_A_loss: 0.3337, G_B_loss: 0.6594\n",
      "Epoch [99/200], Step [941/1067], D_A_loss: 0.0721, D_B_loss: 0.0875, G_A_loss: 0.5957, G_B_loss: 0.2261\n",
      "Epoch [99/200], Step [951/1067], D_A_loss: 0.0507, D_B_loss: 0.1372, G_A_loss: 1.2329, G_B_loss: 0.5168\n",
      "Epoch [99/200], Step [961/1067], D_A_loss: 0.0818, D_B_loss: 0.1563, G_A_loss: 1.1723, G_B_loss: 0.5308\n",
      "Epoch [99/200], Step [971/1067], D_A_loss: 0.1705, D_B_loss: 0.0341, G_A_loss: 0.5829, G_B_loss: 0.2934\n",
      "Epoch [99/200], Step [981/1067], D_A_loss: 0.0600, D_B_loss: 0.0378, G_A_loss: 0.8910, G_B_loss: 1.0644\n",
      "Epoch [99/200], Step [991/1067], D_A_loss: 0.0830, D_B_loss: 0.0327, G_A_loss: 0.7552, G_B_loss: 0.1759\n",
      "Epoch [99/200], Step [1001/1067], D_A_loss: 0.0736, D_B_loss: 0.0250, G_A_loss: 0.6744, G_B_loss: 0.6073\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [99/200], Step [1011/1067], D_A_loss: 0.1286, D_B_loss: 0.0889, G_A_loss: 1.0919, G_B_loss: 0.5702\n",
      "Epoch [99/200], Step [1021/1067], D_A_loss: 0.0896, D_B_loss: 0.0589, G_A_loss: 0.7013, G_B_loss: 0.4769\n",
      "Epoch [99/200], Step [1031/1067], D_A_loss: 0.0514, D_B_loss: 0.0342, G_A_loss: 1.1241, G_B_loss: 0.5932\n",
      "Epoch [99/200], Step [1041/1067], D_A_loss: 0.2405, D_B_loss: 0.0117, G_A_loss: 1.0034, G_B_loss: 0.6041\n",
      "Epoch [99/200], Step [1051/1067], D_A_loss: 0.2176, D_B_loss: 0.0405, G_A_loss: 0.3317, G_B_loss: 0.2545\n",
      "Epoch [99/200], Step [1061/1067], D_A_loss: 0.1096, D_B_loss: 0.0220, G_A_loss: 1.0326, G_B_loss: 0.6339\n",
      "Epoch [100/200], Step [1/1067], D_A_loss: 0.0368, D_B_loss: 0.0172, G_A_loss: 1.3327, G_B_loss: 0.8004\n",
      "Epoch [100/200], Step [11/1067], D_A_loss: 0.1779, D_B_loss: 0.0300, G_A_loss: 0.7486, G_B_loss: 0.2233\n",
      "Epoch [100/200], Step [21/1067], D_A_loss: 0.1050, D_B_loss: 0.0099, G_A_loss: 0.6786, G_B_loss: 0.4149\n",
      "Epoch [100/200], Step [31/1067], D_A_loss: 0.2058, D_B_loss: 0.0172, G_A_loss: 0.7538, G_B_loss: 0.2413\n",
      "Epoch [100/200], Step [41/1067], D_A_loss: 0.0475, D_B_loss: 0.0358, G_A_loss: 0.6834, G_B_loss: 0.1997\n",
      "Epoch [100/200], Step [51/1067], D_A_loss: 0.3144, D_B_loss: 0.0318, G_A_loss: 0.7125, G_B_loss: 0.8931\n",
      "Epoch [100/200], Step [61/1067], D_A_loss: 0.1410, D_B_loss: 0.0252, G_A_loss: 1.1534, G_B_loss: 0.3451\n",
      "Epoch [100/200], Step [71/1067], D_A_loss: 0.0279, D_B_loss: 0.0190, G_A_loss: 0.8232, G_B_loss: 0.8087\n",
      "Epoch [100/200], Step [81/1067], D_A_loss: 0.2861, D_B_loss: 0.1457, G_A_loss: 0.9200, G_B_loss: 0.1291\n",
      "Epoch [100/200], Step [91/1067], D_A_loss: 0.2795, D_B_loss: 0.0456, G_A_loss: 0.5435, G_B_loss: 0.8948\n",
      "Epoch [100/200], Step [101/1067], D_A_loss: 0.1086, D_B_loss: 0.0140, G_A_loss: 0.8067, G_B_loss: 0.3773\n",
      "Epoch [100/200], Step [111/1067], D_A_loss: 0.0754, D_B_loss: 0.1738, G_A_loss: 0.5808, G_B_loss: 0.7126\n",
      "Epoch [100/200], Step [121/1067], D_A_loss: 0.0941, D_B_loss: 0.0340, G_A_loss: 0.8044, G_B_loss: 0.6981\n",
      "Epoch [100/200], Step [131/1067], D_A_loss: 0.2224, D_B_loss: 0.0464, G_A_loss: 0.7875, G_B_loss: 0.1685\n",
      "Epoch [100/200], Step [141/1067], D_A_loss: 0.0759, D_B_loss: 0.0292, G_A_loss: 0.9781, G_B_loss: 0.2230\n",
      "Epoch [100/200], Step [151/1067], D_A_loss: 0.1013, D_B_loss: 0.0333, G_A_loss: 0.3654, G_B_loss: 0.8837\n",
      "Epoch [100/200], Step [161/1067], D_A_loss: 0.1752, D_B_loss: 0.0188, G_A_loss: 0.8011, G_B_loss: 0.2501\n",
      "Epoch [100/200], Step [171/1067], D_A_loss: 0.0886, D_B_loss: 0.0749, G_A_loss: 0.6174, G_B_loss: 0.6211\n",
      "Epoch [100/200], Step [181/1067], D_A_loss: 0.2116, D_B_loss: 0.0196, G_A_loss: 0.8358, G_B_loss: 0.8277\n",
      "Epoch [100/200], Step [191/1067], D_A_loss: 0.1910, D_B_loss: 0.0595, G_A_loss: 0.5243, G_B_loss: 0.2135\n",
      "Epoch [100/200], Step [201/1067], D_A_loss: 0.1145, D_B_loss: 0.0230, G_A_loss: 0.9513, G_B_loss: 0.5776\n",
      "Epoch [100/200], Step [211/1067], D_A_loss: 0.0249, D_B_loss: 0.0175, G_A_loss: 1.2027, G_B_loss: 0.4553\n",
      "Epoch [100/200], Step [221/1067], D_A_loss: 0.0346, D_B_loss: 0.0281, G_A_loss: 0.7676, G_B_loss: 0.4271\n",
      "Epoch [100/200], Step [231/1067], D_A_loss: 0.0436, D_B_loss: 0.0812, G_A_loss: 0.4572, G_B_loss: 0.7238\n",
      "Epoch [100/200], Step [241/1067], D_A_loss: 0.0452, D_B_loss: 0.0484, G_A_loss: 0.7533, G_B_loss: 0.6767\n",
      "Epoch [100/200], Step [251/1067], D_A_loss: 0.1164, D_B_loss: 0.0322, G_A_loss: 0.7988, G_B_loss: 0.6443\n",
      "Epoch [100/200], Step [261/1067], D_A_loss: 0.1026, D_B_loss: 0.0305, G_A_loss: 0.6724, G_B_loss: 0.4242\n",
      "Epoch [100/200], Step [271/1067], D_A_loss: 0.0941, D_B_loss: 0.0132, G_A_loss: 0.5882, G_B_loss: 0.6240\n",
      "Epoch [100/200], Step [281/1067], D_A_loss: 0.0834, D_B_loss: 0.0216, G_A_loss: 1.0692, G_B_loss: 0.5512\n",
      "Epoch [100/200], Step [291/1067], D_A_loss: 0.0300, D_B_loss: 0.0123, G_A_loss: 1.0309, G_B_loss: 0.5703\n",
      "Epoch [100/200], Step [301/1067], D_A_loss: 0.0812, D_B_loss: 0.0245, G_A_loss: 1.1479, G_B_loss: 0.7021\n",
      "Epoch [100/200], Step [311/1067], D_A_loss: 0.0376, D_B_loss: 0.0548, G_A_loss: 0.5045, G_B_loss: 0.5683\n",
      "Epoch [100/200], Step [321/1067], D_A_loss: 0.1968, D_B_loss: 0.0669, G_A_loss: 0.5475, G_B_loss: 0.9062\n",
      "Epoch [100/200], Step [331/1067], D_A_loss: 0.0501, D_B_loss: 0.0323, G_A_loss: 0.8653, G_B_loss: 0.5624\n",
      "Epoch [100/200], Step [341/1067], D_A_loss: 0.1979, D_B_loss: 0.0318, G_A_loss: 1.0939, G_B_loss: 0.5377\n",
      "Epoch [100/200], Step [351/1067], D_A_loss: 0.0996, D_B_loss: 0.0333, G_A_loss: 0.6826, G_B_loss: 0.4455\n",
      "Epoch [100/200], Step [361/1067], D_A_loss: 0.0530, D_B_loss: 0.0937, G_A_loss: 0.4140, G_B_loss: 0.2908\n",
      "Epoch [100/200], Step [371/1067], D_A_loss: 0.0922, D_B_loss: 0.0561, G_A_loss: 0.5540, G_B_loss: 0.4378\n",
      "Epoch [100/200], Step [381/1067], D_A_loss: 0.0739, D_B_loss: 0.0245, G_A_loss: 0.4892, G_B_loss: 0.4957\n",
      "Epoch [100/200], Step [391/1067], D_A_loss: 0.0817, D_B_loss: 0.0748, G_A_loss: 0.9801, G_B_loss: 0.5080\n",
      "Epoch [100/200], Step [401/1067], D_A_loss: 0.1061, D_B_loss: 0.0671, G_A_loss: 0.5287, G_B_loss: 0.3647\n",
      "Epoch [100/200], Step [411/1067], D_A_loss: 0.1508, D_B_loss: 0.0188, G_A_loss: 0.7889, G_B_loss: 0.5253\n",
      "Epoch [100/200], Step [421/1067], D_A_loss: 0.1576, D_B_loss: 0.0514, G_A_loss: 0.5905, G_B_loss: 0.2929\n",
      "Epoch [100/200], Step [431/1067], D_A_loss: 0.0423, D_B_loss: 0.0709, G_A_loss: 0.8363, G_B_loss: 0.9321\n",
      "Epoch [100/200], Step [441/1067], D_A_loss: 0.0913, D_B_loss: 0.0123, G_A_loss: 1.0840, G_B_loss: 0.4196\n",
      "Epoch [100/200], Step [451/1067], D_A_loss: 0.0275, D_B_loss: 0.0524, G_A_loss: 0.5362, G_B_loss: 0.5364\n",
      "Epoch [100/200], Step [461/1067], D_A_loss: 0.0899, D_B_loss: 0.0825, G_A_loss: 0.7671, G_B_loss: 0.4539\n",
      "Epoch [100/200], Step [471/1067], D_A_loss: 0.1600, D_B_loss: 0.0344, G_A_loss: 0.9896, G_B_loss: 0.4813\n",
      "Epoch [100/200], Step [481/1067], D_A_loss: 0.6690, D_B_loss: 0.0118, G_A_loss: 0.6206, G_B_loss: 0.0630\n",
      "Epoch [100/200], Step [491/1067], D_A_loss: 0.1122, D_B_loss: 0.0173, G_A_loss: 0.8238, G_B_loss: 0.4698\n",
      "Epoch [100/200], Step [501/1067], D_A_loss: 0.1615, D_B_loss: 0.0378, G_A_loss: 0.4326, G_B_loss: 0.6230\n",
      "Epoch [100/200], Step [511/1067], D_A_loss: 0.1862, D_B_loss: 0.0180, G_A_loss: 1.1884, G_B_loss: 0.5216\n",
      "Epoch [100/200], Step [521/1067], D_A_loss: 0.0831, D_B_loss: 0.0687, G_A_loss: 0.6264, G_B_loss: 0.4696\n",
      "Epoch [100/200], Step [531/1067], D_A_loss: 0.1723, D_B_loss: 0.0326, G_A_loss: 0.5202, G_B_loss: 0.3383\n",
      "Epoch [100/200], Step [541/1067], D_A_loss: 0.0973, D_B_loss: 0.0186, G_A_loss: 1.1611, G_B_loss: 0.3982\n",
      "Epoch [100/200], Step [551/1067], D_A_loss: 0.2262, D_B_loss: 0.0158, G_A_loss: 0.9517, G_B_loss: 0.2292\n",
      "Epoch [100/200], Step [561/1067], D_A_loss: 0.0390, D_B_loss: 0.0203, G_A_loss: 0.6593, G_B_loss: 0.6190\n",
      "Epoch [100/200], Step [571/1067], D_A_loss: 0.1734, D_B_loss: 0.0189, G_A_loss: 0.7113, G_B_loss: 1.0552\n",
      "Epoch [100/200], Step [581/1067], D_A_loss: 0.0918, D_B_loss: 0.0924, G_A_loss: 0.6904, G_B_loss: 0.4952\n",
      "Epoch [100/200], Step [591/1067], D_A_loss: 0.0517, D_B_loss: 0.0325, G_A_loss: 0.6420, G_B_loss: 0.6754\n",
      "Epoch [100/200], Step [601/1067], D_A_loss: 0.2305, D_B_loss: 0.0326, G_A_loss: 0.8692, G_B_loss: 0.7537\n",
      "Epoch [100/200], Step [611/1067], D_A_loss: 0.1058, D_B_loss: 0.0697, G_A_loss: 0.5548, G_B_loss: 0.3753\n",
      "Epoch [100/200], Step [621/1067], D_A_loss: 0.1067, D_B_loss: 0.0257, G_A_loss: 0.8375, G_B_loss: 0.3203\n",
      "Epoch [100/200], Step [631/1067], D_A_loss: 0.0673, D_B_loss: 0.0121, G_A_loss: 0.6066, G_B_loss: 0.3272\n",
      "Epoch [100/200], Step [641/1067], D_A_loss: 0.0943, D_B_loss: 0.0209, G_A_loss: 0.7442, G_B_loss: 0.8454\n",
      "Epoch [100/200], Step [651/1067], D_A_loss: 0.0710, D_B_loss: 0.0296, G_A_loss: 0.8379, G_B_loss: 0.5280\n",
      "Epoch [100/200], Step [661/1067], D_A_loss: 0.1424, D_B_loss: 0.0436, G_A_loss: 0.7392, G_B_loss: 0.6608\n",
      "Epoch [100/200], Step [671/1067], D_A_loss: 0.1232, D_B_loss: 0.0578, G_A_loss: 0.4840, G_B_loss: 0.3038\n",
      "Epoch [100/200], Step [681/1067], D_A_loss: 0.1263, D_B_loss: 0.0963, G_A_loss: 0.4850, G_B_loss: 0.3875\n",
      "Epoch [100/200], Step [691/1067], D_A_loss: 0.1057, D_B_loss: 0.0219, G_A_loss: 0.7737, G_B_loss: 0.4036\n",
      "Epoch [100/200], Step [701/1067], D_A_loss: 0.2366, D_B_loss: 0.1286, G_A_loss: 0.6332, G_B_loss: 0.8585\n",
      "Epoch [100/200], Step [711/1067], D_A_loss: 0.0267, D_B_loss: 0.0404, G_A_loss: 0.7771, G_B_loss: 0.9281\n",
      "Epoch [100/200], Step [721/1067], D_A_loss: 0.0843, D_B_loss: 0.0180, G_A_loss: 0.7975, G_B_loss: 0.3168\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/200], Step [731/1067], D_A_loss: 0.2177, D_B_loss: 0.0719, G_A_loss: 0.6143, G_B_loss: 0.3769\n",
      "Epoch [100/200], Step [741/1067], D_A_loss: 0.2071, D_B_loss: 0.0229, G_A_loss: 0.4971, G_B_loss: 0.7714\n",
      "Epoch [100/200], Step [751/1067], D_A_loss: 0.0637, D_B_loss: 0.0861, G_A_loss: 0.5112, G_B_loss: 0.8035\n",
      "Epoch [100/200], Step [761/1067], D_A_loss: 0.0689, D_B_loss: 0.0539, G_A_loss: 1.0990, G_B_loss: 0.3555\n",
      "Epoch [100/200], Step [771/1067], D_A_loss: 0.1696, D_B_loss: 0.0138, G_A_loss: 1.0973, G_B_loss: 0.3020\n",
      "Epoch [100/200], Step [781/1067], D_A_loss: 0.1653, D_B_loss: 0.0079, G_A_loss: 0.8378, G_B_loss: 1.2106\n",
      "Epoch [100/200], Step [791/1067], D_A_loss: 0.0977, D_B_loss: 0.0108, G_A_loss: 0.8179, G_B_loss: 0.8944\n",
      "Epoch [100/200], Step [801/1067], D_A_loss: 0.1172, D_B_loss: 0.0173, G_A_loss: 0.8709, G_B_loss: 0.3482\n",
      "Epoch [100/200], Step [811/1067], D_A_loss: 0.1029, D_B_loss: 0.0150, G_A_loss: 0.8393, G_B_loss: 0.3340\n",
      "Epoch [100/200], Step [821/1067], D_A_loss: 0.0550, D_B_loss: 0.0249, G_A_loss: 0.7700, G_B_loss: 0.6080\n",
      "Epoch [100/200], Step [831/1067], D_A_loss: 0.0685, D_B_loss: 0.0170, G_A_loss: 1.1127, G_B_loss: 0.3717\n",
      "Epoch [100/200], Step [841/1067], D_A_loss: 0.0968, D_B_loss: 0.0630, G_A_loss: 0.5288, G_B_loss: 0.5846\n",
      "Epoch [100/200], Step [851/1067], D_A_loss: 0.2340, D_B_loss: 0.0187, G_A_loss: 0.7950, G_B_loss: 0.7219\n",
      "Epoch [100/200], Step [861/1067], D_A_loss: 0.0683, D_B_loss: 0.0661, G_A_loss: 1.1245, G_B_loss: 0.4644\n",
      "Epoch [100/200], Step [871/1067], D_A_loss: 0.2874, D_B_loss: 0.0382, G_A_loss: 1.0367, G_B_loss: 0.0991\n",
      "Epoch [100/200], Step [881/1067], D_A_loss: 0.2309, D_B_loss: 0.0605, G_A_loss: 0.8562, G_B_loss: 0.5212\n",
      "Epoch [100/200], Step [891/1067], D_A_loss: 0.1760, D_B_loss: 0.0148, G_A_loss: 1.5212, G_B_loss: 0.4859\n",
      "Epoch [100/200], Step [901/1067], D_A_loss: 0.1634, D_B_loss: 0.0250, G_A_loss: 1.0655, G_B_loss: 0.5862\n",
      "Epoch [100/200], Step [911/1067], D_A_loss: 0.1699, D_B_loss: 0.0447, G_A_loss: 1.3129, G_B_loss: 0.7522\n",
      "Epoch [100/200], Step [921/1067], D_A_loss: 0.0386, D_B_loss: 0.1033, G_A_loss: 1.2101, G_B_loss: 0.7137\n",
      "Epoch [100/200], Step [931/1067], D_A_loss: 0.0250, D_B_loss: 0.0319, G_A_loss: 0.7746, G_B_loss: 0.3196\n",
      "Epoch [100/200], Step [941/1067], D_A_loss: 0.1200, D_B_loss: 0.0374, G_A_loss: 0.5981, G_B_loss: 0.4220\n",
      "Epoch [100/200], Step [951/1067], D_A_loss: 0.0424, D_B_loss: 0.0268, G_A_loss: 0.6943, G_B_loss: 0.5635\n",
      "Epoch [100/200], Step [961/1067], D_A_loss: 0.0847, D_B_loss: 0.0840, G_A_loss: 0.6092, G_B_loss: 0.9745\n",
      "Epoch [100/200], Step [971/1067], D_A_loss: 0.0527, D_B_loss: 0.0167, G_A_loss: 0.6446, G_B_loss: 0.8788\n",
      "Epoch [100/200], Step [981/1067], D_A_loss: 0.1378, D_B_loss: 0.0590, G_A_loss: 0.6427, G_B_loss: 0.8357\n",
      "Epoch [100/200], Step [991/1067], D_A_loss: 0.0898, D_B_loss: 0.0340, G_A_loss: 0.6918, G_B_loss: 0.4465\n",
      "Epoch [100/200], Step [1001/1067], D_A_loss: 0.0620, D_B_loss: 0.0613, G_A_loss: 0.6191, G_B_loss: 0.7155\n",
      "Epoch [100/200], Step [1011/1067], D_A_loss: 0.1530, D_B_loss: 0.0211, G_A_loss: 0.5006, G_B_loss: 0.5384\n",
      "Epoch [100/200], Step [1021/1067], D_A_loss: 0.1317, D_B_loss: 0.0763, G_A_loss: 0.4147, G_B_loss: 0.4114\n",
      "Epoch [100/200], Step [1031/1067], D_A_loss: 0.2244, D_B_loss: 0.0113, G_A_loss: 0.9026, G_B_loss: 0.8027\n",
      "Epoch [100/200], Step [1041/1067], D_A_loss: 0.2461, D_B_loss: 0.0160, G_A_loss: 1.1468, G_B_loss: 0.4131\n",
      "Epoch [100/200], Step [1051/1067], D_A_loss: 0.1073, D_B_loss: 0.0726, G_A_loss: 0.4650, G_B_loss: 0.6742\n",
      "Epoch [100/200], Step [1061/1067], D_A_loss: 0.0498, D_B_loss: 0.1105, G_A_loss: 0.2805, G_B_loss: 0.5608\n",
      "Epoch [101/200], Step [1/1067], D_A_loss: 0.0827, D_B_loss: 0.0389, G_A_loss: 0.7443, G_B_loss: 0.5668\n",
      "Epoch [101/200], Step [11/1067], D_A_loss: 0.2364, D_B_loss: 0.0820, G_A_loss: 1.0655, G_B_loss: 1.1088\n",
      "Epoch [101/200], Step [21/1067], D_A_loss: 0.0836, D_B_loss: 0.0245, G_A_loss: 0.9101, G_B_loss: 0.4821\n",
      "Epoch [101/200], Step [31/1067], D_A_loss: 0.1579, D_B_loss: 0.0481, G_A_loss: 0.6095, G_B_loss: 0.2805\n",
      "Epoch [101/200], Step [41/1067], D_A_loss: 0.0661, D_B_loss: 0.0475, G_A_loss: 1.0724, G_B_loss: 0.9166\n",
      "Epoch [101/200], Step [51/1067], D_A_loss: 0.0884, D_B_loss: 0.0248, G_A_loss: 0.7937, G_B_loss: 0.4118\n",
      "Epoch [101/200], Step [61/1067], D_A_loss: 0.1882, D_B_loss: 0.0143, G_A_loss: 0.6694, G_B_loss: 0.2430\n",
      "Epoch [101/200], Step [71/1067], D_A_loss: 0.1768, D_B_loss: 0.0245, G_A_loss: 0.9719, G_B_loss: 0.6982\n",
      "Epoch [101/200], Step [81/1067], D_A_loss: 0.1060, D_B_loss: 0.0221, G_A_loss: 1.3305, G_B_loss: 0.5079\n",
      "Epoch [101/200], Step [91/1067], D_A_loss: 0.0260, D_B_loss: 0.0227, G_A_loss: 0.9326, G_B_loss: 0.9908\n",
      "Epoch [101/200], Step [101/1067], D_A_loss: 0.1454, D_B_loss: 0.0390, G_A_loss: 1.0602, G_B_loss: 0.5304\n",
      "Epoch [101/200], Step [111/1067], D_A_loss: 0.1343, D_B_loss: 0.1892, G_A_loss: 0.9582, G_B_loss: 0.4165\n",
      "Epoch [101/200], Step [121/1067], D_A_loss: 0.2005, D_B_loss: 0.0489, G_A_loss: 0.7769, G_B_loss: 0.3522\n",
      "Epoch [101/200], Step [131/1067], D_A_loss: 0.1426, D_B_loss: 0.0226, G_A_loss: 0.7510, G_B_loss: 0.2676\n",
      "Epoch [101/200], Step [141/1067], D_A_loss: 0.3572, D_B_loss: 0.0329, G_A_loss: 1.0391, G_B_loss: 0.0736\n",
      "Epoch [101/200], Step [151/1067], D_A_loss: 0.0441, D_B_loss: 0.0225, G_A_loss: 0.9273, G_B_loss: 0.3524\n",
      "Epoch [101/200], Step [161/1067], D_A_loss: 0.1668, D_B_loss: 0.0133, G_A_loss: 0.9806, G_B_loss: 0.8011\n",
      "Epoch [101/200], Step [171/1067], D_A_loss: 0.1621, D_B_loss: 0.0301, G_A_loss: 0.4207, G_B_loss: 0.6379\n",
      "Epoch [101/200], Step [181/1067], D_A_loss: 0.1749, D_B_loss: 0.0201, G_A_loss: 0.8036, G_B_loss: 0.7133\n",
      "Epoch [101/200], Step [191/1067], D_A_loss: 0.0413, D_B_loss: 0.0466, G_A_loss: 0.8881, G_B_loss: 0.3609\n",
      "Epoch [101/200], Step [201/1067], D_A_loss: 0.0871, D_B_loss: 0.0220, G_A_loss: 1.0530, G_B_loss: 0.4164\n",
      "Epoch [101/200], Step [211/1067], D_A_loss: 0.1346, D_B_loss: 0.0448, G_A_loss: 0.6279, G_B_loss: 0.2555\n",
      "Epoch [101/200], Step [221/1067], D_A_loss: 0.0551, D_B_loss: 0.0132, G_A_loss: 0.9395, G_B_loss: 0.6247\n",
      "Epoch [101/200], Step [231/1067], D_A_loss: 0.0747, D_B_loss: 0.0372, G_A_loss: 0.7074, G_B_loss: 0.5948\n",
      "Epoch [101/200], Step [241/1067], D_A_loss: 0.1238, D_B_loss: 0.0300, G_A_loss: 0.6773, G_B_loss: 1.0541\n",
      "Epoch [101/200], Step [251/1067], D_A_loss: 0.0470, D_B_loss: 0.0111, G_A_loss: 0.8280, G_B_loss: 0.6165\n",
      "Epoch [101/200], Step [261/1067], D_A_loss: 0.1786, D_B_loss: 0.0243, G_A_loss: 0.8072, G_B_loss: 0.5412\n",
      "Epoch [101/200], Step [271/1067], D_A_loss: 0.1578, D_B_loss: 0.0167, G_A_loss: 0.9368, G_B_loss: 1.1554\n",
      "Epoch [101/200], Step [281/1067], D_A_loss: 0.0948, D_B_loss: 0.0250, G_A_loss: 0.9025, G_B_loss: 0.8559\n",
      "Epoch [101/200], Step [291/1067], D_A_loss: 0.0894, D_B_loss: 0.0432, G_A_loss: 0.6552, G_B_loss: 0.4035\n",
      "Epoch [101/200], Step [301/1067], D_A_loss: 0.0993, D_B_loss: 0.0245, G_A_loss: 0.7556, G_B_loss: 0.9585\n",
      "Epoch [101/200], Step [311/1067], D_A_loss: 0.0575, D_B_loss: 0.0139, G_A_loss: 0.9025, G_B_loss: 0.6216\n",
      "Epoch [101/200], Step [321/1067], D_A_loss: 0.0715, D_B_loss: 0.0178, G_A_loss: 0.8939, G_B_loss: 0.6160\n",
      "Epoch [101/200], Step [331/1067], D_A_loss: 0.0243, D_B_loss: 0.0175, G_A_loss: 0.7835, G_B_loss: 0.3225\n",
      "Epoch [101/200], Step [341/1067], D_A_loss: 0.1327, D_B_loss: 0.1512, G_A_loss: 0.4070, G_B_loss: 0.4132\n",
      "Epoch [101/200], Step [351/1067], D_A_loss: 0.1895, D_B_loss: 0.0120, G_A_loss: 1.0117, G_B_loss: 0.6272\n",
      "Epoch [101/200], Step [361/1067], D_A_loss: 0.1265, D_B_loss: 0.0557, G_A_loss: 0.7220, G_B_loss: 0.4642\n",
      "Epoch [101/200], Step [371/1067], D_A_loss: 0.1173, D_B_loss: 0.0145, G_A_loss: 1.0544, G_B_loss: 0.7722\n",
      "Epoch [101/200], Step [381/1067], D_A_loss: 0.0543, D_B_loss: 0.0462, G_A_loss: 0.8650, G_B_loss: 0.7417\n",
      "Epoch [101/200], Step [391/1067], D_A_loss: 0.0358, D_B_loss: 0.0640, G_A_loss: 1.0833, G_B_loss: 0.4232\n",
      "Epoch [101/200], Step [401/1067], D_A_loss: 0.1815, D_B_loss: 0.0171, G_A_loss: 0.9071, G_B_loss: 0.9680\n",
      "Epoch [101/200], Step [411/1067], D_A_loss: 0.1137, D_B_loss: 0.0261, G_A_loss: 0.7223, G_B_loss: 0.3563\n",
      "Epoch [101/200], Step [421/1067], D_A_loss: 0.0684, D_B_loss: 0.0394, G_A_loss: 0.9103, G_B_loss: 0.5176\n",
      "Epoch [101/200], Step [431/1067], D_A_loss: 0.2061, D_B_loss: 0.0312, G_A_loss: 1.0641, G_B_loss: 0.6719\n",
      "Epoch [101/200], Step [441/1067], D_A_loss: 0.0759, D_B_loss: 0.0292, G_A_loss: 0.7942, G_B_loss: 0.6600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [101/200], Step [451/1067], D_A_loss: 0.0542, D_B_loss: 0.1262, G_A_loss: 0.3561, G_B_loss: 0.9462\n",
      "Epoch [101/200], Step [461/1067], D_A_loss: 0.0522, D_B_loss: 0.0295, G_A_loss: 0.8925, G_B_loss: 1.0894\n",
      "Epoch [101/200], Step [471/1067], D_A_loss: 0.1534, D_B_loss: 0.0574, G_A_loss: 0.5885, G_B_loss: 0.3202\n",
      "Epoch [101/200], Step [481/1067], D_A_loss: 0.1443, D_B_loss: 0.0565, G_A_loss: 0.9216, G_B_loss: 0.2821\n",
      "Epoch [101/200], Step [491/1067], D_A_loss: 0.1996, D_B_loss: 0.0620, G_A_loss: 0.4881, G_B_loss: 0.2896\n",
      "Epoch [101/200], Step [501/1067], D_A_loss: 0.1242, D_B_loss: 0.0543, G_A_loss: 1.0050, G_B_loss: 0.4545\n",
      "Epoch [101/200], Step [511/1067], D_A_loss: 0.1727, D_B_loss: 0.0203, G_A_loss: 0.9766, G_B_loss: 0.3922\n",
      "Epoch [101/200], Step [521/1067], D_A_loss: 0.0743, D_B_loss: 0.0224, G_A_loss: 1.0026, G_B_loss: 0.5608\n",
      "Epoch [101/200], Step [531/1067], D_A_loss: 0.0563, D_B_loss: 0.0085, G_A_loss: 0.5889, G_B_loss: 0.9148\n",
      "Epoch [101/200], Step [541/1067], D_A_loss: 0.1889, D_B_loss: 0.0574, G_A_loss: 0.6201, G_B_loss: 0.5974\n",
      "Epoch [101/200], Step [551/1067], D_A_loss: 0.1611, D_B_loss: 0.0161, G_A_loss: 0.7565, G_B_loss: 0.2487\n",
      "Epoch [101/200], Step [561/1067], D_A_loss: 0.0552, D_B_loss: 0.0166, G_A_loss: 1.1815, G_B_loss: 0.6515\n",
      "Epoch [101/200], Step [571/1067], D_A_loss: 0.1137, D_B_loss: 0.1161, G_A_loss: 0.9201, G_B_loss: 0.3801\n",
      "Epoch [101/200], Step [581/1067], D_A_loss: 0.1592, D_B_loss: 0.0758, G_A_loss: 0.5936, G_B_loss: 0.8197\n",
      "Epoch [101/200], Step [591/1067], D_A_loss: 0.1544, D_B_loss: 0.0117, G_A_loss: 0.9227, G_B_loss: 0.3150\n",
      "Epoch [101/200], Step [601/1067], D_A_loss: 0.1343, D_B_loss: 0.0225, G_A_loss: 1.0900, G_B_loss: 0.4878\n",
      "Epoch [101/200], Step [611/1067], D_A_loss: 0.1457, D_B_loss: 0.0392, G_A_loss: 1.0667, G_B_loss: 0.2979\n",
      "Epoch [101/200], Step [621/1067], D_A_loss: 0.0354, D_B_loss: 0.0142, G_A_loss: 0.8644, G_B_loss: 0.6027\n",
      "Epoch [101/200], Step [631/1067], D_A_loss: 0.0232, D_B_loss: 0.0247, G_A_loss: 1.3697, G_B_loss: 0.5870\n",
      "Epoch [101/200], Step [641/1067], D_A_loss: 0.1728, D_B_loss: 0.0621, G_A_loss: 0.4236, G_B_loss: 0.7505\n",
      "Epoch [101/200], Step [651/1067], D_A_loss: 0.0457, D_B_loss: 0.0420, G_A_loss: 0.5690, G_B_loss: 0.7126\n",
      "Epoch [101/200], Step [661/1067], D_A_loss: 0.1214, D_B_loss: 0.0119, G_A_loss: 0.8465, G_B_loss: 0.3216\n",
      "Epoch [101/200], Step [671/1067], D_A_loss: 0.0827, D_B_loss: 0.0278, G_A_loss: 1.1503, G_B_loss: 0.7144\n",
      "Epoch [101/200], Step [681/1067], D_A_loss: 0.1399, D_B_loss: 0.0272, G_A_loss: 0.7114, G_B_loss: 0.8127\n",
      "Epoch [101/200], Step [691/1067], D_A_loss: 0.0308, D_B_loss: 0.0146, G_A_loss: 1.0029, G_B_loss: 0.8360\n",
      "Epoch [101/200], Step [701/1067], D_A_loss: 0.1387, D_B_loss: 0.0167, G_A_loss: 0.8148, G_B_loss: 0.4181\n",
      "Epoch [101/200], Step [711/1067], D_A_loss: 0.0390, D_B_loss: 0.0144, G_A_loss: 0.8995, G_B_loss: 0.9531\n",
      "Epoch [101/200], Step [721/1067], D_A_loss: 0.1873, D_B_loss: 0.0535, G_A_loss: 1.1068, G_B_loss: 0.2774\n",
      "Epoch [101/200], Step [731/1067], D_A_loss: 0.0403, D_B_loss: 0.0261, G_A_loss: 0.9913, G_B_loss: 0.3980\n",
      "Epoch [101/200], Step [741/1067], D_A_loss: 0.0296, D_B_loss: 0.0147, G_A_loss: 0.6439, G_B_loss: 0.1697\n",
      "Epoch [101/200], Step [751/1067], D_A_loss: 0.0923, D_B_loss: 0.0354, G_A_loss: 0.8633, G_B_loss: 0.4521\n",
      "Epoch [101/200], Step [761/1067], D_A_loss: 0.0730, D_B_loss: 0.0259, G_A_loss: 0.5200, G_B_loss: 0.4938\n",
      "Epoch [101/200], Step [771/1067], D_A_loss: 0.0720, D_B_loss: 0.0165, G_A_loss: 1.3868, G_B_loss: 0.5577\n",
      "Epoch [101/200], Step [781/1067], D_A_loss: 0.0467, D_B_loss: 0.0343, G_A_loss: 0.7916, G_B_loss: 0.3927\n",
      "Epoch [101/200], Step [791/1067], D_A_loss: 0.0729, D_B_loss: 0.0222, G_A_loss: 0.8075, G_B_loss: 0.5085\n",
      "Epoch [101/200], Step [801/1067], D_A_loss: 0.1557, D_B_loss: 0.0409, G_A_loss: 0.6257, G_B_loss: 0.5551\n",
      "Epoch [101/200], Step [811/1067], D_A_loss: 0.0548, D_B_loss: 0.0199, G_A_loss: 1.1151, G_B_loss: 0.6588\n",
      "Epoch [101/200], Step [821/1067], D_A_loss: 0.2128, D_B_loss: 0.0152, G_A_loss: 1.0320, G_B_loss: 0.6618\n",
      "Epoch [101/200], Step [831/1067], D_A_loss: 0.1126, D_B_loss: 0.0309, G_A_loss: 0.6513, G_B_loss: 0.3685\n",
      "Epoch [101/200], Step [841/1067], D_A_loss: 0.1495, D_B_loss: 0.0159, G_A_loss: 0.9027, G_B_loss: 0.2655\n",
      "Epoch [101/200], Step [851/1067], D_A_loss: 0.0641, D_B_loss: 0.0302, G_A_loss: 0.6557, G_B_loss: 0.3556\n",
      "Epoch [101/200], Step [861/1067], D_A_loss: 0.0490, D_B_loss: 0.0698, G_A_loss: 0.5139, G_B_loss: 0.7136\n",
      "Epoch [101/200], Step [871/1067], D_A_loss: 0.0374, D_B_loss: 0.0265, G_A_loss: 0.9507, G_B_loss: 0.3433\n",
      "Epoch [101/200], Step [881/1067], D_A_loss: 0.0564, D_B_loss: 0.1477, G_A_loss: 1.0957, G_B_loss: 0.2918\n",
      "Epoch [101/200], Step [891/1067], D_A_loss: 0.0782, D_B_loss: 0.0098, G_A_loss: 0.9934, G_B_loss: 0.6610\n",
      "Epoch [101/200], Step [901/1067], D_A_loss: 0.1750, D_B_loss: 0.0208, G_A_loss: 0.9988, G_B_loss: 0.4445\n",
      "Epoch [101/200], Step [911/1067], D_A_loss: 0.1627, D_B_loss: 0.0145, G_A_loss: 0.9447, G_B_loss: 0.5709\n",
      "Epoch [101/200], Step [921/1067], D_A_loss: 0.0367, D_B_loss: 0.0308, G_A_loss: 0.6701, G_B_loss: 0.5412\n",
      "Epoch [101/200], Step [931/1067], D_A_loss: 0.2345, D_B_loss: 0.1183, G_A_loss: 0.7251, G_B_loss: 0.1288\n",
      "Epoch [101/200], Step [941/1067], D_A_loss: 0.0482, D_B_loss: 0.0485, G_A_loss: 1.0454, G_B_loss: 0.6605\n",
      "Epoch [101/200], Step [951/1067], D_A_loss: 0.0807, D_B_loss: 0.0713, G_A_loss: 1.0331, G_B_loss: 0.4188\n",
      "Epoch [101/200], Step [961/1067], D_A_loss: 0.1878, D_B_loss: 0.1929, G_A_loss: 1.1569, G_B_loss: 0.2328\n",
      "Epoch [101/200], Step [971/1067], D_A_loss: 0.1041, D_B_loss: 0.0288, G_A_loss: 0.7180, G_B_loss: 0.5324\n",
      "Epoch [101/200], Step [981/1067], D_A_loss: 0.0534, D_B_loss: 0.0322, G_A_loss: 0.9398, G_B_loss: 0.6931\n",
      "Epoch [101/200], Step [991/1067], D_A_loss: 0.0781, D_B_loss: 0.0239, G_A_loss: 1.0258, G_B_loss: 0.6913\n",
      "Epoch [101/200], Step [1001/1067], D_A_loss: 0.0258, D_B_loss: 0.0695, G_A_loss: 0.4799, G_B_loss: 0.4517\n",
      "Epoch [101/200], Step [1011/1067], D_A_loss: 0.1581, D_B_loss: 0.0207, G_A_loss: 0.3342, G_B_loss: 0.5779\n",
      "Epoch [101/200], Step [1021/1067], D_A_loss: 0.0901, D_B_loss: 0.0691, G_A_loss: 0.8563, G_B_loss: 0.3507\n",
      "Epoch [101/200], Step [1031/1067], D_A_loss: 0.1482, D_B_loss: 0.0265, G_A_loss: 0.7326, G_B_loss: 0.1095\n",
      "Epoch [101/200], Step [1041/1067], D_A_loss: 0.1589, D_B_loss: 0.0715, G_A_loss: 0.8633, G_B_loss: 0.4522\n",
      "Epoch [101/200], Step [1051/1067], D_A_loss: 0.1168, D_B_loss: 0.0233, G_A_loss: 1.0586, G_B_loss: 0.8087\n",
      "Epoch [101/200], Step [1061/1067], D_A_loss: 0.0683, D_B_loss: 0.0402, G_A_loss: 0.8374, G_B_loss: 0.4538\n",
      "Epoch [102/200], Step [1/1067], D_A_loss: 0.2977, D_B_loss: 0.0165, G_A_loss: 0.6730, G_B_loss: 0.1076\n",
      "Epoch [102/200], Step [11/1067], D_A_loss: 0.0874, D_B_loss: 0.0208, G_A_loss: 1.0029, G_B_loss: 0.3849\n",
      "Epoch [102/200], Step [21/1067], D_A_loss: 0.0422, D_B_loss: 0.0389, G_A_loss: 0.7659, G_B_loss: 0.3710\n",
      "Epoch [102/200], Step [31/1067], D_A_loss: 0.2387, D_B_loss: 0.0188, G_A_loss: 0.6385, G_B_loss: 0.7829\n",
      "Epoch [102/200], Step [41/1067], D_A_loss: 0.1364, D_B_loss: 0.0290, G_A_loss: 0.9299, G_B_loss: 0.4091\n",
      "Epoch [102/200], Step [51/1067], D_A_loss: 0.0998, D_B_loss: 0.0228, G_A_loss: 0.9127, G_B_loss: 0.4204\n",
      "Epoch [102/200], Step [61/1067], D_A_loss: 0.2171, D_B_loss: 0.0197, G_A_loss: 0.8091, G_B_loss: 0.4233\n",
      "Epoch [102/200], Step [71/1067], D_A_loss: 0.1058, D_B_loss: 0.0468, G_A_loss: 0.8759, G_B_loss: 0.5389\n",
      "Epoch [102/200], Step [81/1067], D_A_loss: 0.0759, D_B_loss: 0.0138, G_A_loss: 0.8570, G_B_loss: 0.5550\n",
      "Epoch [102/200], Step [91/1067], D_A_loss: 0.1075, D_B_loss: 0.1226, G_A_loss: 0.9355, G_B_loss: 0.3932\n",
      "Epoch [102/200], Step [101/1067], D_A_loss: 0.0270, D_B_loss: 0.0120, G_A_loss: 1.0577, G_B_loss: 0.3628\n",
      "Epoch [102/200], Step [111/1067], D_A_loss: 0.0563, D_B_loss: 0.0218, G_A_loss: 0.8656, G_B_loss: 0.5247\n",
      "Epoch [102/200], Step [121/1067], D_A_loss: 0.1156, D_B_loss: 0.0485, G_A_loss: 0.7842, G_B_loss: 0.5299\n",
      "Epoch [102/200], Step [131/1067], D_A_loss: 0.1466, D_B_loss: 0.0171, G_A_loss: 0.8371, G_B_loss: 0.5508\n",
      "Epoch [102/200], Step [141/1067], D_A_loss: 0.0547, D_B_loss: 0.0389, G_A_loss: 0.6555, G_B_loss: 0.7569\n",
      "Epoch [102/200], Step [151/1067], D_A_loss: 0.0914, D_B_loss: 0.0389, G_A_loss: 0.8885, G_B_loss: 0.6787\n",
      "Epoch [102/200], Step [161/1067], D_A_loss: 0.0643, D_B_loss: 0.0454, G_A_loss: 0.8391, G_B_loss: 0.5971\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [102/200], Step [171/1067], D_A_loss: 0.0292, D_B_loss: 0.0168, G_A_loss: 0.9607, G_B_loss: 0.5355\n",
      "Epoch [102/200], Step [181/1067], D_A_loss: 0.1552, D_B_loss: 0.0402, G_A_loss: 0.7318, G_B_loss: 0.3378\n",
      "Epoch [102/200], Step [191/1067], D_A_loss: 0.1886, D_B_loss: 0.1947, G_A_loss: 1.1871, G_B_loss: 0.5057\n",
      "Epoch [102/200], Step [201/1067], D_A_loss: 0.0292, D_B_loss: 0.0123, G_A_loss: 0.9220, G_B_loss: 0.2603\n",
      "Epoch [102/200], Step [211/1067], D_A_loss: 0.1636, D_B_loss: 0.0333, G_A_loss: 1.0186, G_B_loss: 0.8008\n",
      "Epoch [102/200], Step [221/1067], D_A_loss: 0.0547, D_B_loss: 0.0524, G_A_loss: 0.8124, G_B_loss: 0.7741\n",
      "Epoch [102/200], Step [231/1067], D_A_loss: 0.0470, D_B_loss: 0.0319, G_A_loss: 0.7341, G_B_loss: 0.1587\n",
      "Epoch [102/200], Step [241/1067], D_A_loss: 0.0940, D_B_loss: 0.1069, G_A_loss: 0.3691, G_B_loss: 0.5215\n",
      "Epoch [102/200], Step [251/1067], D_A_loss: 0.0509, D_B_loss: 0.0210, G_A_loss: 0.8772, G_B_loss: 0.7669\n",
      "Epoch [102/200], Step [261/1067], D_A_loss: 0.0808, D_B_loss: 0.0114, G_A_loss: 0.8778, G_B_loss: 0.5486\n",
      "Epoch [102/200], Step [271/1067], D_A_loss: 0.0937, D_B_loss: 0.0150, G_A_loss: 1.0260, G_B_loss: 0.4904\n",
      "Epoch [102/200], Step [281/1067], D_A_loss: 0.0269, D_B_loss: 0.0478, G_A_loss: 0.6608, G_B_loss: 0.9324\n",
      "Epoch [102/200], Step [291/1067], D_A_loss: 0.0651, D_B_loss: 0.0188, G_A_loss: 0.7325, G_B_loss: 0.3632\n",
      "Epoch [102/200], Step [301/1067], D_A_loss: 0.0690, D_B_loss: 0.0154, G_A_loss: 1.0697, G_B_loss: 0.4951\n",
      "Epoch [102/200], Step [311/1067], D_A_loss: 0.1139, D_B_loss: 0.0440, G_A_loss: 1.0096, G_B_loss: 0.3632\n",
      "Epoch [102/200], Step [321/1067], D_A_loss: 0.0281, D_B_loss: 0.0190, G_A_loss: 0.8006, G_B_loss: 0.7855\n",
      "Epoch [102/200], Step [331/1067], D_A_loss: 0.2795, D_B_loss: 0.0156, G_A_loss: 0.8816, G_B_loss: 0.1062\n",
      "Epoch [102/200], Step [341/1067], D_A_loss: 0.1127, D_B_loss: 0.0145, G_A_loss: 0.7990, G_B_loss: 0.3546\n",
      "Epoch [102/200], Step [351/1067], D_A_loss: 0.0551, D_B_loss: 0.0455, G_A_loss: 0.5558, G_B_loss: 0.5250\n",
      "Epoch [102/200], Step [361/1067], D_A_loss: 0.1467, D_B_loss: 0.0159, G_A_loss: 1.0867, G_B_loss: 0.2790\n",
      "Epoch [102/200], Step [371/1067], D_A_loss: 0.2738, D_B_loss: 0.0348, G_A_loss: 0.6375, G_B_loss: 0.1986\n",
      "Epoch [102/200], Step [381/1067], D_A_loss: 0.0520, D_B_loss: 0.0971, G_A_loss: 0.9753, G_B_loss: 0.8667\n",
      "Epoch [102/200], Step [391/1067], D_A_loss: 0.0790, D_B_loss: 0.0264, G_A_loss: 0.9945, G_B_loss: 0.2662\n",
      "Epoch [102/200], Step [401/1067], D_A_loss: 0.0666, D_B_loss: 0.0240, G_A_loss: 0.9551, G_B_loss: 0.5355\n",
      "Epoch [102/200], Step [411/1067], D_A_loss: 0.2218, D_B_loss: 0.0481, G_A_loss: 1.0571, G_B_loss: 0.4562\n",
      "Epoch [102/200], Step [421/1067], D_A_loss: 0.0958, D_B_loss: 0.0783, G_A_loss: 0.4202, G_B_loss: 0.5050\n",
      "Epoch [102/200], Step [431/1067], D_A_loss: 0.0460, D_B_loss: 0.0314, G_A_loss: 1.0162, G_B_loss: 0.5743\n",
      "Epoch [102/200], Step [441/1067], D_A_loss: 0.2625, D_B_loss: 0.0270, G_A_loss: 0.8597, G_B_loss: 0.6781\n",
      "Epoch [102/200], Step [451/1067], D_A_loss: 0.0920, D_B_loss: 0.0179, G_A_loss: 0.8794, G_B_loss: 0.6408\n",
      "Epoch [102/200], Step [461/1067], D_A_loss: 0.2343, D_B_loss: 0.0176, G_A_loss: 1.1035, G_B_loss: 0.2907\n",
      "Epoch [102/200], Step [471/1067], D_A_loss: 0.0548, D_B_loss: 0.0148, G_A_loss: 0.8183, G_B_loss: 0.4721\n",
      "Epoch [102/200], Step [481/1067], D_A_loss: 0.0337, D_B_loss: 0.0156, G_A_loss: 0.9352, G_B_loss: 0.9460\n",
      "Epoch [102/200], Step [491/1067], D_A_loss: 0.1811, D_B_loss: 0.1149, G_A_loss: 0.3302, G_B_loss: 0.2213\n",
      "Epoch [102/200], Step [501/1067], D_A_loss: 0.1290, D_B_loss: 0.0112, G_A_loss: 1.0324, G_B_loss: 0.6021\n",
      "Epoch [102/200], Step [511/1067], D_A_loss: 0.1356, D_B_loss: 0.0245, G_A_loss: 1.1048, G_B_loss: 0.3546\n",
      "Epoch [102/200], Step [521/1067], D_A_loss: 0.0548, D_B_loss: 0.0266, G_A_loss: 1.0698, G_B_loss: 0.3390\n",
      "Epoch [102/200], Step [531/1067], D_A_loss: 0.1004, D_B_loss: 0.0209, G_A_loss: 0.8653, G_B_loss: 1.0922\n",
      "Epoch [102/200], Step [541/1067], D_A_loss: 0.1016, D_B_loss: 0.0591, G_A_loss: 0.4997, G_B_loss: 0.7313\n",
      "Epoch [102/200], Step [551/1067], D_A_loss: 0.1498, D_B_loss: 0.0832, G_A_loss: 0.3760, G_B_loss: 0.7321\n",
      "Epoch [102/200], Step [561/1067], D_A_loss: 0.0590, D_B_loss: 0.0723, G_A_loss: 0.4884, G_B_loss: 0.5933\n",
      "Epoch [102/200], Step [571/1067], D_A_loss: 0.1358, D_B_loss: 0.0441, G_A_loss: 0.5889, G_B_loss: 0.3003\n",
      "Epoch [102/200], Step [581/1067], D_A_loss: 0.0505, D_B_loss: 0.0160, G_A_loss: 0.8412, G_B_loss: 0.7746\n",
      "Epoch [102/200], Step [591/1067], D_A_loss: 0.0950, D_B_loss: 0.0120, G_A_loss: 0.9935, G_B_loss: 0.4064\n",
      "Epoch [102/200], Step [601/1067], D_A_loss: 0.2723, D_B_loss: 0.0580, G_A_loss: 0.6199, G_B_loss: 0.0647\n",
      "Epoch [102/200], Step [611/1067], D_A_loss: 0.0828, D_B_loss: 0.0248, G_A_loss: 1.1959, G_B_loss: 0.7052\n",
      "Epoch [102/200], Step [621/1067], D_A_loss: 0.1730, D_B_loss: 0.0243, G_A_loss: 0.6468, G_B_loss: 0.8492\n",
      "Epoch [102/200], Step [631/1067], D_A_loss: 0.0580, D_B_loss: 0.0340, G_A_loss: 0.7138, G_B_loss: 0.2897\n",
      "Epoch [102/200], Step [641/1067], D_A_loss: 0.1154, D_B_loss: 0.0305, G_A_loss: 1.4429, G_B_loss: 0.3244\n",
      "Epoch [102/200], Step [651/1067], D_A_loss: 0.0694, D_B_loss: 0.0123, G_A_loss: 0.8864, G_B_loss: 0.4376\n",
      "Epoch [102/200], Step [661/1067], D_A_loss: 0.2278, D_B_loss: 0.0080, G_A_loss: 0.9932, G_B_loss: 0.1749\n",
      "Epoch [102/200], Step [671/1067], D_A_loss: 0.1447, D_B_loss: 0.0318, G_A_loss: 0.5759, G_B_loss: 0.9337\n",
      "Epoch [102/200], Step [681/1067], D_A_loss: 0.1140, D_B_loss: 0.0161, G_A_loss: 0.9605, G_B_loss: 0.5104\n",
      "Epoch [102/200], Step [691/1067], D_A_loss: 0.0578, D_B_loss: 0.0173, G_A_loss: 0.9311, G_B_loss: 0.7139\n",
      "Epoch [102/200], Step [701/1067], D_A_loss: 0.1856, D_B_loss: 0.0214, G_A_loss: 0.6890, G_B_loss: 0.2440\n",
      "Epoch [102/200], Step [711/1067], D_A_loss: 0.0863, D_B_loss: 0.0080, G_A_loss: 1.3810, G_B_loss: 0.7231\n",
      "Epoch [102/200], Step [721/1067], D_A_loss: 0.0409, D_B_loss: 0.0380, G_A_loss: 0.8956, G_B_loss: 0.3858\n",
      "Epoch [102/200], Step [731/1067], D_A_loss: 0.1629, D_B_loss: 0.0162, G_A_loss: 0.9099, G_B_loss: 0.2748\n",
      "Epoch [102/200], Step [741/1067], D_A_loss: 0.0555, D_B_loss: 0.0138, G_A_loss: 0.6489, G_B_loss: 0.4364\n",
      "Epoch [102/200], Step [751/1067], D_A_loss: 0.0465, D_B_loss: 0.0222, G_A_loss: 0.7433, G_B_loss: 0.5714\n",
      "Epoch [102/200], Step [761/1067], D_A_loss: 0.1715, D_B_loss: 0.0272, G_A_loss: 0.7849, G_B_loss: 0.6744\n",
      "Epoch [102/200], Step [771/1067], D_A_loss: 0.1958, D_B_loss: 0.0117, G_A_loss: 0.8838, G_B_loss: 1.0788\n",
      "Epoch [102/200], Step [781/1067], D_A_loss: 0.1495, D_B_loss: 0.0323, G_A_loss: 0.7004, G_B_loss: 0.7134\n",
      "Epoch [102/200], Step [791/1067], D_A_loss: 0.0694, D_B_loss: 0.0355, G_A_loss: 0.9326, G_B_loss: 0.4453\n",
      "Epoch [102/200], Step [801/1067], D_A_loss: 0.2117, D_B_loss: 0.0086, G_A_loss: 0.9577, G_B_loss: 0.7291\n",
      "Epoch [102/200], Step [811/1067], D_A_loss: 0.0776, D_B_loss: 0.0156, G_A_loss: 0.6111, G_B_loss: 0.5833\n",
      "Epoch [102/200], Step [821/1067], D_A_loss: 0.2242, D_B_loss: 0.0377, G_A_loss: 1.3554, G_B_loss: 0.1775\n",
      "Epoch [102/200], Step [831/1067], D_A_loss: 0.0799, D_B_loss: 0.0522, G_A_loss: 1.0857, G_B_loss: 0.6067\n",
      "Epoch [102/200], Step [841/1067], D_A_loss: 0.0467, D_B_loss: 0.0144, G_A_loss: 1.0791, G_B_loss: 0.3355\n",
      "Epoch [102/200], Step [851/1067], D_A_loss: 0.0481, D_B_loss: 0.0387, G_A_loss: 1.0212, G_B_loss: 0.2439\n",
      "Epoch [102/200], Step [861/1067], D_A_loss: 0.2939, D_B_loss: 0.0153, G_A_loss: 0.8872, G_B_loss: 0.3292\n",
      "Epoch [102/200], Step [871/1067], D_A_loss: 0.0344, D_B_loss: 0.0112, G_A_loss: 0.9664, G_B_loss: 0.9677\n",
      "Epoch [102/200], Step [881/1067], D_A_loss: 0.2611, D_B_loss: 0.0159, G_A_loss: 0.9270, G_B_loss: 0.9058\n",
      "Epoch [102/200], Step [891/1067], D_A_loss: 0.1391, D_B_loss: 0.0121, G_A_loss: 0.9129, G_B_loss: 0.7376\n",
      "Epoch [102/200], Step [901/1067], D_A_loss: 0.2649, D_B_loss: 0.0666, G_A_loss: 0.7460, G_B_loss: 0.1443\n",
      "Epoch [102/200], Step [911/1067], D_A_loss: 0.1381, D_B_loss: 0.0329, G_A_loss: 0.7137, G_B_loss: 0.6680\n",
      "Epoch [102/200], Step [921/1067], D_A_loss: 0.0838, D_B_loss: 0.0297, G_A_loss: 0.7328, G_B_loss: 0.6486\n",
      "Epoch [102/200], Step [931/1067], D_A_loss: 0.1320, D_B_loss: 0.0162, G_A_loss: 0.7573, G_B_loss: 0.5552\n",
      "Epoch [102/200], Step [941/1067], D_A_loss: 0.1394, D_B_loss: 0.1553, G_A_loss: 0.9071, G_B_loss: 0.6589\n",
      "Epoch [102/200], Step [951/1067], D_A_loss: 0.0584, D_B_loss: 0.0324, G_A_loss: 0.7878, G_B_loss: 0.5674\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [102/200], Step [961/1067], D_A_loss: 0.0663, D_B_loss: 0.0333, G_A_loss: 0.7115, G_B_loss: 0.3935\n",
      "Epoch [102/200], Step [971/1067], D_A_loss: 0.0713, D_B_loss: 0.0156, G_A_loss: 0.6964, G_B_loss: 0.1296\n",
      "Epoch [102/200], Step [981/1067], D_A_loss: 0.2362, D_B_loss: 0.0235, G_A_loss: 1.0651, G_B_loss: 0.1680\n",
      "Epoch [102/200], Step [991/1067], D_A_loss: 0.1267, D_B_loss: 0.0199, G_A_loss: 0.5874, G_B_loss: 0.5330\n",
      "Epoch [102/200], Step [1001/1067], D_A_loss: 0.1467, D_B_loss: 0.0827, G_A_loss: 0.9141, G_B_loss: 0.2833\n",
      "Epoch [102/200], Step [1011/1067], D_A_loss: 0.1378, D_B_loss: 0.0183, G_A_loss: 1.0878, G_B_loss: 0.3167\n",
      "Epoch [102/200], Step [1021/1067], D_A_loss: 0.1331, D_B_loss: 0.0218, G_A_loss: 0.9133, G_B_loss: 1.1310\n",
      "Epoch [102/200], Step [1031/1067], D_A_loss: 0.1477, D_B_loss: 0.0278, G_A_loss: 0.7288, G_B_loss: 0.3519\n",
      "Epoch [102/200], Step [1041/1067], D_A_loss: 0.0293, D_B_loss: 0.0141, G_A_loss: 0.9208, G_B_loss: 0.7753\n",
      "Epoch [102/200], Step [1051/1067], D_A_loss: 0.1235, D_B_loss: 0.0200, G_A_loss: 0.4476, G_B_loss: 0.5318\n",
      "Epoch [102/200], Step [1061/1067], D_A_loss: 0.0217, D_B_loss: 0.0281, G_A_loss: 0.7297, G_B_loss: 0.6761\n",
      "Epoch [103/200], Step [1/1067], D_A_loss: 0.2425, D_B_loss: 0.0627, G_A_loss: 0.9542, G_B_loss: 0.5685\n",
      "Epoch [103/200], Step [11/1067], D_A_loss: 0.1879, D_B_loss: 0.0145, G_A_loss: 0.8562, G_B_loss: 0.6064\n",
      "Epoch [103/200], Step [21/1067], D_A_loss: 0.1124, D_B_loss: 0.0405, G_A_loss: 1.0704, G_B_loss: 0.6070\n",
      "Epoch [103/200], Step [31/1067], D_A_loss: 0.0742, D_B_loss: 0.1009, G_A_loss: 1.1361, G_B_loss: 0.4808\n",
      "Epoch [103/200], Step [41/1067], D_A_loss: 0.1031, D_B_loss: 0.0424, G_A_loss: 1.3066, G_B_loss: 0.4152\n",
      "Epoch [103/200], Step [51/1067], D_A_loss: 0.1351, D_B_loss: 0.0650, G_A_loss: 0.4338, G_B_loss: 0.3060\n",
      "Epoch [103/200], Step [61/1067], D_A_loss: 0.0558, D_B_loss: 0.0119, G_A_loss: 0.6410, G_B_loss: 0.3795\n",
      "Epoch [103/200], Step [71/1067], D_A_loss: 0.0365, D_B_loss: 0.0217, G_A_loss: 0.7969, G_B_loss: 0.2302\n",
      "Epoch [103/200], Step [81/1067], D_A_loss: 0.0512, D_B_loss: 0.0152, G_A_loss: 0.9470, G_B_loss: 0.2465\n",
      "Epoch [103/200], Step [91/1067], D_A_loss: 0.0477, D_B_loss: 0.0203, G_A_loss: 0.8071, G_B_loss: 0.3937\n",
      "Epoch [103/200], Step [101/1067], D_A_loss: 0.1120, D_B_loss: 0.0313, G_A_loss: 1.0540, G_B_loss: 0.4852\n",
      "Epoch [103/200], Step [111/1067], D_A_loss: 0.0458, D_B_loss: 0.0302, G_A_loss: 0.7819, G_B_loss: 0.5472\n",
      "Epoch [103/200], Step [121/1067], D_A_loss: 0.1652, D_B_loss: 0.0222, G_A_loss: 0.8412, G_B_loss: 0.6823\n",
      "Epoch [103/200], Step [131/1067], D_A_loss: 0.1502, D_B_loss: 0.0264, G_A_loss: 0.5887, G_B_loss: 0.3533\n",
      "Epoch [103/200], Step [141/1067], D_A_loss: 0.1522, D_B_loss: 0.0107, G_A_loss: 0.8858, G_B_loss: 0.3660\n",
      "Epoch [103/200], Step [151/1067], D_A_loss: 0.1180, D_B_loss: 0.0927, G_A_loss: 0.4412, G_B_loss: 0.6553\n",
      "Epoch [103/200], Step [161/1067], D_A_loss: 0.0321, D_B_loss: 0.0190, G_A_loss: 1.1191, G_B_loss: 0.9503\n",
      "Epoch [103/200], Step [171/1067], D_A_loss: 0.0949, D_B_loss: 0.0115, G_A_loss: 0.9295, G_B_loss: 0.4127\n",
      "Epoch [103/200], Step [181/1067], D_A_loss: 0.0577, D_B_loss: 0.0293, G_A_loss: 1.0150, G_B_loss: 0.6013\n",
      "Epoch [103/200], Step [191/1067], D_A_loss: 0.0796, D_B_loss: 0.0176, G_A_loss: 1.1905, G_B_loss: 0.5532\n",
      "Epoch [103/200], Step [201/1067], D_A_loss: 0.0852, D_B_loss: 0.0304, G_A_loss: 1.1648, G_B_loss: 0.5071\n",
      "Epoch [103/200], Step [211/1067], D_A_loss: 0.0529, D_B_loss: 0.0315, G_A_loss: 0.7052, G_B_loss: 1.0355\n",
      "Epoch [103/200], Step [221/1067], D_A_loss: 0.0596, D_B_loss: 0.0327, G_A_loss: 0.4963, G_B_loss: 0.7790\n",
      "Epoch [103/200], Step [231/1067], D_A_loss: 0.0854, D_B_loss: 0.0378, G_A_loss: 0.7038, G_B_loss: 0.4144\n",
      "Epoch [103/200], Step [241/1067], D_A_loss: 0.0480, D_B_loss: 0.0803, G_A_loss: 0.6199, G_B_loss: 0.6608\n",
      "Epoch [103/200], Step [251/1067], D_A_loss: 0.0702, D_B_loss: 0.0079, G_A_loss: 0.6854, G_B_loss: 0.6997\n",
      "Epoch [103/200], Step [261/1067], D_A_loss: 0.0650, D_B_loss: 0.0279, G_A_loss: 0.6795, G_B_loss: 0.6509\n",
      "Epoch [103/200], Step [271/1067], D_A_loss: 0.0501, D_B_loss: 0.0216, G_A_loss: 0.7340, G_B_loss: 0.6755\n",
      "Epoch [103/200], Step [281/1067], D_A_loss: 0.0289, D_B_loss: 0.0311, G_A_loss: 0.6880, G_B_loss: 0.5250\n",
      "Epoch [103/200], Step [291/1067], D_A_loss: 0.0278, D_B_loss: 0.0285, G_A_loss: 0.6509, G_B_loss: 0.3461\n",
      "Epoch [103/200], Step [301/1067], D_A_loss: 0.1074, D_B_loss: 0.1635, G_A_loss: 0.8831, G_B_loss: 0.3421\n",
      "Epoch [103/200], Step [311/1067], D_A_loss: 0.2098, D_B_loss: 0.0335, G_A_loss: 0.7836, G_B_loss: 0.2655\n",
      "Epoch [103/200], Step [321/1067], D_A_loss: 0.0695, D_B_loss: 0.0200, G_A_loss: 1.0626, G_B_loss: 0.5283\n",
      "Epoch [103/200], Step [331/1067], D_A_loss: 0.0456, D_B_loss: 0.0100, G_A_loss: 1.0298, G_B_loss: 0.7844\n",
      "Epoch [103/200], Step [341/1067], D_A_loss: 0.0595, D_B_loss: 0.0706, G_A_loss: 0.8270, G_B_loss: 0.3820\n",
      "Epoch [103/200], Step [351/1067], D_A_loss: 0.1920, D_B_loss: 0.0443, G_A_loss: 0.7527, G_B_loss: 0.4919\n",
      "Epoch [103/200], Step [361/1067], D_A_loss: 0.1154, D_B_loss: 0.0251, G_A_loss: 0.7488, G_B_loss: 0.3545\n",
      "Epoch [103/200], Step [371/1067], D_A_loss: 0.0247, D_B_loss: 0.0267, G_A_loss: 0.6528, G_B_loss: 0.6167\n",
      "Epoch [103/200], Step [381/1067], D_A_loss: 0.1954, D_B_loss: 0.0208, G_A_loss: 0.8121, G_B_loss: 1.0360\n",
      "Epoch [103/200], Step [391/1067], D_A_loss: 0.1647, D_B_loss: 0.1161, G_A_loss: 1.3583, G_B_loss: 0.2331\n",
      "Epoch [103/200], Step [401/1067], D_A_loss: 0.0627, D_B_loss: 0.0227, G_A_loss: 0.5611, G_B_loss: 0.3511\n",
      "Epoch [103/200], Step [411/1067], D_A_loss: 0.1393, D_B_loss: 0.0995, G_A_loss: 0.3903, G_B_loss: 0.6776\n",
      "Epoch [103/200], Step [421/1067], D_A_loss: 0.1411, D_B_loss: 0.0202, G_A_loss: 0.6478, G_B_loss: 0.6671\n",
      "Epoch [103/200], Step [431/1067], D_A_loss: 0.0605, D_B_loss: 0.0145, G_A_loss: 0.8179, G_B_loss: 0.4146\n",
      "Epoch [103/200], Step [441/1067], D_A_loss: 0.0508, D_B_loss: 0.0117, G_A_loss: 0.6305, G_B_loss: 0.3486\n",
      "Epoch [103/200], Step [451/1067], D_A_loss: 0.0913, D_B_loss: 0.0612, G_A_loss: 1.0455, G_B_loss: 0.4088\n",
      "Epoch [103/200], Step [461/1067], D_A_loss: 0.0872, D_B_loss: 0.0513, G_A_loss: 1.0484, G_B_loss: 0.4758\n",
      "Epoch [103/200], Step [471/1067], D_A_loss: 0.1106, D_B_loss: 0.0484, G_A_loss: 0.5780, G_B_loss: 0.4242\n",
      "Epoch [103/200], Step [481/1067], D_A_loss: 0.1644, D_B_loss: 0.0283, G_A_loss: 0.7012, G_B_loss: 0.2863\n",
      "Epoch [103/200], Step [491/1067], D_A_loss: 0.0767, D_B_loss: 0.0465, G_A_loss: 0.5642, G_B_loss: 0.4533\n",
      "Epoch [103/200], Step [501/1067], D_A_loss: 0.1077, D_B_loss: 0.0493, G_A_loss: 1.1386, G_B_loss: 0.2755\n",
      "Epoch [103/200], Step [511/1067], D_A_loss: 0.1335, D_B_loss: 0.0228, G_A_loss: 0.5826, G_B_loss: 0.3615\n",
      "Epoch [103/200], Step [521/1067], D_A_loss: 0.0817, D_B_loss: 0.0833, G_A_loss: 1.1600, G_B_loss: 0.4548\n",
      "Epoch [103/200], Step [531/1067], D_A_loss: 0.0734, D_B_loss: 0.0138, G_A_loss: 0.8096, G_B_loss: 0.4824\n",
      "Epoch [103/200], Step [541/1067], D_A_loss: 0.0926, D_B_loss: 0.0241, G_A_loss: 0.7515, G_B_loss: 0.6741\n",
      "Epoch [103/200], Step [551/1067], D_A_loss: 0.0835, D_B_loss: 0.0438, G_A_loss: 0.6212, G_B_loss: 0.8121\n",
      "Epoch [103/200], Step [561/1067], D_A_loss: 0.1081, D_B_loss: 0.0273, G_A_loss: 0.7329, G_B_loss: 0.5016\n",
      "Epoch [103/200], Step [571/1067], D_A_loss: 0.1757, D_B_loss: 0.0375, G_A_loss: 1.0507, G_B_loss: 0.7483\n",
      "Epoch [103/200], Step [581/1067], D_A_loss: 0.0654, D_B_loss: 0.0279, G_A_loss: 0.5504, G_B_loss: 0.4970\n",
      "Epoch [103/200], Step [591/1067], D_A_loss: 0.0445, D_B_loss: 0.0308, G_A_loss: 1.2048, G_B_loss: 0.5561\n",
      "Epoch [103/200], Step [601/1067], D_A_loss: 0.0773, D_B_loss: 0.0829, G_A_loss: 0.4756, G_B_loss: 0.3336\n",
      "Epoch [103/200], Step [611/1067], D_A_loss: 0.0724, D_B_loss: 0.0261, G_A_loss: 0.4893, G_B_loss: 0.5653\n",
      "Epoch [103/200], Step [621/1067], D_A_loss: 0.0963, D_B_loss: 0.0443, G_A_loss: 0.4402, G_B_loss: 0.8937\n",
      "Epoch [103/200], Step [631/1067], D_A_loss: 0.1150, D_B_loss: 0.0139, G_A_loss: 0.8351, G_B_loss: 0.6616\n",
      "Epoch [103/200], Step [641/1067], D_A_loss: 0.1453, D_B_loss: 0.0133, G_A_loss: 0.6935, G_B_loss: 0.3606\n",
      "Epoch [103/200], Step [651/1067], D_A_loss: 0.0599, D_B_loss: 0.0248, G_A_loss: 1.1118, G_B_loss: 0.6029\n",
      "Epoch [103/200], Step [661/1067], D_A_loss: 0.0419, D_B_loss: 0.0291, G_A_loss: 0.6788, G_B_loss: 0.4803\n",
      "Epoch [103/200], Step [671/1067], D_A_loss: 0.1476, D_B_loss: 0.0585, G_A_loss: 0.8424, G_B_loss: 0.3107\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [103/200], Step [681/1067], D_A_loss: 0.0798, D_B_loss: 0.0155, G_A_loss: 0.9192, G_B_loss: 0.4854\n",
      "Epoch [103/200], Step [691/1067], D_A_loss: 0.4707, D_B_loss: 0.0178, G_A_loss: 1.0549, G_B_loss: 0.9066\n",
      "Epoch [103/200], Step [701/1067], D_A_loss: 0.0492, D_B_loss: 0.1525, G_A_loss: 0.9741, G_B_loss: 0.6348\n",
      "Epoch [103/200], Step [711/1067], D_A_loss: 0.1380, D_B_loss: 0.0134, G_A_loss: 0.8520, G_B_loss: 0.3482\n",
      "Epoch [103/200], Step [721/1067], D_A_loss: 0.1781, D_B_loss: 0.0097, G_A_loss: 0.8999, G_B_loss: 0.4359\n",
      "Epoch [103/200], Step [731/1067], D_A_loss: 0.0607, D_B_loss: 0.0187, G_A_loss: 0.7811, G_B_loss: 1.0838\n",
      "Epoch [103/200], Step [741/1067], D_A_loss: 0.0464, D_B_loss: 0.0326, G_A_loss: 0.7828, G_B_loss: 0.6625\n",
      "Epoch [103/200], Step [751/1067], D_A_loss: 0.1853, D_B_loss: 0.1103, G_A_loss: 1.1083, G_B_loss: 0.1223\n",
      "Epoch [103/200], Step [761/1067], D_A_loss: 0.0960, D_B_loss: 0.0278, G_A_loss: 0.6440, G_B_loss: 0.3916\n",
      "Epoch [103/200], Step [771/1067], D_A_loss: 0.0809, D_B_loss: 0.0095, G_A_loss: 0.9788, G_B_loss: 0.4471\n",
      "Epoch [103/200], Step [781/1067], D_A_loss: 0.1223, D_B_loss: 0.0428, G_A_loss: 1.2081, G_B_loss: 0.5101\n",
      "Epoch [103/200], Step [791/1067], D_A_loss: 0.1052, D_B_loss: 0.0365, G_A_loss: 0.5727, G_B_loss: 0.4075\n",
      "Epoch [103/200], Step [801/1067], D_A_loss: 0.0997, D_B_loss: 0.0192, G_A_loss: 0.7010, G_B_loss: 0.7008\n",
      "Epoch [103/200], Step [811/1067], D_A_loss: 0.1325, D_B_loss: 0.0429, G_A_loss: 1.1241, G_B_loss: 0.3552\n",
      "Epoch [103/200], Step [821/1067], D_A_loss: 0.0636, D_B_loss: 0.0235, G_A_loss: 1.0912, G_B_loss: 0.7867\n",
      "Epoch [103/200], Step [831/1067], D_A_loss: 0.0822, D_B_loss: 0.0409, G_A_loss: 0.5367, G_B_loss: 0.4380\n",
      "Epoch [103/200], Step [841/1067], D_A_loss: 0.0631, D_B_loss: 0.0330, G_A_loss: 0.8249, G_B_loss: 0.6043\n",
      "Epoch [103/200], Step [851/1067], D_A_loss: 0.0367, D_B_loss: 0.0204, G_A_loss: 0.9618, G_B_loss: 0.8150\n",
      "Epoch [103/200], Step [861/1067], D_A_loss: 0.0751, D_B_loss: 0.0655, G_A_loss: 0.5036, G_B_loss: 0.9990\n",
      "Epoch [103/200], Step [871/1067], D_A_loss: 0.2010, D_B_loss: 0.0308, G_A_loss: 1.1733, G_B_loss: 0.2155\n",
      "Epoch [103/200], Step [881/1067], D_A_loss: 0.0701, D_B_loss: 0.0325, G_A_loss: 0.7032, G_B_loss: 0.5244\n",
      "Epoch [103/200], Step [891/1067], D_A_loss: 0.1251, D_B_loss: 0.0384, G_A_loss: 0.6641, G_B_loss: 0.4688\n",
      "Epoch [103/200], Step [901/1067], D_A_loss: 0.0333, D_B_loss: 0.0295, G_A_loss: 0.6931, G_B_loss: 0.4837\n",
      "Epoch [103/200], Step [911/1067], D_A_loss: 0.0333, D_B_loss: 0.0435, G_A_loss: 0.5588, G_B_loss: 1.2043\n",
      "Epoch [103/200], Step [921/1067], D_A_loss: 0.0329, D_B_loss: 0.0224, G_A_loss: 0.7264, G_B_loss: 0.3025\n",
      "Epoch [103/200], Step [931/1067], D_A_loss: 0.1657, D_B_loss: 0.0121, G_A_loss: 1.0605, G_B_loss: 0.5039\n",
      "Epoch [103/200], Step [941/1067], D_A_loss: 0.0954, D_B_loss: 0.0726, G_A_loss: 0.6970, G_B_loss: 0.6341\n",
      "Epoch [103/200], Step [951/1067], D_A_loss: 0.0957, D_B_loss: 0.0306, G_A_loss: 0.7358, G_B_loss: 0.4241\n",
      "Epoch [103/200], Step [961/1067], D_A_loss: 0.0422, D_B_loss: 0.0200, G_A_loss: 0.8509, G_B_loss: 0.7169\n",
      "Epoch [103/200], Step [971/1067], D_A_loss: 0.0800, D_B_loss: 0.0275, G_A_loss: 1.0492, G_B_loss: 0.5937\n",
      "Epoch [103/200], Step [981/1067], D_A_loss: 0.0928, D_B_loss: 0.0114, G_A_loss: 1.0495, G_B_loss: 0.4272\n",
      "Epoch [103/200], Step [991/1067], D_A_loss: 0.0919, D_B_loss: 0.0102, G_A_loss: 0.7226, G_B_loss: 0.5568\n",
      "Epoch [103/200], Step [1001/1067], D_A_loss: 0.0605, D_B_loss: 0.0202, G_A_loss: 1.2786, G_B_loss: 0.5441\n",
      "Epoch [103/200], Step [1011/1067], D_A_loss: 0.0909, D_B_loss: 0.0168, G_A_loss: 0.8996, G_B_loss: 0.4981\n",
      "Epoch [103/200], Step [1021/1067], D_A_loss: 0.1275, D_B_loss: 0.0578, G_A_loss: 1.0593, G_B_loss: 0.4196\n",
      "Epoch [103/200], Step [1031/1067], D_A_loss: 0.0329, D_B_loss: 0.0540, G_A_loss: 0.5408, G_B_loss: 0.3817\n",
      "Epoch [103/200], Step [1041/1067], D_A_loss: 0.1946, D_B_loss: 0.0394, G_A_loss: 0.6800, G_B_loss: 0.2872\n",
      "Epoch [103/200], Step [1051/1067], D_A_loss: 0.0554, D_B_loss: 0.0217, G_A_loss: 0.8293, G_B_loss: 0.6895\n",
      "Epoch [103/200], Step [1061/1067], D_A_loss: 0.0547, D_B_loss: 0.0158, G_A_loss: 0.8440, G_B_loss: 0.4275\n",
      "Epoch [104/200], Step [1/1067], D_A_loss: 0.0277, D_B_loss: 0.0399, G_A_loss: 0.6062, G_B_loss: 0.8271\n",
      "Epoch [104/200], Step [11/1067], D_A_loss: 0.0476, D_B_loss: 0.0250, G_A_loss: 0.6926, G_B_loss: 0.1434\n",
      "Epoch [104/200], Step [21/1067], D_A_loss: 0.0457, D_B_loss: 0.0104, G_A_loss: 1.1048, G_B_loss: 0.6165\n",
      "Epoch [104/200], Step [31/1067], D_A_loss: 0.0619, D_B_loss: 0.0304, G_A_loss: 0.7702, G_B_loss: 0.5334\n",
      "Epoch [104/200], Step [41/1067], D_A_loss: 0.0997, D_B_loss: 0.0248, G_A_loss: 0.7977, G_B_loss: 0.4535\n",
      "Epoch [104/200], Step [51/1067], D_A_loss: 0.0520, D_B_loss: 0.0322, G_A_loss: 0.8540, G_B_loss: 0.8311\n",
      "Epoch [104/200], Step [61/1067], D_A_loss: 0.0666, D_B_loss: 0.0512, G_A_loss: 1.0737, G_B_loss: 0.4144\n",
      "Epoch [104/200], Step [71/1067], D_A_loss: 0.0458, D_B_loss: 0.0218, G_A_loss: 0.8601, G_B_loss: 0.3505\n",
      "Epoch [104/200], Step [81/1067], D_A_loss: 0.0669, D_B_loss: 0.0453, G_A_loss: 1.1558, G_B_loss: 0.6533\n",
      "Epoch [104/200], Step [91/1067], D_A_loss: 0.0931, D_B_loss: 0.0225, G_A_loss: 0.7959, G_B_loss: 0.4830\n",
      "Epoch [104/200], Step [101/1067], D_A_loss: 0.0863, D_B_loss: 0.0275, G_A_loss: 0.7802, G_B_loss: 0.5737\n",
      "Epoch [104/200], Step [111/1067], D_A_loss: 0.0249, D_B_loss: 0.0505, G_A_loss: 0.6017, G_B_loss: 0.4646\n",
      "Epoch [104/200], Step [121/1067], D_A_loss: 0.1769, D_B_loss: 0.0202, G_A_loss: 0.8238, G_B_loss: 0.2509\n",
      "Epoch [104/200], Step [131/1067], D_A_loss: 0.0847, D_B_loss: 0.0157, G_A_loss: 1.0472, G_B_loss: 0.5343\n",
      "Epoch [104/200], Step [141/1067], D_A_loss: 0.0901, D_B_loss: 0.0171, G_A_loss: 0.7618, G_B_loss: 0.5333\n",
      "Epoch [104/200], Step [151/1067], D_A_loss: 0.0370, D_B_loss: 0.0092, G_A_loss: 1.1028, G_B_loss: 0.3794\n",
      "Epoch [104/200], Step [161/1067], D_A_loss: 0.1275, D_B_loss: 0.0398, G_A_loss: 0.6199, G_B_loss: 0.4279\n",
      "Epoch [104/200], Step [171/1067], D_A_loss: 0.1832, D_B_loss: 0.0731, G_A_loss: 0.4623, G_B_loss: 0.7681\n",
      "Epoch [104/200], Step [181/1067], D_A_loss: 0.2142, D_B_loss: 0.0203, G_A_loss: 0.8393, G_B_loss: 0.4634\n",
      "Epoch [104/200], Step [191/1067], D_A_loss: 0.0815, D_B_loss: 0.1212, G_A_loss: 0.6463, G_B_loss: 0.7706\n",
      "Epoch [104/200], Step [201/1067], D_A_loss: 0.0854, D_B_loss: 0.0148, G_A_loss: 0.9262, G_B_loss: 0.4478\n",
      "Epoch [104/200], Step [211/1067], D_A_loss: 0.0811, D_B_loss: 0.0410, G_A_loss: 0.9484, G_B_loss: 0.4904\n",
      "Epoch [104/200], Step [221/1067], D_A_loss: 0.1896, D_B_loss: 0.0590, G_A_loss: 0.5908, G_B_loss: 0.2161\n",
      "Epoch [104/200], Step [231/1067], D_A_loss: 0.1290, D_B_loss: 0.0086, G_A_loss: 0.9783, G_B_loss: 0.3158\n",
      "Epoch [104/200], Step [241/1067], D_A_loss: 0.0885, D_B_loss: 0.0206, G_A_loss: 0.9274, G_B_loss: 0.2363\n",
      "Epoch [104/200], Step [251/1067], D_A_loss: 0.1684, D_B_loss: 0.0554, G_A_loss: 0.7771, G_B_loss: 0.3483\n",
      "Epoch [104/200], Step [261/1067], D_A_loss: 0.0463, D_B_loss: 0.0545, G_A_loss: 0.5895, G_B_loss: 0.6551\n",
      "Epoch [104/200], Step [271/1067], D_A_loss: 0.0426, D_B_loss: 0.0247, G_A_loss: 0.6267, G_B_loss: 0.7416\n",
      "Epoch [104/200], Step [281/1067], D_A_loss: 0.0280, D_B_loss: 0.0119, G_A_loss: 0.7461, G_B_loss: 0.7193\n",
      "Epoch [104/200], Step [291/1067], D_A_loss: 0.0360, D_B_loss: 0.0206, G_A_loss: 0.7550, G_B_loss: 1.0599\n",
      "Epoch [104/200], Step [301/1067], D_A_loss: 0.1367, D_B_loss: 0.0214, G_A_loss: 0.9523, G_B_loss: 0.7022\n",
      "Epoch [104/200], Step [311/1067], D_A_loss: 0.0343, D_B_loss: 0.0310, G_A_loss: 0.5615, G_B_loss: 0.8152\n",
      "Epoch [104/200], Step [321/1067], D_A_loss: 0.0449, D_B_loss: 0.0323, G_A_loss: 0.7550, G_B_loss: 0.5850\n",
      "Epoch [104/200], Step [331/1067], D_A_loss: 0.2219, D_B_loss: 0.0318, G_A_loss: 0.6611, G_B_loss: 1.3736\n",
      "Epoch [104/200], Step [341/1067], D_A_loss: 0.1028, D_B_loss: 0.0225, G_A_loss: 0.6185, G_B_loss: 0.3459\n",
      "Epoch [104/200], Step [351/1067], D_A_loss: 0.0301, D_B_loss: 0.0342, G_A_loss: 0.5967, G_B_loss: 0.9252\n",
      "Epoch [104/200], Step [361/1067], D_A_loss: 0.0763, D_B_loss: 0.0255, G_A_loss: 0.6945, G_B_loss: 0.5708\n",
      "Epoch [104/200], Step [371/1067], D_A_loss: 0.1039, D_B_loss: 0.0227, G_A_loss: 0.7023, G_B_loss: 0.4406\n",
      "Epoch [104/200], Step [381/1067], D_A_loss: 0.1337, D_B_loss: 0.0495, G_A_loss: 0.9457, G_B_loss: 0.3238\n",
      "Epoch [104/200], Step [391/1067], D_A_loss: 0.0580, D_B_loss: 0.0303, G_A_loss: 0.6931, G_B_loss: 0.2182\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [104/200], Step [401/1067], D_A_loss: 0.0877, D_B_loss: 0.0106, G_A_loss: 0.9245, G_B_loss: 0.4355\n",
      "Epoch [104/200], Step [411/1067], D_A_loss: 0.0715, D_B_loss: 0.0712, G_A_loss: 0.8830, G_B_loss: 1.0893\n",
      "Epoch [104/200], Step [421/1067], D_A_loss: 0.0856, D_B_loss: 0.0269, G_A_loss: 0.6893, G_B_loss: 0.4761\n",
      "Epoch [104/200], Step [431/1067], D_A_loss: 0.0599, D_B_loss: 0.0165, G_A_loss: 0.7035, G_B_loss: 0.7662\n",
      "Epoch [104/200], Step [441/1067], D_A_loss: 0.0367, D_B_loss: 0.0400, G_A_loss: 1.0353, G_B_loss: 0.4293\n",
      "Epoch [104/200], Step [451/1067], D_A_loss: 0.2228, D_B_loss: 0.0332, G_A_loss: 1.1898, G_B_loss: 0.2563\n",
      "Epoch [104/200], Step [461/1067], D_A_loss: 0.0372, D_B_loss: 0.0180, G_A_loss: 0.8700, G_B_loss: 0.8179\n",
      "Epoch [104/200], Step [471/1067], D_A_loss: 0.0198, D_B_loss: 0.0220, G_A_loss: 1.0357, G_B_loss: 1.0304\n",
      "Epoch [104/200], Step [481/1067], D_A_loss: 0.0348, D_B_loss: 0.0456, G_A_loss: 0.9112, G_B_loss: 0.7692\n",
      "Epoch [104/200], Step [491/1067], D_A_loss: 0.0305, D_B_loss: 0.0469, G_A_loss: 0.6683, G_B_loss: 0.1540\n",
      "Epoch [104/200], Step [501/1067], D_A_loss: 0.1332, D_B_loss: 0.0407, G_A_loss: 0.9565, G_B_loss: 0.3567\n",
      "Epoch [104/200], Step [511/1067], D_A_loss: 0.0798, D_B_loss: 0.0286, G_A_loss: 0.9320, G_B_loss: 0.7653\n",
      "Epoch [104/200], Step [521/1067], D_A_loss: 0.0215, D_B_loss: 0.0258, G_A_loss: 0.7225, G_B_loss: 0.4920\n",
      "Epoch [104/200], Step [531/1067], D_A_loss: 0.0357, D_B_loss: 0.0094, G_A_loss: 0.9867, G_B_loss: 0.3083\n",
      "Epoch [104/200], Step [541/1067], D_A_loss: 0.1599, D_B_loss: 0.0347, G_A_loss: 0.7020, G_B_loss: 0.2563\n",
      "Epoch [104/200], Step [551/1067], D_A_loss: 0.0423, D_B_loss: 0.0393, G_A_loss: 0.6502, G_B_loss: 0.6257\n",
      "Epoch [104/200], Step [561/1067], D_A_loss: 0.0446, D_B_loss: 0.0175, G_A_loss: 0.8030, G_B_loss: 0.4395\n",
      "Epoch [104/200], Step [571/1067], D_A_loss: 0.1298, D_B_loss: 0.0978, G_A_loss: 0.4668, G_B_loss: 0.4527\n",
      "Epoch [104/200], Step [581/1067], D_A_loss: 0.0741, D_B_loss: 0.0417, G_A_loss: 0.8456, G_B_loss: 0.5059\n",
      "Epoch [104/200], Step [591/1067], D_A_loss: 0.0364, D_B_loss: 0.0507, G_A_loss: 0.5295, G_B_loss: 1.1239\n",
      "Epoch [104/200], Step [601/1067], D_A_loss: 0.0560, D_B_loss: 0.0088, G_A_loss: 1.1252, G_B_loss: 0.3110\n",
      "Epoch [104/200], Step [611/1067], D_A_loss: 0.1627, D_B_loss: 0.0118, G_A_loss: 0.7428, G_B_loss: 0.2688\n",
      "Epoch [104/200], Step [621/1067], D_A_loss: 0.0676, D_B_loss: 0.0107, G_A_loss: 0.8030, G_B_loss: 0.9078\n",
      "Epoch [104/200], Step [631/1067], D_A_loss: 0.0347, D_B_loss: 0.0197, G_A_loss: 1.1651, G_B_loss: 0.2879\n",
      "Epoch [104/200], Step [641/1067], D_A_loss: 0.0498, D_B_loss: 0.0217, G_A_loss: 0.6942, G_B_loss: 0.3367\n",
      "Epoch [104/200], Step [651/1067], D_A_loss: 0.0434, D_B_loss: 0.0251, G_A_loss: 0.4790, G_B_loss: 0.1688\n",
      "Epoch [104/200], Step [661/1067], D_A_loss: 0.1122, D_B_loss: 0.0104, G_A_loss: 1.0130, G_B_loss: 0.4279\n",
      "Epoch [104/200], Step [671/1067], D_A_loss: 0.0531, D_B_loss: 0.0161, G_A_loss: 0.8411, G_B_loss: 0.7807\n",
      "Epoch [104/200], Step [681/1067], D_A_loss: 0.0552, D_B_loss: 0.0608, G_A_loss: 0.8013, G_B_loss: 0.5572\n",
      "Epoch [104/200], Step [691/1067], D_A_loss: 0.1286, D_B_loss: 0.0534, G_A_loss: 0.5183, G_B_loss: 1.1055\n",
      "Epoch [104/200], Step [701/1067], D_A_loss: 0.0400, D_B_loss: 0.0780, G_A_loss: 1.1365, G_B_loss: 0.7880\n",
      "Epoch [104/200], Step [711/1067], D_A_loss: 0.0712, D_B_loss: 0.0708, G_A_loss: 0.5457, G_B_loss: 1.2007\n",
      "Epoch [104/200], Step [721/1067], D_A_loss: 0.0694, D_B_loss: 0.0110, G_A_loss: 1.3471, G_B_loss: 0.5032\n",
      "Epoch [104/200], Step [731/1067], D_A_loss: 0.0819, D_B_loss: 0.0302, G_A_loss: 0.6672, G_B_loss: 0.8710\n",
      "Epoch [104/200], Step [741/1067], D_A_loss: 0.1515, D_B_loss: 0.0497, G_A_loss: 0.5670, G_B_loss: 0.3192\n",
      "Epoch [104/200], Step [751/1067], D_A_loss: 0.1248, D_B_loss: 0.0229, G_A_loss: 0.7262, G_B_loss: 0.6403\n",
      "Epoch [104/200], Step [761/1067], D_A_loss: 0.1378, D_B_loss: 0.0265, G_A_loss: 1.0836, G_B_loss: 0.5733\n",
      "Epoch [104/200], Step [771/1067], D_A_loss: 0.0916, D_B_loss: 0.0302, G_A_loss: 0.4507, G_B_loss: 0.5177\n",
      "Epoch [104/200], Step [781/1067], D_A_loss: 0.0491, D_B_loss: 0.0356, G_A_loss: 0.8768, G_B_loss: 0.6654\n",
      "Epoch [104/200], Step [791/1067], D_A_loss: 0.0904, D_B_loss: 0.0472, G_A_loss: 0.5307, G_B_loss: 0.4652\n",
      "Epoch [104/200], Step [801/1067], D_A_loss: 0.0627, D_B_loss: 0.0429, G_A_loss: 1.0785, G_B_loss: 0.7207\n",
      "Epoch [104/200], Step [811/1067], D_A_loss: 0.0565, D_B_loss: 0.0171, G_A_loss: 0.9182, G_B_loss: 0.5577\n",
      "Epoch [104/200], Step [821/1067], D_A_loss: 0.0913, D_B_loss: 0.0499, G_A_loss: 0.6734, G_B_loss: 0.4760\n",
      "Epoch [104/200], Step [831/1067], D_A_loss: 0.1397, D_B_loss: 0.0782, G_A_loss: 0.7634, G_B_loss: 0.4711\n",
      "Epoch [104/200], Step [841/1067], D_A_loss: 0.1320, D_B_loss: 0.0223, G_A_loss: 1.1153, G_B_loss: 0.4716\n",
      "Epoch [104/200], Step [851/1067], D_A_loss: 0.1354, D_B_loss: 0.0233, G_A_loss: 1.3061, G_B_loss: 0.3008\n",
      "Epoch [104/200], Step [861/1067], D_A_loss: 0.1404, D_B_loss: 0.0186, G_A_loss: 0.7974, G_B_loss: 0.9584\n",
      "Epoch [104/200], Step [871/1067], D_A_loss: 0.0701, D_B_loss: 0.0192, G_A_loss: 0.8606, G_B_loss: 0.3010\n",
      "Epoch [104/200], Step [881/1067], D_A_loss: 0.1696, D_B_loss: 0.0353, G_A_loss: 1.1442, G_B_loss: 0.4976\n",
      "Epoch [104/200], Step [891/1067], D_A_loss: 0.1178, D_B_loss: 0.1625, G_A_loss: 0.9010, G_B_loss: 0.2473\n",
      "Epoch [104/200], Step [901/1067], D_A_loss: 0.0210, D_B_loss: 0.0529, G_A_loss: 0.7966, G_B_loss: 0.5101\n",
      "Epoch [104/200], Step [911/1067], D_A_loss: 0.0460, D_B_loss: 0.0680, G_A_loss: 0.6875, G_B_loss: 0.6171\n",
      "Epoch [104/200], Step [921/1067], D_A_loss: 0.0452, D_B_loss: 0.0203, G_A_loss: 0.5988, G_B_loss: 1.1147\n",
      "Epoch [104/200], Step [931/1067], D_A_loss: 0.0565, D_B_loss: 0.0316, G_A_loss: 0.6462, G_B_loss: 0.3972\n",
      "Epoch [104/200], Step [941/1067], D_A_loss: 0.1371, D_B_loss: 0.0200, G_A_loss: 1.2206, G_B_loss: 0.3307\n",
      "Epoch [104/200], Step [951/1067], D_A_loss: 0.1723, D_B_loss: 0.0104, G_A_loss: 0.9610, G_B_loss: 0.4736\n",
      "Epoch [104/200], Step [961/1067], D_A_loss: 0.0469, D_B_loss: 0.0215, G_A_loss: 1.0585, G_B_loss: 0.9168\n",
      "Epoch [104/200], Step [971/1067], D_A_loss: 0.2888, D_B_loss: 0.0236, G_A_loss: 1.2306, G_B_loss: 0.0914\n",
      "Epoch [104/200], Step [981/1067], D_A_loss: 0.1177, D_B_loss: 0.0193, G_A_loss: 0.8393, G_B_loss: 0.3579\n",
      "Epoch [104/200], Step [991/1067], D_A_loss: 0.0522, D_B_loss: 0.0475, G_A_loss: 1.0788, G_B_loss: 0.5722\n",
      "Epoch [104/200], Step [1001/1067], D_A_loss: 0.1146, D_B_loss: 0.1632, G_A_loss: 0.7253, G_B_loss: 0.8481\n",
      "Epoch [104/200], Step [1011/1067], D_A_loss: 0.2435, D_B_loss: 0.0113, G_A_loss: 0.6117, G_B_loss: 0.2118\n",
      "Epoch [104/200], Step [1021/1067], D_A_loss: 0.1336, D_B_loss: 0.0102, G_A_loss: 0.5603, G_B_loss: 0.8123\n",
      "Epoch [104/200], Step [1031/1067], D_A_loss: 0.0635, D_B_loss: 0.0416, G_A_loss: 0.7524, G_B_loss: 0.4154\n",
      "Epoch [104/200], Step [1041/1067], D_A_loss: 0.2905, D_B_loss: 0.0162, G_A_loss: 0.7701, G_B_loss: 0.8100\n",
      "Epoch [104/200], Step [1051/1067], D_A_loss: 0.0438, D_B_loss: 0.0642, G_A_loss: 0.4272, G_B_loss: 0.9523\n",
      "Epoch [104/200], Step [1061/1067], D_A_loss: 0.1370, D_B_loss: 0.0499, G_A_loss: 0.5143, G_B_loss: 0.6597\n",
      "Epoch [105/200], Step [1/1067], D_A_loss: 0.0872, D_B_loss: 0.0290, G_A_loss: 0.6327, G_B_loss: 0.1305\n",
      "Epoch [105/200], Step [11/1067], D_A_loss: 0.0946, D_B_loss: 0.0251, G_A_loss: 0.8828, G_B_loss: 0.6936\n",
      "Epoch [105/200], Step [21/1067], D_A_loss: 0.0426, D_B_loss: 0.0226, G_A_loss: 0.8477, G_B_loss: 0.6145\n",
      "Epoch [105/200], Step [31/1067], D_A_loss: 0.0589, D_B_loss: 0.0217, G_A_loss: 0.9351, G_B_loss: 0.6679\n",
      "Epoch [105/200], Step [41/1067], D_A_loss: 0.0479, D_B_loss: 0.0183, G_A_loss: 0.7413, G_B_loss: 0.1162\n",
      "Epoch [105/200], Step [51/1067], D_A_loss: 0.2734, D_B_loss: 0.0301, G_A_loss: 0.7505, G_B_loss: 0.1047\n",
      "Epoch [105/200], Step [61/1067], D_A_loss: 0.1204, D_B_loss: 0.3828, G_A_loss: 0.9370, G_B_loss: 0.5680\n",
      "Epoch [105/200], Step [71/1067], D_A_loss: 0.0399, D_B_loss: 0.0165, G_A_loss: 0.8695, G_B_loss: 0.6526\n",
      "Epoch [105/200], Step [81/1067], D_A_loss: 0.0226, D_B_loss: 0.0165, G_A_loss: 0.9764, G_B_loss: 0.4746\n",
      "Epoch [105/200], Step [91/1067], D_A_loss: 0.2194, D_B_loss: 0.0091, G_A_loss: 0.9271, G_B_loss: 0.6896\n",
      "Epoch [105/200], Step [101/1067], D_A_loss: 0.2558, D_B_loss: 0.0675, G_A_loss: 0.4440, G_B_loss: 0.7477\n",
      "Epoch [105/200], Step [111/1067], D_A_loss: 0.0738, D_B_loss: 0.0164, G_A_loss: 0.6429, G_B_loss: 0.4844\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [105/200], Step [121/1067], D_A_loss: 0.0743, D_B_loss: 0.0385, G_A_loss: 0.6021, G_B_loss: 0.6261\n",
      "Epoch [105/200], Step [131/1067], D_A_loss: 0.0701, D_B_loss: 0.0362, G_A_loss: 0.9164, G_B_loss: 0.5423\n",
      "Epoch [105/200], Step [141/1067], D_A_loss: 0.1178, D_B_loss: 0.0266, G_A_loss: 1.0779, G_B_loss: 0.4615\n",
      "Epoch [105/200], Step [151/1067], D_A_loss: 0.0789, D_B_loss: 0.0851, G_A_loss: 0.5021, G_B_loss: 1.2776\n",
      "Epoch [105/200], Step [161/1067], D_A_loss: 0.0723, D_B_loss: 0.0873, G_A_loss: 0.8597, G_B_loss: 0.1822\n",
      "Epoch [105/200], Step [171/1067], D_A_loss: 0.2205, D_B_loss: 0.0297, G_A_loss: 0.6211, G_B_loss: 0.7178\n",
      "Epoch [105/200], Step [181/1067], D_A_loss: 0.0522, D_B_loss: 0.0621, G_A_loss: 1.0942, G_B_loss: 0.3039\n",
      "Epoch [105/200], Step [191/1067], D_A_loss: 0.1085, D_B_loss: 0.0291, G_A_loss: 0.8190, G_B_loss: 0.9539\n",
      "Epoch [105/200], Step [201/1067], D_A_loss: 0.1072, D_B_loss: 0.0177, G_A_loss: 1.0680, G_B_loss: 0.4298\n",
      "Epoch [105/200], Step [211/1067], D_A_loss: 0.0935, D_B_loss: 0.0204, G_A_loss: 0.4074, G_B_loss: 0.4716\n",
      "Epoch [105/200], Step [221/1067], D_A_loss: 0.0923, D_B_loss: 0.0716, G_A_loss: 0.6061, G_B_loss: 0.4272\n",
      "Epoch [105/200], Step [231/1067], D_A_loss: 0.2125, D_B_loss: 0.0390, G_A_loss: 0.4791, G_B_loss: 0.7018\n",
      "Epoch [105/200], Step [241/1067], D_A_loss: 0.0278, D_B_loss: 0.0312, G_A_loss: 0.6736, G_B_loss: 0.8182\n",
      "Epoch [105/200], Step [251/1067], D_A_loss: 0.0619, D_B_loss: 0.0398, G_A_loss: 1.0704, G_B_loss: 0.7960\n",
      "Epoch [105/200], Step [261/1067], D_A_loss: 0.2843, D_B_loss: 0.0078, G_A_loss: 0.5444, G_B_loss: 0.4612\n",
      "Epoch [105/200], Step [271/1067], D_A_loss: 0.1118, D_B_loss: 0.0905, G_A_loss: 0.5215, G_B_loss: 0.3762\n",
      "Epoch [105/200], Step [281/1067], D_A_loss: 0.0363, D_B_loss: 0.1235, G_A_loss: 0.7566, G_B_loss: 0.3873\n",
      "Epoch [105/200], Step [291/1067], D_A_loss: 0.0208, D_B_loss: 0.0168, G_A_loss: 0.8263, G_B_loss: 0.4602\n",
      "Epoch [105/200], Step [301/1067], D_A_loss: 0.1583, D_B_loss: 0.0392, G_A_loss: 0.5951, G_B_loss: 0.3114\n",
      "Epoch [105/200], Step [311/1067], D_A_loss: 0.0724, D_B_loss: 0.0923, G_A_loss: 0.6816, G_B_loss: 0.4972\n",
      "Epoch [105/200], Step [321/1067], D_A_loss: 0.0839, D_B_loss: 0.0578, G_A_loss: 0.7182, G_B_loss: 0.5884\n",
      "Epoch [105/200], Step [331/1067], D_A_loss: 0.1083, D_B_loss: 0.0870, G_A_loss: 0.5824, G_B_loss: 0.4153\n",
      "Epoch [105/200], Step [341/1067], D_A_loss: 0.1301, D_B_loss: 0.0225, G_A_loss: 0.6744, G_B_loss: 0.4035\n",
      "Epoch [105/200], Step [351/1067], D_A_loss: 0.1526, D_B_loss: 0.0088, G_A_loss: 0.7920, G_B_loss: 0.9129\n",
      "Epoch [105/200], Step [361/1067], D_A_loss: 0.0790, D_B_loss: 0.0543, G_A_loss: 0.8077, G_B_loss: 0.5306\n",
      "Epoch [105/200], Step [371/1067], D_A_loss: 0.0604, D_B_loss: 0.0094, G_A_loss: 0.8925, G_B_loss: 0.5699\n",
      "Epoch [105/200], Step [381/1067], D_A_loss: 0.0385, D_B_loss: 0.0141, G_A_loss: 0.8921, G_B_loss: 0.6216\n",
      "Epoch [105/200], Step [391/1067], D_A_loss: 0.1213, D_B_loss: 0.0510, G_A_loss: 0.6390, G_B_loss: 0.4424\n",
      "Epoch [105/200], Step [401/1067], D_A_loss: 0.0998, D_B_loss: 0.0112, G_A_loss: 1.1398, G_B_loss: 0.3824\n",
      "Epoch [105/200], Step [411/1067], D_A_loss: 0.0347, D_B_loss: 0.0141, G_A_loss: 0.9028, G_B_loss: 0.8046\n",
      "Epoch [105/200], Step [421/1067], D_A_loss: 0.1484, D_B_loss: 0.0756, G_A_loss: 0.6233, G_B_loss: 0.3317\n",
      "Epoch [105/200], Step [431/1067], D_A_loss: 0.0688, D_B_loss: 0.0505, G_A_loss: 0.5438, G_B_loss: 0.5926\n",
      "Epoch [105/200], Step [441/1067], D_A_loss: 0.0281, D_B_loss: 0.0141, G_A_loss: 1.1879, G_B_loss: 0.3931\n",
      "Epoch [105/200], Step [451/1067], D_A_loss: 0.0256, D_B_loss: 0.0087, G_A_loss: 0.9689, G_B_loss: 0.3709\n",
      "Epoch [105/200], Step [461/1067], D_A_loss: 0.0317, D_B_loss: 0.0416, G_A_loss: 0.5999, G_B_loss: 1.3717\n",
      "Epoch [105/200], Step [471/1067], D_A_loss: 0.0924, D_B_loss: 0.0111, G_A_loss: 0.6441, G_B_loss: 1.2857\n",
      "Epoch [105/200], Step [481/1067], D_A_loss: 0.1604, D_B_loss: 0.0228, G_A_loss: 1.1361, G_B_loss: 0.2900\n",
      "Epoch [105/200], Step [491/1067], D_A_loss: 0.0950, D_B_loss: 0.0383, G_A_loss: 0.8699, G_B_loss: 0.4138\n",
      "Epoch [105/200], Step [501/1067], D_A_loss: 0.0398, D_B_loss: 0.0181, G_A_loss: 0.7885, G_B_loss: 1.1154\n",
      "Epoch [105/200], Step [511/1067], D_A_loss: 0.2097, D_B_loss: 0.1255, G_A_loss: 0.3842, G_B_loss: 0.2091\n",
      "Epoch [105/200], Step [521/1067], D_A_loss: 0.0746, D_B_loss: 0.0158, G_A_loss: 1.0336, G_B_loss: 0.5297\n",
      "Epoch [105/200], Step [531/1067], D_A_loss: 0.1184, D_B_loss: 0.0338, G_A_loss: 0.7114, G_B_loss: 0.4182\n",
      "Epoch [105/200], Step [541/1067], D_A_loss: 0.0370, D_B_loss: 0.0268, G_A_loss: 1.1033, G_B_loss: 0.5894\n",
      "Epoch [105/200], Step [551/1067], D_A_loss: 0.0478, D_B_loss: 0.0117, G_A_loss: 1.1364, G_B_loss: 0.3454\n",
      "Epoch [105/200], Step [561/1067], D_A_loss: 0.2019, D_B_loss: 0.0316, G_A_loss: 0.9998, G_B_loss: 0.9507\n",
      "Epoch [105/200], Step [571/1067], D_A_loss: 0.0324, D_B_loss: 0.0396, G_A_loss: 0.6400, G_B_loss: 0.7956\n",
      "Epoch [105/200], Step [581/1067], D_A_loss: 0.0409, D_B_loss: 0.0264, G_A_loss: 0.6877, G_B_loss: 0.7135\n",
      "Epoch [105/200], Step [591/1067], D_A_loss: 0.0241, D_B_loss: 0.0478, G_A_loss: 0.5608, G_B_loss: 0.2119\n",
      "Epoch [105/200], Step [601/1067], D_A_loss: 0.1724, D_B_loss: 0.0612, G_A_loss: 0.6949, G_B_loss: 0.4142\n",
      "Epoch [105/200], Step [611/1067], D_A_loss: 0.0967, D_B_loss: 0.0064, G_A_loss: 0.7894, G_B_loss: 0.9060\n",
      "Epoch [105/200], Step [621/1067], D_A_loss: 0.1090, D_B_loss: 0.0197, G_A_loss: 0.7435, G_B_loss: 0.7557\n",
      "Epoch [105/200], Step [631/1067], D_A_loss: 0.1295, D_B_loss: 0.0195, G_A_loss: 0.6472, G_B_loss: 0.6232\n",
      "Epoch [105/200], Step [641/1067], D_A_loss: 0.0895, D_B_loss: 0.0496, G_A_loss: 0.8839, G_B_loss: 0.6165\n",
      "Epoch [105/200], Step [651/1067], D_A_loss: 0.0487, D_B_loss: 0.0256, G_A_loss: 0.8027, G_B_loss: 0.7635\n",
      "Epoch [105/200], Step [661/1067], D_A_loss: 0.0585, D_B_loss: 0.0144, G_A_loss: 0.7960, G_B_loss: 0.6981\n",
      "Epoch [105/200], Step [671/1067], D_A_loss: 0.1320, D_B_loss: 0.0243, G_A_loss: 0.7013, G_B_loss: 0.2544\n",
      "Epoch [105/200], Step [681/1067], D_A_loss: 0.0809, D_B_loss: 0.0252, G_A_loss: 0.7133, G_B_loss: 0.5546\n",
      "Epoch [105/200], Step [691/1067], D_A_loss: 0.0314, D_B_loss: 0.0183, G_A_loss: 1.0615, G_B_loss: 0.5390\n",
      "Epoch [105/200], Step [701/1067], D_A_loss: 0.1427, D_B_loss: 0.0437, G_A_loss: 1.0525, G_B_loss: 0.2896\n",
      "Epoch [105/200], Step [711/1067], D_A_loss: 0.1996, D_B_loss: 0.0238, G_A_loss: 0.6773, G_B_loss: 0.6006\n",
      "Epoch [105/200], Step [721/1067], D_A_loss: 0.0492, D_B_loss: 0.0516, G_A_loss: 0.7660, G_B_loss: 0.2573\n",
      "Epoch [105/200], Step [731/1067], D_A_loss: 0.0764, D_B_loss: 0.0276, G_A_loss: 0.7935, G_B_loss: 0.1900\n",
      "Epoch [105/200], Step [741/1067], D_A_loss: 0.0753, D_B_loss: 0.0284, G_A_loss: 0.6953, G_B_loss: 0.7427\n",
      "Epoch [105/200], Step [751/1067], D_A_loss: 0.1400, D_B_loss: 0.0234, G_A_loss: 0.8419, G_B_loss: 0.7026\n",
      "Epoch [105/200], Step [761/1067], D_A_loss: 0.0809, D_B_loss: 0.0130, G_A_loss: 0.8532, G_B_loss: 0.6174\n",
      "Epoch [105/200], Step [771/1067], D_A_loss: 0.0696, D_B_loss: 0.0159, G_A_loss: 0.5610, G_B_loss: 0.5497\n",
      "Epoch [105/200], Step [781/1067], D_A_loss: 0.0576, D_B_loss: 0.0510, G_A_loss: 1.2031, G_B_loss: 0.6572\n",
      "Epoch [105/200], Step [791/1067], D_A_loss: 0.0536, D_B_loss: 0.0162, G_A_loss: 1.0358, G_B_loss: 0.1644\n",
      "Epoch [105/200], Step [801/1067], D_A_loss: 0.0295, D_B_loss: 0.1452, G_A_loss: 0.8032, G_B_loss: 0.9124\n",
      "Epoch [105/200], Step [811/1067], D_A_loss: 0.0655, D_B_loss: 0.0546, G_A_loss: 1.1833, G_B_loss: 0.5622\n",
      "Epoch [105/200], Step [821/1067], D_A_loss: 0.0600, D_B_loss: 0.0192, G_A_loss: 0.8655, G_B_loss: 0.3744\n",
      "Epoch [105/200], Step [831/1067], D_A_loss: 0.0931, D_B_loss: 0.0380, G_A_loss: 0.6673, G_B_loss: 0.5461\n",
      "Epoch [105/200], Step [841/1067], D_A_loss: 0.0433, D_B_loss: 0.0363, G_A_loss: 1.2033, G_B_loss: 0.7600\n",
      "Epoch [105/200], Step [851/1067], D_A_loss: 0.1591, D_B_loss: 0.0146, G_A_loss: 1.0847, G_B_loss: 0.7813\n",
      "Epoch [105/200], Step [861/1067], D_A_loss: 0.2164, D_B_loss: 0.1041, G_A_loss: 1.2465, G_B_loss: 0.6389\n",
      "Epoch [105/200], Step [871/1067], D_A_loss: 0.0465, D_B_loss: 0.0133, G_A_loss: 0.9236, G_B_loss: 0.7401\n",
      "Epoch [105/200], Step [881/1067], D_A_loss: 0.0997, D_B_loss: 0.0217, G_A_loss: 1.1697, G_B_loss: 0.5141\n",
      "Epoch [105/200], Step [891/1067], D_A_loss: 0.1622, D_B_loss: 0.0304, G_A_loss: 1.1628, G_B_loss: 0.6446\n",
      "Epoch [105/200], Step [901/1067], D_A_loss: 0.1382, D_B_loss: 0.0227, G_A_loss: 1.0652, G_B_loss: 0.5099\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [105/200], Step [911/1067], D_A_loss: 0.0701, D_B_loss: 0.1028, G_A_loss: 0.7800, G_B_loss: 0.2699\n",
      "Epoch [105/200], Step [921/1067], D_A_loss: 0.2884, D_B_loss: 0.0197, G_A_loss: 0.6028, G_B_loss: 0.6852\n",
      "Epoch [105/200], Step [931/1067], D_A_loss: 0.2188, D_B_loss: 0.0374, G_A_loss: 0.6613, G_B_loss: 0.1603\n",
      "Epoch [105/200], Step [941/1067], D_A_loss: 0.0666, D_B_loss: 0.0738, G_A_loss: 0.4633, G_B_loss: 0.5343\n",
      "Epoch [105/200], Step [951/1067], D_A_loss: 0.0459, D_B_loss: 0.0346, G_A_loss: 0.7031, G_B_loss: 0.6954\n",
      "Epoch [105/200], Step [961/1067], D_A_loss: 0.0987, D_B_loss: 0.0115, G_A_loss: 0.9728, G_B_loss: 0.8772\n",
      "Epoch [105/200], Step [971/1067], D_A_loss: 0.1272, D_B_loss: 0.2713, G_A_loss: 0.7568, G_B_loss: 0.4510\n",
      "Epoch [105/200], Step [981/1067], D_A_loss: 0.1953, D_B_loss: 0.2179, G_A_loss: 0.8536, G_B_loss: 0.6876\n",
      "Epoch [105/200], Step [991/1067], D_A_loss: 0.0929, D_B_loss: 0.0232, G_A_loss: 0.7393, G_B_loss: 0.6356\n",
      "Epoch [105/200], Step [1001/1067], D_A_loss: 0.0424, D_B_loss: 0.0864, G_A_loss: 0.5187, G_B_loss: 0.6540\n",
      "Epoch [105/200], Step [1011/1067], D_A_loss: 0.0942, D_B_loss: 0.0853, G_A_loss: 0.4422, G_B_loss: 0.7025\n",
      "Epoch [105/200], Step [1021/1067], D_A_loss: 0.1833, D_B_loss: 0.0539, G_A_loss: 0.5042, G_B_loss: 0.9724\n",
      "Epoch [105/200], Step [1031/1067], D_A_loss: 0.0394, D_B_loss: 0.0615, G_A_loss: 0.5508, G_B_loss: 0.7916\n",
      "Epoch [105/200], Step [1041/1067], D_A_loss: 0.1231, D_B_loss: 0.0613, G_A_loss: 1.0646, G_B_loss: 0.3794\n",
      "Epoch [105/200], Step [1051/1067], D_A_loss: 0.0847, D_B_loss: 0.0624, G_A_loss: 0.4952, G_B_loss: 0.5283\n",
      "Epoch [105/200], Step [1061/1067], D_A_loss: 0.1142, D_B_loss: 0.2461, G_A_loss: 0.7257, G_B_loss: 0.4274\n",
      "Epoch [106/200], Step [1/1067], D_A_loss: 0.1117, D_B_loss: 0.0090, G_A_loss: 1.1249, G_B_loss: 0.3690\n",
      "Epoch [106/200], Step [11/1067], D_A_loss: 0.1811, D_B_loss: 0.0158, G_A_loss: 1.1370, G_B_loss: 0.2219\n",
      "Epoch [106/200], Step [21/1067], D_A_loss: 0.1206, D_B_loss: 0.0233, G_A_loss: 0.8380, G_B_loss: 0.3584\n",
      "Epoch [106/200], Step [31/1067], D_A_loss: 0.0392, D_B_loss: 0.0199, G_A_loss: 0.8609, G_B_loss: 1.0946\n",
      "Epoch [106/200], Step [41/1067], D_A_loss: 0.3525, D_B_loss: 0.1200, G_A_loss: 0.5317, G_B_loss: 0.0980\n",
      "Epoch [106/200], Step [51/1067], D_A_loss: 0.1081, D_B_loss: 0.0581, G_A_loss: 1.3635, G_B_loss: 0.3595\n",
      "Epoch [106/200], Step [61/1067], D_A_loss: 0.0967, D_B_loss: 0.0099, G_A_loss: 0.9350, G_B_loss: 0.4798\n",
      "Epoch [106/200], Step [71/1067], D_A_loss: 0.0204, D_B_loss: 0.0393, G_A_loss: 0.6721, G_B_loss: 0.8084\n",
      "Epoch [106/200], Step [81/1067], D_A_loss: 0.0973, D_B_loss: 0.0145, G_A_loss: 0.9193, G_B_loss: 0.7932\n",
      "Epoch [106/200], Step [91/1067], D_A_loss: 0.0743, D_B_loss: 0.0340, G_A_loss: 0.4830, G_B_loss: 1.0308\n",
      "Epoch [106/200], Step [101/1067], D_A_loss: 0.1331, D_B_loss: 0.0631, G_A_loss: 0.6586, G_B_loss: 0.7073\n",
      "Epoch [106/200], Step [111/1067], D_A_loss: 0.1598, D_B_loss: 0.0194, G_A_loss: 0.5524, G_B_loss: 0.7232\n",
      "Epoch [106/200], Step [121/1067], D_A_loss: 0.0524, D_B_loss: 0.0401, G_A_loss: 0.9798, G_B_loss: 0.4330\n",
      "Epoch [106/200], Step [131/1067], D_A_loss: 0.1831, D_B_loss: 0.0596, G_A_loss: 0.8912, G_B_loss: 0.3068\n",
      "Epoch [106/200], Step [141/1067], D_A_loss: 0.0888, D_B_loss: 0.0221, G_A_loss: 1.1006, G_B_loss: 0.6089\n",
      "Epoch [106/200], Step [151/1067], D_A_loss: 0.1436, D_B_loss: 0.0596, G_A_loss: 0.6044, G_B_loss: 0.4196\n",
      "Epoch [106/200], Step [161/1067], D_A_loss: 0.1065, D_B_loss: 0.0376, G_A_loss: 0.6326, G_B_loss: 0.3952\n",
      "Epoch [106/200], Step [171/1067], D_A_loss: 0.0774, D_B_loss: 0.0203, G_A_loss: 0.9236, G_B_loss: 0.2459\n",
      "Epoch [106/200], Step [181/1067], D_A_loss: 0.0662, D_B_loss: 0.0326, G_A_loss: 1.2318, G_B_loss: 0.3614\n",
      "Epoch [106/200], Step [191/1067], D_A_loss: 0.1480, D_B_loss: 0.0477, G_A_loss: 0.9517, G_B_loss: 0.4582\n",
      "Epoch [106/200], Step [201/1067], D_A_loss: 0.0989, D_B_loss: 0.0227, G_A_loss: 0.7022, G_B_loss: 0.4149\n",
      "Epoch [106/200], Step [211/1067], D_A_loss: 0.1077, D_B_loss: 0.0562, G_A_loss: 0.7339, G_B_loss: 0.8581\n",
      "Epoch [106/200], Step [221/1067], D_A_loss: 0.1095, D_B_loss: 0.0254, G_A_loss: 0.9259, G_B_loss: 0.2546\n",
      "Epoch [106/200], Step [231/1067], D_A_loss: 0.1124, D_B_loss: 0.0583, G_A_loss: 0.6300, G_B_loss: 0.3465\n",
      "Epoch [106/200], Step [241/1067], D_A_loss: 0.0403, D_B_loss: 0.0114, G_A_loss: 1.1146, G_B_loss: 0.5735\n",
      "Epoch [106/200], Step [251/1067], D_A_loss: 0.0422, D_B_loss: 0.0340, G_A_loss: 0.9955, G_B_loss: 0.3758\n",
      "Epoch [106/200], Step [261/1067], D_A_loss: 0.0420, D_B_loss: 0.0758, G_A_loss: 0.4533, G_B_loss: 0.2519\n",
      "Epoch [106/200], Step [271/1067], D_A_loss: 0.2145, D_B_loss: 0.0318, G_A_loss: 1.4086, G_B_loss: 0.4557\n",
      "Epoch [106/200], Step [281/1067], D_A_loss: 0.0419, D_B_loss: 0.0203, G_A_loss: 0.6538, G_B_loss: 0.7826\n",
      "Epoch [106/200], Step [291/1067], D_A_loss: 0.2802, D_B_loss: 0.0235, G_A_loss: 0.5547, G_B_loss: 1.1179\n",
      "Epoch [106/200], Step [301/1067], D_A_loss: 0.1480, D_B_loss: 0.0261, G_A_loss: 0.6723, G_B_loss: 0.6253\n",
      "Epoch [106/200], Step [311/1067], D_A_loss: 0.1979, D_B_loss: 0.0217, G_A_loss: 0.6178, G_B_loss: 0.1977\n",
      "Epoch [106/200], Step [321/1067], D_A_loss: 0.0801, D_B_loss: 0.1540, G_A_loss: 0.8765, G_B_loss: 0.5183\n",
      "Epoch [106/200], Step [331/1067], D_A_loss: 0.0680, D_B_loss: 0.0100, G_A_loss: 0.8673, G_B_loss: 0.6816\n",
      "Epoch [106/200], Step [341/1067], D_A_loss: 0.0796, D_B_loss: 0.0233, G_A_loss: 0.7501, G_B_loss: 0.5618\n",
      "Epoch [106/200], Step [351/1067], D_A_loss: 0.0336, D_B_loss: 0.0625, G_A_loss: 0.4190, G_B_loss: 0.4633\n",
      "Epoch [106/200], Step [361/1067], D_A_loss: 0.0596, D_B_loss: 0.0132, G_A_loss: 1.1677, G_B_loss: 0.5534\n",
      "Epoch [106/200], Step [371/1067], D_A_loss: 0.1652, D_B_loss: 0.0454, G_A_loss: 0.7416, G_B_loss: 0.7230\n",
      "Epoch [106/200], Step [381/1067], D_A_loss: 0.2437, D_B_loss: 0.0152, G_A_loss: 1.0878, G_B_loss: 0.5445\n",
      "Epoch [106/200], Step [391/1067], D_A_loss: 0.0502, D_B_loss: 0.0202, G_A_loss: 0.8325, G_B_loss: 1.0571\n",
      "Epoch [106/200], Step [401/1067], D_A_loss: 0.0665, D_B_loss: 0.0812, G_A_loss: 0.9545, G_B_loss: 0.6618\n",
      "Epoch [106/200], Step [411/1067], D_A_loss: 0.0804, D_B_loss: 0.0114, G_A_loss: 0.8335, G_B_loss: 0.5160\n",
      "Epoch [106/200], Step [421/1067], D_A_loss: 0.1591, D_B_loss: 0.0176, G_A_loss: 0.9405, G_B_loss: 0.9268\n",
      "Epoch [106/200], Step [431/1067], D_A_loss: 0.0360, D_B_loss: 0.1111, G_A_loss: 0.6204, G_B_loss: 0.9640\n",
      "Epoch [106/200], Step [441/1067], D_A_loss: 0.0449, D_B_loss: 0.0245, G_A_loss: 0.9126, G_B_loss: 0.7796\n",
      "Epoch [106/200], Step [451/1067], D_A_loss: 0.0980, D_B_loss: 0.0129, G_A_loss: 0.9309, G_B_loss: 0.5893\n",
      "Epoch [106/200], Step [461/1067], D_A_loss: 0.1054, D_B_loss: 0.0085, G_A_loss: 0.9596, G_B_loss: 1.0062\n",
      "Epoch [106/200], Step [471/1067], D_A_loss: 0.0613, D_B_loss: 0.0182, G_A_loss: 1.2668, G_B_loss: 0.6971\n",
      "Epoch [106/200], Step [481/1067], D_A_loss: 0.0997, D_B_loss: 0.0142, G_A_loss: 0.7635, G_B_loss: 0.3999\n",
      "Epoch [106/200], Step [491/1067], D_A_loss: 0.0599, D_B_loss: 0.0688, G_A_loss: 0.7066, G_B_loss: 0.5329\n",
      "Epoch [106/200], Step [501/1067], D_A_loss: 0.0259, D_B_loss: 0.0404, G_A_loss: 0.6030, G_B_loss: 0.7869\n",
      "Epoch [106/200], Step [511/1067], D_A_loss: 0.0223, D_B_loss: 0.0440, G_A_loss: 0.6406, G_B_loss: 0.9040\n",
      "Epoch [106/200], Step [521/1067], D_A_loss: 0.0810, D_B_loss: 0.0196, G_A_loss: 0.8297, G_B_loss: 0.7915\n",
      "Epoch [106/200], Step [531/1067], D_A_loss: 0.0844, D_B_loss: 0.0498, G_A_loss: 1.1748, G_B_loss: 0.2226\n",
      "Epoch [106/200], Step [541/1067], D_A_loss: 0.0693, D_B_loss: 0.0335, G_A_loss: 0.6588, G_B_loss: 0.7693\n",
      "Epoch [106/200], Step [551/1067], D_A_loss: 0.0596, D_B_loss: 0.0960, G_A_loss: 0.3573, G_B_loss: 1.3627\n",
      "Epoch [106/200], Step [561/1067], D_A_loss: 0.1465, D_B_loss: 0.0482, G_A_loss: 0.6072, G_B_loss: 0.4099\n",
      "Epoch [106/200], Step [571/1067], D_A_loss: 0.2390, D_B_loss: 0.0183, G_A_loss: 0.7818, G_B_loss: 0.5783\n",
      "Epoch [106/200], Step [581/1067], D_A_loss: 0.1172, D_B_loss: 0.0241, G_A_loss: 0.7498, G_B_loss: 0.3733\n",
      "Epoch [106/200], Step [591/1067], D_A_loss: 0.1714, D_B_loss: 0.0343, G_A_loss: 1.2045, G_B_loss: 0.3374\n",
      "Epoch [106/200], Step [601/1067], D_A_loss: 0.2281, D_B_loss: 0.0195, G_A_loss: 0.8179, G_B_loss: 0.3509\n",
      "Epoch [106/200], Step [611/1067], D_A_loss: 0.1715, D_B_loss: 0.0385, G_A_loss: 0.7790, G_B_loss: 0.7221\n",
      "Epoch [106/200], Step [621/1067], D_A_loss: 0.1199, D_B_loss: 0.0301, G_A_loss: 0.7828, G_B_loss: 0.5031\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [106/200], Step [631/1067], D_A_loss: 0.0548, D_B_loss: 0.0179, G_A_loss: 0.6658, G_B_loss: 0.6669\n",
      "Epoch [106/200], Step [641/1067], D_A_loss: 0.0341, D_B_loss: 0.0094, G_A_loss: 1.1353, G_B_loss: 0.6314\n",
      "Epoch [106/200], Step [651/1067], D_A_loss: 0.0907, D_B_loss: 0.0685, G_A_loss: 0.9407, G_B_loss: 0.4820\n",
      "Epoch [106/200], Step [661/1067], D_A_loss: 0.0270, D_B_loss: 0.0290, G_A_loss: 0.8928, G_B_loss: 0.8575\n",
      "Epoch [106/200], Step [671/1067], D_A_loss: 0.1929, D_B_loss: 0.0228, G_A_loss: 0.8304, G_B_loss: 0.2084\n",
      "Epoch [106/200], Step [681/1067], D_A_loss: 0.0278, D_B_loss: 0.0351, G_A_loss: 0.8122, G_B_loss: 0.3441\n",
      "Epoch [106/200], Step [691/1067], D_A_loss: 0.1043, D_B_loss: 0.0626, G_A_loss: 1.0027, G_B_loss: 0.7150\n",
      "Epoch [106/200], Step [701/1067], D_A_loss: 0.1015, D_B_loss: 0.0326, G_A_loss: 0.9077, G_B_loss: 0.2753\n",
      "Epoch [106/200], Step [711/1067], D_A_loss: 0.0344, D_B_loss: 0.0089, G_A_loss: 0.7462, G_B_loss: 0.9216\n",
      "Epoch [106/200], Step [721/1067], D_A_loss: 0.1195, D_B_loss: 0.0220, G_A_loss: 0.9432, G_B_loss: 0.6352\n",
      "Epoch [106/200], Step [731/1067], D_A_loss: 0.1212, D_B_loss: 0.0382, G_A_loss: 0.9181, G_B_loss: 0.4698\n",
      "Epoch [106/200], Step [741/1067], D_A_loss: 0.0919, D_B_loss: 0.1114, G_A_loss: 0.8879, G_B_loss: 0.5082\n",
      "Epoch [106/200], Step [751/1067], D_A_loss: 0.0738, D_B_loss: 0.0260, G_A_loss: 1.0874, G_B_loss: 0.5083\n",
      "Epoch [106/200], Step [761/1067], D_A_loss: 0.0573, D_B_loss: 0.0367, G_A_loss: 1.0241, G_B_loss: 0.6011\n",
      "Epoch [106/200], Step [771/1067], D_A_loss: 0.2779, D_B_loss: 0.0206, G_A_loss: 1.1804, G_B_loss: 0.1402\n",
      "Epoch [106/200], Step [781/1067], D_A_loss: 0.0379, D_B_loss: 0.0682, G_A_loss: 0.5297, G_B_loss: 0.8408\n",
      "Epoch [106/200], Step [791/1067], D_A_loss: 0.0487, D_B_loss: 0.0402, G_A_loss: 1.1997, G_B_loss: 0.2128\n",
      "Epoch [106/200], Step [801/1067], D_A_loss: 0.0382, D_B_loss: 0.0796, G_A_loss: 0.4382, G_B_loss: 0.6692\n",
      "Epoch [106/200], Step [811/1067], D_A_loss: 0.0754, D_B_loss: 0.0287, G_A_loss: 0.7249, G_B_loss: 0.4921\n",
      "Epoch [106/200], Step [821/1067], D_A_loss: 0.1191, D_B_loss: 0.0261, G_A_loss: 0.7348, G_B_loss: 0.3320\n",
      "Epoch [106/200], Step [831/1067], D_A_loss: 0.1212, D_B_loss: 0.0281, G_A_loss: 0.5813, G_B_loss: 0.5952\n",
      "Epoch [106/200], Step [841/1067], D_A_loss: 0.0577, D_B_loss: 0.0272, G_A_loss: 0.7227, G_B_loss: 0.3124\n",
      "Epoch [106/200], Step [851/1067], D_A_loss: 0.0900, D_B_loss: 0.0463, G_A_loss: 0.5800, G_B_loss: 0.4101\n",
      "Epoch [106/200], Step [861/1067], D_A_loss: 0.1659, D_B_loss: 0.0149, G_A_loss: 1.0875, G_B_loss: 0.5403\n",
      "Epoch [106/200], Step [871/1067], D_A_loss: 0.0723, D_B_loss: 0.0138, G_A_loss: 0.7249, G_B_loss: 0.5947\n",
      "Epoch [106/200], Step [881/1067], D_A_loss: 0.0995, D_B_loss: 0.0268, G_A_loss: 0.5530, G_B_loss: 0.4960\n",
      "Epoch [106/200], Step [891/1067], D_A_loss: 0.0601, D_B_loss: 0.0191, G_A_loss: 0.4457, G_B_loss: 0.4281\n",
      "Epoch [106/200], Step [901/1067], D_A_loss: 0.0714, D_B_loss: 0.0266, G_A_loss: 0.6951, G_B_loss: 0.7322\n",
      "Epoch [106/200], Step [911/1067], D_A_loss: 0.1095, D_B_loss: 0.0375, G_A_loss: 0.7466, G_B_loss: 0.5465\n",
      "Epoch [106/200], Step [921/1067], D_A_loss: 0.0583, D_B_loss: 0.0610, G_A_loss: 0.9604, G_B_loss: 0.1696\n",
      "Epoch [106/200], Step [931/1067], D_A_loss: 0.1732, D_B_loss: 0.0426, G_A_loss: 1.0443, G_B_loss: 0.3543\n",
      "Epoch [106/200], Step [941/1067], D_A_loss: 0.0507, D_B_loss: 0.0127, G_A_loss: 0.8156, G_B_loss: 0.6064\n",
      "Epoch [106/200], Step [951/1067], D_A_loss: 0.0678, D_B_loss: 0.0100, G_A_loss: 0.8941, G_B_loss: 0.8187\n",
      "Epoch [106/200], Step [961/1067], D_A_loss: 0.0944, D_B_loss: 0.0089, G_A_loss: 1.1014, G_B_loss: 0.1769\n",
      "Epoch [106/200], Step [971/1067], D_A_loss: 0.4510, D_B_loss: 0.1349, G_A_loss: 0.8891, G_B_loss: 0.0264\n",
      "Epoch [106/200], Step [981/1067], D_A_loss: 0.0754, D_B_loss: 0.0088, G_A_loss: 0.4495, G_B_loss: 0.5016\n",
      "Epoch [106/200], Step [991/1067], D_A_loss: 0.1114, D_B_loss: 0.1027, G_A_loss: 0.8664, G_B_loss: 0.3865\n",
      "Epoch [106/200], Step [1001/1067], D_A_loss: 0.0941, D_B_loss: 0.0505, G_A_loss: 0.7864, G_B_loss: 1.1011\n",
      "Epoch [106/200], Step [1011/1067], D_A_loss: 0.2201, D_B_loss: 0.0160, G_A_loss: 0.9005, G_B_loss: 0.2726\n",
      "Epoch [106/200], Step [1021/1067], D_A_loss: 0.2251, D_B_loss: 0.0202, G_A_loss: 0.8424, G_B_loss: 0.5212\n",
      "Epoch [106/200], Step [1031/1067], D_A_loss: 0.0802, D_B_loss: 0.0086, G_A_loss: 0.9700, G_B_loss: 0.8049\n",
      "Epoch [106/200], Step [1041/1067], D_A_loss: 0.0372, D_B_loss: 0.0117, G_A_loss: 0.8774, G_B_loss: 0.5779\n",
      "Epoch [106/200], Step [1051/1067], D_A_loss: 0.1204, D_B_loss: 0.0435, G_A_loss: 0.7691, G_B_loss: 0.8144\n",
      "Epoch [106/200], Step [1061/1067], D_A_loss: 0.1483, D_B_loss: 0.0538, G_A_loss: 0.9273, G_B_loss: 0.7902\n",
      "Epoch [107/200], Step [1/1067], D_A_loss: 0.0929, D_B_loss: 0.0163, G_A_loss: 0.5038, G_B_loss: 0.5186\n",
      "Epoch [107/200], Step [11/1067], D_A_loss: 0.1449, D_B_loss: 0.0189, G_A_loss: 0.8443, G_B_loss: 0.4777\n",
      "Epoch [107/200], Step [21/1067], D_A_loss: 0.0700, D_B_loss: 0.0689, G_A_loss: 1.2314, G_B_loss: 0.5351\n",
      "Epoch [107/200], Step [31/1067], D_A_loss: 0.0509, D_B_loss: 0.0848, G_A_loss: 0.5084, G_B_loss: 0.5078\n",
      "Epoch [107/200], Step [41/1067], D_A_loss: 0.0279, D_B_loss: 0.0211, G_A_loss: 0.8847, G_B_loss: 0.4779\n",
      "Epoch [107/200], Step [51/1067], D_A_loss: 0.0710, D_B_loss: 0.0215, G_A_loss: 1.1991, G_B_loss: 0.1860\n",
      "Epoch [107/200], Step [61/1067], D_A_loss: 0.1409, D_B_loss: 0.0838, G_A_loss: 0.4647, G_B_loss: 1.0949\n",
      "Epoch [107/200], Step [71/1067], D_A_loss: 0.0977, D_B_loss: 0.0242, G_A_loss: 1.3027, G_B_loss: 0.4870\n",
      "Epoch [107/200], Step [81/1067], D_A_loss: 0.0279, D_B_loss: 0.0421, G_A_loss: 1.3022, G_B_loss: 1.2091\n",
      "Epoch [107/200], Step [91/1067], D_A_loss: 0.0304, D_B_loss: 0.0343, G_A_loss: 0.6146, G_B_loss: 0.7055\n",
      "Epoch [107/200], Step [101/1067], D_A_loss: 0.0765, D_B_loss: 0.0394, G_A_loss: 0.6756, G_B_loss: 0.2325\n",
      "Epoch [107/200], Step [111/1067], D_A_loss: 0.0270, D_B_loss: 0.0103, G_A_loss: 1.1299, G_B_loss: 0.6754\n",
      "Epoch [107/200], Step [121/1067], D_A_loss: 0.1255, D_B_loss: 0.0193, G_A_loss: 0.9566, G_B_loss: 0.5823\n",
      "Epoch [107/200], Step [131/1067], D_A_loss: 0.0534, D_B_loss: 0.0151, G_A_loss: 0.6598, G_B_loss: 0.5473\n",
      "Epoch [107/200], Step [141/1067], D_A_loss: 0.1222, D_B_loss: 0.0179, G_A_loss: 0.8763, G_B_loss: 0.2761\n",
      "Epoch [107/200], Step [151/1067], D_A_loss: 0.0573, D_B_loss: 0.0380, G_A_loss: 0.5531, G_B_loss: 0.6270\n",
      "Epoch [107/200], Step [161/1067], D_A_loss: 0.0758, D_B_loss: 0.0150, G_A_loss: 0.7925, G_B_loss: 0.1388\n",
      "Epoch [107/200], Step [171/1067], D_A_loss: 0.2231, D_B_loss: 0.0659, G_A_loss: 0.8355, G_B_loss: 0.1620\n",
      "Epoch [107/200], Step [181/1067], D_A_loss: 0.0345, D_B_loss: 0.0505, G_A_loss: 0.6205, G_B_loss: 0.7768\n",
      "Epoch [107/200], Step [191/1067], D_A_loss: 0.0510, D_B_loss: 0.0320, G_A_loss: 1.0464, G_B_loss: 0.4950\n",
      "Epoch [107/200], Step [201/1067], D_A_loss: 0.1222, D_B_loss: 0.0392, G_A_loss: 1.1363, G_B_loss: 0.5447\n",
      "Epoch [107/200], Step [211/1067], D_A_loss: 0.1664, D_B_loss: 0.0139, G_A_loss: 1.3115, G_B_loss: 0.2577\n",
      "Epoch [107/200], Step [221/1067], D_A_loss: 0.1130, D_B_loss: 0.0200, G_A_loss: 0.9146, G_B_loss: 0.5041\n",
      "Epoch [107/200], Step [231/1067], D_A_loss: 0.1112, D_B_loss: 0.0685, G_A_loss: 0.5347, G_B_loss: 1.1073\n",
      "Epoch [107/200], Step [241/1067], D_A_loss: 0.1163, D_B_loss: 0.0156, G_A_loss: 1.0761, G_B_loss: 0.4501\n",
      "Epoch [107/200], Step [251/1067], D_A_loss: 0.1286, D_B_loss: 0.0130, G_A_loss: 0.5416, G_B_loss: 0.3846\n",
      "Epoch [107/200], Step [261/1067], D_A_loss: 0.0306, D_B_loss: 0.0494, G_A_loss: 0.9096, G_B_loss: 0.4370\n",
      "Epoch [107/200], Step [271/1067], D_A_loss: 0.0708, D_B_loss: 0.0314, G_A_loss: 0.6491, G_B_loss: 1.0811\n",
      "Epoch [107/200], Step [281/1067], D_A_loss: 0.0597, D_B_loss: 0.0149, G_A_loss: 0.4906, G_B_loss: 0.5326\n",
      "Epoch [107/200], Step [291/1067], D_A_loss: 0.1005, D_B_loss: 0.0296, G_A_loss: 0.5864, G_B_loss: 0.4056\n",
      "Epoch [107/200], Step [301/1067], D_A_loss: 0.1279, D_B_loss: 0.0402, G_A_loss: 0.6963, G_B_loss: 0.3344\n",
      "Epoch [107/200], Step [311/1067], D_A_loss: 0.1423, D_B_loss: 0.0136, G_A_loss: 1.0496, G_B_loss: 0.5488\n",
      "Epoch [107/200], Step [321/1067], D_A_loss: 0.1201, D_B_loss: 0.0272, G_A_loss: 0.7197, G_B_loss: 0.4739\n",
      "Epoch [107/200], Step [331/1067], D_A_loss: 0.2054, D_B_loss: 0.0287, G_A_loss: 0.8292, G_B_loss: 0.1951\n",
      "Epoch [107/200], Step [341/1067], D_A_loss: 0.0492, D_B_loss: 0.0315, G_A_loss: 0.6695, G_B_loss: 0.4144\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [107/200], Step [351/1067], D_A_loss: 0.0334, D_B_loss: 0.0144, G_A_loss: 0.8615, G_B_loss: 0.7015\n",
      "Epoch [107/200], Step [361/1067], D_A_loss: 0.0275, D_B_loss: 0.1503, G_A_loss: 0.6696, G_B_loss: 0.1238\n",
      "Epoch [107/200], Step [371/1067], D_A_loss: 0.0698, D_B_loss: 0.0174, G_A_loss: 0.5637, G_B_loss: 0.4588\n",
      "Epoch [107/200], Step [381/1067], D_A_loss: 0.0534, D_B_loss: 0.0248, G_A_loss: 0.7901, G_B_loss: 0.5807\n",
      "Epoch [107/200], Step [391/1067], D_A_loss: 0.0286, D_B_loss: 0.0154, G_A_loss: 0.9267, G_B_loss: 0.7209\n",
      "Epoch [107/200], Step [401/1067], D_A_loss: 0.0918, D_B_loss: 0.0159, G_A_loss: 0.7616, G_B_loss: 0.5341\n",
      "Epoch [107/200], Step [411/1067], D_A_loss: 0.0214, D_B_loss: 0.0155, G_A_loss: 1.0455, G_B_loss: 0.8513\n",
      "Epoch [107/200], Step [421/1067], D_A_loss: 0.0613, D_B_loss: 0.0687, G_A_loss: 1.1143, G_B_loss: 0.4063\n",
      "Epoch [107/200], Step [431/1067], D_A_loss: 0.0862, D_B_loss: 0.0126, G_A_loss: 0.9882, G_B_loss: 0.4534\n",
      "Epoch [107/200], Step [441/1067], D_A_loss: 0.0774, D_B_loss: 0.0360, G_A_loss: 1.3082, G_B_loss: 0.4800\n",
      "Epoch [107/200], Step [451/1067], D_A_loss: 0.2136, D_B_loss: 0.0210, G_A_loss: 0.4679, G_B_loss: 0.9465\n",
      "Epoch [107/200], Step [461/1067], D_A_loss: 0.0870, D_B_loss: 0.0993, G_A_loss: 0.4314, G_B_loss: 0.5452\n",
      "Epoch [107/200], Step [471/1067], D_A_loss: 0.0286, D_B_loss: 0.0406, G_A_loss: 0.5887, G_B_loss: 0.5046\n",
      "Epoch [107/200], Step [481/1067], D_A_loss: 0.0820, D_B_loss: 0.0651, G_A_loss: 0.4781, G_B_loss: 0.3113\n",
      "Epoch [107/200], Step [491/1067], D_A_loss: 0.0796, D_B_loss: 0.0617, G_A_loss: 0.7160, G_B_loss: 0.1516\n",
      "Epoch [107/200], Step [501/1067], D_A_loss: 0.1100, D_B_loss: 0.1818, G_A_loss: 0.1776, G_B_loss: 0.6162\n",
      "Epoch [107/200], Step [511/1067], D_A_loss: 0.1404, D_B_loss: 0.0455, G_A_loss: 0.8149, G_B_loss: 0.5556\n",
      "Epoch [107/200], Step [521/1067], D_A_loss: 0.0772, D_B_loss: 0.0116, G_A_loss: 1.0153, G_B_loss: 0.6553\n",
      "Epoch [107/200], Step [531/1067], D_A_loss: 0.0460, D_B_loss: 0.0356, G_A_loss: 0.4120, G_B_loss: 0.6719\n",
      "Epoch [107/200], Step [541/1067], D_A_loss: 0.0701, D_B_loss: 0.0301, G_A_loss: 0.5019, G_B_loss: 0.9674\n",
      "Epoch [107/200], Step [551/1067], D_A_loss: 0.0686, D_B_loss: 0.0175, G_A_loss: 0.4275, G_B_loss: 0.4154\n",
      "Epoch [107/200], Step [561/1067], D_A_loss: 0.1261, D_B_loss: 0.0147, G_A_loss: 1.1192, G_B_loss: 0.3799\n",
      "Epoch [107/200], Step [571/1067], D_A_loss: 0.0372, D_B_loss: 0.0491, G_A_loss: 0.8951, G_B_loss: 0.7556\n",
      "Epoch [107/200], Step [581/1067], D_A_loss: 0.0320, D_B_loss: 0.0205, G_A_loss: 0.7290, G_B_loss: 0.5578\n",
      "Epoch [107/200], Step [591/1067], D_A_loss: 0.1072, D_B_loss: 0.0225, G_A_loss: 0.7239, G_B_loss: 0.4707\n",
      "Epoch [107/200], Step [601/1067], D_A_loss: 0.0990, D_B_loss: 0.0607, G_A_loss: 0.6308, G_B_loss: 0.4458\n",
      "Epoch [107/200], Step [611/1067], D_A_loss: 0.0999, D_B_loss: 0.0175, G_A_loss: 0.6403, G_B_loss: 0.4013\n",
      "Epoch [107/200], Step [621/1067], D_A_loss: 0.0435, D_B_loss: 0.0302, G_A_loss: 0.8954, G_B_loss: 0.6481\n",
      "Epoch [107/200], Step [631/1067], D_A_loss: 0.1520, D_B_loss: 0.0239, G_A_loss: 1.0108, G_B_loss: 1.2535\n",
      "Epoch [107/200], Step [641/1067], D_A_loss: 0.1734, D_B_loss: 0.0254, G_A_loss: 1.0326, G_B_loss: 0.5234\n",
      "Epoch [107/200], Step [651/1067], D_A_loss: 0.0767, D_B_loss: 0.0146, G_A_loss: 0.9223, G_B_loss: 0.6459\n",
      "Epoch [107/200], Step [661/1067], D_A_loss: 0.0440, D_B_loss: 0.0429, G_A_loss: 1.4213, G_B_loss: 0.6289\n",
      "Epoch [107/200], Step [671/1067], D_A_loss: 0.1394, D_B_loss: 0.0103, G_A_loss: 0.7077, G_B_loss: 0.8509\n",
      "Epoch [107/200], Step [681/1067], D_A_loss: 0.1449, D_B_loss: 0.1414, G_A_loss: 0.7526, G_B_loss: 0.4583\n",
      "Epoch [107/200], Step [691/1067], D_A_loss: 0.2309, D_B_loss: 0.0150, G_A_loss: 0.6963, G_B_loss: 0.1700\n",
      "Epoch [107/200], Step [701/1067], D_A_loss: 0.1203, D_B_loss: 0.0218, G_A_loss: 0.8308, G_B_loss: 0.6643\n",
      "Epoch [107/200], Step [711/1067], D_A_loss: 0.0368, D_B_loss: 0.0226, G_A_loss: 1.1880, G_B_loss: 0.7211\n",
      "Epoch [107/200], Step [721/1067], D_A_loss: 0.0238, D_B_loss: 0.0447, G_A_loss: 0.9038, G_B_loss: 0.1782\n",
      "Epoch [107/200], Step [731/1067], D_A_loss: 0.1197, D_B_loss: 0.0401, G_A_loss: 0.5579, G_B_loss: 0.2578\n",
      "Epoch [107/200], Step [741/1067], D_A_loss: 0.1113, D_B_loss: 0.0147, G_A_loss: 0.8210, G_B_loss: 0.5026\n",
      "Epoch [107/200], Step [751/1067], D_A_loss: 0.0493, D_B_loss: 0.0125, G_A_loss: 1.0025, G_B_loss: 0.1676\n",
      "Epoch [107/200], Step [761/1067], D_A_loss: 0.0984, D_B_loss: 0.0135, G_A_loss: 0.9832, G_B_loss: 0.3847\n",
      "Epoch [107/200], Step [771/1067], D_A_loss: 0.0739, D_B_loss: 0.0147, G_A_loss: 1.1406, G_B_loss: 0.6169\n",
      "Epoch [107/200], Step [781/1067], D_A_loss: 0.1508, D_B_loss: 0.0095, G_A_loss: 1.0598, G_B_loss: 0.7323\n",
      "Epoch [107/200], Step [791/1067], D_A_loss: 0.0606, D_B_loss: 0.0327, G_A_loss: 1.0729, G_B_loss: 0.4095\n",
      "Epoch [107/200], Step [801/1067], D_A_loss: 0.0611, D_B_loss: 0.0505, G_A_loss: 1.0643, G_B_loss: 0.5010\n",
      "Epoch [107/200], Step [811/1067], D_A_loss: 0.0649, D_B_loss: 0.0635, G_A_loss: 0.9643, G_B_loss: 0.7839\n",
      "Epoch [107/200], Step [821/1067], D_A_loss: 0.1382, D_B_loss: 0.0619, G_A_loss: 0.7946, G_B_loss: 0.4638\n",
      "Epoch [107/200], Step [831/1067], D_A_loss: 0.0692, D_B_loss: 0.0398, G_A_loss: 0.7461, G_B_loss: 0.5952\n",
      "Epoch [107/200], Step [841/1067], D_A_loss: 0.0466, D_B_loss: 0.0471, G_A_loss: 0.8167, G_B_loss: 0.6934\n",
      "Epoch [107/200], Step [851/1067], D_A_loss: 0.0363, D_B_loss: 0.0140, G_A_loss: 0.9231, G_B_loss: 0.3214\n",
      "Epoch [107/200], Step [861/1067], D_A_loss: 0.1622, D_B_loss: 0.0215, G_A_loss: 0.7807, G_B_loss: 0.3118\n",
      "Epoch [107/200], Step [871/1067], D_A_loss: 0.0828, D_B_loss: 0.0428, G_A_loss: 0.5725, G_B_loss: 0.5102\n",
      "Epoch [107/200], Step [881/1067], D_A_loss: 0.0887, D_B_loss: 0.0461, G_A_loss: 1.0870, G_B_loss: 0.3940\n",
      "Epoch [107/200], Step [891/1067], D_A_loss: 0.1905, D_B_loss: 0.0574, G_A_loss: 0.8414, G_B_loss: 0.5517\n",
      "Epoch [107/200], Step [901/1067], D_A_loss: 0.0236, D_B_loss: 0.0110, G_A_loss: 0.9765, G_B_loss: 0.2895\n",
      "Epoch [107/200], Step [911/1067], D_A_loss: 0.1782, D_B_loss: 0.0183, G_A_loss: 0.7841, G_B_loss: 0.4337\n",
      "Epoch [107/200], Step [921/1067], D_A_loss: 0.1148, D_B_loss: 0.0109, G_A_loss: 1.0262, G_B_loss: 0.4220\n",
      "Epoch [107/200], Step [931/1067], D_A_loss: 0.2426, D_B_loss: 0.0288, G_A_loss: 0.8981, G_B_loss: 0.8989\n",
      "Epoch [107/200], Step [941/1067], D_A_loss: 0.0770, D_B_loss: 0.0249, G_A_loss: 0.7635, G_B_loss: 0.6104\n",
      "Epoch [107/200], Step [951/1067], D_A_loss: 0.0546, D_B_loss: 0.0211, G_A_loss: 0.7875, G_B_loss: 0.5452\n",
      "Epoch [107/200], Step [961/1067], D_A_loss: 0.0446, D_B_loss: 0.0654, G_A_loss: 1.1410, G_B_loss: 0.8643\n",
      "Epoch [107/200], Step [971/1067], D_A_loss: 0.2000, D_B_loss: 0.0365, G_A_loss: 1.1461, G_B_loss: 0.2072\n",
      "Epoch [107/200], Step [981/1067], D_A_loss: 0.0672, D_B_loss: 0.0150, G_A_loss: 0.8025, G_B_loss: 0.8126\n",
      "Epoch [107/200], Step [991/1067], D_A_loss: 0.0767, D_B_loss: 0.0108, G_A_loss: 1.0636, G_B_loss: 0.6434\n",
      "Epoch [107/200], Step [1001/1067], D_A_loss: 0.1685, D_B_loss: 0.0269, G_A_loss: 0.6656, G_B_loss: 0.3926\n",
      "Epoch [107/200], Step [1011/1067], D_A_loss: 0.0586, D_B_loss: 0.0474, G_A_loss: 0.8339, G_B_loss: 0.8472\n",
      "Epoch [107/200], Step [1021/1067], D_A_loss: 0.2173, D_B_loss: 0.0546, G_A_loss: 0.9882, G_B_loss: 0.5835\n",
      "Epoch [107/200], Step [1031/1067], D_A_loss: 0.1656, D_B_loss: 0.0526, G_A_loss: 0.6825, G_B_loss: 0.9872\n",
      "Epoch [107/200], Step [1041/1067], D_A_loss: 0.1071, D_B_loss: 0.0135, G_A_loss: 0.7909, G_B_loss: 0.6801\n",
      "Epoch [107/200], Step [1051/1067], D_A_loss: 0.1015, D_B_loss: 0.0132, G_A_loss: 0.9468, G_B_loss: 0.4366\n",
      "Epoch [107/200], Step [1061/1067], D_A_loss: 0.1077, D_B_loss: 0.0160, G_A_loss: 0.7587, G_B_loss: 0.5552\n",
      "Epoch [108/200], Step [1/1067], D_A_loss: 0.0378, D_B_loss: 0.0131, G_A_loss: 0.9138, G_B_loss: 0.6141\n",
      "Epoch [108/200], Step [11/1067], D_A_loss: 0.1744, D_B_loss: 0.0118, G_A_loss: 0.8395, G_B_loss: 0.4040\n",
      "Epoch [108/200], Step [21/1067], D_A_loss: 0.0389, D_B_loss: 0.0196, G_A_loss: 0.4519, G_B_loss: 0.8997\n",
      "Epoch [108/200], Step [31/1067], D_A_loss: 0.1348, D_B_loss: 0.0125, G_A_loss: 0.5813, G_B_loss: 0.3227\n",
      "Epoch [108/200], Step [41/1067], D_A_loss: 0.0479, D_B_loss: 0.0710, G_A_loss: 0.6894, G_B_loss: 0.5422\n",
      "Epoch [108/200], Step [51/1067], D_A_loss: 0.2328, D_B_loss: 0.0119, G_A_loss: 0.9799, G_B_loss: 0.1751\n",
      "Epoch [108/200], Step [61/1067], D_A_loss: 0.0907, D_B_loss: 0.0177, G_A_loss: 0.8663, G_B_loss: 0.4204\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [108/200], Step [71/1067], D_A_loss: 0.1455, D_B_loss: 0.0211, G_A_loss: 1.0177, G_B_loss: 0.8598\n",
      "Epoch [108/200], Step [81/1067], D_A_loss: 0.0739, D_B_loss: 0.0110, G_A_loss: 1.1088, G_B_loss: 0.8029\n",
      "Epoch [108/200], Step [91/1067], D_A_loss: 0.0670, D_B_loss: 0.0737, G_A_loss: 0.8974, G_B_loss: 0.9256\n",
      "Epoch [108/200], Step [101/1067], D_A_loss: 0.1920, D_B_loss: 0.0152, G_A_loss: 1.1891, G_B_loss: 0.4165\n",
      "Epoch [108/200], Step [111/1067], D_A_loss: 0.2936, D_B_loss: 0.0527, G_A_loss: 0.5735, G_B_loss: 0.4335\n",
      "Epoch [108/200], Step [121/1067], D_A_loss: 0.0494, D_B_loss: 0.0804, G_A_loss: 0.8539, G_B_loss: 0.6132\n",
      "Epoch [108/200], Step [131/1067], D_A_loss: 0.1446, D_B_loss: 0.0340, G_A_loss: 1.0615, G_B_loss: 0.5466\n",
      "Epoch [108/200], Step [141/1067], D_A_loss: 0.1112, D_B_loss: 0.0275, G_A_loss: 0.7395, G_B_loss: 0.1494\n",
      "Epoch [108/200], Step [151/1067], D_A_loss: 0.1975, D_B_loss: 0.0213, G_A_loss: 0.6803, G_B_loss: 0.2842\n",
      "Epoch [108/200], Step [161/1067], D_A_loss: 0.0609, D_B_loss: 0.0264, G_A_loss: 1.3902, G_B_loss: 0.5017\n",
      "Epoch [108/200], Step [171/1067], D_A_loss: 0.0732, D_B_loss: 0.0145, G_A_loss: 1.1386, G_B_loss: 0.9342\n",
      "Epoch [108/200], Step [181/1067], D_A_loss: 0.0563, D_B_loss: 0.0079, G_A_loss: 0.9092, G_B_loss: 0.5587\n",
      "Epoch [108/200], Step [191/1067], D_A_loss: 0.0734, D_B_loss: 0.0372, G_A_loss: 0.7247, G_B_loss: 0.5158\n",
      "Epoch [108/200], Step [201/1067], D_A_loss: 0.0801, D_B_loss: 0.0102, G_A_loss: 0.9494, G_B_loss: 0.4295\n",
      "Epoch [108/200], Step [211/1067], D_A_loss: 0.0831, D_B_loss: 0.0460, G_A_loss: 0.7164, G_B_loss: 0.6571\n",
      "Epoch [108/200], Step [221/1067], D_A_loss: 0.1863, D_B_loss: 0.0410, G_A_loss: 0.6145, G_B_loss: 0.2575\n",
      "Epoch [108/200], Step [231/1067], D_A_loss: 0.0636, D_B_loss: 0.0507, G_A_loss: 0.4190, G_B_loss: 0.6236\n",
      "Epoch [108/200], Step [241/1067], D_A_loss: 0.1465, D_B_loss: 0.0457, G_A_loss: 1.2795, G_B_loss: 0.2775\n",
      "Epoch [108/200], Step [251/1067], D_A_loss: 0.1747, D_B_loss: 0.0148, G_A_loss: 0.6948, G_B_loss: 0.5111\n",
      "Epoch [108/200], Step [261/1067], D_A_loss: 0.0935, D_B_loss: 0.0402, G_A_loss: 0.9275, G_B_loss: 0.4781\n",
      "Epoch [108/200], Step [271/1067], D_A_loss: 0.0274, D_B_loss: 0.0263, G_A_loss: 0.9049, G_B_loss: 0.5650\n",
      "Epoch [108/200], Step [281/1067], D_A_loss: 0.0549, D_B_loss: 0.1112, G_A_loss: 0.3890, G_B_loss: 0.8749\n",
      "Epoch [108/200], Step [291/1067], D_A_loss: 0.0588, D_B_loss: 0.0745, G_A_loss: 0.3931, G_B_loss: 0.5863\n",
      "Epoch [108/200], Step [301/1067], D_A_loss: 0.0913, D_B_loss: 0.0224, G_A_loss: 0.8227, G_B_loss: 0.5389\n",
      "Epoch [108/200], Step [311/1067], D_A_loss: 0.1297, D_B_loss: 0.0596, G_A_loss: 0.6161, G_B_loss: 0.3934\n",
      "Epoch [108/200], Step [321/1067], D_A_loss: 0.0549, D_B_loss: 0.0635, G_A_loss: 0.8490, G_B_loss: 0.5530\n",
      "Epoch [108/200], Step [331/1067], D_A_loss: 0.0483, D_B_loss: 0.0617, G_A_loss: 0.5013, G_B_loss: 0.6091\n",
      "Epoch [108/200], Step [341/1067], D_A_loss: 0.0612, D_B_loss: 0.0110, G_A_loss: 0.9169, G_B_loss: 0.6226\n",
      "Epoch [108/200], Step [351/1067], D_A_loss: 0.1625, D_B_loss: 0.0163, G_A_loss: 0.8061, G_B_loss: 0.8066\n",
      "Epoch [108/200], Step [361/1067], D_A_loss: 0.0857, D_B_loss: 0.0148, G_A_loss: 0.6697, G_B_loss: 0.3879\n",
      "Epoch [108/200], Step [371/1067], D_A_loss: 0.0903, D_B_loss: 0.0503, G_A_loss: 0.5075, G_B_loss: 0.8399\n",
      "Epoch [108/200], Step [381/1067], D_A_loss: 0.0592, D_B_loss: 0.0169, G_A_loss: 0.8480, G_B_loss: 0.6188\n",
      "Epoch [108/200], Step [391/1067], D_A_loss: 0.1331, D_B_loss: 0.0236, G_A_loss: 0.8059, G_B_loss: 0.9228\n",
      "Epoch [108/200], Step [401/1067], D_A_loss: 0.1677, D_B_loss: 0.0132, G_A_loss: 0.9576, G_B_loss: 0.3091\n",
      "Epoch [108/200], Step [411/1067], D_A_loss: 0.0839, D_B_loss: 0.0279, G_A_loss: 1.0896, G_B_loss: 0.3574\n",
      "Epoch [108/200], Step [421/1067], D_A_loss: 0.0423, D_B_loss: 0.0200, G_A_loss: 0.6341, G_B_loss: 0.9076\n",
      "Epoch [108/200], Step [431/1067], D_A_loss: 0.1428, D_B_loss: 0.0318, G_A_loss: 0.6198, G_B_loss: 0.9838\n",
      "Epoch [108/200], Step [441/1067], D_A_loss: 0.1348, D_B_loss: 0.0286, G_A_loss: 1.0615, G_B_loss: 0.3105\n",
      "Epoch [108/200], Step [451/1067], D_A_loss: 0.2400, D_B_loss: 0.0799, G_A_loss: 1.3835, G_B_loss: 0.3152\n",
      "Epoch [108/200], Step [461/1067], D_A_loss: 0.0445, D_B_loss: 0.0160, G_A_loss: 1.0276, G_B_loss: 0.3270\n",
      "Epoch [108/200], Step [471/1067], D_A_loss: 0.0586, D_B_loss: 0.1020, G_A_loss: 1.2150, G_B_loss: 0.5924\n",
      "Epoch [108/200], Step [481/1067], D_A_loss: 0.1117, D_B_loss: 0.0459, G_A_loss: 0.8387, G_B_loss: 0.3515\n",
      "Epoch [108/200], Step [491/1067], D_A_loss: 0.0271, D_B_loss: 0.0183, G_A_loss: 0.6886, G_B_loss: 0.9767\n",
      "Epoch [108/200], Step [501/1067], D_A_loss: 0.1096, D_B_loss: 0.0412, G_A_loss: 0.5301, G_B_loss: 0.9028\n",
      "Epoch [108/200], Step [511/1067], D_A_loss: 0.2177, D_B_loss: 0.0430, G_A_loss: 0.8735, G_B_loss: 0.2210\n",
      "Epoch [108/200], Step [521/1067], D_A_loss: 0.0852, D_B_loss: 0.0252, G_A_loss: 0.8149, G_B_loss: 0.6054\n",
      "Epoch [108/200], Step [531/1067], D_A_loss: 0.0794, D_B_loss: 0.0178, G_A_loss: 0.8904, G_B_loss: 0.6406\n",
      "Epoch [108/200], Step [541/1067], D_A_loss: 0.0910, D_B_loss: 0.0250, G_A_loss: 1.1453, G_B_loss: 0.4495\n",
      "Epoch [108/200], Step [551/1067], D_A_loss: 0.3240, D_B_loss: 0.0296, G_A_loss: 1.1705, G_B_loss: 0.1216\n",
      "Epoch [108/200], Step [561/1067], D_A_loss: 0.2273, D_B_loss: 0.0416, G_A_loss: 0.7614, G_B_loss: 0.2902\n",
      "Epoch [108/200], Step [571/1067], D_A_loss: 0.1600, D_B_loss: 0.0280, G_A_loss: 0.8574, G_B_loss: 0.2856\n",
      "Epoch [108/200], Step [581/1067], D_A_loss: 0.1114, D_B_loss: 0.0465, G_A_loss: 0.8495, G_B_loss: 0.5866\n",
      "Epoch [108/200], Step [591/1067], D_A_loss: 0.1167, D_B_loss: 0.0229, G_A_loss: 1.0994, G_B_loss: 0.4054\n",
      "Epoch [108/200], Step [601/1067], D_A_loss: 0.0850, D_B_loss: 0.0210, G_A_loss: 0.6329, G_B_loss: 0.4617\n",
      "Epoch [108/200], Step [611/1067], D_A_loss: 0.0267, D_B_loss: 0.0133, G_A_loss: 0.5687, G_B_loss: 0.6554\n",
      "Epoch [108/200], Step [621/1067], D_A_loss: 0.0644, D_B_loss: 0.0188, G_A_loss: 0.8870, G_B_loss: 0.5994\n",
      "Epoch [108/200], Step [631/1067], D_A_loss: 0.3061, D_B_loss: 0.0278, G_A_loss: 0.7454, G_B_loss: 0.2312\n",
      "Epoch [108/200], Step [641/1067], D_A_loss: 0.0536, D_B_loss: 0.0208, G_A_loss: 1.1978, G_B_loss: 0.2629\n",
      "Epoch [108/200], Step [651/1067], D_A_loss: 0.0503, D_B_loss: 0.0110, G_A_loss: 1.0209, G_B_loss: 0.7061\n",
      "Epoch [108/200], Step [661/1067], D_A_loss: 0.1221, D_B_loss: 0.0212, G_A_loss: 0.7839, G_B_loss: 0.4607\n",
      "Epoch [108/200], Step [671/1067], D_A_loss: 0.0875, D_B_loss: 0.0407, G_A_loss: 0.8143, G_B_loss: 0.6245\n",
      "Epoch [108/200], Step [681/1067], D_A_loss: 0.0868, D_B_loss: 0.0341, G_A_loss: 0.7398, G_B_loss: 0.4248\n",
      "Epoch [108/200], Step [691/1067], D_A_loss: 0.0442, D_B_loss: 0.0158, G_A_loss: 0.7829, G_B_loss: 0.8242\n",
      "Epoch [108/200], Step [701/1067], D_A_loss: 0.1172, D_B_loss: 0.0354, G_A_loss: 1.0432, G_B_loss: 0.4168\n",
      "Epoch [108/200], Step [711/1067], D_A_loss: 0.0998, D_B_loss: 0.0313, G_A_loss: 0.5323, G_B_loss: 0.6194\n",
      "Epoch [108/200], Step [721/1067], D_A_loss: 0.0761, D_B_loss: 0.0109, G_A_loss: 0.7860, G_B_loss: 0.2711\n",
      "Epoch [108/200], Step [731/1067], D_A_loss: 0.0339, D_B_loss: 0.0423, G_A_loss: 1.0963, G_B_loss: 0.3641\n",
      "Epoch [108/200], Step [741/1067], D_A_loss: 0.1275, D_B_loss: 0.1288, G_A_loss: 0.8276, G_B_loss: 0.8797\n",
      "Epoch [108/200], Step [751/1067], D_A_loss: 0.0621, D_B_loss: 0.0492, G_A_loss: 0.6239, G_B_loss: 0.7296\n",
      "Epoch [108/200], Step [761/1067], D_A_loss: 0.0569, D_B_loss: 0.0127, G_A_loss: 0.7923, G_B_loss: 0.5880\n",
      "Epoch [108/200], Step [771/1067], D_A_loss: 0.1549, D_B_loss: 0.0308, G_A_loss: 0.8201, G_B_loss: 0.4873\n",
      "Epoch [108/200], Step [781/1067], D_A_loss: 0.3535, D_B_loss: 0.0124, G_A_loss: 1.0110, G_B_loss: 1.0718\n",
      "Epoch [108/200], Step [791/1067], D_A_loss: 0.0500, D_B_loss: 0.0867, G_A_loss: 0.4212, G_B_loss: 0.6407\n",
      "Epoch [108/200], Step [801/1067], D_A_loss: 0.1797, D_B_loss: 0.0226, G_A_loss: 0.9182, G_B_loss: 0.5893\n",
      "Epoch [108/200], Step [811/1067], D_A_loss: 0.0417, D_B_loss: 0.1659, G_A_loss: 0.8619, G_B_loss: 0.5171\n",
      "Epoch [108/200], Step [821/1067], D_A_loss: 0.1057, D_B_loss: 0.0592, G_A_loss: 0.4778, G_B_loss: 0.6332\n",
      "Epoch [108/200], Step [831/1067], D_A_loss: 0.0784, D_B_loss: 0.0200, G_A_loss: 0.8379, G_B_loss: 0.7442\n",
      "Epoch [108/200], Step [841/1067], D_A_loss: 0.0240, D_B_loss: 0.0169, G_A_loss: 0.9450, G_B_loss: 0.7535\n",
      "Epoch [108/200], Step [851/1067], D_A_loss: 0.1159, D_B_loss: 0.0111, G_A_loss: 0.9172, G_B_loss: 0.6434\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [108/200], Step [861/1067], D_A_loss: 0.2206, D_B_loss: 0.0449, G_A_loss: 0.6798, G_B_loss: 0.1357\n",
      "Epoch [108/200], Step [871/1067], D_A_loss: 0.0884, D_B_loss: 0.0435, G_A_loss: 1.0770, G_B_loss: 0.4395\n",
      "Epoch [108/200], Step [881/1067], D_A_loss: 0.0385, D_B_loss: 0.0305, G_A_loss: 0.7920, G_B_loss: 0.6557\n",
      "Epoch [108/200], Step [891/1067], D_A_loss: 0.0700, D_B_loss: 0.0816, G_A_loss: 1.9025, G_B_loss: 0.4956\n",
      "Epoch [108/200], Step [901/1067], D_A_loss: 0.0900, D_B_loss: 0.0677, G_A_loss: 0.7208, G_B_loss: 0.5196\n",
      "Epoch [108/200], Step [911/1067], D_A_loss: 0.0432, D_B_loss: 0.0466, G_A_loss: 0.9506, G_B_loss: 0.6266\n",
      "Epoch [108/200], Step [921/1067], D_A_loss: 0.0554, D_B_loss: 0.0409, G_A_loss: 0.7702, G_B_loss: 0.7006\n",
      "Epoch [108/200], Step [931/1067], D_A_loss: 0.3103, D_B_loss: 0.1693, G_A_loss: 1.0917, G_B_loss: 0.0862\n",
      "Epoch [108/200], Step [941/1067], D_A_loss: 0.1447, D_B_loss: 0.0257, G_A_loss: 0.6878, G_B_loss: 0.3447\n",
      "Epoch [108/200], Step [951/1067], D_A_loss: 0.0782, D_B_loss: 0.0367, G_A_loss: 0.9996, G_B_loss: 0.7327\n",
      "Epoch [108/200], Step [961/1067], D_A_loss: 0.0280, D_B_loss: 0.1859, G_A_loss: 0.6535, G_B_loss: 0.2715\n",
      "Epoch [108/200], Step [971/1067], D_A_loss: 0.0782, D_B_loss: 0.0226, G_A_loss: 0.7732, G_B_loss: 0.7847\n",
      "Epoch [108/200], Step [981/1067], D_A_loss: 0.0936, D_B_loss: 0.0157, G_A_loss: 0.5963, G_B_loss: 0.4898\n",
      "Epoch [108/200], Step [991/1067], D_A_loss: 0.1533, D_B_loss: 0.0673, G_A_loss: 1.1038, G_B_loss: 0.4610\n",
      "Epoch [108/200], Step [1001/1067], D_A_loss: 0.0405, D_B_loss: 0.0398, G_A_loss: 0.6829, G_B_loss: 0.5420\n",
      "Epoch [108/200], Step [1011/1067], D_A_loss: 0.1164, D_B_loss: 0.1528, G_A_loss: 0.8660, G_B_loss: 0.3820\n",
      "Epoch [108/200], Step [1021/1067], D_A_loss: 0.0418, D_B_loss: 0.0876, G_A_loss: 0.4227, G_B_loss: 0.8564\n",
      "Epoch [108/200], Step [1031/1067], D_A_loss: 0.0707, D_B_loss: 0.0345, G_A_loss: 0.7367, G_B_loss: 1.0579\n",
      "Epoch [108/200], Step [1041/1067], D_A_loss: 0.0532, D_B_loss: 0.0352, G_A_loss: 0.6303, G_B_loss: 0.7107\n",
      "Epoch [108/200], Step [1051/1067], D_A_loss: 0.0617, D_B_loss: 0.0524, G_A_loss: 1.0948, G_B_loss: 0.8086\n",
      "Epoch [108/200], Step [1061/1067], D_A_loss: 0.1711, D_B_loss: 0.0439, G_A_loss: 0.6423, G_B_loss: 0.3698\n",
      "Epoch [109/200], Step [1/1067], D_A_loss: 0.0633, D_B_loss: 0.0252, G_A_loss: 0.6986, G_B_loss: 0.5435\n",
      "Epoch [109/200], Step [11/1067], D_A_loss: 0.0902, D_B_loss: 0.0327, G_A_loss: 0.8650, G_B_loss: 0.7465\n",
      "Epoch [109/200], Step [21/1067], D_A_loss: 0.0271, D_B_loss: 0.0145, G_A_loss: 0.9105, G_B_loss: 0.6122\n",
      "Epoch [109/200], Step [31/1067], D_A_loss: 0.0539, D_B_loss: 0.0099, G_A_loss: 0.8111, G_B_loss: 0.7961\n",
      "Epoch [109/200], Step [41/1067], D_A_loss: 0.1599, D_B_loss: 0.0389, G_A_loss: 0.9127, G_B_loss: 0.1305\n",
      "Epoch [109/200], Step [51/1067], D_A_loss: 0.1131, D_B_loss: 0.0090, G_A_loss: 0.9003, G_B_loss: 0.7133\n",
      "Epoch [109/200], Step [61/1067], D_A_loss: 0.1549, D_B_loss: 0.0376, G_A_loss: 0.9883, G_B_loss: 0.6003\n",
      "Epoch [109/200], Step [71/1067], D_A_loss: 0.1140, D_B_loss: 0.0675, G_A_loss: 0.8447, G_B_loss: 0.8275\n",
      "Epoch [109/200], Step [81/1067], D_A_loss: 0.1510, D_B_loss: 0.0294, G_A_loss: 0.7310, G_B_loss: 0.2891\n",
      "Epoch [109/200], Step [91/1067], D_A_loss: 0.0597, D_B_loss: 0.0326, G_A_loss: 0.8228, G_B_loss: 1.4363\n",
      "Epoch [109/200], Step [101/1067], D_A_loss: 0.0257, D_B_loss: 0.0194, G_A_loss: 1.0715, G_B_loss: 0.2639\n",
      "Epoch [109/200], Step [111/1067], D_A_loss: 0.0327, D_B_loss: 0.0097, G_A_loss: 0.8919, G_B_loss: 0.5749\n",
      "Epoch [109/200], Step [121/1067], D_A_loss: 0.2261, D_B_loss: 0.0420, G_A_loss: 0.6004, G_B_loss: 0.1601\n",
      "Epoch [109/200], Step [131/1067], D_A_loss: 0.0557, D_B_loss: 0.0994, G_A_loss: 0.4897, G_B_loss: 0.4509\n",
      "Epoch [109/200], Step [141/1067], D_A_loss: 0.0834, D_B_loss: 0.0331, G_A_loss: 0.6738, G_B_loss: 0.4915\n",
      "Epoch [109/200], Step [151/1067], D_A_loss: 0.0461, D_B_loss: 0.0639, G_A_loss: 0.5235, G_B_loss: 0.6558\n",
      "Epoch [109/200], Step [161/1067], D_A_loss: 0.1017, D_B_loss: 0.0112, G_A_loss: 0.8306, G_B_loss: 0.4513\n",
      "Epoch [109/200], Step [171/1067], D_A_loss: 0.1846, D_B_loss: 0.1000, G_A_loss: 0.3411, G_B_loss: 0.6176\n",
      "Epoch [109/200], Step [181/1067], D_A_loss: 0.0847, D_B_loss: 0.0469, G_A_loss: 1.2737, G_B_loss: 0.3219\n",
      "Epoch [109/200], Step [191/1067], D_A_loss: 0.0406, D_B_loss: 0.0147, G_A_loss: 0.4087, G_B_loss: 0.6007\n",
      "Epoch [109/200], Step [201/1067], D_A_loss: 0.0755, D_B_loss: 0.0456, G_A_loss: 1.2136, G_B_loss: 0.5008\n",
      "Epoch [109/200], Step [211/1067], D_A_loss: 0.1049, D_B_loss: 0.0404, G_A_loss: 0.7950, G_B_loss: 0.6412\n",
      "Epoch [109/200], Step [221/1067], D_A_loss: 0.1407, D_B_loss: 0.0136, G_A_loss: 1.1108, G_B_loss: 0.3526\n",
      "Epoch [109/200], Step [231/1067], D_A_loss: 0.1597, D_B_loss: 0.1839, G_A_loss: 0.9170, G_B_loss: 1.6484\n",
      "Epoch [109/200], Step [241/1067], D_A_loss: 0.1327, D_B_loss: 0.0172, G_A_loss: 0.7839, G_B_loss: 0.9171\n",
      "Epoch [109/200], Step [251/1067], D_A_loss: 0.0268, D_B_loss: 0.0086, G_A_loss: 1.0676, G_B_loss: 0.3994\n",
      "Epoch [109/200], Step [261/1067], D_A_loss: 0.0414, D_B_loss: 0.0145, G_A_loss: 0.7733, G_B_loss: 0.1978\n",
      "Epoch [109/200], Step [271/1067], D_A_loss: 0.1052, D_B_loss: 0.0181, G_A_loss: 0.6970, G_B_loss: 0.9256\n",
      "Epoch [109/200], Step [281/1067], D_A_loss: 0.1161, D_B_loss: 0.0213, G_A_loss: 0.7870, G_B_loss: 0.3992\n",
      "Epoch [109/200], Step [291/1067], D_A_loss: 0.0347, D_B_loss: 0.0170, G_A_loss: 0.5803, G_B_loss: 0.2697\n",
      "Epoch [109/200], Step [301/1067], D_A_loss: 0.0275, D_B_loss: 0.0289, G_A_loss: 1.2652, G_B_loss: 0.0844\n",
      "Epoch [109/200], Step [311/1067], D_A_loss: 0.1610, D_B_loss: 0.0239, G_A_loss: 0.6920, G_B_loss: 0.6480\n",
      "Epoch [109/200], Step [321/1067], D_A_loss: 0.0780, D_B_loss: 0.0132, G_A_loss: 0.8284, G_B_loss: 0.7709\n",
      "Epoch [109/200], Step [331/1067], D_A_loss: 0.0382, D_B_loss: 0.0130, G_A_loss: 0.6387, G_B_loss: 0.8088\n",
      "Epoch [109/200], Step [341/1067], D_A_loss: 0.0942, D_B_loss: 0.0120, G_A_loss: 0.6212, G_B_loss: 0.3966\n",
      "Epoch [109/200], Step [351/1067], D_A_loss: 0.0713, D_B_loss: 0.0240, G_A_loss: 0.9011, G_B_loss: 0.4252\n",
      "Epoch [109/200], Step [361/1067], D_A_loss: 0.0887, D_B_loss: 0.0100, G_A_loss: 0.9293, G_B_loss: 0.4940\n",
      "Epoch [109/200], Step [371/1067], D_A_loss: 0.1686, D_B_loss: 0.0097, G_A_loss: 0.5092, G_B_loss: 0.5729\n",
      "Epoch [109/200], Step [381/1067], D_A_loss: 0.0636, D_B_loss: 0.0387, G_A_loss: 0.5922, G_B_loss: 0.6158\n",
      "Epoch [109/200], Step [391/1067], D_A_loss: 0.0280, D_B_loss: 0.0331, G_A_loss: 0.4847, G_B_loss: 0.3284\n",
      "Epoch [109/200], Step [401/1067], D_A_loss: 0.0474, D_B_loss: 0.0429, G_A_loss: 1.3669, G_B_loss: 0.6068\n",
      "Epoch [109/200], Step [411/1067], D_A_loss: 0.0434, D_B_loss: 0.0449, G_A_loss: 0.6609, G_B_loss: 0.9223\n",
      "Epoch [109/200], Step [421/1067], D_A_loss: 0.2440, D_B_loss: 0.0260, G_A_loss: 0.9154, G_B_loss: 0.1463\n",
      "Epoch [109/200], Step [431/1067], D_A_loss: 0.1093, D_B_loss: 0.0231, G_A_loss: 0.4574, G_B_loss: 0.7228\n",
      "Epoch [109/200], Step [441/1067], D_A_loss: 0.0471, D_B_loss: 0.0428, G_A_loss: 0.5635, G_B_loss: 0.2558\n",
      "Epoch [109/200], Step [451/1067], D_A_loss: 0.1156, D_B_loss: 0.0230, G_A_loss: 0.9187, G_B_loss: 0.4596\n",
      "Epoch [109/200], Step [461/1067], D_A_loss: 0.0790, D_B_loss: 0.0908, G_A_loss: 0.5808, G_B_loss: 0.4024\n",
      "Epoch [109/200], Step [471/1067], D_A_loss: 0.0606, D_B_loss: 0.0413, G_A_loss: 0.4432, G_B_loss: 0.8838\n",
      "Epoch [109/200], Step [481/1067], D_A_loss: 0.1873, D_B_loss: 0.0238, G_A_loss: 0.9698, G_B_loss: 0.6569\n",
      "Epoch [109/200], Step [491/1067], D_A_loss: 0.0688, D_B_loss: 0.0403, G_A_loss: 0.8180, G_B_loss: 0.6779\n",
      "Epoch [109/200], Step [501/1067], D_A_loss: 0.0344, D_B_loss: 0.0356, G_A_loss: 0.7171, G_B_loss: 0.6759\n",
      "Epoch [109/200], Step [511/1067], D_A_loss: 0.2036, D_B_loss: 0.0398, G_A_loss: 0.6839, G_B_loss: 0.3547\n",
      "Epoch [109/200], Step [521/1067], D_A_loss: 0.0717, D_B_loss: 0.0484, G_A_loss: 0.9352, G_B_loss: 0.2967\n",
      "Epoch [109/200], Step [531/1067], D_A_loss: 0.1008, D_B_loss: 0.1171, G_A_loss: 0.6938, G_B_loss: 0.5971\n",
      "Epoch [109/200], Step [541/1067], D_A_loss: 0.0745, D_B_loss: 0.0090, G_A_loss: 0.7044, G_B_loss: 0.5498\n",
      "Epoch [109/200], Step [551/1067], D_A_loss: 0.0383, D_B_loss: 0.0131, G_A_loss: 0.8286, G_B_loss: 0.2328\n",
      "Epoch [109/200], Step [561/1067], D_A_loss: 0.0410, D_B_loss: 0.0620, G_A_loss: 0.5086, G_B_loss: 0.3753\n",
      "Epoch [109/200], Step [571/1067], D_A_loss: 0.1465, D_B_loss: 0.0367, G_A_loss: 0.5228, G_B_loss: 0.3034\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [109/200], Step [581/1067], D_A_loss: 0.0431, D_B_loss: 0.0338, G_A_loss: 0.7802, G_B_loss: 0.3514\n",
      "Epoch [109/200], Step [591/1067], D_A_loss: 0.0898, D_B_loss: 0.0392, G_A_loss: 1.3633, G_B_loss: 0.5612\n",
      "Epoch [109/200], Step [601/1067], D_A_loss: 0.0834, D_B_loss: 0.0289, G_A_loss: 0.9040, G_B_loss: 0.5011\n",
      "Epoch [109/200], Step [611/1067], D_A_loss: 0.0968, D_B_loss: 0.0583, G_A_loss: 0.7691, G_B_loss: 0.4784\n",
      "Epoch [109/200], Step [621/1067], D_A_loss: 0.0254, D_B_loss: 0.0138, G_A_loss: 0.8460, G_B_loss: 0.6125\n",
      "Epoch [109/200], Step [631/1067], D_A_loss: 0.1150, D_B_loss: 0.0116, G_A_loss: 1.0510, G_B_loss: 0.4010\n",
      "Epoch [109/200], Step [641/1067], D_A_loss: 0.1341, D_B_loss: 0.0593, G_A_loss: 0.4131, G_B_loss: 0.3175\n",
      "Epoch [109/200], Step [651/1067], D_A_loss: 0.0600, D_B_loss: 0.1365, G_A_loss: 0.4144, G_B_loss: 0.6567\n",
      "Epoch [109/200], Step [661/1067], D_A_loss: 0.0892, D_B_loss: 0.0087, G_A_loss: 0.6525, G_B_loss: 0.4204\n",
      "Epoch [109/200], Step [671/1067], D_A_loss: 0.1733, D_B_loss: 0.0251, G_A_loss: 0.7164, G_B_loss: 0.2852\n",
      "Epoch [109/200], Step [681/1067], D_A_loss: 0.1431, D_B_loss: 0.0231, G_A_loss: 0.8825, G_B_loss: 0.2982\n",
      "Epoch [109/200], Step [691/1067], D_A_loss: 0.1377, D_B_loss: 0.0184, G_A_loss: 0.7671, G_B_loss: 0.2943\n",
      "Epoch [109/200], Step [701/1067], D_A_loss: 0.0688, D_B_loss: 0.0129, G_A_loss: 0.6412, G_B_loss: 0.5418\n",
      "Epoch [109/200], Step [711/1067], D_A_loss: 0.1304, D_B_loss: 0.0765, G_A_loss: 0.5244, G_B_loss: 0.2857\n",
      "Epoch [109/200], Step [721/1067], D_A_loss: 0.0457, D_B_loss: 0.0388, G_A_loss: 0.6052, G_B_loss: 0.9390\n",
      "Epoch [109/200], Step [731/1067], D_A_loss: 0.0685, D_B_loss: 0.0245, G_A_loss: 0.7019, G_B_loss: 0.4079\n",
      "Epoch [109/200], Step [741/1067], D_A_loss: 0.0619, D_B_loss: 0.0087, G_A_loss: 0.9797, G_B_loss: 0.4336\n",
      "Epoch [109/200], Step [751/1067], D_A_loss: 0.1921, D_B_loss: 0.0404, G_A_loss: 0.8796, G_B_loss: 0.3837\n",
      "Epoch [109/200], Step [761/1067], D_A_loss: 0.3198, D_B_loss: 0.0144, G_A_loss: 0.3632, G_B_loss: 0.4115\n",
      "Epoch [109/200], Step [771/1067], D_A_loss: 0.3333, D_B_loss: 0.0193, G_A_loss: 0.8049, G_B_loss: 0.5869\n",
      "Epoch [109/200], Step [781/1067], D_A_loss: 0.0311, D_B_loss: 0.0171, G_A_loss: 0.8271, G_B_loss: 0.2319\n",
      "Epoch [109/200], Step [791/1067], D_A_loss: 0.1091, D_B_loss: 0.0154, G_A_loss: 0.9359, G_B_loss: 0.4993\n",
      "Epoch [109/200], Step [801/1067], D_A_loss: 0.0860, D_B_loss: 0.0582, G_A_loss: 0.4779, G_B_loss: 0.7723\n",
      "Epoch [109/200], Step [811/1067], D_A_loss: 0.1182, D_B_loss: 0.0539, G_A_loss: 0.6916, G_B_loss: 0.8173\n",
      "Epoch [109/200], Step [821/1067], D_A_loss: 0.0504, D_B_loss: 0.0181, G_A_loss: 0.9653, G_B_loss: 0.4217\n",
      "Epoch [109/200], Step [831/1067], D_A_loss: 0.0830, D_B_loss: 0.0158, G_A_loss: 1.2155, G_B_loss: 0.4977\n",
      "Epoch [109/200], Step [841/1067], D_A_loss: 0.2258, D_B_loss: 0.0273, G_A_loss: 0.7537, G_B_loss: 1.1613\n",
      "Epoch [109/200], Step [851/1067], D_A_loss: 0.0898, D_B_loss: 0.0253, G_A_loss: 0.7124, G_B_loss: 0.5533\n",
      "Epoch [109/200], Step [861/1067], D_A_loss: 0.1723, D_B_loss: 0.0387, G_A_loss: 1.2186, G_B_loss: 0.2606\n",
      "Epoch [109/200], Step [871/1067], D_A_loss: 0.0501, D_B_loss: 0.0184, G_A_loss: 1.0064, G_B_loss: 0.3878\n",
      "Epoch [109/200], Step [881/1067], D_A_loss: 0.0860, D_B_loss: 0.0712, G_A_loss: 0.6977, G_B_loss: 0.4471\n",
      "Epoch [109/200], Step [891/1067], D_A_loss: 0.1271, D_B_loss: 0.0145, G_A_loss: 0.7067, G_B_loss: 0.5606\n",
      "Epoch [109/200], Step [901/1067], D_A_loss: 0.0635, D_B_loss: 0.0342, G_A_loss: 0.7002, G_B_loss: 0.8054\n",
      "Epoch [109/200], Step [911/1067], D_A_loss: 0.0400, D_B_loss: 0.0235, G_A_loss: 0.7355, G_B_loss: 0.9701\n",
      "Epoch [109/200], Step [921/1067], D_A_loss: 0.0438, D_B_loss: 0.0504, G_A_loss: 0.7136, G_B_loss: 0.4811\n",
      "Epoch [109/200], Step [931/1067], D_A_loss: 0.1146, D_B_loss: 0.0346, G_A_loss: 0.6137, G_B_loss: 1.1214\n",
      "Epoch [109/200], Step [941/1067], D_A_loss: 0.1490, D_B_loss: 0.0221, G_A_loss: 1.0697, G_B_loss: 0.5751\n",
      "Epoch [109/200], Step [951/1067], D_A_loss: 0.0745, D_B_loss: 0.0100, G_A_loss: 0.5421, G_B_loss: 0.6691\n",
      "Epoch [109/200], Step [961/1067], D_A_loss: 0.0829, D_B_loss: 0.0176, G_A_loss: 0.5999, G_B_loss: 0.9899\n",
      "Epoch [109/200], Step [971/1067], D_A_loss: 0.1472, D_B_loss: 0.0621, G_A_loss: 0.5714, G_B_loss: 0.3447\n",
      "Epoch [109/200], Step [981/1067], D_A_loss: 0.0359, D_B_loss: 0.0629, G_A_loss: 0.4446, G_B_loss: 0.6493\n",
      "Epoch [109/200], Step [991/1067], D_A_loss: 0.1790, D_B_loss: 0.0376, G_A_loss: 1.0699, G_B_loss: 0.9556\n",
      "Epoch [109/200], Step [1001/1067], D_A_loss: 0.2166, D_B_loss: 0.0498, G_A_loss: 0.7150, G_B_loss: 0.3408\n",
      "Epoch [109/200], Step [1011/1067], D_A_loss: 0.1660, D_B_loss: 0.0278, G_A_loss: 0.6942, G_B_loss: 0.4491\n",
      "Epoch [109/200], Step [1021/1067], D_A_loss: 0.2070, D_B_loss: 0.0182, G_A_loss: 0.8161, G_B_loss: 0.4948\n",
      "Epoch [109/200], Step [1031/1067], D_A_loss: 0.1408, D_B_loss: 0.0169, G_A_loss: 0.7430, G_B_loss: 0.2069\n",
      "Epoch [109/200], Step [1041/1067], D_A_loss: 0.0713, D_B_loss: 0.0139, G_A_loss: 1.0138, G_B_loss: 1.0473\n",
      "Epoch [109/200], Step [1051/1067], D_A_loss: 0.0448, D_B_loss: 0.0203, G_A_loss: 0.8418, G_B_loss: 0.6952\n",
      "Epoch [109/200], Step [1061/1067], D_A_loss: 0.0714, D_B_loss: 0.0144, G_A_loss: 1.0218, G_B_loss: 0.3733\n",
      "Epoch [110/200], Step [1/1067], D_A_loss: 0.0955, D_B_loss: 0.0158, G_A_loss: 0.8083, G_B_loss: 0.4005\n",
      "Epoch [110/200], Step [11/1067], D_A_loss: 0.1542, D_B_loss: 0.0589, G_A_loss: 0.7414, G_B_loss: 0.5117\n",
      "Epoch [110/200], Step [21/1067], D_A_loss: 0.2681, D_B_loss: 0.0197, G_A_loss: 0.5251, G_B_loss: 0.1585\n",
      "Epoch [110/200], Step [31/1067], D_A_loss: 0.0712, D_B_loss: 0.0508, G_A_loss: 0.5945, G_B_loss: 0.6816\n",
      "Epoch [110/200], Step [41/1067], D_A_loss: 0.0611, D_B_loss: 0.0142, G_A_loss: 0.8750, G_B_loss: 0.7143\n",
      "Epoch [110/200], Step [51/1067], D_A_loss: 0.0369, D_B_loss: 0.0361, G_A_loss: 0.6166, G_B_loss: 0.6371\n",
      "Epoch [110/200], Step [61/1067], D_A_loss: 0.0348, D_B_loss: 0.0431, G_A_loss: 0.6063, G_B_loss: 0.8336\n",
      "Epoch [110/200], Step [71/1067], D_A_loss: 0.0530, D_B_loss: 0.0241, G_A_loss: 0.9781, G_B_loss: 0.4829\n",
      "Epoch [110/200], Step [81/1067], D_A_loss: 0.1859, D_B_loss: 0.0194, G_A_loss: 1.2749, G_B_loss: 0.5099\n",
      "Epoch [110/200], Step [91/1067], D_A_loss: 0.0720, D_B_loss: 0.0126, G_A_loss: 0.8539, G_B_loss: 0.7133\n",
      "Epoch [110/200], Step [101/1067], D_A_loss: 0.0801, D_B_loss: 0.0322, G_A_loss: 0.4532, G_B_loss: 0.6682\n",
      "Epoch [110/200], Step [111/1067], D_A_loss: 0.0943, D_B_loss: 0.0667, G_A_loss: 0.6732, G_B_loss: 0.7507\n",
      "Epoch [110/200], Step [121/1067], D_A_loss: 0.0658, D_B_loss: 0.0273, G_A_loss: 0.6617, G_B_loss: 0.5043\n",
      "Epoch [110/200], Step [131/1067], D_A_loss: 0.1903, D_B_loss: 0.0225, G_A_loss: 0.8254, G_B_loss: 0.1894\n",
      "Epoch [110/200], Step [141/1067], D_A_loss: 0.1349, D_B_loss: 0.0235, G_A_loss: 0.8298, G_B_loss: 0.3400\n",
      "Epoch [110/200], Step [151/1067], D_A_loss: 0.1397, D_B_loss: 0.0348, G_A_loss: 0.7193, G_B_loss: 0.2735\n",
      "Epoch [110/200], Step [161/1067], D_A_loss: 0.0505, D_B_loss: 0.0343, G_A_loss: 0.8241, G_B_loss: 0.2944\n",
      "Epoch [110/200], Step [171/1067], D_A_loss: 0.0773, D_B_loss: 0.0305, G_A_loss: 0.8498, G_B_loss: 0.3872\n",
      "Epoch [110/200], Step [181/1067], D_A_loss: 0.0398, D_B_loss: 0.0298, G_A_loss: 0.7896, G_B_loss: 0.5671\n",
      "Epoch [110/200], Step [191/1067], D_A_loss: 0.0717, D_B_loss: 0.0207, G_A_loss: 0.9564, G_B_loss: 0.4797\n",
      "Epoch [110/200], Step [201/1067], D_A_loss: 0.0989, D_B_loss: 0.0853, G_A_loss: 1.4696, G_B_loss: 0.2091\n",
      "Epoch [110/200], Step [211/1067], D_A_loss: 0.0360, D_B_loss: 0.0127, G_A_loss: 0.9649, G_B_loss: 0.5275\n",
      "Epoch [110/200], Step [221/1067], D_A_loss: 0.1135, D_B_loss: 0.0322, G_A_loss: 0.4978, G_B_loss: 0.7492\n",
      "Epoch [110/200], Step [231/1067], D_A_loss: 0.0311, D_B_loss: 0.0190, G_A_loss: 0.8910, G_B_loss: 0.5310\n",
      "Epoch [110/200], Step [241/1067], D_A_loss: 0.1751, D_B_loss: 0.0164, G_A_loss: 0.7888, G_B_loss: 0.3566\n",
      "Epoch [110/200], Step [251/1067], D_A_loss: 0.0873, D_B_loss: 0.0454, G_A_loss: 0.9139, G_B_loss: 0.5151\n",
      "Epoch [110/200], Step [261/1067], D_A_loss: 0.0841, D_B_loss: 0.0127, G_A_loss: 1.0159, G_B_loss: 0.6591\n",
      "Epoch [110/200], Step [271/1067], D_A_loss: 0.0499, D_B_loss: 0.0164, G_A_loss: 0.9773, G_B_loss: 0.5523\n",
      "Epoch [110/200], Step [281/1067], D_A_loss: 0.0599, D_B_loss: 0.0364, G_A_loss: 0.6352, G_B_loss: 0.5397\n",
      "Epoch [110/200], Step [291/1067], D_A_loss: 0.0262, D_B_loss: 0.0253, G_A_loss: 0.4985, G_B_loss: 0.3156\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [110/200], Step [301/1067], D_A_loss: 0.0855, D_B_loss: 0.0592, G_A_loss: 1.0758, G_B_loss: 0.9609\n",
      "Epoch [110/200], Step [311/1067], D_A_loss: 0.1255, D_B_loss: 0.0223, G_A_loss: 0.7370, G_B_loss: 0.6934\n",
      "Epoch [110/200], Step [321/1067], D_A_loss: 0.1837, D_B_loss: 0.0142, G_A_loss: 0.8957, G_B_loss: 0.4511\n",
      "Epoch [110/200], Step [331/1067], D_A_loss: 0.1977, D_B_loss: 0.0220, G_A_loss: 0.9516, G_B_loss: 1.0488\n",
      "Epoch [110/200], Step [341/1067], D_A_loss: 0.0389, D_B_loss: 0.0093, G_A_loss: 0.9681, G_B_loss: 0.5535\n",
      "Epoch [110/200], Step [351/1067], D_A_loss: 0.2607, D_B_loss: 0.1380, G_A_loss: 0.8240, G_B_loss: 0.1103\n",
      "Epoch [110/200], Step [361/1067], D_A_loss: 0.0252, D_B_loss: 0.0461, G_A_loss: 0.7592, G_B_loss: 0.8312\n",
      "Epoch [110/200], Step [371/1067], D_A_loss: 0.1258, D_B_loss: 0.0377, G_A_loss: 0.6410, G_B_loss: 0.3410\n",
      "Epoch [110/200], Step [381/1067], D_A_loss: 0.1349, D_B_loss: 0.0074, G_A_loss: 1.0223, G_B_loss: 0.2839\n",
      "Epoch [110/200], Step [391/1067], D_A_loss: 0.1962, D_B_loss: 0.0115, G_A_loss: 1.0416, G_B_loss: 0.7737\n",
      "Epoch [110/200], Step [401/1067], D_A_loss: 0.0575, D_B_loss: 0.0154, G_A_loss: 1.1566, G_B_loss: 0.9232\n",
      "Epoch [110/200], Step [411/1067], D_A_loss: 0.0506, D_B_loss: 0.0536, G_A_loss: 1.0038, G_B_loss: 0.1510\n",
      "Epoch [110/200], Step [421/1067], D_A_loss: 0.2770, D_B_loss: 0.0256, G_A_loss: 1.2135, G_B_loss: 0.1101\n",
      "Epoch [110/200], Step [431/1067], D_A_loss: 0.0206, D_B_loss: 0.0102, G_A_loss: 0.9399, G_B_loss: 0.5533\n",
      "Epoch [110/200], Step [441/1067], D_A_loss: 0.0575, D_B_loss: 0.0248, G_A_loss: 1.2932, G_B_loss: 0.5855\n",
      "Epoch [110/200], Step [451/1067], D_A_loss: 0.0666, D_B_loss: 0.0860, G_A_loss: 0.9698, G_B_loss: 0.7056\n",
      "Epoch [110/200], Step [461/1067], D_A_loss: 0.0978, D_B_loss: 0.0240, G_A_loss: 1.1901, G_B_loss: 0.4977\n",
      "Epoch [110/200], Step [471/1067], D_A_loss: 0.0971, D_B_loss: 0.0127, G_A_loss: 0.9068, G_B_loss: 0.4021\n",
      "Epoch [110/200], Step [481/1067], D_A_loss: 0.1690, D_B_loss: 0.0297, G_A_loss: 0.6120, G_B_loss: 0.3480\n",
      "Epoch [110/200], Step [491/1067], D_A_loss: 0.0772, D_B_loss: 0.0726, G_A_loss: 0.4485, G_B_loss: 0.4478\n",
      "Epoch [110/200], Step [501/1067], D_A_loss: 0.1634, D_B_loss: 0.0525, G_A_loss: 1.0331, G_B_loss: 0.6788\n",
      "Epoch [110/200], Step [511/1067], D_A_loss: 0.0590, D_B_loss: 0.0289, G_A_loss: 1.0742, G_B_loss: 0.5395\n",
      "Epoch [110/200], Step [521/1067], D_A_loss: 0.0590, D_B_loss: 0.0372, G_A_loss: 0.6706, G_B_loss: 1.0979\n",
      "Epoch [110/200], Step [531/1067], D_A_loss: 0.0838, D_B_loss: 0.0228, G_A_loss: 0.8480, G_B_loss: 0.7615\n",
      "Epoch [110/200], Step [541/1067], D_A_loss: 0.1056, D_B_loss: 0.0149, G_A_loss: 1.0957, G_B_loss: 1.1992\n",
      "Epoch [110/200], Step [551/1067], D_A_loss: 0.1554, D_B_loss: 0.0313, G_A_loss: 0.5371, G_B_loss: 0.2814\n",
      "Epoch [110/200], Step [561/1067], D_A_loss: 0.1368, D_B_loss: 0.0287, G_A_loss: 1.1165, G_B_loss: 0.3939\n",
      "Epoch [110/200], Step [571/1067], D_A_loss: 0.0403, D_B_loss: 0.0113, G_A_loss: 0.6877, G_B_loss: 0.4505\n",
      "Epoch [110/200], Step [581/1067], D_A_loss: 0.1248, D_B_loss: 0.0409, G_A_loss: 1.1797, G_B_loss: 0.3522\n",
      "Epoch [110/200], Step [591/1067], D_A_loss: 0.0649, D_B_loss: 0.0086, G_A_loss: 0.6997, G_B_loss: 0.5344\n",
      "Epoch [110/200], Step [601/1067], D_A_loss: 0.2072, D_B_loss: 0.0888, G_A_loss: 0.4105, G_B_loss: 0.9680\n",
      "Epoch [110/200], Step [611/1067], D_A_loss: 0.0593, D_B_loss: 0.0130, G_A_loss: 0.8899, G_B_loss: 0.3421\n",
      "Epoch [110/200], Step [621/1067], D_A_loss: 0.1103, D_B_loss: 0.0215, G_A_loss: 1.0530, G_B_loss: 0.7624\n",
      "Epoch [110/200], Step [631/1067], D_A_loss: 0.1195, D_B_loss: 0.0112, G_A_loss: 0.7136, G_B_loss: 0.4611\n",
      "Epoch [110/200], Step [641/1067], D_A_loss: 0.0563, D_B_loss: 0.0416, G_A_loss: 1.1258, G_B_loss: 0.4587\n",
      "Epoch [110/200], Step [651/1067], D_A_loss: 0.2544, D_B_loss: 0.0279, G_A_loss: 0.7557, G_B_loss: 0.1718\n",
      "Epoch [110/200], Step [661/1067], D_A_loss: 0.3077, D_B_loss: 0.0164, G_A_loss: 0.8850, G_B_loss: 0.1434\n",
      "Epoch [110/200], Step [671/1067], D_A_loss: 0.1504, D_B_loss: 0.0137, G_A_loss: 1.0327, G_B_loss: 0.2811\n",
      "Epoch [110/200], Step [681/1067], D_A_loss: 0.1621, D_B_loss: 0.0666, G_A_loss: 0.4183, G_B_loss: 0.4431\n",
      "Epoch [110/200], Step [691/1067], D_A_loss: 0.0902, D_B_loss: 0.0353, G_A_loss: 1.1410, G_B_loss: 0.3958\n",
      "Epoch [110/200], Step [701/1067], D_A_loss: 0.0444, D_B_loss: 0.0356, G_A_loss: 0.9557, G_B_loss: 0.1810\n",
      "Epoch [110/200], Step [711/1067], D_A_loss: 0.1708, D_B_loss: 0.0104, G_A_loss: 1.1635, G_B_loss: 0.5297\n",
      "Epoch [110/200], Step [721/1067], D_A_loss: 0.0806, D_B_loss: 0.0196, G_A_loss: 0.8620, G_B_loss: 0.5936\n",
      "Epoch [110/200], Step [731/1067], D_A_loss: 0.1669, D_B_loss: 0.0167, G_A_loss: 1.0069, G_B_loss: 0.8754\n",
      "Epoch [110/200], Step [741/1067], D_A_loss: 0.2392, D_B_loss: 0.0209, G_A_loss: 0.8608, G_B_loss: 0.4594\n",
      "Epoch [110/200], Step [751/1067], D_A_loss: 0.0649, D_B_loss: 0.0594, G_A_loss: 1.0400, G_B_loss: 0.5294\n",
      "Epoch [110/200], Step [761/1067], D_A_loss: 0.0356, D_B_loss: 0.0184, G_A_loss: 1.1825, G_B_loss: 0.4502\n",
      "Epoch [110/200], Step [771/1067], D_A_loss: 0.1459, D_B_loss: 0.0235, G_A_loss: 0.7508, G_B_loss: 0.6296\n",
      "Epoch [110/200], Step [781/1067], D_A_loss: 0.0718, D_B_loss: 0.0360, G_A_loss: 0.5308, G_B_loss: 0.4910\n",
      "Epoch [110/200], Step [791/1067], D_A_loss: 0.0467, D_B_loss: 0.0141, G_A_loss: 0.9854, G_B_loss: 0.4225\n",
      "Epoch [110/200], Step [801/1067], D_A_loss: 0.0162, D_B_loss: 0.0153, G_A_loss: 0.8930, G_B_loss: 0.9740\n",
      "Epoch [110/200], Step [811/1067], D_A_loss: 0.0739, D_B_loss: 0.0399, G_A_loss: 0.5832, G_B_loss: 0.6042\n",
      "Epoch [110/200], Step [821/1067], D_A_loss: 0.1626, D_B_loss: 0.0129, G_A_loss: 1.1173, G_B_loss: 0.2466\n",
      "Epoch [110/200], Step [831/1067], D_A_loss: 0.1006, D_B_loss: 0.0596, G_A_loss: 1.0251, G_B_loss: 0.5026\n",
      "Epoch [110/200], Step [841/1067], D_A_loss: 0.1556, D_B_loss: 0.0238, G_A_loss: 0.7806, G_B_loss: 1.0035\n",
      "Epoch [110/200], Step [851/1067], D_A_loss: 0.2090, D_B_loss: 0.1430, G_A_loss: 0.5851, G_B_loss: 0.4073\n",
      "Epoch [110/200], Step [861/1067], D_A_loss: 0.1141, D_B_loss: 0.0164, G_A_loss: 1.0534, G_B_loss: 0.3955\n",
      "Epoch [110/200], Step [871/1067], D_A_loss: 0.0824, D_B_loss: 0.0556, G_A_loss: 1.0949, G_B_loss: 0.5858\n",
      "Epoch [110/200], Step [881/1067], D_A_loss: 0.1464, D_B_loss: 0.0259, G_A_loss: 1.3644, G_B_loss: 0.3930\n",
      "Epoch [110/200], Step [891/1067], D_A_loss: 0.1795, D_B_loss: 0.0057, G_A_loss: 0.9894, G_B_loss: 0.5316\n",
      "Epoch [110/200], Step [901/1067], D_A_loss: 0.1249, D_B_loss: 0.0208, G_A_loss: 0.7781, G_B_loss: 0.5619\n",
      "Epoch [110/200], Step [911/1067], D_A_loss: 0.0371, D_B_loss: 0.0097, G_A_loss: 0.8651, G_B_loss: 0.4535\n",
      "Epoch [110/200], Step [921/1067], D_A_loss: 0.2067, D_B_loss: 0.0233, G_A_loss: 0.7014, G_B_loss: 0.2193\n",
      "Epoch [110/200], Step [931/1067], D_A_loss: 0.0757, D_B_loss: 0.0102, G_A_loss: 0.8502, G_B_loss: 0.4762\n",
      "Epoch [110/200], Step [941/1067], D_A_loss: 0.0556, D_B_loss: 0.0300, G_A_loss: 0.6830, G_B_loss: 0.4465\n",
      "Epoch [110/200], Step [951/1067], D_A_loss: 0.2201, D_B_loss: 0.0181, G_A_loss: 0.6916, G_B_loss: 0.5113\n",
      "Epoch [110/200], Step [961/1067], D_A_loss: 0.2185, D_B_loss: 0.0171, G_A_loss: 0.9918, G_B_loss: 0.2057\n",
      "Epoch [110/200], Step [971/1067], D_A_loss: 0.0785, D_B_loss: 0.0239, G_A_loss: 0.7189, G_B_loss: 0.6577\n",
      "Epoch [110/200], Step [981/1067], D_A_loss: 0.0354, D_B_loss: 0.0075, G_A_loss: 0.9626, G_B_loss: 0.4161\n",
      "Epoch [110/200], Step [991/1067], D_A_loss: 0.0939, D_B_loss: 0.0139, G_A_loss: 0.8964, G_B_loss: 0.3585\n",
      "Epoch [110/200], Step [1001/1067], D_A_loss: 0.0615, D_B_loss: 0.0682, G_A_loss: 0.5789, G_B_loss: 0.9990\n",
      "Epoch [110/200], Step [1011/1067], D_A_loss: 0.1182, D_B_loss: 0.0153, G_A_loss: 0.9624, G_B_loss: 0.3038\n",
      "Epoch [110/200], Step [1021/1067], D_A_loss: 0.0820, D_B_loss: 0.0320, G_A_loss: 0.5855, G_B_loss: 0.4987\n",
      "Epoch [110/200], Step [1031/1067], D_A_loss: 0.0486, D_B_loss: 0.0555, G_A_loss: 0.5412, G_B_loss: 0.3696\n",
      "Epoch [110/200], Step [1041/1067], D_A_loss: 0.0970, D_B_loss: 0.0866, G_A_loss: 0.5481, G_B_loss: 0.7128\n",
      "Epoch [110/200], Step [1051/1067], D_A_loss: 0.0756, D_B_loss: 0.0202, G_A_loss: 0.9725, G_B_loss: 0.6513\n",
      "Epoch [110/200], Step [1061/1067], D_A_loss: 0.0670, D_B_loss: 0.0131, G_A_loss: 1.2009, G_B_loss: 0.9228\n",
      "Epoch [111/200], Step [1/1067], D_A_loss: 0.1328, D_B_loss: 0.0242, G_A_loss: 0.6735, G_B_loss: 0.2983\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [111/200], Step [11/1067], D_A_loss: 0.0904, D_B_loss: 0.0183, G_A_loss: 0.7960, G_B_loss: 0.4209\n",
      "Epoch [111/200], Step [21/1067], D_A_loss: 0.1693, D_B_loss: 0.0252, G_A_loss: 0.7298, G_B_loss: 0.3487\n",
      "Epoch [111/200], Step [31/1067], D_A_loss: 0.1076, D_B_loss: 0.0166, G_A_loss: 1.0261, G_B_loss: 0.4131\n",
      "Epoch [111/200], Step [41/1067], D_A_loss: 0.1304, D_B_loss: 0.0233, G_A_loss: 0.8528, G_B_loss: 0.5641\n",
      "Epoch [111/200], Step [51/1067], D_A_loss: 0.1059, D_B_loss: 0.0179, G_A_loss: 0.9983, G_B_loss: 0.5149\n",
      "Epoch [111/200], Step [61/1067], D_A_loss: 0.1118, D_B_loss: 0.0607, G_A_loss: 0.5120, G_B_loss: 0.5959\n",
      "Epoch [111/200], Step [71/1067], D_A_loss: 0.0263, D_B_loss: 0.0518, G_A_loss: 0.8990, G_B_loss: 0.6007\n",
      "Epoch [111/200], Step [81/1067], D_A_loss: 0.0460, D_B_loss: 0.0335, G_A_loss: 0.7269, G_B_loss: 0.5559\n",
      "Epoch [111/200], Step [91/1067], D_A_loss: 0.0376, D_B_loss: 0.0402, G_A_loss: 0.6383, G_B_loss: 0.7890\n",
      "Epoch [111/200], Step [101/1067], D_A_loss: 0.0450, D_B_loss: 0.0192, G_A_loss: 0.9557, G_B_loss: 0.3668\n",
      "Epoch [111/200], Step [111/1067], D_A_loss: 0.1940, D_B_loss: 0.0452, G_A_loss: 0.6451, G_B_loss: 0.5004\n",
      "Epoch [111/200], Step [121/1067], D_A_loss: 0.0924, D_B_loss: 0.0990, G_A_loss: 0.5465, G_B_loss: 1.0269\n",
      "Epoch [111/200], Step [131/1067], D_A_loss: 0.3217, D_B_loss: 0.0911, G_A_loss: 1.1375, G_B_loss: 0.0905\n",
      "Epoch [111/200], Step [141/1067], D_A_loss: 0.1698, D_B_loss: 0.0081, G_A_loss: 1.0751, G_B_loss: 0.1889\n",
      "Epoch [111/200], Step [151/1067], D_A_loss: 0.0669, D_B_loss: 0.0187, G_A_loss: 0.5781, G_B_loss: 1.1448\n",
      "Epoch [111/200], Step [161/1067], D_A_loss: 0.1039, D_B_loss: 0.0721, G_A_loss: 0.7237, G_B_loss: 0.3946\n",
      "Epoch [111/200], Step [171/1067], D_A_loss: 0.0718, D_B_loss: 0.0289, G_A_loss: 1.2968, G_B_loss: 0.6660\n",
      "Epoch [111/200], Step [181/1067], D_A_loss: 0.2781, D_B_loss: 0.0329, G_A_loss: 0.7173, G_B_loss: 0.7124\n",
      "Epoch [111/200], Step [191/1067], D_A_loss: 0.0962, D_B_loss: 0.2107, G_A_loss: 0.8108, G_B_loss: 0.4254\n",
      "Epoch [111/200], Step [201/1067], D_A_loss: 0.0829, D_B_loss: 0.0402, G_A_loss: 0.5781, G_B_loss: 0.3493\n",
      "Epoch [111/200], Step [211/1067], D_A_loss: 0.1465, D_B_loss: 0.0829, G_A_loss: 0.4507, G_B_loss: 0.5928\n",
      "Epoch [111/200], Step [221/1067], D_A_loss: 0.0487, D_B_loss: 0.0448, G_A_loss: 0.7766, G_B_loss: 0.3201\n",
      "Epoch [111/200], Step [231/1067], D_A_loss: 0.0498, D_B_loss: 0.0346, G_A_loss: 1.0418, G_B_loss: 0.5679\n",
      "Epoch [111/200], Step [241/1067], D_A_loss: 0.0840, D_B_loss: 0.0342, G_A_loss: 0.9014, G_B_loss: 0.6562\n",
      "Epoch [111/200], Step [251/1067], D_A_loss: 0.0352, D_B_loss: 0.0207, G_A_loss: 0.9733, G_B_loss: 0.3031\n",
      "Epoch [111/200], Step [261/1067], D_A_loss: 0.1064, D_B_loss: 0.0160, G_A_loss: 0.8212, G_B_loss: 1.0256\n",
      "Epoch [111/200], Step [271/1067], D_A_loss: 0.1338, D_B_loss: 0.0189, G_A_loss: 1.2886, G_B_loss: 0.7832\n",
      "Epoch [111/200], Step [281/1067], D_A_loss: 0.1648, D_B_loss: 0.0388, G_A_loss: 1.4556, G_B_loss: 0.5084\n",
      "Epoch [111/200], Step [291/1067], D_A_loss: 0.1080, D_B_loss: 0.0216, G_A_loss: 0.4004, G_B_loss: 0.5536\n",
      "Epoch [111/200], Step [301/1067], D_A_loss: 0.1532, D_B_loss: 0.0183, G_A_loss: 0.8609, G_B_loss: 0.5408\n",
      "Epoch [111/200], Step [311/1067], D_A_loss: 0.1060, D_B_loss: 0.0147, G_A_loss: 0.9435, G_B_loss: 0.3912\n",
      "Epoch [111/200], Step [321/1067], D_A_loss: 0.0313, D_B_loss: 0.0134, G_A_loss: 0.8167, G_B_loss: 0.4598\n",
      "Epoch [111/200], Step [331/1067], D_A_loss: 0.0775, D_B_loss: 0.0088, G_A_loss: 0.6155, G_B_loss: 0.6036\n",
      "Epoch [111/200], Step [341/1067], D_A_loss: 0.0314, D_B_loss: 0.0273, G_A_loss: 0.8970, G_B_loss: 0.9438\n",
      "Epoch [111/200], Step [351/1067], D_A_loss: 0.0771, D_B_loss: 0.0418, G_A_loss: 0.8270, G_B_loss: 0.5220\n",
      "Epoch [111/200], Step [361/1067], D_A_loss: 0.0920, D_B_loss: 0.0122, G_A_loss: 0.7478, G_B_loss: 0.6090\n",
      "Epoch [111/200], Step [371/1067], D_A_loss: 0.1282, D_B_loss: 0.0119, G_A_loss: 0.9569, G_B_loss: 0.9289\n",
      "Epoch [111/200], Step [381/1067], D_A_loss: 0.0306, D_B_loss: 0.0150, G_A_loss: 1.0379, G_B_loss: 0.5139\n",
      "Epoch [111/200], Step [391/1067], D_A_loss: 0.1024, D_B_loss: 0.0153, G_A_loss: 0.6201, G_B_loss: 0.4327\n",
      "Epoch [111/200], Step [401/1067], D_A_loss: 0.0944, D_B_loss: 0.0137, G_A_loss: 0.9221, G_B_loss: 0.5339\n",
      "Epoch [111/200], Step [411/1067], D_A_loss: 0.1299, D_B_loss: 0.0296, G_A_loss: 0.7007, G_B_loss: 0.7655\n",
      "Epoch [111/200], Step [421/1067], D_A_loss: 0.0412, D_B_loss: 0.0908, G_A_loss: 0.3896, G_B_loss: 0.7315\n",
      "Epoch [111/200], Step [431/1067], D_A_loss: 0.0404, D_B_loss: 0.0279, G_A_loss: 0.7780, G_B_loss: 0.7111\n",
      "Epoch [111/200], Step [441/1067], D_A_loss: 0.1266, D_B_loss: 0.0220, G_A_loss: 0.6810, G_B_loss: 1.0822\n",
      "Epoch [111/200], Step [451/1067], D_A_loss: 0.1413, D_B_loss: 0.0238, G_A_loss: 1.2905, G_B_loss: 0.7175\n",
      "Epoch [111/200], Step [461/1067], D_A_loss: 0.0376, D_B_loss: 0.0439, G_A_loss: 0.5029, G_B_loss: 0.2534\n",
      "Epoch [111/200], Step [471/1067], D_A_loss: 0.1888, D_B_loss: 0.0125, G_A_loss: 0.9120, G_B_loss: 0.7856\n",
      "Epoch [111/200], Step [481/1067], D_A_loss: 0.0439, D_B_loss: 0.0114, G_A_loss: 1.0447, G_B_loss: 0.1889\n",
      "Epoch [111/200], Step [491/1067], D_A_loss: 0.0377, D_B_loss: 0.0523, G_A_loss: 0.5836, G_B_loss: 0.6781\n",
      "Epoch [111/200], Step [501/1067], D_A_loss: 0.0726, D_B_loss: 0.0204, G_A_loss: 0.9814, G_B_loss: 0.5862\n",
      "Epoch [111/200], Step [511/1067], D_A_loss: 0.0305, D_B_loss: 0.0285, G_A_loss: 1.0609, G_B_loss: 0.3420\n",
      "Epoch [111/200], Step [521/1067], D_A_loss: 0.1225, D_B_loss: 0.0111, G_A_loss: 1.0408, G_B_loss: 0.7587\n",
      "Epoch [111/200], Step [531/1067], D_A_loss: 0.1766, D_B_loss: 0.0197, G_A_loss: 0.7564, G_B_loss: 0.6777\n",
      "Epoch [111/200], Step [541/1067], D_A_loss: 0.1342, D_B_loss: 0.0134, G_A_loss: 0.4939, G_B_loss: 0.9776\n",
      "Epoch [111/200], Step [551/1067], D_A_loss: 0.1510, D_B_loss: 0.2209, G_A_loss: 0.2420, G_B_loss: 0.7804\n",
      "Epoch [111/200], Step [561/1067], D_A_loss: 0.0955, D_B_loss: 0.0404, G_A_loss: 0.8317, G_B_loss: 0.7350\n",
      "Epoch [111/200], Step [571/1067], D_A_loss: 0.0542, D_B_loss: 0.0561, G_A_loss: 0.5700, G_B_loss: 0.7893\n",
      "Epoch [111/200], Step [581/1067], D_A_loss: 0.1261, D_B_loss: 0.0222, G_A_loss: 0.8456, G_B_loss: 0.3738\n",
      "Epoch [111/200], Step [591/1067], D_A_loss: 0.2160, D_B_loss: 0.0338, G_A_loss: 0.7273, G_B_loss: 0.4732\n",
      "Epoch [111/200], Step [601/1067], D_A_loss: 0.0530, D_B_loss: 0.0148, G_A_loss: 0.8043, G_B_loss: 0.5824\n",
      "Epoch [111/200], Step [611/1067], D_A_loss: 0.1013, D_B_loss: 0.0451, G_A_loss: 1.0953, G_B_loss: 0.3251\n",
      "Epoch [111/200], Step [621/1067], D_A_loss: 0.0457, D_B_loss: 0.0236, G_A_loss: 1.5376, G_B_loss: 0.4181\n",
      "Epoch [111/200], Step [631/1067], D_A_loss: 0.1788, D_B_loss: 0.0198, G_A_loss: 1.0713, G_B_loss: 0.5319\n",
      "Epoch [111/200], Step [641/1067], D_A_loss: 0.0681, D_B_loss: 0.0330, G_A_loss: 0.8899, G_B_loss: 0.5440\n",
      "Epoch [111/200], Step [651/1067], D_A_loss: 0.0892, D_B_loss: 0.0696, G_A_loss: 1.1758, G_B_loss: 0.6223\n",
      "Epoch [111/200], Step [661/1067], D_A_loss: 0.1015, D_B_loss: 0.0124, G_A_loss: 0.5302, G_B_loss: 0.6171\n",
      "Epoch [111/200], Step [671/1067], D_A_loss: 0.0660, D_B_loss: 0.0345, G_A_loss: 0.9881, G_B_loss: 0.8747\n",
      "Epoch [111/200], Step [681/1067], D_A_loss: 0.1446, D_B_loss: 0.0717, G_A_loss: 0.9210, G_B_loss: 0.2744\n",
      "Epoch [111/200], Step [691/1067], D_A_loss: 0.1050, D_B_loss: 0.0340, G_A_loss: 0.7518, G_B_loss: 0.4074\n",
      "Epoch [111/200], Step [701/1067], D_A_loss: 0.1305, D_B_loss: 0.0226, G_A_loss: 0.7415, G_B_loss: 1.1306\n",
      "Epoch [111/200], Step [711/1067], D_A_loss: 0.1559, D_B_loss: 0.0232, G_A_loss: 1.0394, G_B_loss: 0.3597\n",
      "Epoch [111/200], Step [721/1067], D_A_loss: 0.0348, D_B_loss: 0.0096, G_A_loss: 0.8522, G_B_loss: 0.8951\n",
      "Epoch [111/200], Step [731/1067], D_A_loss: 0.1302, D_B_loss: 0.0155, G_A_loss: 1.0052, G_B_loss: 0.4069\n",
      "Epoch [111/200], Step [741/1067], D_A_loss: 0.1694, D_B_loss: 0.0331, G_A_loss: 0.6107, G_B_loss: 0.4292\n",
      "Epoch [111/200], Step [751/1067], D_A_loss: 0.0940, D_B_loss: 0.0119, G_A_loss: 0.6991, G_B_loss: 0.5690\n",
      "Epoch [111/200], Step [761/1067], D_A_loss: 0.0642, D_B_loss: 0.0267, G_A_loss: 1.1620, G_B_loss: 0.8157\n",
      "Epoch [111/200], Step [771/1067], D_A_loss: 0.0282, D_B_loss: 0.0348, G_A_loss: 0.6386, G_B_loss: 0.9372\n",
      "Epoch [111/200], Step [781/1067], D_A_loss: 0.0470, D_B_loss: 0.0338, G_A_loss: 1.1326, G_B_loss: 0.5035\n",
      "Epoch [111/200], Step [791/1067], D_A_loss: 0.0426, D_B_loss: 0.0224, G_A_loss: 1.0042, G_B_loss: 0.6663\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [111/200], Step [801/1067], D_A_loss: 0.1557, D_B_loss: 0.0252, G_A_loss: 1.2738, G_B_loss: 0.3050\n",
      "Epoch [111/200], Step [811/1067], D_A_loss: 0.0391, D_B_loss: 0.0213, G_A_loss: 1.0550, G_B_loss: 0.5649\n",
      "Epoch [111/200], Step [821/1067], D_A_loss: 0.1314, D_B_loss: 0.0437, G_A_loss: 0.6243, G_B_loss: 0.5366\n",
      "Epoch [111/200], Step [831/1067], D_A_loss: 0.0314, D_B_loss: 0.0339, G_A_loss: 0.9607, G_B_loss: 0.7811\n",
      "Epoch [111/200], Step [841/1067], D_A_loss: 0.1008, D_B_loss: 0.0323, G_A_loss: 0.6314, G_B_loss: 0.3419\n",
      "Epoch [111/200], Step [851/1067], D_A_loss: 0.0656, D_B_loss: 0.0931, G_A_loss: 0.4332, G_B_loss: 0.7716\n",
      "Epoch [111/200], Step [861/1067], D_A_loss: 0.1684, D_B_loss: 0.0112, G_A_loss: 0.6316, G_B_loss: 0.2481\n",
      "Epoch [111/200], Step [871/1067], D_A_loss: 0.1604, D_B_loss: 0.0732, G_A_loss: 1.2267, G_B_loss: 0.7312\n",
      "Epoch [111/200], Step [881/1067], D_A_loss: 0.0271, D_B_loss: 0.0515, G_A_loss: 0.6467, G_B_loss: 0.6955\n",
      "Epoch [111/200], Step [891/1067], D_A_loss: 0.2214, D_B_loss: 0.0364, G_A_loss: 0.6980, G_B_loss: 0.2502\n",
      "Epoch [111/200], Step [901/1067], D_A_loss: 0.2144, D_B_loss: 0.0191, G_A_loss: 0.9296, G_B_loss: 0.5324\n",
      "Epoch [111/200], Step [911/1067], D_A_loss: 0.1564, D_B_loss: 0.0196, G_A_loss: 0.9459, G_B_loss: 0.3822\n",
      "Epoch [111/200], Step [921/1067], D_A_loss: 0.0722, D_B_loss: 0.1095, G_A_loss: 0.5843, G_B_loss: 0.5165\n",
      "Epoch [111/200], Step [931/1067], D_A_loss: 0.0609, D_B_loss: 0.0448, G_A_loss: 0.6848, G_B_loss: 0.5862\n",
      "Epoch [111/200], Step [941/1067], D_A_loss: 0.1047, D_B_loss: 0.0288, G_A_loss: 1.0520, G_B_loss: 0.8544\n",
      "Epoch [111/200], Step [951/1067], D_A_loss: 0.0899, D_B_loss: 0.0098, G_A_loss: 0.6248, G_B_loss: 0.5148\n",
      "Epoch [111/200], Step [961/1067], D_A_loss: 0.0479, D_B_loss: 0.0431, G_A_loss: 0.6222, G_B_loss: 1.0639\n",
      "Epoch [111/200], Step [971/1067], D_A_loss: 0.0833, D_B_loss: 0.0155, G_A_loss: 0.9037, G_B_loss: 0.5425\n",
      "Epoch [111/200], Step [981/1067], D_A_loss: 0.0838, D_B_loss: 0.0161, G_A_loss: 1.2636, G_B_loss: 0.4790\n",
      "Epoch [111/200], Step [991/1067], D_A_loss: 0.1683, D_B_loss: 0.0514, G_A_loss: 1.1166, G_B_loss: 0.4656\n",
      "Epoch [111/200], Step [1001/1067], D_A_loss: 0.1249, D_B_loss: 0.0356, G_A_loss: 0.7076, G_B_loss: 0.3144\n",
      "Epoch [111/200], Step [1011/1067], D_A_loss: 0.0813, D_B_loss: 0.0716, G_A_loss: 0.8764, G_B_loss: 0.4884\n",
      "Epoch [111/200], Step [1021/1067], D_A_loss: 0.1048, D_B_loss: 0.0253, G_A_loss: 0.7791, G_B_loss: 0.3515\n",
      "Epoch [111/200], Step [1031/1067], D_A_loss: 0.1771, D_B_loss: 0.0162, G_A_loss: 0.6900, G_B_loss: 0.4076\n",
      "Epoch [111/200], Step [1041/1067], D_A_loss: 0.1434, D_B_loss: 0.0524, G_A_loss: 0.5450, G_B_loss: 1.0167\n",
      "Epoch [111/200], Step [1051/1067], D_A_loss: 0.0305, D_B_loss: 0.0263, G_A_loss: 0.6890, G_B_loss: 0.7335\n",
      "Epoch [111/200], Step [1061/1067], D_A_loss: 0.1404, D_B_loss: 0.0648, G_A_loss: 0.6649, G_B_loss: 0.2864\n",
      "Epoch [112/200], Step [1/1067], D_A_loss: 0.0541, D_B_loss: 0.0542, G_A_loss: 0.7631, G_B_loss: 0.5355\n",
      "Epoch [112/200], Step [11/1067], D_A_loss: 0.0653, D_B_loss: 0.0144, G_A_loss: 0.7889, G_B_loss: 0.5715\n",
      "Epoch [112/200], Step [21/1067], D_A_loss: 0.2086, D_B_loss: 0.0268, G_A_loss: 0.9645, G_B_loss: 0.2647\n",
      "Epoch [112/200], Step [31/1067], D_A_loss: 0.0629, D_B_loss: 0.0178, G_A_loss: 1.2535, G_B_loss: 0.5630\n",
      "Epoch [112/200], Step [41/1067], D_A_loss: 0.0873, D_B_loss: 0.0343, G_A_loss: 0.7759, G_B_loss: 0.5070\n",
      "Epoch [112/200], Step [51/1067], D_A_loss: 0.2039, D_B_loss: 0.0085, G_A_loss: 0.7664, G_B_loss: 0.1714\n",
      "Epoch [112/200], Step [61/1067], D_A_loss: 0.0416, D_B_loss: 0.0305, G_A_loss: 1.2192, G_B_loss: 0.2911\n",
      "Epoch [112/200], Step [71/1067], D_A_loss: 0.0509, D_B_loss: 0.0265, G_A_loss: 0.7205, G_B_loss: 0.4725\n",
      "Epoch [112/200], Step [81/1067], D_A_loss: 0.0662, D_B_loss: 0.0896, G_A_loss: 1.0757, G_B_loss: 0.6265\n",
      "Epoch [112/200], Step [91/1067], D_A_loss: 0.0546, D_B_loss: 0.0208, G_A_loss: 0.8969, G_B_loss: 0.8307\n",
      "Epoch [112/200], Step [101/1067], D_A_loss: 0.1152, D_B_loss: 0.0483, G_A_loss: 0.9408, G_B_loss: 0.6632\n",
      "Epoch [112/200], Step [111/1067], D_A_loss: 0.0452, D_B_loss: 0.0349, G_A_loss: 0.9482, G_B_loss: 0.7164\n",
      "Epoch [112/200], Step [121/1067], D_A_loss: 0.1295, D_B_loss: 0.0605, G_A_loss: 1.2420, G_B_loss: 0.3741\n",
      "Epoch [112/200], Step [131/1067], D_A_loss: 0.0940, D_B_loss: 0.0136, G_A_loss: 1.2068, G_B_loss: 0.5673\n",
      "Epoch [112/200], Step [141/1067], D_A_loss: 0.0392, D_B_loss: 0.0177, G_A_loss: 0.6180, G_B_loss: 0.4786\n",
      "Epoch [112/200], Step [151/1067], D_A_loss: 0.0314, D_B_loss: 0.0601, G_A_loss: 0.9700, G_B_loss: 0.6036\n",
      "Epoch [112/200], Step [161/1067], D_A_loss: 0.0353, D_B_loss: 0.0363, G_A_loss: 1.1686, G_B_loss: 0.3832\n",
      "Epoch [112/200], Step [171/1067], D_A_loss: 0.0925, D_B_loss: 0.0460, G_A_loss: 0.6185, G_B_loss: 0.5997\n",
      "Epoch [112/200], Step [181/1067], D_A_loss: 0.2032, D_B_loss: 0.0215, G_A_loss: 0.9512, G_B_loss: 0.2578\n",
      "Epoch [112/200], Step [191/1067], D_A_loss: 0.1294, D_B_loss: 0.0118, G_A_loss: 1.0271, G_B_loss: 1.1896\n",
      "Epoch [112/200], Step [201/1067], D_A_loss: 0.0373, D_B_loss: 0.0260, G_A_loss: 1.1330, G_B_loss: 0.9338\n",
      "Epoch [112/200], Step [211/1067], D_A_loss: 0.1038, D_B_loss: 0.0490, G_A_loss: 0.8521, G_B_loss: 0.8861\n",
      "Epoch [112/200], Step [221/1067], D_A_loss: 0.0340, D_B_loss: 0.0180, G_A_loss: 1.2110, G_B_loss: 0.6263\n",
      "Epoch [112/200], Step [231/1067], D_A_loss: 0.0241, D_B_loss: 0.0373, G_A_loss: 0.6141, G_B_loss: 0.5890\n",
      "Epoch [112/200], Step [241/1067], D_A_loss: 0.0754, D_B_loss: 0.0251, G_A_loss: 0.7856, G_B_loss: 0.5051\n",
      "Epoch [112/200], Step [251/1067], D_A_loss: 0.1156, D_B_loss: 0.0357, G_A_loss: 1.0931, G_B_loss: 0.3904\n",
      "Epoch [112/200], Step [261/1067], D_A_loss: 0.0937, D_B_loss: 0.0166, G_A_loss: 1.2055, G_B_loss: 1.0035\n",
      "Epoch [112/200], Step [271/1067], D_A_loss: 0.2257, D_B_loss: 0.0352, G_A_loss: 1.4190, G_B_loss: 0.2101\n",
      "Epoch [112/200], Step [281/1067], D_A_loss: 0.0552, D_B_loss: 0.0405, G_A_loss: 0.3451, G_B_loss: 0.4999\n",
      "Epoch [112/200], Step [291/1067], D_A_loss: 0.1878, D_B_loss: 0.0092, G_A_loss: 1.0941, G_B_loss: 0.4953\n",
      "Epoch [112/200], Step [301/1067], D_A_loss: 0.1092, D_B_loss: 0.0230, G_A_loss: 0.6963, G_B_loss: 0.3784\n",
      "Epoch [112/200], Step [311/1067], D_A_loss: 0.0667, D_B_loss: 0.1104, G_A_loss: 0.7540, G_B_loss: 0.5009\n",
      "Epoch [112/200], Step [321/1067], D_A_loss: 0.1005, D_B_loss: 0.0374, G_A_loss: 0.5386, G_B_loss: 0.7110\n",
      "Epoch [112/200], Step [331/1067], D_A_loss: 0.1875, D_B_loss: 0.0334, G_A_loss: 1.1930, G_B_loss: 0.9055\n",
      "Epoch [112/200], Step [341/1067], D_A_loss: 0.1030, D_B_loss: 0.0154, G_A_loss: 0.8000, G_B_loss: 0.6751\n",
      "Epoch [112/200], Step [351/1067], D_A_loss: 0.4315, D_B_loss: 0.0265, G_A_loss: 1.0612, G_B_loss: 0.0450\n",
      "Epoch [112/200], Step [361/1067], D_A_loss: 0.0483, D_B_loss: 0.0239, G_A_loss: 0.5262, G_B_loss: 0.4390\n",
      "Epoch [112/200], Step [371/1067], D_A_loss: 0.0449, D_B_loss: 0.0182, G_A_loss: 0.7617, G_B_loss: 0.7859\n",
      "Epoch [112/200], Step [381/1067], D_A_loss: 0.0397, D_B_loss: 0.0330, G_A_loss: 0.7671, G_B_loss: 0.9458\n",
      "Epoch [112/200], Step [391/1067], D_A_loss: 0.0881, D_B_loss: 0.0209, G_A_loss: 1.1427, G_B_loss: 0.2468\n",
      "Epoch [112/200], Step [401/1067], D_A_loss: 0.0927, D_B_loss: 0.0459, G_A_loss: 0.9037, G_B_loss: 0.7005\n",
      "Epoch [112/200], Step [411/1067], D_A_loss: 0.1025, D_B_loss: 0.0315, G_A_loss: 0.6438, G_B_loss: 0.9117\n",
      "Epoch [112/200], Step [421/1067], D_A_loss: 0.0940, D_B_loss: 0.0722, G_A_loss: 0.5254, G_B_loss: 0.3918\n",
      "Epoch [112/200], Step [431/1067], D_A_loss: 0.1299, D_B_loss: 0.0659, G_A_loss: 0.5112, G_B_loss: 0.3275\n",
      "Epoch [112/200], Step [441/1067], D_A_loss: 0.0352, D_B_loss: 0.0242, G_A_loss: 1.1512, G_B_loss: 0.7568\n",
      "Epoch [112/200], Step [451/1067], D_A_loss: 0.1172, D_B_loss: 0.0639, G_A_loss: 0.7228, G_B_loss: 0.3406\n",
      "Epoch [112/200], Step [461/1067], D_A_loss: 0.0582, D_B_loss: 0.0305, G_A_loss: 0.7310, G_B_loss: 0.4993\n",
      "Epoch [112/200], Step [471/1067], D_A_loss: 0.2195, D_B_loss: 0.1316, G_A_loss: 1.2771, G_B_loss: 0.2279\n",
      "Epoch [112/200], Step [481/1067], D_A_loss: 0.1464, D_B_loss: 0.0169, G_A_loss: 0.4784, G_B_loss: 0.4354\n",
      "Epoch [112/200], Step [491/1067], D_A_loss: 0.0262, D_B_loss: 0.0588, G_A_loss: 1.1555, G_B_loss: 0.4833\n",
      "Epoch [112/200], Step [501/1067], D_A_loss: 0.0729, D_B_loss: 0.0131, G_A_loss: 1.0667, G_B_loss: 0.5087\n",
      "Epoch [112/200], Step [511/1067], D_A_loss: 0.1491, D_B_loss: 0.0252, G_A_loss: 0.8324, G_B_loss: 0.2930\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [112/200], Step [521/1067], D_A_loss: 0.0710, D_B_loss: 0.0132, G_A_loss: 1.1754, G_B_loss: 0.5860\n",
      "Epoch [112/200], Step [531/1067], D_A_loss: 0.1895, D_B_loss: 0.0102, G_A_loss: 0.9356, G_B_loss: 0.3234\n",
      "Epoch [112/200], Step [541/1067], D_A_loss: 0.0506, D_B_loss: 0.0182, G_A_loss: 1.1159, G_B_loss: 0.7904\n",
      "Epoch [112/200], Step [551/1067], D_A_loss: 0.1771, D_B_loss: 0.0135, G_A_loss: 1.0912, G_B_loss: 0.2977\n",
      "Epoch [112/200], Step [561/1067], D_A_loss: 0.0533, D_B_loss: 0.0439, G_A_loss: 0.7124, G_B_loss: 0.8092\n",
      "Epoch [112/200], Step [571/1067], D_A_loss: 0.0826, D_B_loss: 0.0236, G_A_loss: 1.1336, G_B_loss: 0.5936\n",
      "Epoch [112/200], Step [581/1067], D_A_loss: 0.1529, D_B_loss: 0.0193, G_A_loss: 1.0396, G_B_loss: 0.2645\n",
      "Epoch [112/200], Step [591/1067], D_A_loss: 0.1037, D_B_loss: 0.0289, G_A_loss: 0.6565, G_B_loss: 0.4282\n",
      "Epoch [112/200], Step [601/1067], D_A_loss: 0.0591, D_B_loss: 0.0178, G_A_loss: 0.9751, G_B_loss: 0.7003\n",
      "Epoch [112/200], Step [611/1067], D_A_loss: 0.0739, D_B_loss: 0.0161, G_A_loss: 0.9843, G_B_loss: 0.7073\n",
      "Epoch [112/200], Step [621/1067], D_A_loss: 0.0599, D_B_loss: 0.0347, G_A_loss: 0.6397, G_B_loss: 0.3316\n",
      "Epoch [112/200], Step [631/1067], D_A_loss: 0.1358, D_B_loss: 0.0784, G_A_loss: 0.2980, G_B_loss: 0.6284\n",
      "Epoch [112/200], Step [641/1067], D_A_loss: 0.1383, D_B_loss: 0.0076, G_A_loss: 1.2404, G_B_loss: 0.3813\n",
      "Epoch [112/200], Step [651/1067], D_A_loss: 0.0562, D_B_loss: 0.3470, G_A_loss: 1.1010, G_B_loss: 0.2960\n",
      "Epoch [112/200], Step [661/1067], D_A_loss: 0.1081, D_B_loss: 0.0294, G_A_loss: 0.6502, G_B_loss: 0.4970\n",
      "Epoch [112/200], Step [671/1067], D_A_loss: 0.1050, D_B_loss: 0.0256, G_A_loss: 0.6338, G_B_loss: 0.3643\n",
      "Epoch [112/200], Step [681/1067], D_A_loss: 0.0473, D_B_loss: 0.0415, G_A_loss: 0.7642, G_B_loss: 0.3766\n",
      "Epoch [112/200], Step [691/1067], D_A_loss: 0.0567, D_B_loss: 0.0235, G_A_loss: 0.9294, G_B_loss: 0.5236\n",
      "Epoch [112/200], Step [701/1067], D_A_loss: 0.1742, D_B_loss: 0.0117, G_A_loss: 0.9323, G_B_loss: 0.8162\n",
      "Epoch [112/200], Step [711/1067], D_A_loss: 0.1974, D_B_loss: 0.0433, G_A_loss: 0.9589, G_B_loss: 0.8942\n",
      "Epoch [112/200], Step [721/1067], D_A_loss: 0.0740, D_B_loss: 0.0163, G_A_loss: 0.7909, G_B_loss: 0.5393\n",
      "Epoch [112/200], Step [731/1067], D_A_loss: 0.1229, D_B_loss: 0.0253, G_A_loss: 0.8398, G_B_loss: 0.8123\n",
      "Epoch [112/200], Step [741/1067], D_A_loss: 0.1531, D_B_loss: 0.0132, G_A_loss: 0.8827, G_B_loss: 0.7640\n",
      "Epoch [112/200], Step [751/1067], D_A_loss: 0.1368, D_B_loss: 0.0151, G_A_loss: 0.8138, G_B_loss: 0.4124\n",
      "Epoch [112/200], Step [761/1067], D_A_loss: 0.1930, D_B_loss: 0.0185, G_A_loss: 0.6831, G_B_loss: 0.3679\n",
      "Epoch [112/200], Step [771/1067], D_A_loss: 0.0536, D_B_loss: 0.0502, G_A_loss: 1.0197, G_B_loss: 0.6035\n",
      "Epoch [112/200], Step [781/1067], D_A_loss: 0.0773, D_B_loss: 0.0272, G_A_loss: 0.7653, G_B_loss: 0.5301\n",
      "Epoch [112/200], Step [791/1067], D_A_loss: 0.0490, D_B_loss: 0.0632, G_A_loss: 0.4851, G_B_loss: 0.7017\n",
      "Epoch [112/200], Step [801/1067], D_A_loss: 0.0957, D_B_loss: 0.0115, G_A_loss: 0.7232, G_B_loss: 0.3785\n",
      "Epoch [112/200], Step [811/1067], D_A_loss: 0.1532, D_B_loss: 0.0269, G_A_loss: 0.8072, G_B_loss: 0.2964\n",
      "Epoch [112/200], Step [821/1067], D_A_loss: 0.0449, D_B_loss: 0.0490, G_A_loss: 1.4051, G_B_loss: 0.7588\n",
      "Epoch [112/200], Step [831/1067], D_A_loss: 0.1189, D_B_loss: 0.0726, G_A_loss: 1.2340, G_B_loss: 0.6616\n",
      "Epoch [112/200], Step [841/1067], D_A_loss: 0.2015, D_B_loss: 0.0146, G_A_loss: 0.9922, G_B_loss: 0.2528\n",
      "Epoch [112/200], Step [851/1067], D_A_loss: 0.0421, D_B_loss: 0.0551, G_A_loss: 0.7237, G_B_loss: 0.5744\n",
      "Epoch [112/200], Step [861/1067], D_A_loss: 0.0794, D_B_loss: 0.0342, G_A_loss: 0.8476, G_B_loss: 0.3949\n",
      "Epoch [112/200], Step [871/1067], D_A_loss: 0.0834, D_B_loss: 0.0130, G_A_loss: 0.9129, G_B_loss: 0.5130\n",
      "Epoch [112/200], Step [881/1067], D_A_loss: 0.0532, D_B_loss: 0.0405, G_A_loss: 0.8386, G_B_loss: 0.9635\n",
      "Epoch [112/200], Step [891/1067], D_A_loss: 0.0296, D_B_loss: 0.0218, G_A_loss: 0.6760, G_B_loss: 0.7689\n",
      "Epoch [112/200], Step [901/1067], D_A_loss: 0.0331, D_B_loss: 0.0601, G_A_loss: 1.1432, G_B_loss: 0.8762\n",
      "Epoch [112/200], Step [911/1067], D_A_loss: 0.0888, D_B_loss: 0.0308, G_A_loss: 0.6318, G_B_loss: 0.5672\n",
      "Epoch [112/200], Step [921/1067], D_A_loss: 0.0265, D_B_loss: 0.0236, G_A_loss: 0.7189, G_B_loss: 0.4883\n",
      "Epoch [112/200], Step [931/1067], D_A_loss: 0.0540, D_B_loss: 0.1558, G_A_loss: 0.3018, G_B_loss: 0.7268\n",
      "Epoch [112/200], Step [941/1067], D_A_loss: 0.0881, D_B_loss: 0.0141, G_A_loss: 0.3492, G_B_loss: 0.4996\n",
      "Epoch [112/200], Step [951/1067], D_A_loss: 0.0349, D_B_loss: 0.0318, G_A_loss: 0.9048, G_B_loss: 0.8013\n",
      "Epoch [112/200], Step [961/1067], D_A_loss: 0.1051, D_B_loss: 0.0349, G_A_loss: 0.6833, G_B_loss: 0.7550\n",
      "Epoch [112/200], Step [971/1067], D_A_loss: 0.0710, D_B_loss: 0.0256, G_A_loss: 0.8273, G_B_loss: 0.6529\n",
      "Epoch [112/200], Step [981/1067], D_A_loss: 0.1048, D_B_loss: 0.2323, G_A_loss: 0.5591, G_B_loss: 0.4125\n",
      "Epoch [112/200], Step [991/1067], D_A_loss: 0.0978, D_B_loss: 0.0174, G_A_loss: 1.0844, G_B_loss: 0.7608\n",
      "Epoch [112/200], Step [1001/1067], D_A_loss: 0.0415, D_B_loss: 0.1098, G_A_loss: 0.8515, G_B_loss: 0.3495\n",
      "Epoch [112/200], Step [1011/1067], D_A_loss: 0.0635, D_B_loss: 0.1069, G_A_loss: 1.5080, G_B_loss: 0.6954\n",
      "Epoch [112/200], Step [1021/1067], D_A_loss: 0.0631, D_B_loss: 0.0085, G_A_loss: 1.0238, G_B_loss: 0.3622\n",
      "Epoch [112/200], Step [1031/1067], D_A_loss: 0.1426, D_B_loss: 0.0367, G_A_loss: 0.5846, G_B_loss: 0.4777\n",
      "Epoch [112/200], Step [1041/1067], D_A_loss: 0.0343, D_B_loss: 0.0199, G_A_loss: 0.7358, G_B_loss: 0.6504\n",
      "Epoch [112/200], Step [1051/1067], D_A_loss: 0.0445, D_B_loss: 0.0652, G_A_loss: 0.4657, G_B_loss: 0.7698\n",
      "Epoch [112/200], Step [1061/1067], D_A_loss: 0.1681, D_B_loss: 0.0101, G_A_loss: 0.8731, G_B_loss: 0.2282\n",
      "Epoch [113/200], Step [1/1067], D_A_loss: 0.0715, D_B_loss: 0.0502, G_A_loss: 1.2215, G_B_loss: 0.5010\n",
      "Epoch [113/200], Step [11/1067], D_A_loss: 0.0374, D_B_loss: 0.0127, G_A_loss: 0.8976, G_B_loss: 0.6089\n",
      "Epoch [113/200], Step [21/1067], D_A_loss: 0.1621, D_B_loss: 0.0098, G_A_loss: 1.2526, G_B_loss: 0.5405\n",
      "Epoch [113/200], Step [31/1067], D_A_loss: 0.0930, D_B_loss: 0.0098, G_A_loss: 1.1466, G_B_loss: 0.3912\n",
      "Epoch [113/200], Step [41/1067], D_A_loss: 0.0379, D_B_loss: 0.0378, G_A_loss: 1.0857, G_B_loss: 0.6264\n",
      "Epoch [113/200], Step [51/1067], D_A_loss: 0.0567, D_B_loss: 0.0929, G_A_loss: 0.5851, G_B_loss: 0.5529\n",
      "Epoch [113/200], Step [61/1067], D_A_loss: 0.0516, D_B_loss: 0.0631, G_A_loss: 1.2943, G_B_loss: 0.2062\n",
      "Epoch [113/200], Step [71/1067], D_A_loss: 0.0178, D_B_loss: 0.0306, G_A_loss: 0.6582, G_B_loss: 0.8678\n",
      "Epoch [113/200], Step [81/1067], D_A_loss: 0.0978, D_B_loss: 0.0234, G_A_loss: 0.8225, G_B_loss: 0.6403\n",
      "Epoch [113/200], Step [91/1067], D_A_loss: 0.3040, D_B_loss: 0.0259, G_A_loss: 0.7928, G_B_loss: 0.2273\n",
      "Epoch [113/200], Step [101/1067], D_A_loss: 0.0447, D_B_loss: 0.0243, G_A_loss: 0.8989, G_B_loss: 0.3836\n",
      "Epoch [113/200], Step [111/1067], D_A_loss: 0.1033, D_B_loss: 0.0120, G_A_loss: 0.9290, G_B_loss: 0.3896\n",
      "Epoch [113/200], Step [121/1067], D_A_loss: 0.2031, D_B_loss: 0.0449, G_A_loss: 1.0535, G_B_loss: 0.2813\n",
      "Epoch [113/200], Step [131/1067], D_A_loss: 0.0726, D_B_loss: 0.0207, G_A_loss: 0.7614, G_B_loss: 0.6493\n",
      "Epoch [113/200], Step [141/1067], D_A_loss: 0.1562, D_B_loss: 0.0209, G_A_loss: 0.7970, G_B_loss: 0.1949\n",
      "Epoch [113/200], Step [151/1067], D_A_loss: 0.2570, D_B_loss: 0.0254, G_A_loss: 1.1596, G_B_loss: 0.2838\n",
      "Epoch [113/200], Step [161/1067], D_A_loss: 0.0960, D_B_loss: 0.0256, G_A_loss: 0.8454, G_B_loss: 0.4291\n",
      "Epoch [113/200], Step [171/1067], D_A_loss: 0.0761, D_B_loss: 0.0316, G_A_loss: 0.8951, G_B_loss: 0.7663\n",
      "Epoch [113/200], Step [181/1067], D_A_loss: 0.1016, D_B_loss: 0.1048, G_A_loss: 0.3348, G_B_loss: 0.4422\n",
      "Epoch [113/200], Step [191/1067], D_A_loss: 0.1028, D_B_loss: 0.0176, G_A_loss: 0.7553, G_B_loss: 0.8772\n",
      "Epoch [113/200], Step [201/1067], D_A_loss: 0.0278, D_B_loss: 0.0180, G_A_loss: 0.8225, G_B_loss: 0.6319\n",
      "Epoch [113/200], Step [211/1067], D_A_loss: 0.1409, D_B_loss: 0.0110, G_A_loss: 0.8124, G_B_loss: 0.3367\n",
      "Epoch [113/200], Step [221/1067], D_A_loss: 0.3583, D_B_loss: 0.0174, G_A_loss: 0.7654, G_B_loss: 1.0407\n",
      "Epoch [113/200], Step [231/1067], D_A_loss: 0.0594, D_B_loss: 0.0281, G_A_loss: 0.4171, G_B_loss: 0.5768\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [113/200], Step [241/1067], D_A_loss: 0.0956, D_B_loss: 0.0135, G_A_loss: 1.0261, G_B_loss: 1.0561\n",
      "Epoch [113/200], Step [251/1067], D_A_loss: 0.0566, D_B_loss: 0.0150, G_A_loss: 1.0321, G_B_loss: 0.5857\n",
      "Epoch [113/200], Step [261/1067], D_A_loss: 0.1217, D_B_loss: 0.0711, G_A_loss: 0.7121, G_B_loss: 0.4331\n",
      "Epoch [113/200], Step [271/1067], D_A_loss: 0.0485, D_B_loss: 0.0246, G_A_loss: 0.8112, G_B_loss: 0.5761\n",
      "Epoch [113/200], Step [281/1067], D_A_loss: 0.0814, D_B_loss: 0.0176, G_A_loss: 0.5734, G_B_loss: 0.6410\n",
      "Epoch [113/200], Step [291/1067], D_A_loss: 0.1031, D_B_loss: 0.0825, G_A_loss: 0.4963, G_B_loss: 0.4828\n",
      "Epoch [113/200], Step [301/1067], D_A_loss: 0.1539, D_B_loss: 0.0142, G_A_loss: 0.7192, G_B_loss: 0.3460\n",
      "Epoch [113/200], Step [311/1067], D_A_loss: 0.0947, D_B_loss: 0.0101, G_A_loss: 1.1225, G_B_loss: 0.5340\n",
      "Epoch [113/200], Step [321/1067], D_A_loss: 0.0382, D_B_loss: 0.0256, G_A_loss: 0.6668, G_B_loss: 0.2810\n",
      "Epoch [113/200], Step [331/1067], D_A_loss: 0.1004, D_B_loss: 0.0174, G_A_loss: 1.2715, G_B_loss: 0.7088\n",
      "Epoch [113/200], Step [341/1067], D_A_loss: 0.1934, D_B_loss: 0.0531, G_A_loss: 0.5857, G_B_loss: 0.9214\n",
      "Epoch [113/200], Step [351/1067], D_A_loss: 0.1485, D_B_loss: 0.0382, G_A_loss: 0.7373, G_B_loss: 0.3509\n",
      "Epoch [113/200], Step [361/1067], D_A_loss: 0.1403, D_B_loss: 0.0403, G_A_loss: 0.6793, G_B_loss: 0.3951\n",
      "Epoch [113/200], Step [371/1067], D_A_loss: 0.1524, D_B_loss: 0.0150, G_A_loss: 0.7987, G_B_loss: 0.6234\n",
      "Epoch [113/200], Step [381/1067], D_A_loss: 0.0741, D_B_loss: 0.0152, G_A_loss: 0.7079, G_B_loss: 0.7693\n",
      "Epoch [113/200], Step [391/1067], D_A_loss: 0.0803, D_B_loss: 0.0401, G_A_loss: 0.6411, G_B_loss: 1.0337\n",
      "Epoch [113/200], Step [401/1067], D_A_loss: 0.0453, D_B_loss: 0.0231, G_A_loss: 0.7374, G_B_loss: 0.9969\n",
      "Epoch [113/200], Step [411/1067], D_A_loss: 0.1113, D_B_loss: 0.0149, G_A_loss: 0.8738, G_B_loss: 0.4467\n",
      "Epoch [113/200], Step [421/1067], D_A_loss: 0.1547, D_B_loss: 0.0104, G_A_loss: 1.0206, G_B_loss: 0.5756\n",
      "Epoch [113/200], Step [431/1067], D_A_loss: 0.1082, D_B_loss: 0.0265, G_A_loss: 0.8168, G_B_loss: 0.4596\n",
      "Epoch [113/200], Step [441/1067], D_A_loss: 0.0567, D_B_loss: 0.0100, G_A_loss: 0.8980, G_B_loss: 1.1350\n",
      "Epoch [113/200], Step [451/1067], D_A_loss: 0.0666, D_B_loss: 0.0155, G_A_loss: 0.6365, G_B_loss: 0.3020\n",
      "Epoch [113/200], Step [461/1067], D_A_loss: 0.1558, D_B_loss: 0.0087, G_A_loss: 1.0167, G_B_loss: 0.3059\n",
      "Epoch [113/200], Step [471/1067], D_A_loss: 0.0429, D_B_loss: 0.0303, G_A_loss: 0.9357, G_B_loss: 0.6318\n",
      "Epoch [113/200], Step [481/1067], D_A_loss: 0.0806, D_B_loss: 0.0210, G_A_loss: 0.8702, G_B_loss: 0.7024\n",
      "Epoch [113/200], Step [491/1067], D_A_loss: 0.1063, D_B_loss: 0.0148, G_A_loss: 0.9625, G_B_loss: 0.4527\n",
      "Epoch [113/200], Step [501/1067], D_A_loss: 0.2133, D_B_loss: 0.0106, G_A_loss: 0.8190, G_B_loss: 0.2103\n",
      "Epoch [113/200], Step [511/1067], D_A_loss: 0.0663, D_B_loss: 0.0145, G_A_loss: 0.6393, G_B_loss: 0.4116\n",
      "Epoch [113/200], Step [521/1067], D_A_loss: 0.1077, D_B_loss: 0.0734, G_A_loss: 0.5060, G_B_loss: 0.8928\n",
      "Epoch [113/200], Step [531/1067], D_A_loss: 0.0866, D_B_loss: 0.1764, G_A_loss: 1.1562, G_B_loss: 0.4954\n",
      "Epoch [113/200], Step [541/1067], D_A_loss: 0.0339, D_B_loss: 0.0447, G_A_loss: 1.0105, G_B_loss: 0.7049\n",
      "Epoch [113/200], Step [551/1067], D_A_loss: 0.2256, D_B_loss: 0.0669, G_A_loss: 0.4597, G_B_loss: 0.3641\n",
      "Epoch [113/200], Step [561/1067], D_A_loss: 0.0681, D_B_loss: 0.0205, G_A_loss: 1.0023, G_B_loss: 0.5532\n",
      "Epoch [113/200], Step [571/1067], D_A_loss: 0.0958, D_B_loss: 0.0174, G_A_loss: 0.7029, G_B_loss: 0.7493\n",
      "Epoch [113/200], Step [581/1067], D_A_loss: 0.1803, D_B_loss: 0.0665, G_A_loss: 0.5669, G_B_loss: 0.7897\n",
      "Epoch [113/200], Step [591/1067], D_A_loss: 0.0439, D_B_loss: 0.1043, G_A_loss: 0.9154, G_B_loss: 0.7181\n",
      "Epoch [113/200], Step [601/1067], D_A_loss: 0.0554, D_B_loss: 0.0201, G_A_loss: 0.9549, G_B_loss: 0.5781\n",
      "Epoch [113/200], Step [611/1067], D_A_loss: 0.0380, D_B_loss: 0.0126, G_A_loss: 0.9521, G_B_loss: 0.8078\n",
      "Epoch [113/200], Step [621/1067], D_A_loss: 0.1124, D_B_loss: 0.0342, G_A_loss: 0.7912, G_B_loss: 0.3828\n",
      "Epoch [113/200], Step [631/1067], D_A_loss: 0.0991, D_B_loss: 0.0149, G_A_loss: 1.2549, G_B_loss: 0.4957\n",
      "Epoch [113/200], Step [641/1067], D_A_loss: 0.0342, D_B_loss: 0.0185, G_A_loss: 0.8254, G_B_loss: 0.8040\n",
      "Epoch [113/200], Step [651/1067], D_A_loss: 0.1206, D_B_loss: 0.0080, G_A_loss: 0.8908, G_B_loss: 0.8083\n",
      "Epoch [113/200], Step [661/1067], D_A_loss: 0.0874, D_B_loss: 0.0153, G_A_loss: 0.9375, G_B_loss: 0.5765\n",
      "Epoch [113/200], Step [671/1067], D_A_loss: 0.2103, D_B_loss: 0.0313, G_A_loss: 0.6356, G_B_loss: 0.1847\n",
      "Epoch [113/200], Step [681/1067], D_A_loss: 0.0877, D_B_loss: 0.0642, G_A_loss: 0.4775, G_B_loss: 0.7143\n",
      "Epoch [113/200], Step [691/1067], D_A_loss: 0.0346, D_B_loss: 0.0163, G_A_loss: 0.6741, G_B_loss: 0.2236\n",
      "Epoch [113/200], Step [701/1067], D_A_loss: 0.0372, D_B_loss: 0.0165, G_A_loss: 0.8548, G_B_loss: 0.7235\n",
      "Epoch [113/200], Step [711/1067], D_A_loss: 0.0430, D_B_loss: 0.0719, G_A_loss: 0.9359, G_B_loss: 0.2673\n",
      "Epoch [113/200], Step [721/1067], D_A_loss: 0.0644, D_B_loss: 0.0151, G_A_loss: 0.7821, G_B_loss: 0.7116\n",
      "Epoch [113/200], Step [731/1067], D_A_loss: 0.1692, D_B_loss: 0.0134, G_A_loss: 0.6662, G_B_loss: 0.8792\n",
      "Epoch [113/200], Step [741/1067], D_A_loss: 0.2204, D_B_loss: 0.0254, G_A_loss: 0.7738, G_B_loss: 0.3915\n",
      "Epoch [113/200], Step [751/1067], D_A_loss: 0.0592, D_B_loss: 0.0581, G_A_loss: 0.4901, G_B_loss: 0.4157\n",
      "Epoch [113/200], Step [761/1067], D_A_loss: 0.0448, D_B_loss: 0.0201, G_A_loss: 1.0123, G_B_loss: 0.4499\n",
      "Epoch [113/200], Step [771/1067], D_A_loss: 0.0213, D_B_loss: 0.0828, G_A_loss: 1.2581, G_B_loss: 0.8354\n",
      "Epoch [113/200], Step [781/1067], D_A_loss: 0.1203, D_B_loss: 0.1223, G_A_loss: 0.3570, G_B_loss: 0.4877\n",
      "Epoch [113/200], Step [791/1067], D_A_loss: 0.2396, D_B_loss: 0.0224, G_A_loss: 0.7948, G_B_loss: 0.4419\n",
      "Epoch [113/200], Step [801/1067], D_A_loss: 0.1469, D_B_loss: 0.0138, G_A_loss: 0.8190, G_B_loss: 0.3385\n",
      "Epoch [113/200], Step [811/1067], D_A_loss: 0.1188, D_B_loss: 0.0202, G_A_loss: 0.8330, G_B_loss: 0.4621\n",
      "Epoch [113/200], Step [821/1067], D_A_loss: 0.0574, D_B_loss: 0.0416, G_A_loss: 0.6454, G_B_loss: 0.5760\n",
      "Epoch [113/200], Step [831/1067], D_A_loss: 0.0639, D_B_loss: 0.0207, G_A_loss: 0.9471, G_B_loss: 1.0378\n",
      "Epoch [113/200], Step [841/1067], D_A_loss: 0.1181, D_B_loss: 0.0199, G_A_loss: 1.2297, G_B_loss: 0.5863\n",
      "Epoch [113/200], Step [851/1067], D_A_loss: 0.0614, D_B_loss: 0.0178, G_A_loss: 0.8672, G_B_loss: 0.5260\n",
      "Epoch [113/200], Step [861/1067], D_A_loss: 0.1755, D_B_loss: 0.0856, G_A_loss: 0.4887, G_B_loss: 0.5920\n",
      "Epoch [113/200], Step [871/1067], D_A_loss: 0.0545, D_B_loss: 0.0269, G_A_loss: 0.7760, G_B_loss: 0.6467\n",
      "Epoch [113/200], Step [881/1067], D_A_loss: 0.1434, D_B_loss: 0.0400, G_A_loss: 1.0600, G_B_loss: 0.2870\n",
      "Epoch [113/200], Step [891/1067], D_A_loss: 0.0425, D_B_loss: 0.0212, G_A_loss: 0.5749, G_B_loss: 0.6387\n",
      "Epoch [113/200], Step [901/1067], D_A_loss: 0.1016, D_B_loss: 0.0545, G_A_loss: 0.9048, G_B_loss: 0.6421\n",
      "Epoch [113/200], Step [911/1067], D_A_loss: 0.0801, D_B_loss: 0.0217, G_A_loss: 1.0173, G_B_loss: 0.5537\n",
      "Epoch [113/200], Step [921/1067], D_A_loss: 0.0413, D_B_loss: 0.0124, G_A_loss: 0.8144, G_B_loss: 0.6162\n",
      "Epoch [113/200], Step [931/1067], D_A_loss: 0.1248, D_B_loss: 0.0166, G_A_loss: 1.0802, G_B_loss: 0.3348\n",
      "Epoch [113/200], Step [941/1067], D_A_loss: 0.0453, D_B_loss: 0.0123, G_A_loss: 0.8348, G_B_loss: 0.7064\n",
      "Epoch [113/200], Step [951/1067], D_A_loss: 0.0531, D_B_loss: 0.0229, G_A_loss: 0.8529, G_B_loss: 0.3629\n",
      "Epoch [113/200], Step [961/1067], D_A_loss: 0.0778, D_B_loss: 0.0173, G_A_loss: 0.7551, G_B_loss: 0.6349\n",
      "Epoch [113/200], Step [971/1067], D_A_loss: 0.0562, D_B_loss: 0.0163, G_A_loss: 0.9397, G_B_loss: 1.0087\n",
      "Epoch [113/200], Step [981/1067], D_A_loss: 0.0797, D_B_loss: 0.1748, G_A_loss: 1.5429, G_B_loss: 0.7524\n",
      "Epoch [113/200], Step [991/1067], D_A_loss: 0.1067, D_B_loss: 0.0150, G_A_loss: 0.6155, G_B_loss: 0.4578\n",
      "Epoch [113/200], Step [1001/1067], D_A_loss: 0.1113, D_B_loss: 0.0613, G_A_loss: 0.8215, G_B_loss: 0.5962\n",
      "Epoch [113/200], Step [1011/1067], D_A_loss: 0.0921, D_B_loss: 0.0478, G_A_loss: 0.7240, G_B_loss: 0.3924\n",
      "Epoch [113/200], Step [1021/1067], D_A_loss: 0.1573, D_B_loss: 0.0101, G_A_loss: 0.9299, G_B_loss: 0.8538\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [113/200], Step [1031/1067], D_A_loss: 0.0979, D_B_loss: 0.0315, G_A_loss: 0.7046, G_B_loss: 0.3842\n",
      "Epoch [113/200], Step [1041/1067], D_A_loss: 0.0301, D_B_loss: 0.0417, G_A_loss: 0.8318, G_B_loss: 0.8211\n",
      "Epoch [113/200], Step [1051/1067], D_A_loss: 0.0347, D_B_loss: 0.0404, G_A_loss: 0.7037, G_B_loss: 0.5097\n",
      "Epoch [113/200], Step [1061/1067], D_A_loss: 0.0447, D_B_loss: 0.0150, G_A_loss: 0.4725, G_B_loss: 0.3030\n",
      "Epoch [114/200], Step [1/1067], D_A_loss: 0.1901, D_B_loss: 0.0657, G_A_loss: 1.1210, G_B_loss: 0.2154\n",
      "Epoch [114/200], Step [11/1067], D_A_loss: 0.0920, D_B_loss: 0.0331, G_A_loss: 0.6420, G_B_loss: 0.4017\n",
      "Epoch [114/200], Step [21/1067], D_A_loss: 0.1238, D_B_loss: 0.0586, G_A_loss: 0.9534, G_B_loss: 0.8670\n",
      "Epoch [114/200], Step [31/1067], D_A_loss: 0.1592, D_B_loss: 0.0294, G_A_loss: 1.4314, G_B_loss: 0.2494\n",
      "Epoch [114/200], Step [41/1067], D_A_loss: 0.3601, D_B_loss: 0.0344, G_A_loss: 1.1690, G_B_loss: 0.0528\n",
      "Epoch [114/200], Step [51/1067], D_A_loss: 0.0660, D_B_loss: 0.0153, G_A_loss: 0.7688, G_B_loss: 0.8211\n",
      "Epoch [114/200], Step [61/1067], D_A_loss: 0.0575, D_B_loss: 0.0146, G_A_loss: 1.0624, G_B_loss: 0.2343\n",
      "Epoch [114/200], Step [71/1067], D_A_loss: 0.0422, D_B_loss: 0.0241, G_A_loss: 1.0410, G_B_loss: 0.3500\n",
      "Epoch [114/200], Step [81/1067], D_A_loss: 0.2050, D_B_loss: 0.0117, G_A_loss: 0.8085, G_B_loss: 0.1668\n",
      "Epoch [114/200], Step [91/1067], D_A_loss: 0.0641, D_B_loss: 0.0750, G_A_loss: 0.4251, G_B_loss: 0.6213\n",
      "Epoch [114/200], Step [101/1067], D_A_loss: 0.0413, D_B_loss: 0.0219, G_A_loss: 0.7750, G_B_loss: 0.7657\n",
      "Epoch [114/200], Step [111/1067], D_A_loss: 0.0698, D_B_loss: 0.0426, G_A_loss: 0.9904, G_B_loss: 0.6136\n",
      "Epoch [114/200], Step [121/1067], D_A_loss: 0.1621, D_B_loss: 0.0255, G_A_loss: 0.6202, G_B_loss: 0.6518\n",
      "Epoch [114/200], Step [131/1067], D_A_loss: 0.1682, D_B_loss: 0.0355, G_A_loss: 1.0382, G_B_loss: 0.3558\n",
      "Epoch [114/200], Step [141/1067], D_A_loss: 0.0244, D_B_loss: 0.0803, G_A_loss: 0.9014, G_B_loss: 0.4608\n",
      "Epoch [114/200], Step [151/1067], D_A_loss: 0.1227, D_B_loss: 0.0257, G_A_loss: 0.4476, G_B_loss: 0.5843\n",
      "Epoch [114/200], Step [161/1067], D_A_loss: 0.0441, D_B_loss: 0.0168, G_A_loss: 0.9472, G_B_loss: 0.1945\n",
      "Epoch [114/200], Step [171/1067], D_A_loss: 0.0310, D_B_loss: 0.0325, G_A_loss: 1.2042, G_B_loss: 0.4519\n",
      "Epoch [114/200], Step [181/1067], D_A_loss: 0.2400, D_B_loss: 0.0186, G_A_loss: 0.9264, G_B_loss: 0.5076\n",
      "Epoch [114/200], Step [191/1067], D_A_loss: 0.1206, D_B_loss: 0.0420, G_A_loss: 1.0137, G_B_loss: 0.6830\n",
      "Epoch [114/200], Step [201/1067], D_A_loss: 0.1577, D_B_loss: 0.0190, G_A_loss: 0.8489, G_B_loss: 0.3195\n",
      "Epoch [114/200], Step [211/1067], D_A_loss: 0.0833, D_B_loss: 0.0321, G_A_loss: 0.8909, G_B_loss: 0.5204\n",
      "Epoch [114/200], Step [221/1067], D_A_loss: 0.2056, D_B_loss: 0.0357, G_A_loss: 1.0842, G_B_loss: 0.4465\n",
      "Epoch [114/200], Step [231/1067], D_A_loss: 0.1012, D_B_loss: 0.0225, G_A_loss: 1.1100, G_B_loss: 0.8742\n",
      "Epoch [114/200], Step [241/1067], D_A_loss: 0.1242, D_B_loss: 0.0925, G_A_loss: 0.7750, G_B_loss: 0.3349\n",
      "Epoch [114/200], Step [251/1067], D_A_loss: 0.0698, D_B_loss: 0.0255, G_A_loss: 0.7036, G_B_loss: 0.5950\n",
      "Epoch [114/200], Step [261/1067], D_A_loss: 0.0740, D_B_loss: 0.0101, G_A_loss: 1.0264, G_B_loss: 0.2257\n",
      "Epoch [114/200], Step [271/1067], D_A_loss: 0.1080, D_B_loss: 0.0616, G_A_loss: 0.3848, G_B_loss: 0.5279\n",
      "Epoch [114/200], Step [281/1067], D_A_loss: 0.0295, D_B_loss: 0.0368, G_A_loss: 0.7666, G_B_loss: 0.9383\n",
      "Epoch [114/200], Step [291/1067], D_A_loss: 0.0461, D_B_loss: 0.0266, G_A_loss: 1.1425, G_B_loss: 0.4762\n",
      "Epoch [114/200], Step [301/1067], D_A_loss: 0.0794, D_B_loss: 0.0202, G_A_loss: 0.9146, G_B_loss: 0.5432\n",
      "Epoch [114/200], Step [311/1067], D_A_loss: 0.0351, D_B_loss: 0.0840, G_A_loss: 0.6005, G_B_loss: 0.4728\n",
      "Epoch [114/200], Step [321/1067], D_A_loss: 0.0741, D_B_loss: 0.0446, G_A_loss: 1.2453, G_B_loss: 0.4134\n",
      "Epoch [114/200], Step [331/1067], D_A_loss: 0.1630, D_B_loss: 0.0125, G_A_loss: 0.8032, G_B_loss: 0.3068\n",
      "Epoch [114/200], Step [341/1067], D_A_loss: 0.0357, D_B_loss: 0.0122, G_A_loss: 0.8810, G_B_loss: 0.6907\n",
      "Epoch [114/200], Step [351/1067], D_A_loss: 0.0555, D_B_loss: 0.0149, G_A_loss: 0.8670, G_B_loss: 0.6191\n",
      "Epoch [114/200], Step [361/1067], D_A_loss: 0.0726, D_B_loss: 0.0321, G_A_loss: 0.6131, G_B_loss: 0.3309\n",
      "Epoch [114/200], Step [371/1067], D_A_loss: 0.0438, D_B_loss: 0.0096, G_A_loss: 0.9173, G_B_loss: 0.3504\n",
      "Epoch [114/200], Step [381/1067], D_A_loss: 0.1350, D_B_loss: 0.0172, G_A_loss: 1.0291, G_B_loss: 0.1611\n",
      "Epoch [114/200], Step [391/1067], D_A_loss: 0.1097, D_B_loss: 0.0274, G_A_loss: 1.0624, G_B_loss: 0.3867\n",
      "Epoch [114/200], Step [401/1067], D_A_loss: 0.1433, D_B_loss: 0.0781, G_A_loss: 0.5808, G_B_loss: 0.3832\n",
      "Epoch [114/200], Step [411/1067], D_A_loss: 0.1022, D_B_loss: 0.0145, G_A_loss: 0.8139, G_B_loss: 0.8827\n",
      "Epoch [114/200], Step [421/1067], D_A_loss: 0.0886, D_B_loss: 0.0136, G_A_loss: 1.1385, G_B_loss: 0.4167\n",
      "Epoch [114/200], Step [431/1067], D_A_loss: 0.1095, D_B_loss: 0.0071, G_A_loss: 1.1338, G_B_loss: 0.3671\n",
      "Epoch [114/200], Step [441/1067], D_A_loss: 0.1828, D_B_loss: 0.0306, G_A_loss: 0.6315, G_B_loss: 0.5119\n",
      "Epoch [114/200], Step [451/1067], D_A_loss: 0.0723, D_B_loss: 0.0793, G_A_loss: 0.4554, G_B_loss: 0.2468\n",
      "Epoch [114/200], Step [461/1067], D_A_loss: 0.0576, D_B_loss: 0.0117, G_A_loss: 1.0896, G_B_loss: 0.5482\n",
      "Epoch [114/200], Step [471/1067], D_A_loss: 0.1075, D_B_loss: 0.0294, G_A_loss: 0.8064, G_B_loss: 0.3505\n",
      "Epoch [114/200], Step [481/1067], D_A_loss: 0.0981, D_B_loss: 0.1234, G_A_loss: 1.0186, G_B_loss: 0.5173\n",
      "Epoch [114/200], Step [491/1067], D_A_loss: 0.0788, D_B_loss: 0.0586, G_A_loss: 0.9462, G_B_loss: 0.5696\n",
      "Epoch [114/200], Step [501/1067], D_A_loss: 0.1257, D_B_loss: 0.0496, G_A_loss: 1.0808, G_B_loss: 0.4237\n",
      "Epoch [114/200], Step [511/1067], D_A_loss: 0.2871, D_B_loss: 0.0295, G_A_loss: 0.8978, G_B_loss: 0.2482\n",
      "Epoch [114/200], Step [521/1067], D_A_loss: 0.0472, D_B_loss: 0.0164, G_A_loss: 0.3959, G_B_loss: 0.4389\n",
      "Epoch [114/200], Step [531/1067], D_A_loss: 0.0278, D_B_loss: 0.0841, G_A_loss: 0.8561, G_B_loss: 0.6340\n",
      "Epoch [114/200], Step [541/1067], D_A_loss: 0.0407, D_B_loss: 0.0225, G_A_loss: 0.9163, G_B_loss: 0.9162\n",
      "Epoch [114/200], Step [551/1067], D_A_loss: 0.0562, D_B_loss: 0.0237, G_A_loss: 0.7056, G_B_loss: 0.3361\n",
      "Epoch [114/200], Step [561/1067], D_A_loss: 0.1560, D_B_loss: 0.0163, G_A_loss: 0.7094, G_B_loss: 0.3667\n",
      "Epoch [114/200], Step [571/1067], D_A_loss: 0.0850, D_B_loss: 0.0396, G_A_loss: 1.0517, G_B_loss: 0.7121\n",
      "Epoch [114/200], Step [581/1067], D_A_loss: 0.1224, D_B_loss: 0.0869, G_A_loss: 0.5072, G_B_loss: 0.3657\n",
      "Epoch [114/200], Step [591/1067], D_A_loss: 0.0827, D_B_loss: 0.0089, G_A_loss: 1.0346, G_B_loss: 0.4419\n",
      "Epoch [114/200], Step [601/1067], D_A_loss: 0.0468, D_B_loss: 0.0086, G_A_loss: 0.8523, G_B_loss: 0.6736\n",
      "Epoch [114/200], Step [611/1067], D_A_loss: 0.0542, D_B_loss: 0.0814, G_A_loss: 1.3703, G_B_loss: 0.6627\n",
      "Epoch [114/200], Step [621/1067], D_A_loss: 0.0857, D_B_loss: 0.0296, G_A_loss: 0.6954, G_B_loss: 0.4079\n",
      "Epoch [114/200], Step [631/1067], D_A_loss: 0.0697, D_B_loss: 0.0141, G_A_loss: 1.0196, G_B_loss: 0.2493\n",
      "Epoch [114/200], Step [641/1067], D_A_loss: 0.0637, D_B_loss: 0.0732, G_A_loss: 0.9747, G_B_loss: 0.4460\n",
      "Epoch [114/200], Step [651/1067], D_A_loss: 0.1665, D_B_loss: 0.0108, G_A_loss: 0.7834, G_B_loss: 0.4720\n",
      "Epoch [114/200], Step [661/1067], D_A_loss: 0.0383, D_B_loss: 0.0098, G_A_loss: 0.9948, G_B_loss: 0.4547\n",
      "Epoch [114/200], Step [671/1067], D_A_loss: 0.0567, D_B_loss: 0.0451, G_A_loss: 1.1434, G_B_loss: 0.5319\n",
      "Epoch [114/200], Step [681/1067], D_A_loss: 0.0910, D_B_loss: 0.0300, G_A_loss: 0.8943, G_B_loss: 0.4407\n",
      "Epoch [114/200], Step [691/1067], D_A_loss: 0.0350, D_B_loss: 0.0529, G_A_loss: 0.5271, G_B_loss: 0.9615\n",
      "Epoch [114/200], Step [701/1067], D_A_loss: 0.3174, D_B_loss: 0.0179, G_A_loss: 0.7739, G_B_loss: 0.2728\n",
      "Epoch [114/200], Step [711/1067], D_A_loss: 0.0393, D_B_loss: 0.0459, G_A_loss: 0.9220, G_B_loss: 0.7435\n",
      "Epoch [114/200], Step [721/1067], D_A_loss: 0.0978, D_B_loss: 0.0251, G_A_loss: 0.5588, G_B_loss: 0.3831\n",
      "Epoch [114/200], Step [731/1067], D_A_loss: 0.0420, D_B_loss: 0.0176, G_A_loss: 0.8968, G_B_loss: 0.5837\n",
      "Epoch [114/200], Step [741/1067], D_A_loss: 0.0763, D_B_loss: 0.0440, G_A_loss: 0.6133, G_B_loss: 0.5708\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [114/200], Step [751/1067], D_A_loss: 0.1479, D_B_loss: 0.0079, G_A_loss: 1.1007, G_B_loss: 0.4381\n",
      "Epoch [114/200], Step [761/1067], D_A_loss: 0.0472, D_B_loss: 0.0126, G_A_loss: 1.2337, G_B_loss: 0.4175\n",
      "Epoch [114/200], Step [771/1067], D_A_loss: 0.0693, D_B_loss: 0.0298, G_A_loss: 0.6545, G_B_loss: 0.5015\n",
      "Epoch [114/200], Step [781/1067], D_A_loss: 0.1922, D_B_loss: 0.0425, G_A_loss: 1.0918, G_B_loss: 0.2385\n",
      "Epoch [114/200], Step [791/1067], D_A_loss: 0.1478, D_B_loss: 0.0251, G_A_loss: 0.6970, G_B_loss: 0.9084\n",
      "Epoch [114/200], Step [801/1067], D_A_loss: 0.0876, D_B_loss: 0.0276, G_A_loss: 0.9359, G_B_loss: 0.2984\n",
      "Epoch [114/200], Step [811/1067], D_A_loss: 0.0364, D_B_loss: 0.0538, G_A_loss: 0.7516, G_B_loss: 0.4284\n",
      "Epoch [114/200], Step [821/1067], D_A_loss: 0.0371, D_B_loss: 0.0141, G_A_loss: 1.1477, G_B_loss: 0.7793\n",
      "Epoch [114/200], Step [831/1067], D_A_loss: 0.3877, D_B_loss: 0.0162, G_A_loss: 0.4844, G_B_loss: 0.4111\n",
      "Epoch [114/200], Step [841/1067], D_A_loss: 0.0797, D_B_loss: 0.0152, G_A_loss: 0.8724, G_B_loss: 0.4864\n",
      "Epoch [114/200], Step [851/1067], D_A_loss: 0.1247, D_B_loss: 0.0135, G_A_loss: 0.9108, G_B_loss: 0.7251\n",
      "Epoch [114/200], Step [861/1067], D_A_loss: 0.0713, D_B_loss: 0.0170, G_A_loss: 1.2566, G_B_loss: 0.7636\n",
      "Epoch [114/200], Step [871/1067], D_A_loss: 0.2277, D_B_loss: 0.0621, G_A_loss: 0.9343, G_B_loss: 0.7153\n",
      "Epoch [114/200], Step [881/1067], D_A_loss: 0.0521, D_B_loss: 0.0482, G_A_loss: 0.5589, G_B_loss: 0.2785\n",
      "Epoch [114/200], Step [891/1067], D_A_loss: 0.0937, D_B_loss: 0.1184, G_A_loss: 0.8562, G_B_loss: 0.4508\n",
      "Epoch [114/200], Step [901/1067], D_A_loss: 0.1224, D_B_loss: 0.0187, G_A_loss: 1.1417, G_B_loss: 0.8349\n",
      "Epoch [114/200], Step [911/1067], D_A_loss: 0.1548, D_B_loss: 0.0264, G_A_loss: 1.0547, G_B_loss: 0.3416\n",
      "Epoch [114/200], Step [921/1067], D_A_loss: 0.1639, D_B_loss: 0.0497, G_A_loss: 1.0059, G_B_loss: 0.3215\n",
      "Epoch [114/200], Step [931/1067], D_A_loss: 0.1601, D_B_loss: 0.0189, G_A_loss: 1.2940, G_B_loss: 0.3703\n",
      "Epoch [114/200], Step [941/1067], D_A_loss: 0.2125, D_B_loss: 0.0278, G_A_loss: 0.9505, G_B_loss: 0.2775\n",
      "Epoch [114/200], Step [951/1067], D_A_loss: 0.0631, D_B_loss: 0.0395, G_A_loss: 0.6377, G_B_loss: 0.6420\n",
      "Epoch [114/200], Step [961/1067], D_A_loss: 0.1466, D_B_loss: 0.0168, G_A_loss: 0.6639, G_B_loss: 0.6085\n",
      "Epoch [114/200], Step [971/1067], D_A_loss: 0.1131, D_B_loss: 0.0096, G_A_loss: 1.0311, G_B_loss: 0.3803\n",
      "Epoch [114/200], Step [981/1067], D_A_loss: 0.0278, D_B_loss: 0.0074, G_A_loss: 0.8845, G_B_loss: 0.7496\n",
      "Epoch [114/200], Step [991/1067], D_A_loss: 0.0324, D_B_loss: 0.0112, G_A_loss: 0.7115, G_B_loss: 0.8278\n",
      "Epoch [114/200], Step [1001/1067], D_A_loss: 0.0504, D_B_loss: 0.0227, G_A_loss: 0.9991, G_B_loss: 0.2508\n",
      "Epoch [114/200], Step [1011/1067], D_A_loss: 0.0476, D_B_loss: 0.0148, G_A_loss: 1.3794, G_B_loss: 0.5972\n",
      "Epoch [114/200], Step [1021/1067], D_A_loss: 0.0730, D_B_loss: 0.0154, G_A_loss: 1.1177, G_B_loss: 0.2706\n",
      "Epoch [114/200], Step [1031/1067], D_A_loss: 0.1653, D_B_loss: 0.0533, G_A_loss: 0.8893, G_B_loss: 0.2927\n",
      "Epoch [114/200], Step [1041/1067], D_A_loss: 0.0326, D_B_loss: 0.0280, G_A_loss: 0.9608, G_B_loss: 1.1059\n",
      "Epoch [114/200], Step [1051/1067], D_A_loss: 0.2967, D_B_loss: 0.0472, G_A_loss: 0.5152, G_B_loss: 1.4039\n",
      "Epoch [114/200], Step [1061/1067], D_A_loss: 0.0344, D_B_loss: 0.0134, G_A_loss: 0.5170, G_B_loss: 0.8467\n",
      "Epoch [115/200], Step [1/1067], D_A_loss: 0.0821, D_B_loss: 0.0464, G_A_loss: 0.5524, G_B_loss: 0.4576\n",
      "Epoch [115/200], Step [11/1067], D_A_loss: 0.1297, D_B_loss: 0.0161, G_A_loss: 0.8559, G_B_loss: 0.7506\n",
      "Epoch [115/200], Step [21/1067], D_A_loss: 0.1681, D_B_loss: 0.0281, G_A_loss: 0.9015, G_B_loss: 0.4352\n",
      "Epoch [115/200], Step [31/1067], D_A_loss: 0.0292, D_B_loss: 0.0904, G_A_loss: 0.7116, G_B_loss: 0.3522\n",
      "Epoch [115/200], Step [41/1067], D_A_loss: 0.0160, D_B_loss: 0.0468, G_A_loss: 0.8749, G_B_loss: 0.5757\n",
      "Epoch [115/200], Step [51/1067], D_A_loss: 0.0223, D_B_loss: 0.0578, G_A_loss: 0.7460, G_B_loss: 0.6646\n",
      "Epoch [115/200], Step [61/1067], D_A_loss: 0.2054, D_B_loss: 0.0198, G_A_loss: 0.8003, G_B_loss: 0.5662\n",
      "Epoch [115/200], Step [71/1067], D_A_loss: 0.0671, D_B_loss: 0.0158, G_A_loss: 1.1860, G_B_loss: 0.4437\n",
      "Epoch [115/200], Step [81/1067], D_A_loss: 0.1574, D_B_loss: 0.0318, G_A_loss: 0.7555, G_B_loss: 0.4136\n",
      "Epoch [115/200], Step [91/1067], D_A_loss: 0.0309, D_B_loss: 0.0137, G_A_loss: 0.9738, G_B_loss: 0.1672\n",
      "Epoch [115/200], Step [101/1067], D_A_loss: 0.2307, D_B_loss: 0.1279, G_A_loss: 1.0589, G_B_loss: 0.1931\n",
      "Epoch [115/200], Step [111/1067], D_A_loss: 0.0561, D_B_loss: 0.0317, G_A_loss: 0.8361, G_B_loss: 0.2927\n",
      "Epoch [115/200], Step [121/1067], D_A_loss: 0.1290, D_B_loss: 0.0313, G_A_loss: 0.7575, G_B_loss: 0.8513\n",
      "Epoch [115/200], Step [131/1067], D_A_loss: 0.1246, D_B_loss: 0.0552, G_A_loss: 0.5420, G_B_loss: 0.4512\n",
      "Epoch [115/200], Step [141/1067], D_A_loss: 0.0835, D_B_loss: 0.0212, G_A_loss: 1.1441, G_B_loss: 0.6952\n",
      "Epoch [115/200], Step [151/1067], D_A_loss: 0.2137, D_B_loss: 0.0152, G_A_loss: 0.8894, G_B_loss: 0.3664\n",
      "Epoch [115/200], Step [161/1067], D_A_loss: 0.1126, D_B_loss: 0.0271, G_A_loss: 0.6987, G_B_loss: 0.1708\n",
      "Epoch [115/200], Step [171/1067], D_A_loss: 0.0852, D_B_loss: 0.0147, G_A_loss: 0.7583, G_B_loss: 0.5452\n",
      "Epoch [115/200], Step [181/1067], D_A_loss: 0.0441, D_B_loss: 0.0129, G_A_loss: 0.6332, G_B_loss: 0.2884\n",
      "Epoch [115/200], Step [191/1067], D_A_loss: 0.0246, D_B_loss: 0.0155, G_A_loss: 0.7872, G_B_loss: 0.3064\n",
      "Epoch [115/200], Step [201/1067], D_A_loss: 0.0424, D_B_loss: 0.0762, G_A_loss: 0.5394, G_B_loss: 0.7465\n",
      "Epoch [115/200], Step [211/1067], D_A_loss: 0.1696, D_B_loss: 0.0358, G_A_loss: 0.7332, G_B_loss: 0.6766\n",
      "Epoch [115/200], Step [221/1067], D_A_loss: 0.1268, D_B_loss: 0.0197, G_A_loss: 0.4604, G_B_loss: 0.3284\n",
      "Epoch [115/200], Step [231/1067], D_A_loss: 0.1326, D_B_loss: 0.0202, G_A_loss: 1.1077, G_B_loss: 0.7829\n",
      "Epoch [115/200], Step [241/1067], D_A_loss: 0.0589, D_B_loss: 0.0935, G_A_loss: 1.4234, G_B_loss: 0.8257\n",
      "Epoch [115/200], Step [251/1067], D_A_loss: 0.0705, D_B_loss: 0.0446, G_A_loss: 1.0375, G_B_loss: 0.8610\n",
      "Epoch [115/200], Step [261/1067], D_A_loss: 0.0812, D_B_loss: 0.0284, G_A_loss: 0.8146, G_B_loss: 0.4648\n",
      "Epoch [115/200], Step [271/1067], D_A_loss: 0.2424, D_B_loss: 0.0907, G_A_loss: 0.4290, G_B_loss: 0.7455\n",
      "Epoch [115/200], Step [281/1067], D_A_loss: 0.1065, D_B_loss: 0.0879, G_A_loss: 1.0414, G_B_loss: 0.5285\n",
      "Epoch [115/200], Step [291/1067], D_A_loss: 0.2168, D_B_loss: 0.0347, G_A_loss: 0.7583, G_B_loss: 0.1645\n",
      "Epoch [115/200], Step [301/1067], D_A_loss: 0.0901, D_B_loss: 0.0120, G_A_loss: 0.9139, G_B_loss: 0.7623\n",
      "Epoch [115/200], Step [311/1067], D_A_loss: 0.0688, D_B_loss: 0.0334, G_A_loss: 0.9660, G_B_loss: 0.4448\n",
      "Epoch [115/200], Step [321/1067], D_A_loss: 0.1369, D_B_loss: 0.0722, G_A_loss: 0.4632, G_B_loss: 0.9877\n",
      "Epoch [115/200], Step [331/1067], D_A_loss: 0.1609, D_B_loss: 0.0195, G_A_loss: 0.5737, G_B_loss: 0.5122\n",
      "Epoch [115/200], Step [341/1067], D_A_loss: 0.0457, D_B_loss: 0.0268, G_A_loss: 1.2633, G_B_loss: 0.2583\n",
      "Epoch [115/200], Step [351/1067], D_A_loss: 0.1260, D_B_loss: 0.0628, G_A_loss: 0.8760, G_B_loss: 0.9133\n",
      "Epoch [115/200], Step [361/1067], D_A_loss: 0.1022, D_B_loss: 0.0124, G_A_loss: 0.6668, G_B_loss: 0.6791\n",
      "Epoch [115/200], Step [371/1067], D_A_loss: 0.1159, D_B_loss: 0.0238, G_A_loss: 0.7137, G_B_loss: 0.8697\n",
      "Epoch [115/200], Step [381/1067], D_A_loss: 0.1041, D_B_loss: 0.0165, G_A_loss: 0.6321, G_B_loss: 0.6924\n",
      "Epoch [115/200], Step [391/1067], D_A_loss: 0.1894, D_B_loss: 0.0234, G_A_loss: 0.6296, G_B_loss: 0.3027\n",
      "Epoch [115/200], Step [401/1067], D_A_loss: 0.0385, D_B_loss: 0.0808, G_A_loss: 0.4173, G_B_loss: 0.6012\n",
      "Epoch [115/200], Step [411/1067], D_A_loss: 0.0702, D_B_loss: 0.0183, G_A_loss: 1.0269, G_B_loss: 0.4218\n",
      "Epoch [115/200], Step [421/1067], D_A_loss: 0.1142, D_B_loss: 0.0195, G_A_loss: 1.2890, G_B_loss: 0.3295\n",
      "Epoch [115/200], Step [431/1067], D_A_loss: 0.0838, D_B_loss: 0.0274, G_A_loss: 1.2062, G_B_loss: 0.5077\n",
      "Epoch [115/200], Step [441/1067], D_A_loss: 0.0413, D_B_loss: 0.0319, G_A_loss: 0.5735, G_B_loss: 0.9082\n",
      "Epoch [115/200], Step [451/1067], D_A_loss: 0.0257, D_B_loss: 0.0138, G_A_loss: 0.7343, G_B_loss: 0.6259\n",
      "Epoch [115/200], Step [461/1067], D_A_loss: 0.0639, D_B_loss: 0.0185, G_A_loss: 0.8490, G_B_loss: 0.7577\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [115/200], Step [471/1067], D_A_loss: 0.0515, D_B_loss: 0.0322, G_A_loss: 0.7313, G_B_loss: 0.8247\n",
      "Epoch [115/200], Step [481/1067], D_A_loss: 0.0939, D_B_loss: 0.0243, G_A_loss: 0.5262, G_B_loss: 0.3732\n",
      "Epoch [115/200], Step [491/1067], D_A_loss: 0.0590, D_B_loss: 0.0267, G_A_loss: 0.8682, G_B_loss: 0.5960\n",
      "Epoch [115/200], Step [501/1067], D_A_loss: 0.1061, D_B_loss: 0.1410, G_A_loss: 0.2553, G_B_loss: 0.5506\n",
      "Epoch [115/200], Step [511/1067], D_A_loss: 0.1674, D_B_loss: 0.0301, G_A_loss: 1.4647, G_B_loss: 0.2403\n",
      "Epoch [115/200], Step [521/1067], D_A_loss: 0.1056, D_B_loss: 0.0322, G_A_loss: 0.7965, G_B_loss: 0.5981\n",
      "Epoch [115/200], Step [531/1067], D_A_loss: 0.1529, D_B_loss: 0.0465, G_A_loss: 0.6033, G_B_loss: 0.3390\n",
      "Epoch [115/200], Step [541/1067], D_A_loss: 0.2303, D_B_loss: 0.0126, G_A_loss: 1.0164, G_B_loss: 0.3277\n",
      "Epoch [115/200], Step [551/1067], D_A_loss: 0.0929, D_B_loss: 0.0243, G_A_loss: 0.7554, G_B_loss: 0.5148\n",
      "Epoch [115/200], Step [561/1067], D_A_loss: 0.1587, D_B_loss: 0.1207, G_A_loss: 0.8552, G_B_loss: 0.3077\n",
      "Epoch [115/200], Step [571/1067], D_A_loss: 0.1670, D_B_loss: 0.0614, G_A_loss: 0.5374, G_B_loss: 0.3691\n",
      "Epoch [115/200], Step [581/1067], D_A_loss: 0.2113, D_B_loss: 0.0150, G_A_loss: 0.9294, G_B_loss: 0.3791\n",
      "Epoch [115/200], Step [591/1067], D_A_loss: 0.0539, D_B_loss: 0.0322, G_A_loss: 0.6729, G_B_loss: 0.5312\n",
      "Epoch [115/200], Step [601/1067], D_A_loss: 0.0346, D_B_loss: 0.0189, G_A_loss: 1.1207, G_B_loss: 0.6885\n",
      "Epoch [115/200], Step [611/1067], D_A_loss: 0.0199, D_B_loss: 0.0289, G_A_loss: 0.8028, G_B_loss: 0.5363\n",
      "Epoch [115/200], Step [621/1067], D_A_loss: 0.0596, D_B_loss: 0.0504, G_A_loss: 0.9100, G_B_loss: 0.4459\n",
      "Epoch [115/200], Step [631/1067], D_A_loss: 0.0191, D_B_loss: 0.0623, G_A_loss: 0.4498, G_B_loss: 0.9924\n",
      "Epoch [115/200], Step [641/1067], D_A_loss: 0.1360, D_B_loss: 0.0178, G_A_loss: 0.9221, G_B_loss: 0.3169\n",
      "Epoch [115/200], Step [651/1067], D_A_loss: 0.1135, D_B_loss: 0.0158, G_A_loss: 0.8191, G_B_loss: 0.4800\n",
      "Epoch [115/200], Step [661/1067], D_A_loss: 0.0685, D_B_loss: 0.0493, G_A_loss: 0.8245, G_B_loss: 1.2791\n",
      "Epoch [115/200], Step [671/1067], D_A_loss: 0.1514, D_B_loss: 0.0195, G_A_loss: 0.8806, G_B_loss: 0.3283\n",
      "Epoch [115/200], Step [681/1067], D_A_loss: 0.2359, D_B_loss: 0.0132, G_A_loss: 0.5465, G_B_loss: 0.6823\n",
      "Epoch [115/200], Step [691/1067], D_A_loss: 0.1113, D_B_loss: 0.0210, G_A_loss: 0.7689, G_B_loss: 0.3627\n",
      "Epoch [115/200], Step [701/1067], D_A_loss: 0.0628, D_B_loss: 0.0334, G_A_loss: 0.6737, G_B_loss: 0.5706\n",
      "Epoch [115/200], Step [711/1067], D_A_loss: 0.1996, D_B_loss: 0.0124, G_A_loss: 0.8192, G_B_loss: 0.3794\n",
      "Epoch [115/200], Step [721/1067], D_A_loss: 0.0693, D_B_loss: 0.0122, G_A_loss: 1.0654, G_B_loss: 0.7686\n",
      "Epoch [115/200], Step [731/1067], D_A_loss: 0.0215, D_B_loss: 0.0195, G_A_loss: 0.8398, G_B_loss: 0.6287\n",
      "Epoch [115/200], Step [741/1067], D_A_loss: 0.0824, D_B_loss: 0.0214, G_A_loss: 0.7602, G_B_loss: 0.4999\n",
      "Epoch [115/200], Step [751/1067], D_A_loss: 0.1966, D_B_loss: 0.0279, G_A_loss: 0.7292, G_B_loss: 0.4278\n",
      "Epoch [115/200], Step [761/1067], D_A_loss: 0.1556, D_B_loss: 0.0817, G_A_loss: 1.1242, G_B_loss: 0.5309\n",
      "Epoch [115/200], Step [771/1067], D_A_loss: 0.1130, D_B_loss: 0.1053, G_A_loss: 0.5263, G_B_loss: 0.4244\n",
      "Epoch [115/200], Step [781/1067], D_A_loss: 0.0645, D_B_loss: 0.0116, G_A_loss: 1.0989, G_B_loss: 0.5560\n",
      "Epoch [115/200], Step [791/1067], D_A_loss: 0.1827, D_B_loss: 0.0113, G_A_loss: 1.0872, G_B_loss: 0.2789\n",
      "Epoch [115/200], Step [801/1067], D_A_loss: 0.1533, D_B_loss: 0.0185, G_A_loss: 1.2702, G_B_loss: 0.8614\n",
      "Epoch [115/200], Step [811/1067], D_A_loss: 0.1054, D_B_loss: 0.0236, G_A_loss: 0.9395, G_B_loss: 0.3984\n",
      "Epoch [115/200], Step [821/1067], D_A_loss: 0.1530, D_B_loss: 0.0383, G_A_loss: 0.6595, G_B_loss: 0.3839\n",
      "Epoch [115/200], Step [831/1067], D_A_loss: 0.0337, D_B_loss: 0.0136, G_A_loss: 0.8653, G_B_loss: 0.7323\n",
      "Epoch [115/200], Step [841/1067], D_A_loss: 0.0328, D_B_loss: 0.0137, G_A_loss: 1.0344, G_B_loss: 0.4513\n",
      "Epoch [115/200], Step [851/1067], D_A_loss: 0.1892, D_B_loss: 0.1638, G_A_loss: 1.4374, G_B_loss: 0.5132\n",
      "Epoch [115/200], Step [861/1067], D_A_loss: 0.0797, D_B_loss: 0.0152, G_A_loss: 0.8691, G_B_loss: 0.7355\n",
      "Epoch [115/200], Step [871/1067], D_A_loss: 0.0916, D_B_loss: 0.0254, G_A_loss: 0.5646, G_B_loss: 0.6726\n",
      "Epoch [115/200], Step [881/1067], D_A_loss: 0.1470, D_B_loss: 0.0991, G_A_loss: 0.4183, G_B_loss: 0.5325\n",
      "Epoch [115/200], Step [891/1067], D_A_loss: 0.2219, D_B_loss: 0.0371, G_A_loss: 1.0062, G_B_loss: 0.2523\n",
      "Epoch [115/200], Step [901/1067], D_A_loss: 0.1005, D_B_loss: 0.0501, G_A_loss: 0.8214, G_B_loss: 0.6201\n",
      "Epoch [115/200], Step [911/1067], D_A_loss: 0.0279, D_B_loss: 0.0102, G_A_loss: 0.8959, G_B_loss: 0.2679\n",
      "Epoch [115/200], Step [921/1067], D_A_loss: 0.1298, D_B_loss: 0.0327, G_A_loss: 0.6435, G_B_loss: 1.0055\n",
      "Epoch [115/200], Step [931/1067], D_A_loss: 0.2537, D_B_loss: 0.0901, G_A_loss: 1.0955, G_B_loss: 0.1954\n",
      "Epoch [115/200], Step [941/1067], D_A_loss: 0.1943, D_B_loss: 0.0317, G_A_loss: 1.0150, G_B_loss: 0.4007\n",
      "Epoch [115/200], Step [951/1067], D_A_loss: 0.0499, D_B_loss: 0.0548, G_A_loss: 0.9862, G_B_loss: 0.9490\n",
      "Epoch [115/200], Step [961/1067], D_A_loss: 0.0396, D_B_loss: 0.0283, G_A_loss: 0.9345, G_B_loss: 0.8243\n",
      "Epoch [115/200], Step [971/1067], D_A_loss: 0.1597, D_B_loss: 0.0446, G_A_loss: 0.6382, G_B_loss: 0.6235\n",
      "Epoch [115/200], Step [981/1067], D_A_loss: 0.0658, D_B_loss: 0.0166, G_A_loss: 0.8268, G_B_loss: 0.8716\n",
      "Epoch [115/200], Step [991/1067], D_A_loss: 0.1434, D_B_loss: 0.0613, G_A_loss: 0.5289, G_B_loss: 0.5440\n",
      "Epoch [115/200], Step [1001/1067], D_A_loss: 0.0286, D_B_loss: 0.0885, G_A_loss: 1.2362, G_B_loss: 0.6979\n",
      "Epoch [115/200], Step [1011/1067], D_A_loss: 0.1835, D_B_loss: 0.0177, G_A_loss: 1.1792, G_B_loss: 0.7935\n",
      "Epoch [115/200], Step [1021/1067], D_A_loss: 0.0331, D_B_loss: 0.0078, G_A_loss: 0.8196, G_B_loss: 0.5123\n",
      "Epoch [115/200], Step [1031/1067], D_A_loss: 0.0722, D_B_loss: 0.0253, G_A_loss: 0.6843, G_B_loss: 0.4292\n",
      "Epoch [115/200], Step [1041/1067], D_A_loss: 0.0324, D_B_loss: 0.0111, G_A_loss: 0.8455, G_B_loss: 0.7623\n",
      "Epoch [115/200], Step [1051/1067], D_A_loss: 0.1133, D_B_loss: 0.0132, G_A_loss: 1.2197, G_B_loss: 0.9253\n",
      "Epoch [115/200], Step [1061/1067], D_A_loss: 0.1930, D_B_loss: 0.0397, G_A_loss: 0.5788, G_B_loss: 0.1985\n",
      "Epoch [116/200], Step [1/1067], D_A_loss: 0.1314, D_B_loss: 0.0166, G_A_loss: 1.1289, G_B_loss: 0.1621\n",
      "Epoch [116/200], Step [11/1067], D_A_loss: 0.0462, D_B_loss: 0.1396, G_A_loss: 1.4703, G_B_loss: 0.3516\n",
      "Epoch [116/200], Step [21/1067], D_A_loss: 0.0868, D_B_loss: 0.0180, G_A_loss: 0.7602, G_B_loss: 0.6231\n",
      "Epoch [116/200], Step [31/1067], D_A_loss: 0.1195, D_B_loss: 0.0091, G_A_loss: 0.7262, G_B_loss: 0.3730\n",
      "Epoch [116/200], Step [41/1067], D_A_loss: 0.1451, D_B_loss: 0.0102, G_A_loss: 0.8167, G_B_loss: 0.4422\n",
      "Epoch [116/200], Step [51/1067], D_A_loss: 0.0596, D_B_loss: 0.0539, G_A_loss: 0.8383, G_B_loss: 0.4234\n",
      "Epoch [116/200], Step [61/1067], D_A_loss: 0.2151, D_B_loss: 0.0235, G_A_loss: 0.9843, G_B_loss: 0.9520\n",
      "Epoch [116/200], Step [71/1067], D_A_loss: 0.0488, D_B_loss: 0.0126, G_A_loss: 0.8410, G_B_loss: 0.6593\n",
      "Epoch [116/200], Step [81/1067], D_A_loss: 0.0561, D_B_loss: 0.0109, G_A_loss: 0.9904, G_B_loss: 1.0520\n",
      "Epoch [116/200], Step [91/1067], D_A_loss: 0.0340, D_B_loss: 0.0482, G_A_loss: 1.1185, G_B_loss: 0.8282\n",
      "Epoch [116/200], Step [101/1067], D_A_loss: 0.1152, D_B_loss: 0.0134, G_A_loss: 0.5821, G_B_loss: 0.4658\n",
      "Epoch [116/200], Step [111/1067], D_A_loss: 0.1282, D_B_loss: 0.0283, G_A_loss: 0.7562, G_B_loss: 0.4477\n",
      "Epoch [116/200], Step [121/1067], D_A_loss: 0.1249, D_B_loss: 0.0102, G_A_loss: 0.9276, G_B_loss: 0.3321\n",
      "Epoch [116/200], Step [131/1067], D_A_loss: 0.0175, D_B_loss: 0.0432, G_A_loss: 0.7708, G_B_loss: 0.7250\n",
      "Epoch [116/200], Step [141/1067], D_A_loss: 0.0699, D_B_loss: 0.0377, G_A_loss: 1.1002, G_B_loss: 0.6721\n",
      "Epoch [116/200], Step [151/1067], D_A_loss: 0.0283, D_B_loss: 0.1393, G_A_loss: 0.4030, G_B_loss: 0.9374\n",
      "Epoch [116/200], Step [161/1067], D_A_loss: 0.1572, D_B_loss: 0.0538, G_A_loss: 0.5706, G_B_loss: 0.2724\n",
      "Epoch [116/200], Step [171/1067], D_A_loss: 0.1189, D_B_loss: 0.0437, G_A_loss: 0.7734, G_B_loss: 0.1915\n",
      "Epoch [116/200], Step [181/1067], D_A_loss: 0.0707, D_B_loss: 0.0331, G_A_loss: 0.6766, G_B_loss: 0.5095\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [116/200], Step [191/1067], D_A_loss: 0.1977, D_B_loss: 0.0208, G_A_loss: 0.7696, G_B_loss: 0.3591\n",
      "Epoch [116/200], Step [201/1067], D_A_loss: 0.1111, D_B_loss: 0.0425, G_A_loss: 0.9143, G_B_loss: 0.2430\n",
      "Epoch [116/200], Step [211/1067], D_A_loss: 0.1233, D_B_loss: 0.0112, G_A_loss: 0.6432, G_B_loss: 0.4729\n",
      "Epoch [116/200], Step [221/1067], D_A_loss: 0.2035, D_B_loss: 0.0179, G_A_loss: 0.9855, G_B_loss: 0.2101\n",
      "Epoch [116/200], Step [231/1067], D_A_loss: 0.0374, D_B_loss: 0.0832, G_A_loss: 0.7891, G_B_loss: 0.8600\n",
      "Epoch [116/200], Step [241/1067], D_A_loss: 0.1578, D_B_loss: 0.0610, G_A_loss: 0.7182, G_B_loss: 0.5402\n",
      "Epoch [116/200], Step [251/1067], D_A_loss: 0.0368, D_B_loss: 0.0373, G_A_loss: 0.6614, G_B_loss: 0.5788\n",
      "Epoch [116/200], Step [261/1067], D_A_loss: 0.1001, D_B_loss: 0.0577, G_A_loss: 0.5029, G_B_loss: 0.3899\n",
      "Epoch [116/200], Step [271/1067], D_A_loss: 0.1211, D_B_loss: 0.0508, G_A_loss: 0.8874, G_B_loss: 0.2375\n",
      "Epoch [116/200], Step [281/1067], D_A_loss: 0.2359, D_B_loss: 0.0187, G_A_loss: 0.8400, G_B_loss: 0.2434\n",
      "Epoch [116/200], Step [291/1067], D_A_loss: 0.0611, D_B_loss: 0.0502, G_A_loss: 1.0143, G_B_loss: 0.1845\n",
      "Epoch [116/200], Step [301/1067], D_A_loss: 0.0941, D_B_loss: 0.0133, G_A_loss: 0.5099, G_B_loss: 0.8034\n",
      "Epoch [116/200], Step [311/1067], D_A_loss: 0.1908, D_B_loss: 0.0570, G_A_loss: 0.7175, G_B_loss: 0.2087\n",
      "Epoch [116/200], Step [321/1067], D_A_loss: 0.1038, D_B_loss: 0.0604, G_A_loss: 0.6437, G_B_loss: 0.2094\n",
      "Epoch [116/200], Step [331/1067], D_A_loss: 0.0460, D_B_loss: 0.0183, G_A_loss: 0.9959, G_B_loss: 0.5924\n",
      "Epoch [116/200], Step [341/1067], D_A_loss: 0.0650, D_B_loss: 0.0159, G_A_loss: 0.9652, G_B_loss: 0.5144\n",
      "Epoch [116/200], Step [351/1067], D_A_loss: 0.1783, D_B_loss: 0.0115, G_A_loss: 1.1173, G_B_loss: 0.3108\n",
      "Epoch [116/200], Step [361/1067], D_A_loss: 0.1395, D_B_loss: 0.0293, G_A_loss: 1.3196, G_B_loss: 0.4946\n",
      "Epoch [116/200], Step [371/1067], D_A_loss: 0.1875, D_B_loss: 0.0112, G_A_loss: 1.0350, G_B_loss: 1.2275\n",
      "Epoch [116/200], Step [381/1067], D_A_loss: 0.0544, D_B_loss: 0.0467, G_A_loss: 0.5271, G_B_loss: 0.7420\n",
      "Epoch [116/200], Step [391/1067], D_A_loss: 0.0854, D_B_loss: 0.0349, G_A_loss: 0.6730, G_B_loss: 0.7821\n",
      "Epoch [116/200], Step [401/1067], D_A_loss: 0.0322, D_B_loss: 0.0122, G_A_loss: 0.9408, G_B_loss: 0.5204\n",
      "Epoch [116/200], Step [411/1067], D_A_loss: 0.0287, D_B_loss: 0.0117, G_A_loss: 0.9277, G_B_loss: 0.5738\n",
      "Epoch [116/200], Step [421/1067], D_A_loss: 0.1559, D_B_loss: 0.0150, G_A_loss: 0.8494, G_B_loss: 0.5377\n",
      "Epoch [116/200], Step [431/1067], D_A_loss: 0.2709, D_B_loss: 0.0316, G_A_loss: 0.8294, G_B_loss: 0.2306\n",
      "Epoch [116/200], Step [441/1067], D_A_loss: 0.0446, D_B_loss: 0.0254, G_A_loss: 0.7601, G_B_loss: 0.3086\n",
      "Epoch [116/200], Step [451/1067], D_A_loss: 0.1844, D_B_loss: 0.0289, G_A_loss: 0.8748, G_B_loss: 0.3473\n",
      "Epoch [116/200], Step [461/1067], D_A_loss: 0.0674, D_B_loss: 0.0190, G_A_loss: 0.5124, G_B_loss: 0.5249\n",
      "Epoch [116/200], Step [471/1067], D_A_loss: 0.1260, D_B_loss: 0.0128, G_A_loss: 0.4544, G_B_loss: 0.4005\n",
      "Epoch [116/200], Step [481/1067], D_A_loss: 0.0486, D_B_loss: 0.0293, G_A_loss: 0.6943, G_B_loss: 0.3767\n",
      "Epoch [116/200], Step [491/1067], D_A_loss: 0.1051, D_B_loss: 0.0211, G_A_loss: 0.9910, G_B_loss: 0.3940\n",
      "Epoch [116/200], Step [501/1067], D_A_loss: 0.0624, D_B_loss: 0.0359, G_A_loss: 1.1389, G_B_loss: 0.1618\n",
      "Epoch [116/200], Step [511/1067], D_A_loss: 0.1064, D_B_loss: 0.0848, G_A_loss: 0.4645, G_B_loss: 0.4671\n",
      "Epoch [116/200], Step [521/1067], D_A_loss: 0.0756, D_B_loss: 0.0238, G_A_loss: 0.4396, G_B_loss: 0.5464\n",
      "Epoch [116/200], Step [531/1067], D_A_loss: 0.2402, D_B_loss: 0.0107, G_A_loss: 1.2516, G_B_loss: 0.1884\n",
      "Epoch [116/200], Step [541/1067], D_A_loss: 0.1989, D_B_loss: 0.0427, G_A_loss: 1.2621, G_B_loss: 0.3294\n",
      "Epoch [116/200], Step [551/1067], D_A_loss: 0.0565, D_B_loss: 0.0841, G_A_loss: 0.6600, G_B_loss: 0.3911\n",
      "Epoch [116/200], Step [561/1067], D_A_loss: 0.1331, D_B_loss: 0.0263, G_A_loss: 0.7628, G_B_loss: 0.6996\n",
      "Epoch [116/200], Step [571/1067], D_A_loss: 0.0855, D_B_loss: 0.0377, G_A_loss: 0.7839, G_B_loss: 0.9604\n",
      "Epoch [116/200], Step [581/1067], D_A_loss: 0.0656, D_B_loss: 0.0708, G_A_loss: 0.4553, G_B_loss: 0.5807\n",
      "Epoch [116/200], Step [591/1067], D_A_loss: 0.1229, D_B_loss: 0.0328, G_A_loss: 0.7321, G_B_loss: 0.4296\n",
      "Epoch [116/200], Step [601/1067], D_A_loss: 0.0358, D_B_loss: 0.0302, G_A_loss: 0.7153, G_B_loss: 0.7593\n",
      "Epoch [116/200], Step [611/1067], D_A_loss: 0.2048, D_B_loss: 0.0168, G_A_loss: 0.7484, G_B_loss: 0.6567\n",
      "Epoch [116/200], Step [621/1067], D_A_loss: 0.1069, D_B_loss: 0.0208, G_A_loss: 0.9913, G_B_loss: 0.3648\n",
      "Epoch [116/200], Step [631/1067], D_A_loss: 0.1546, D_B_loss: 0.0103, G_A_loss: 1.1205, G_B_loss: 0.3578\n",
      "Epoch [116/200], Step [641/1067], D_A_loss: 0.0327, D_B_loss: 0.0327, G_A_loss: 0.6472, G_B_loss: 1.1868\n",
      "Epoch [116/200], Step [651/1067], D_A_loss: 0.1503, D_B_loss: 0.1078, G_A_loss: 0.8822, G_B_loss: 0.9584\n",
      "Epoch [116/200], Step [661/1067], D_A_loss: 0.1220, D_B_loss: 0.0627, G_A_loss: 0.6650, G_B_loss: 0.0819\n",
      "Epoch [116/200], Step [671/1067], D_A_loss: 0.2296, D_B_loss: 0.0933, G_A_loss: 0.7621, G_B_loss: 0.3250\n",
      "Epoch [116/200], Step [681/1067], D_A_loss: 0.1032, D_B_loss: 0.1208, G_A_loss: 0.4645, G_B_loss: 0.5296\n",
      "Epoch [116/200], Step [691/1067], D_A_loss: 0.0471, D_B_loss: 0.0207, G_A_loss: 0.7567, G_B_loss: 0.7250\n",
      "Epoch [116/200], Step [701/1067], D_A_loss: 0.0936, D_B_loss: 0.0218, G_A_loss: 0.8805, G_B_loss: 0.4490\n",
      "Epoch [116/200], Step [711/1067], D_A_loss: 0.0509, D_B_loss: 0.0172, G_A_loss: 0.7909, G_B_loss: 0.6622\n",
      "Epoch [116/200], Step [721/1067], D_A_loss: 0.3916, D_B_loss: 0.0504, G_A_loss: 0.5714, G_B_loss: 1.0480\n",
      "Epoch [116/200], Step [731/1067], D_A_loss: 0.0563, D_B_loss: 0.0232, G_A_loss: 0.7586, G_B_loss: 0.9008\n",
      "Epoch [116/200], Step [741/1067], D_A_loss: 0.1674, D_B_loss: 0.0969, G_A_loss: 1.1978, G_B_loss: 0.4208\n",
      "Epoch [116/200], Step [751/1067], D_A_loss: 0.0391, D_B_loss: 0.0360, G_A_loss: 0.6766, G_B_loss: 0.4662\n",
      "Epoch [116/200], Step [761/1067], D_A_loss: 0.0250, D_B_loss: 0.0417, G_A_loss: 0.5773, G_B_loss: 0.5490\n",
      "Epoch [116/200], Step [771/1067], D_A_loss: 0.0428, D_B_loss: 0.0677, G_A_loss: 1.2517, G_B_loss: 0.6439\n",
      "Epoch [116/200], Step [781/1067], D_A_loss: 0.0602, D_B_loss: 0.0095, G_A_loss: 1.1870, G_B_loss: 0.5909\n",
      "Epoch [116/200], Step [791/1067], D_A_loss: 0.0474, D_B_loss: 0.1386, G_A_loss: 1.0209, G_B_loss: 0.8897\n",
      "Epoch [116/200], Step [801/1067], D_A_loss: 0.0253, D_B_loss: 0.0189, G_A_loss: 0.9631, G_B_loss: 0.9327\n",
      "Epoch [116/200], Step [811/1067], D_A_loss: 0.1898, D_B_loss: 0.0308, G_A_loss: 0.7011, G_B_loss: 0.1786\n",
      "Epoch [116/200], Step [821/1067], D_A_loss: 0.0611, D_B_loss: 0.0733, G_A_loss: 0.5713, G_B_loss: 0.5572\n",
      "Epoch [116/200], Step [831/1067], D_A_loss: 0.0446, D_B_loss: 0.0101, G_A_loss: 0.9384, G_B_loss: 0.7205\n",
      "Epoch [116/200], Step [841/1067], D_A_loss: 0.1765, D_B_loss: 0.0200, G_A_loss: 0.6375, G_B_loss: 0.2284\n",
      "Epoch [116/200], Step [851/1067], D_A_loss: 0.0740, D_B_loss: 0.0262, G_A_loss: 0.7182, G_B_loss: 0.5651\n",
      "Epoch [116/200], Step [861/1067], D_A_loss: 0.0967, D_B_loss: 0.0116, G_A_loss: 0.8783, G_B_loss: 0.6595\n",
      "Epoch [116/200], Step [871/1067], D_A_loss: 0.0694, D_B_loss: 0.0142, G_A_loss: 1.0220, G_B_loss: 0.2624\n",
      "Epoch [116/200], Step [881/1067], D_A_loss: 0.2300, D_B_loss: 0.0383, G_A_loss: 0.7406, G_B_loss: 0.7571\n",
      "Epoch [116/200], Step [891/1067], D_A_loss: 0.0565, D_B_loss: 0.0110, G_A_loss: 1.0793, G_B_loss: 0.7827\n",
      "Epoch [116/200], Step [901/1067], D_A_loss: 0.1139, D_B_loss: 0.0156, G_A_loss: 1.1370, G_B_loss: 1.0081\n",
      "Epoch [116/200], Step [911/1067], D_A_loss: 0.0511, D_B_loss: 0.0276, G_A_loss: 0.8955, G_B_loss: 0.7018\n",
      "Epoch [116/200], Step [921/1067], D_A_loss: 0.0359, D_B_loss: 0.0199, G_A_loss: 0.4546, G_B_loss: 0.7694\n",
      "Epoch [116/200], Step [931/1067], D_A_loss: 0.1332, D_B_loss: 0.0292, G_A_loss: 0.9717, G_B_loss: 0.3998\n",
      "Epoch [116/200], Step [941/1067], D_A_loss: 0.0741, D_B_loss: 0.0432, G_A_loss: 0.9907, G_B_loss: 0.8123\n",
      "Epoch [116/200], Step [951/1067], D_A_loss: 0.0439, D_B_loss: 0.0296, G_A_loss: 0.7500, G_B_loss: 1.0575\n",
      "Epoch [116/200], Step [961/1067], D_A_loss: 0.0343, D_B_loss: 0.0106, G_A_loss: 0.9728, G_B_loss: 1.2972\n",
      "Epoch [116/200], Step [971/1067], D_A_loss: 0.0495, D_B_loss: 0.0182, G_A_loss: 0.9764, G_B_loss: 1.0745\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [116/200], Step [981/1067], D_A_loss: 0.1353, D_B_loss: 0.0066, G_A_loss: 0.3943, G_B_loss: 0.7669\n",
      "Epoch [116/200], Step [991/1067], D_A_loss: 0.1514, D_B_loss: 0.0805, G_A_loss: 0.4181, G_B_loss: 0.5587\n",
      "Epoch [116/200], Step [1001/1067], D_A_loss: 0.1601, D_B_loss: 0.0539, G_A_loss: 0.7577, G_B_loss: 0.2567\n",
      "Epoch [116/200], Step [1011/1067], D_A_loss: 0.1399, D_B_loss: 0.0108, G_A_loss: 0.9381, G_B_loss: 0.2891\n",
      "Epoch [116/200], Step [1021/1067], D_A_loss: 0.0809, D_B_loss: 0.0198, G_A_loss: 1.1528, G_B_loss: 0.8145\n",
      "Epoch [116/200], Step [1031/1067], D_A_loss: 0.1013, D_B_loss: 0.0125, G_A_loss: 1.0192, G_B_loss: 0.4660\n",
      "Epoch [116/200], Step [1041/1067], D_A_loss: 0.0456, D_B_loss: 0.0300, G_A_loss: 0.6243, G_B_loss: 0.3639\n",
      "Epoch [116/200], Step [1051/1067], D_A_loss: 0.0816, D_B_loss: 0.0304, G_A_loss: 0.8670, G_B_loss: 0.7221\n",
      "Epoch [116/200], Step [1061/1067], D_A_loss: 0.0899, D_B_loss: 0.0495, G_A_loss: 1.3711, G_B_loss: 0.5465\n",
      "Epoch [117/200], Step [1/1067], D_A_loss: 0.0843, D_B_loss: 0.0135, G_A_loss: 0.9522, G_B_loss: 0.5534\n",
      "Epoch [117/200], Step [11/1067], D_A_loss: 0.0883, D_B_loss: 0.0908, G_A_loss: 0.5263, G_B_loss: 0.4918\n",
      "Epoch [117/200], Step [21/1067], D_A_loss: 0.0295, D_B_loss: 0.0091, G_A_loss: 0.6495, G_B_loss: 0.5974\n",
      "Epoch [117/200], Step [31/1067], D_A_loss: 0.0546, D_B_loss: 0.0645, G_A_loss: 0.4767, G_B_loss: 0.9005\n",
      "Epoch [117/200], Step [41/1067], D_A_loss: 0.0930, D_B_loss: 0.0518, G_A_loss: 0.6918, G_B_loss: 0.6518\n",
      "Epoch [117/200], Step [51/1067], D_A_loss: 0.0311, D_B_loss: 0.0137, G_A_loss: 0.9204, G_B_loss: 0.6789\n",
      "Epoch [117/200], Step [61/1067], D_A_loss: 0.0543, D_B_loss: 0.0162, G_A_loss: 0.9397, G_B_loss: 0.7862\n",
      "Epoch [117/200], Step [71/1067], D_A_loss: 0.1465, D_B_loss: 0.0785, G_A_loss: 0.8802, G_B_loss: 0.6368\n",
      "Epoch [117/200], Step [81/1067], D_A_loss: 0.2135, D_B_loss: 0.0154, G_A_loss: 0.8532, G_B_loss: 0.2130\n",
      "Epoch [117/200], Step [91/1067], D_A_loss: 0.1281, D_B_loss: 0.0192, G_A_loss: 0.9641, G_B_loss: 0.6343\n",
      "Epoch [117/200], Step [101/1067], D_A_loss: 0.0706, D_B_loss: 0.0380, G_A_loss: 0.7901, G_B_loss: 0.7314\n",
      "Epoch [117/200], Step [111/1067], D_A_loss: 0.0790, D_B_loss: 0.0167, G_A_loss: 0.9968, G_B_loss: 0.8188\n",
      "Epoch [117/200], Step [121/1067], D_A_loss: 0.0409, D_B_loss: 0.0459, G_A_loss: 1.0230, G_B_loss: 0.6582\n",
      "Epoch [117/200], Step [131/1067], D_A_loss: 0.0595, D_B_loss: 0.0098, G_A_loss: 0.8356, G_B_loss: 0.6390\n",
      "Epoch [117/200], Step [141/1067], D_A_loss: 0.1914, D_B_loss: 0.0824, G_A_loss: 0.4433, G_B_loss: 1.0667\n",
      "Epoch [117/200], Step [151/1067], D_A_loss: 0.1549, D_B_loss: 0.0186, G_A_loss: 1.1276, G_B_loss: 0.3630\n",
      "Epoch [117/200], Step [161/1067], D_A_loss: 0.0404, D_B_loss: 0.0129, G_A_loss: 0.9078, G_B_loss: 0.6607\n",
      "Epoch [117/200], Step [171/1067], D_A_loss: 0.0647, D_B_loss: 0.0357, G_A_loss: 0.5046, G_B_loss: 0.7675\n",
      "Epoch [117/200], Step [181/1067], D_A_loss: 0.0493, D_B_loss: 0.0091, G_A_loss: 0.8900, G_B_loss: 0.3473\n",
      "Epoch [117/200], Step [191/1067], D_A_loss: 0.1265, D_B_loss: 0.0391, G_A_loss: 0.9748, G_B_loss: 0.4438\n",
      "Epoch [117/200], Step [201/1067], D_A_loss: 0.0684, D_B_loss: 0.0354, G_A_loss: 0.7135, G_B_loss: 0.5320\n",
      "Epoch [117/200], Step [211/1067], D_A_loss: 0.0577, D_B_loss: 0.0905, G_A_loss: 1.0303, G_B_loss: 0.7397\n",
      "Epoch [117/200], Step [221/1067], D_A_loss: 0.0640, D_B_loss: 0.0233, G_A_loss: 1.2789, G_B_loss: 0.3879\n",
      "Epoch [117/200], Step [231/1067], D_A_loss: 0.0286, D_B_loss: 0.0226, G_A_loss: 0.8287, G_B_loss: 0.9757\n",
      "Epoch [117/200], Step [241/1067], D_A_loss: 0.1066, D_B_loss: 0.0146, G_A_loss: 0.7920, G_B_loss: 0.4924\n",
      "Epoch [117/200], Step [251/1067], D_A_loss: 0.2656, D_B_loss: 0.0648, G_A_loss: 0.4861, G_B_loss: 0.6759\n",
      "Epoch [117/200], Step [261/1067], D_A_loss: 0.0496, D_B_loss: 0.0599, G_A_loss: 1.2752, G_B_loss: 1.2173\n",
      "Epoch [117/200], Step [271/1067], D_A_loss: 0.0726, D_B_loss: 0.0318, G_A_loss: 1.2284, G_B_loss: 0.6136\n",
      "Epoch [117/200], Step [281/1067], D_A_loss: 0.0411, D_B_loss: 0.0264, G_A_loss: 0.7923, G_B_loss: 0.7388\n",
      "Epoch [117/200], Step [291/1067], D_A_loss: 0.0344, D_B_loss: 0.0121, G_A_loss: 0.8636, G_B_loss: 0.7414\n",
      "Epoch [117/200], Step [301/1067], D_A_loss: 0.0855, D_B_loss: 0.0361, G_A_loss: 0.6147, G_B_loss: 0.4229\n",
      "Epoch [117/200], Step [311/1067], D_A_loss: 0.2244, D_B_loss: 0.0686, G_A_loss: 0.4513, G_B_loss: 0.9590\n",
      "Epoch [117/200], Step [321/1067], D_A_loss: 0.0678, D_B_loss: 0.0555, G_A_loss: 0.4956, G_B_loss: 0.5547\n",
      "Epoch [117/200], Step [331/1067], D_A_loss: 0.0695, D_B_loss: 0.0314, G_A_loss: 1.0059, G_B_loss: 0.8520\n",
      "Epoch [117/200], Step [341/1067], D_A_loss: 0.0628, D_B_loss: 0.0201, G_A_loss: 0.5509, G_B_loss: 0.7993\n",
      "Epoch [117/200], Step [351/1067], D_A_loss: 0.1900, D_B_loss: 0.0446, G_A_loss: 0.7030, G_B_loss: 1.0745\n",
      "Epoch [117/200], Step [361/1067], D_A_loss: 0.0219, D_B_loss: 0.0101, G_A_loss: 1.1871, G_B_loss: 0.5879\n",
      "Epoch [117/200], Step [371/1067], D_A_loss: 0.0822, D_B_loss: 0.0899, G_A_loss: 0.4283, G_B_loss: 0.5262\n",
      "Epoch [117/200], Step [381/1067], D_A_loss: 0.0849, D_B_loss: 0.1493, G_A_loss: 1.4335, G_B_loss: 0.3984\n",
      "Epoch [117/200], Step [391/1067], D_A_loss: 0.0760, D_B_loss: 0.0271, G_A_loss: 0.9445, G_B_loss: 0.8732\n",
      "Epoch [117/200], Step [401/1067], D_A_loss: 0.0409, D_B_loss: 0.0232, G_A_loss: 0.9061, G_B_loss: 0.7353\n",
      "Epoch [117/200], Step [411/1067], D_A_loss: 0.0815, D_B_loss: 0.0149, G_A_loss: 0.4987, G_B_loss: 0.4782\n",
      "Epoch [117/200], Step [421/1067], D_A_loss: 0.1103, D_B_loss: 0.0719, G_A_loss: 0.6230, G_B_loss: 0.5432\n",
      "Epoch [117/200], Step [431/1067], D_A_loss: 0.1769, D_B_loss: 0.0387, G_A_loss: 1.0161, G_B_loss: 0.5261\n",
      "Epoch [117/200], Step [441/1067], D_A_loss: 0.1038, D_B_loss: 0.0795, G_A_loss: 0.4278, G_B_loss: 0.9369\n",
      "Epoch [117/200], Step [451/1067], D_A_loss: 0.0801, D_B_loss: 0.1014, G_A_loss: 1.0860, G_B_loss: 0.2238\n",
      "Epoch [117/200], Step [461/1067], D_A_loss: 0.0395, D_B_loss: 0.0196, G_A_loss: 0.9178, G_B_loss: 0.4753\n",
      "Epoch [117/200], Step [471/1067], D_A_loss: 0.0785, D_B_loss: 0.0615, G_A_loss: 0.5633, G_B_loss: 0.4499\n",
      "Epoch [117/200], Step [481/1067], D_A_loss: 0.1268, D_B_loss: 0.0608, G_A_loss: 0.8704, G_B_loss: 0.3733\n",
      "Epoch [117/200], Step [491/1067], D_A_loss: 0.0572, D_B_loss: 0.0170, G_A_loss: 0.6866, G_B_loss: 0.6650\n",
      "Epoch [117/200], Step [501/1067], D_A_loss: 0.0638, D_B_loss: 0.0325, G_A_loss: 0.6256, G_B_loss: 0.5138\n",
      "Epoch [117/200], Step [511/1067], D_A_loss: 0.0244, D_B_loss: 0.0580, G_A_loss: 0.4917, G_B_loss: 0.5142\n",
      "Epoch [117/200], Step [521/1067], D_A_loss: 0.0406, D_B_loss: 0.0251, G_A_loss: 1.0163, G_B_loss: 0.6826\n",
      "Epoch [117/200], Step [531/1067], D_A_loss: 0.0562, D_B_loss: 0.0201, G_A_loss: 0.7112, G_B_loss: 0.5613\n",
      "Epoch [117/200], Step [541/1067], D_A_loss: 0.1587, D_B_loss: 0.0745, G_A_loss: 0.8789, G_B_loss: 0.2761\n",
      "Epoch [117/200], Step [551/1067], D_A_loss: 0.0651, D_B_loss: 0.0292, G_A_loss: 0.9533, G_B_loss: 0.3823\n",
      "Epoch [117/200], Step [561/1067], D_A_loss: 0.0879, D_B_loss: 0.0146, G_A_loss: 0.8581, G_B_loss: 0.7494\n",
      "Epoch [117/200], Step [571/1067], D_A_loss: 0.1143, D_B_loss: 0.0204, G_A_loss: 0.8570, G_B_loss: 0.3915\n",
      "Epoch [117/200], Step [581/1067], D_A_loss: 0.2363, D_B_loss: 0.0306, G_A_loss: 0.6858, G_B_loss: 0.4436\n",
      "Epoch [117/200], Step [591/1067], D_A_loss: 0.0591, D_B_loss: 0.0790, G_A_loss: 0.5979, G_B_loss: 0.4299\n",
      "Epoch [117/200], Step [601/1067], D_A_loss: 0.1418, D_B_loss: 0.0645, G_A_loss: 0.8440, G_B_loss: 0.4502\n",
      "Epoch [117/200], Step [611/1067], D_A_loss: 0.0409, D_B_loss: 0.0472, G_A_loss: 0.5575, G_B_loss: 0.2913\n",
      "Epoch [117/200], Step [621/1067], D_A_loss: 0.0672, D_B_loss: 0.0103, G_A_loss: 0.9004, G_B_loss: 0.5292\n",
      "Epoch [117/200], Step [631/1067], D_A_loss: 0.0418, D_B_loss: 0.1486, G_A_loss: 1.0847, G_B_loss: 0.2289\n",
      "Epoch [117/200], Step [641/1067], D_A_loss: 0.1141, D_B_loss: 0.0208, G_A_loss: 0.8122, G_B_loss: 0.4452\n",
      "Epoch [117/200], Step [651/1067], D_A_loss: 0.0265, D_B_loss: 0.0722, G_A_loss: 0.5868, G_B_loss: 0.4393\n",
      "Epoch [117/200], Step [661/1067], D_A_loss: 0.0797, D_B_loss: 0.0093, G_A_loss: 1.0867, G_B_loss: 0.7137\n",
      "Epoch [117/200], Step [671/1067], D_A_loss: 0.1640, D_B_loss: 0.0136, G_A_loss: 0.9389, G_B_loss: 0.5769\n",
      "Epoch [117/200], Step [681/1067], D_A_loss: 0.0254, D_B_loss: 0.0894, G_A_loss: 0.4391, G_B_loss: 0.3395\n",
      "Epoch [117/200], Step [691/1067], D_A_loss: 0.1699, D_B_loss: 0.0106, G_A_loss: 0.8865, G_B_loss: 0.6635\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [117/200], Step [701/1067], D_A_loss: 0.1136, D_B_loss: 0.1292, G_A_loss: 0.7484, G_B_loss: 0.3637\n",
      "Epoch [117/200], Step [711/1067], D_A_loss: 0.0868, D_B_loss: 0.0635, G_A_loss: 0.5866, G_B_loss: 0.7118\n",
      "Epoch [117/200], Step [721/1067], D_A_loss: 0.0467, D_B_loss: 0.0114, G_A_loss: 0.6750, G_B_loss: 0.9067\n",
      "Epoch [117/200], Step [731/1067], D_A_loss: 0.1591, D_B_loss: 0.0202, G_A_loss: 0.9761, G_B_loss: 0.2824\n",
      "Epoch [117/200], Step [741/1067], D_A_loss: 0.0937, D_B_loss: 0.0359, G_A_loss: 1.4036, G_B_loss: 0.6715\n",
      "Epoch [117/200], Step [751/1067], D_A_loss: 0.0444, D_B_loss: 0.0195, G_A_loss: 0.7448, G_B_loss: 0.5056\n",
      "Epoch [117/200], Step [761/1067], D_A_loss: 0.2596, D_B_loss: 0.0096, G_A_loss: 1.0006, G_B_loss: 0.3897\n",
      "Epoch [117/200], Step [771/1067], D_A_loss: 0.0760, D_B_loss: 0.0091, G_A_loss: 1.0352, G_B_loss: 0.3320\n",
      "Epoch [117/200], Step [781/1067], D_A_loss: 0.0880, D_B_loss: 0.0911, G_A_loss: 0.7149, G_B_loss: 0.6379\n",
      "Epoch [117/200], Step [791/1067], D_A_loss: 0.2398, D_B_loss: 0.0289, G_A_loss: 0.7138, G_B_loss: 0.5254\n",
      "Epoch [117/200], Step [801/1067], D_A_loss: 0.0518, D_B_loss: 0.0108, G_A_loss: 1.0758, G_B_loss: 0.4978\n",
      "Epoch [117/200], Step [811/1067], D_A_loss: 0.1636, D_B_loss: 0.0346, G_A_loss: 0.7278, G_B_loss: 0.2500\n",
      "Epoch [117/200], Step [821/1067], D_A_loss: 0.0915, D_B_loss: 0.0142, G_A_loss: 0.7102, G_B_loss: 0.9434\n",
      "Epoch [117/200], Step [831/1067], D_A_loss: 0.0543, D_B_loss: 0.0134, G_A_loss: 0.9077, G_B_loss: 0.6013\n",
      "Epoch [117/200], Step [841/1067], D_A_loss: 0.0391, D_B_loss: 0.0426, G_A_loss: 0.5632, G_B_loss: 0.7782\n",
      "Epoch [117/200], Step [851/1067], D_A_loss: 0.1008, D_B_loss: 0.0166, G_A_loss: 0.4738, G_B_loss: 0.3677\n",
      "Epoch [117/200], Step [861/1067], D_A_loss: 0.1247, D_B_loss: 0.0208, G_A_loss: 0.3810, G_B_loss: 0.5486\n",
      "Epoch [117/200], Step [871/1067], D_A_loss: 0.0657, D_B_loss: 0.0711, G_A_loss: 0.5106, G_B_loss: 1.0809\n",
      "Epoch [117/200], Step [881/1067], D_A_loss: 0.0923, D_B_loss: 0.0092, G_A_loss: 0.6438, G_B_loss: 0.5164\n",
      "Epoch [117/200], Step [891/1067], D_A_loss: 0.0430, D_B_loss: 0.0106, G_A_loss: 0.9222, G_B_loss: 0.6300\n",
      "Epoch [117/200], Step [901/1067], D_A_loss: 0.0372, D_B_loss: 0.0198, G_A_loss: 0.7393, G_B_loss: 0.3632\n",
      "Epoch [117/200], Step [911/1067], D_A_loss: 0.0428, D_B_loss: 0.1047, G_A_loss: 1.1179, G_B_loss: 0.2149\n",
      "Epoch [117/200], Step [921/1067], D_A_loss: 0.2818, D_B_loss: 0.0352, G_A_loss: 1.0586, G_B_loss: 0.0872\n",
      "Epoch [117/200], Step [931/1067], D_A_loss: 0.1446, D_B_loss: 0.0197, G_A_loss: 0.7837, G_B_loss: 1.0871\n",
      "Epoch [117/200], Step [941/1067], D_A_loss: 0.1344, D_B_loss: 0.0211, G_A_loss: 1.0232, G_B_loss: 0.2930\n",
      "Epoch [117/200], Step [951/1067], D_A_loss: 0.1937, D_B_loss: 0.1107, G_A_loss: 0.5054, G_B_loss: 0.2782\n",
      "Epoch [117/200], Step [961/1067], D_A_loss: 0.0486, D_B_loss: 0.0579, G_A_loss: 0.8025, G_B_loss: 0.3441\n",
      "Epoch [117/200], Step [971/1067], D_A_loss: 0.1028, D_B_loss: 0.0326, G_A_loss: 0.6968, G_B_loss: 0.4237\n",
      "Epoch [117/200], Step [981/1067], D_A_loss: 0.0329, D_B_loss: 0.0235, G_A_loss: 0.9349, G_B_loss: 0.7337\n",
      "Epoch [117/200], Step [991/1067], D_A_loss: 0.1024, D_B_loss: 0.0436, G_A_loss: 0.6038, G_B_loss: 0.4085\n",
      "Epoch [117/200], Step [1001/1067], D_A_loss: 0.0454, D_B_loss: 0.0418, G_A_loss: 0.6282, G_B_loss: 0.4376\n",
      "Epoch [117/200], Step [1011/1067], D_A_loss: 0.2835, D_B_loss: 0.0106, G_A_loss: 1.2212, G_B_loss: 0.1107\n",
      "Epoch [117/200], Step [1021/1067], D_A_loss: 0.2482, D_B_loss: 0.0404, G_A_loss: 0.9646, G_B_loss: 0.5669\n",
      "Epoch [117/200], Step [1031/1067], D_A_loss: 0.0415, D_B_loss: 0.0250, G_A_loss: 0.5401, G_B_loss: 0.6031\n",
      "Epoch [117/200], Step [1041/1067], D_A_loss: 0.1484, D_B_loss: 0.0254, G_A_loss: 0.8542, G_B_loss: 0.2970\n",
      "Epoch [117/200], Step [1051/1067], D_A_loss: 0.0733, D_B_loss: 0.0291, G_A_loss: 0.5101, G_B_loss: 0.2519\n",
      "Epoch [117/200], Step [1061/1067], D_A_loss: 0.2179, D_B_loss: 0.0224, G_A_loss: 0.7349, G_B_loss: 0.3435\n",
      "Epoch [118/200], Step [1/1067], D_A_loss: 0.0959, D_B_loss: 0.0221, G_A_loss: 0.7773, G_B_loss: 0.5775\n",
      "Epoch [118/200], Step [11/1067], D_A_loss: 0.1026, D_B_loss: 0.0431, G_A_loss: 0.5684, G_B_loss: 1.0608\n",
      "Epoch [118/200], Step [21/1067], D_A_loss: 0.0320, D_B_loss: 0.0160, G_A_loss: 0.8406, G_B_loss: 0.7390\n",
      "Epoch [118/200], Step [31/1067], D_A_loss: 0.0456, D_B_loss: 0.0441, G_A_loss: 1.0004, G_B_loss: 0.5897\n",
      "Epoch [118/200], Step [41/1067], D_A_loss: 0.0282, D_B_loss: 0.0271, G_A_loss: 0.7003, G_B_loss: 0.4294\n",
      "Epoch [118/200], Step [51/1067], D_A_loss: 0.1131, D_B_loss: 0.0257, G_A_loss: 0.9222, G_B_loss: 0.3641\n",
      "Epoch [118/200], Step [61/1067], D_A_loss: 0.3778, D_B_loss: 0.1072, G_A_loss: 0.8406, G_B_loss: 0.0774\n",
      "Epoch [118/200], Step [71/1067], D_A_loss: 0.0605, D_B_loss: 0.0288, G_A_loss: 0.6391, G_B_loss: 0.8800\n",
      "Epoch [118/200], Step [81/1067], D_A_loss: 0.0769, D_B_loss: 0.0238, G_A_loss: 0.9326, G_B_loss: 0.2014\n",
      "Epoch [118/200], Step [91/1067], D_A_loss: 0.1804, D_B_loss: 0.0511, G_A_loss: 0.8409, G_B_loss: 0.3264\n",
      "Epoch [118/200], Step [101/1067], D_A_loss: 0.1242, D_B_loss: 0.0990, G_A_loss: 1.0859, G_B_loss: 0.4325\n",
      "Epoch [118/200], Step [111/1067], D_A_loss: 0.0719, D_B_loss: 0.0136, G_A_loss: 0.6898, G_B_loss: 0.5630\n",
      "Epoch [118/200], Step [121/1067], D_A_loss: 0.0416, D_B_loss: 0.0336, G_A_loss: 0.6777, G_B_loss: 0.6227\n",
      "Epoch [118/200], Step [131/1067], D_A_loss: 0.0713, D_B_loss: 0.1883, G_A_loss: 1.0242, G_B_loss: 0.5541\n",
      "Epoch [118/200], Step [141/1067], D_A_loss: 0.0802, D_B_loss: 0.0290, G_A_loss: 0.4716, G_B_loss: 0.6284\n",
      "Epoch [118/200], Step [151/1067], D_A_loss: 0.1046, D_B_loss: 0.0151, G_A_loss: 0.9675, G_B_loss: 0.5242\n",
      "Epoch [118/200], Step [161/1067], D_A_loss: 0.0704, D_B_loss: 0.0441, G_A_loss: 0.6416, G_B_loss: 0.6258\n",
      "Epoch [118/200], Step [171/1067], D_A_loss: 0.0649, D_B_loss: 0.0130, G_A_loss: 1.0409, G_B_loss: 0.6170\n",
      "Epoch [118/200], Step [181/1067], D_A_loss: 0.0414, D_B_loss: 0.0289, G_A_loss: 0.6492, G_B_loss: 0.1941\n",
      "Epoch [118/200], Step [191/1067], D_A_loss: 0.1823, D_B_loss: 0.0179, G_A_loss: 0.7777, G_B_loss: 0.3037\n",
      "Epoch [118/200], Step [201/1067], D_A_loss: 0.0357, D_B_loss: 0.0245, G_A_loss: 0.8323, G_B_loss: 0.6316\n",
      "Epoch [118/200], Step [211/1067], D_A_loss: 0.2506, D_B_loss: 0.0190, G_A_loss: 0.6739, G_B_loss: 0.2923\n",
      "Epoch [118/200], Step [221/1067], D_A_loss: 0.0404, D_B_loss: 0.0663, G_A_loss: 1.2247, G_B_loss: 0.2556\n",
      "Epoch [118/200], Step [231/1067], D_A_loss: 0.0508, D_B_loss: 0.0127, G_A_loss: 0.9839, G_B_loss: 0.6333\n",
      "Epoch [118/200], Step [241/1067], D_A_loss: 0.1844, D_B_loss: 0.0432, G_A_loss: 1.1321, G_B_loss: 0.2170\n",
      "Epoch [118/200], Step [251/1067], D_A_loss: 0.0993, D_B_loss: 0.0368, G_A_loss: 0.6431, G_B_loss: 0.5208\n",
      "Epoch [118/200], Step [261/1067], D_A_loss: 0.0743, D_B_loss: 0.0194, G_A_loss: 0.9335, G_B_loss: 0.4780\n",
      "Epoch [118/200], Step [271/1067], D_A_loss: 0.0981, D_B_loss: 0.0243, G_A_loss: 0.8987, G_B_loss: 0.3762\n",
      "Epoch [118/200], Step [281/1067], D_A_loss: 0.0478, D_B_loss: 0.0722, G_A_loss: 0.5096, G_B_loss: 1.2334\n",
      "Epoch [118/200], Step [291/1067], D_A_loss: 0.2078, D_B_loss: 0.0600, G_A_loss: 0.4993, G_B_loss: 0.7608\n",
      "Epoch [118/200], Step [301/1067], D_A_loss: 0.0557, D_B_loss: 0.0111, G_A_loss: 0.9247, G_B_loss: 0.4557\n",
      "Epoch [118/200], Step [311/1067], D_A_loss: 0.0532, D_B_loss: 0.0182, G_A_loss: 0.8521, G_B_loss: 0.8857\n",
      "Epoch [118/200], Step [321/1067], D_A_loss: 0.1110, D_B_loss: 0.0271, G_A_loss: 0.7017, G_B_loss: 0.5976\n",
      "Epoch [118/200], Step [331/1067], D_A_loss: 0.0779, D_B_loss: 0.0388, G_A_loss: 0.8811, G_B_loss: 0.4444\n",
      "Epoch [118/200], Step [341/1067], D_A_loss: 0.1190, D_B_loss: 0.0519, G_A_loss: 0.8629, G_B_loss: 0.3910\n",
      "Epoch [118/200], Step [351/1067], D_A_loss: 0.0701, D_B_loss: 0.0169, G_A_loss: 0.7301, G_B_loss: 0.4539\n",
      "Epoch [118/200], Step [361/1067], D_A_loss: 0.2742, D_B_loss: 0.0155, G_A_loss: 1.0996, G_B_loss: 0.6568\n",
      "Epoch [118/200], Step [371/1067], D_A_loss: 0.1028, D_B_loss: 0.0207, G_A_loss: 0.7829, G_B_loss: 0.6164\n",
      "Epoch [118/200], Step [381/1067], D_A_loss: 0.0430, D_B_loss: 0.0165, G_A_loss: 0.7737, G_B_loss: 0.3795\n",
      "Epoch [118/200], Step [391/1067], D_A_loss: 0.1076, D_B_loss: 0.0258, G_A_loss: 0.8807, G_B_loss: 0.5012\n",
      "Epoch [118/200], Step [401/1067], D_A_loss: 0.2193, D_B_loss: 0.0275, G_A_loss: 0.7085, G_B_loss: 0.4267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [166/200], Step [231/1067], D_A_loss: 0.1218, D_B_loss: 0.0406, G_A_loss: 0.8515, G_B_loss: 0.8421\n",
      "Epoch [166/200], Step [241/1067], D_A_loss: 0.0421, D_B_loss: 0.0203, G_A_loss: 1.0404, G_B_loss: 0.7311\n",
      "Epoch [166/200], Step [251/1067], D_A_loss: 0.0433, D_B_loss: 0.0128, G_A_loss: 0.8264, G_B_loss: 0.6600\n",
      "Epoch [166/200], Step [261/1067], D_A_loss: 0.1029, D_B_loss: 0.0207, G_A_loss: 0.7994, G_B_loss: 0.7022\n",
      "Epoch [166/200], Step [271/1067], D_A_loss: 0.0536, D_B_loss: 0.0232, G_A_loss: 1.0566, G_B_loss: 0.5699\n",
      "Epoch [166/200], Step [281/1067], D_A_loss: 0.0563, D_B_loss: 0.0106, G_A_loss: 0.9208, G_B_loss: 0.5963\n",
      "Epoch [166/200], Step [291/1067], D_A_loss: 0.1431, D_B_loss: 0.1339, G_A_loss: 0.3989, G_B_loss: 0.6647\n",
      "Epoch [166/200], Step [301/1067], D_A_loss: 0.0410, D_B_loss: 0.0701, G_A_loss: 0.4252, G_B_loss: 0.6397\n",
      "Epoch [166/200], Step [311/1067], D_A_loss: 0.0307, D_B_loss: 0.0160, G_A_loss: 0.7835, G_B_loss: 0.5179\n",
      "Epoch [166/200], Step [321/1067], D_A_loss: 0.0797, D_B_loss: 0.0176, G_A_loss: 0.9090, G_B_loss: 0.4763\n",
      "Epoch [166/200], Step [331/1067], D_A_loss: 0.0283, D_B_loss: 0.0453, G_A_loss: 1.3169, G_B_loss: 0.6279\n",
      "Epoch [166/200], Step [341/1067], D_A_loss: 0.0775, D_B_loss: 0.0294, G_A_loss: 0.5023, G_B_loss: 0.5134\n",
      "Epoch [166/200], Step [351/1067], D_A_loss: 0.1406, D_B_loss: 0.0305, G_A_loss: 0.4124, G_B_loss: 0.7186\n",
      "Epoch [166/200], Step [361/1067], D_A_loss: 0.0732, D_B_loss: 0.0339, G_A_loss: 0.8558, G_B_loss: 0.7069\n",
      "Epoch [166/200], Step [371/1067], D_A_loss: 0.0230, D_B_loss: 0.0197, G_A_loss: 0.6540, G_B_loss: 0.7678\n",
      "Epoch [166/200], Step [381/1067], D_A_loss: 0.0280, D_B_loss: 0.0147, G_A_loss: 1.0537, G_B_loss: 0.8972\n",
      "Epoch [166/200], Step [391/1067], D_A_loss: 0.0696, D_B_loss: 0.0080, G_A_loss: 0.7850, G_B_loss: 0.8103\n",
      "Epoch [166/200], Step [401/1067], D_A_loss: 0.0967, D_B_loss: 0.0201, G_A_loss: 0.7937, G_B_loss: 0.5944\n",
      "Epoch [166/200], Step [411/1067], D_A_loss: 0.0572, D_B_loss: 0.0174, G_A_loss: 0.9260, G_B_loss: 0.5412\n",
      "Epoch [166/200], Step [421/1067], D_A_loss: 0.1180, D_B_loss: 0.0711, G_A_loss: 0.6783, G_B_loss: 0.5766\n",
      "Epoch [166/200], Step [431/1067], D_A_loss: 0.0731, D_B_loss: 0.0102, G_A_loss: 0.9936, G_B_loss: 0.5801\n",
      "Epoch [166/200], Step [441/1067], D_A_loss: 0.0605, D_B_loss: 0.0401, G_A_loss: 0.8923, G_B_loss: 0.5811\n",
      "Epoch [166/200], Step [451/1067], D_A_loss: 0.0229, D_B_loss: 0.0287, G_A_loss: 0.9500, G_B_loss: 0.8009\n",
      "Epoch [166/200], Step [461/1067], D_A_loss: 0.2462, D_B_loss: 0.0128, G_A_loss: 0.6325, G_B_loss: 0.8006\n",
      "Epoch [166/200], Step [471/1067], D_A_loss: 0.1021, D_B_loss: 0.0441, G_A_loss: 1.1363, G_B_loss: 0.4801\n",
      "Epoch [166/200], Step [481/1067], D_A_loss: 0.0827, D_B_loss: 0.0135, G_A_loss: 0.9279, G_B_loss: 0.4856\n",
      "Epoch [166/200], Step [491/1067], D_A_loss: 0.0236, D_B_loss: 0.0251, G_A_loss: 1.0904, G_B_loss: 0.8864\n",
      "Epoch [166/200], Step [501/1067], D_A_loss: 0.0788, D_B_loss: 0.0347, G_A_loss: 0.6630, G_B_loss: 0.4918\n",
      "Epoch [166/200], Step [511/1067], D_A_loss: 0.0819, D_B_loss: 0.0718, G_A_loss: 0.4395, G_B_loss: 0.6333\n",
      "Epoch [166/200], Step [521/1067], D_A_loss: 0.0261, D_B_loss: 0.0394, G_A_loss: 0.7627, G_B_loss: 0.4461\n",
      "Epoch [166/200], Step [531/1067], D_A_loss: 0.0440, D_B_loss: 0.0359, G_A_loss: 0.7278, G_B_loss: 0.5337\n",
      "Epoch [166/200], Step [541/1067], D_A_loss: 0.0745, D_B_loss: 0.0261, G_A_loss: 0.7932, G_B_loss: 0.6304\n",
      "Epoch [166/200], Step [551/1067], D_A_loss: 0.0347, D_B_loss: 0.0684, G_A_loss: 0.6827, G_B_loss: 0.6823\n",
      "Epoch [166/200], Step [561/1067], D_A_loss: 0.1313, D_B_loss: 0.0173, G_A_loss: 0.9693, G_B_loss: 0.5685\n",
      "Epoch [166/200], Step [571/1067], D_A_loss: 0.0365, D_B_loss: 0.0094, G_A_loss: 0.8222, G_B_loss: 0.9052\n",
      "Epoch [166/200], Step [581/1067], D_A_loss: 0.0339, D_B_loss: 0.0141, G_A_loss: 0.7394, G_B_loss: 0.7068\n",
      "Epoch [166/200], Step [591/1067], D_A_loss: 0.0697, D_B_loss: 0.0248, G_A_loss: 0.4720, G_B_loss: 0.7326\n",
      "Epoch [166/200], Step [601/1067], D_A_loss: 0.0847, D_B_loss: 0.0326, G_A_loss: 1.0143, G_B_loss: 0.6281\n",
      "Epoch [166/200], Step [611/1067], D_A_loss: 0.0438, D_B_loss: 0.0224, G_A_loss: 0.8284, G_B_loss: 0.6551\n",
      "Epoch [166/200], Step [621/1067], D_A_loss: 0.1080, D_B_loss: 0.0163, G_A_loss: 0.7038, G_B_loss: 0.5079\n",
      "Epoch [166/200], Step [631/1067], D_A_loss: 0.1661, D_B_loss: 0.0627, G_A_loss: 0.8537, G_B_loss: 0.3469\n",
      "Epoch [166/200], Step [641/1067], D_A_loss: 0.1101, D_B_loss: 0.0163, G_A_loss: 0.7396, G_B_loss: 0.6959\n",
      "Epoch [166/200], Step [651/1067], D_A_loss: 0.0727, D_B_loss: 0.0287, G_A_loss: 0.6192, G_B_loss: 0.8613\n",
      "Epoch [166/200], Step [661/1067], D_A_loss: 0.1359, D_B_loss: 0.0181, G_A_loss: 0.5767, G_B_loss: 0.6330\n",
      "Epoch [166/200], Step [671/1067], D_A_loss: 0.0587, D_B_loss: 0.0314, G_A_loss: 0.9001, G_B_loss: 0.7277\n",
      "Epoch [166/200], Step [681/1067], D_A_loss: 0.0258, D_B_loss: 0.0161, G_A_loss: 0.9695, G_B_loss: 0.6121\n",
      "Epoch [166/200], Step [691/1067], D_A_loss: 0.1530, D_B_loss: 0.0229, G_A_loss: 0.9287, G_B_loss: 0.8599\n",
      "Epoch [166/200], Step [701/1067], D_A_loss: 0.0372, D_B_loss: 0.0116, G_A_loss: 0.6855, G_B_loss: 0.7001\n",
      "Epoch [166/200], Step [711/1067], D_A_loss: 0.0478, D_B_loss: 0.0170, G_A_loss: 0.8704, G_B_loss: 0.6202\n",
      "Epoch [166/200], Step [721/1067], D_A_loss: 0.0356, D_B_loss: 0.0525, G_A_loss: 0.5468, G_B_loss: 0.7042\n",
      "Epoch [166/200], Step [731/1067], D_A_loss: 0.0497, D_B_loss: 0.0134, G_A_loss: 1.0884, G_B_loss: 0.3838\n",
      "Epoch [166/200], Step [741/1067], D_A_loss: 0.1670, D_B_loss: 0.0088, G_A_loss: 0.9302, G_B_loss: 0.9168\n",
      "Epoch [166/200], Step [751/1067], D_A_loss: 0.0955, D_B_loss: 0.0084, G_A_loss: 0.7292, G_B_loss: 0.3853\n",
      "Epoch [166/200], Step [761/1067], D_A_loss: 0.0328, D_B_loss: 0.0351, G_A_loss: 0.6399, G_B_loss: 0.4824\n",
      "Epoch [166/200], Step [771/1067], D_A_loss: 0.0249, D_B_loss: 0.0247, G_A_loss: 0.7168, G_B_loss: 0.7855\n",
      "Epoch [166/200], Step [781/1067], D_A_loss: 0.0601, D_B_loss: 0.0388, G_A_loss: 1.1110, G_B_loss: 0.5776\n",
      "Epoch [166/200], Step [791/1067], D_A_loss: 0.0249, D_B_loss: 0.0521, G_A_loss: 0.6644, G_B_loss: 0.9023\n",
      "Epoch [166/200], Step [801/1067], D_A_loss: 0.0279, D_B_loss: 0.0296, G_A_loss: 0.3952, G_B_loss: 0.6989\n",
      "Epoch [166/200], Step [811/1067], D_A_loss: 0.0172, D_B_loss: 0.0391, G_A_loss: 0.5930, G_B_loss: 0.7485\n",
      "Epoch [166/200], Step [821/1067], D_A_loss: 0.0754, D_B_loss: 0.0550, G_A_loss: 0.8283, G_B_loss: 0.6259\n",
      "Epoch [166/200], Step [831/1067], D_A_loss: 0.0336, D_B_loss: 0.0125, G_A_loss: 0.7357, G_B_loss: 0.8718\n",
      "Epoch [166/200], Step [841/1067], D_A_loss: 0.0772, D_B_loss: 0.0276, G_A_loss: 0.6799, G_B_loss: 0.7428\n",
      "Epoch [166/200], Step [851/1067], D_A_loss: 0.1088, D_B_loss: 0.0108, G_A_loss: 0.9633, G_B_loss: 0.4590\n",
      "Epoch [166/200], Step [861/1067], D_A_loss: 0.0421, D_B_loss: 0.0121, G_A_loss: 1.0708, G_B_loss: 0.2336\n",
      "Epoch [166/200], Step [871/1067], D_A_loss: 0.0363, D_B_loss: 0.0197, G_A_loss: 0.7889, G_B_loss: 0.6640\n",
      "Epoch [166/200], Step [881/1067], D_A_loss: 0.0967, D_B_loss: 0.0059, G_A_loss: 0.7252, G_B_loss: 0.6869\n",
      "Epoch [166/200], Step [891/1067], D_A_loss: 0.0353, D_B_loss: 0.0303, G_A_loss: 0.4763, G_B_loss: 0.7847\n",
      "Epoch [166/200], Step [901/1067], D_A_loss: 0.0388, D_B_loss: 0.0329, G_A_loss: 0.7764, G_B_loss: 0.9104\n",
      "Epoch [166/200], Step [911/1067], D_A_loss: 0.0268, D_B_loss: 0.0423, G_A_loss: 1.0509, G_B_loss: 0.9108\n",
      "Epoch [166/200], Step [921/1067], D_A_loss: 0.1292, D_B_loss: 0.0257, G_A_loss: 0.7798, G_B_loss: 0.8381\n",
      "Epoch [166/200], Step [931/1067], D_A_loss: 0.0443, D_B_loss: 0.0126, G_A_loss: 0.8820, G_B_loss: 0.8205\n",
      "Epoch [166/200], Step [941/1067], D_A_loss: 0.0549, D_B_loss: 0.0378, G_A_loss: 0.5924, G_B_loss: 0.6548\n",
      "Epoch [166/200], Step [951/1067], D_A_loss: 0.1249, D_B_loss: 0.0097, G_A_loss: 0.9980, G_B_loss: 0.7270\n",
      "Epoch [166/200], Step [961/1067], D_A_loss: 0.1723, D_B_loss: 0.0194, G_A_loss: 0.9472, G_B_loss: 0.7217\n",
      "Epoch [166/200], Step [971/1067], D_A_loss: 0.0278, D_B_loss: 0.0267, G_A_loss: 0.7764, G_B_loss: 0.7042\n",
      "Epoch [166/200], Step [981/1067], D_A_loss: 0.0281, D_B_loss: 0.0276, G_A_loss: 0.6035, G_B_loss: 0.4262\n",
      "Epoch [166/200], Step [991/1067], D_A_loss: 0.0309, D_B_loss: 0.0096, G_A_loss: 0.6963, G_B_loss: 0.3692\n",
      "Epoch [166/200], Step [1001/1067], D_A_loss: 0.0778, D_B_loss: 0.0483, G_A_loss: 0.8553, G_B_loss: 0.9413\n",
      "Epoch [166/200], Step [1011/1067], D_A_loss: 0.1097, D_B_loss: 0.0355, G_A_loss: 0.6530, G_B_loss: 0.5841\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [166/200], Step [1021/1067], D_A_loss: 0.1216, D_B_loss: 0.0106, G_A_loss: 0.6698, G_B_loss: 0.5643\n",
      "Epoch [166/200], Step [1031/1067], D_A_loss: 0.1373, D_B_loss: 0.0245, G_A_loss: 0.8060, G_B_loss: 0.5894\n",
      "Epoch [166/200], Step [1041/1067], D_A_loss: 0.0295, D_B_loss: 0.0134, G_A_loss: 0.7543, G_B_loss: 1.0538\n",
      "Epoch [166/200], Step [1051/1067], D_A_loss: 0.0348, D_B_loss: 0.0128, G_A_loss: 0.8332, G_B_loss: 0.3371\n",
      "Epoch [166/200], Step [1061/1067], D_A_loss: 0.0479, D_B_loss: 0.0651, G_A_loss: 0.6216, G_B_loss: 1.1374\n",
      "Epoch [167/200], Step [1/1067], D_A_loss: 0.1170, D_B_loss: 0.0437, G_A_loss: 0.5544, G_B_loss: 0.7043\n",
      "Epoch [167/200], Step [11/1067], D_A_loss: 0.0369, D_B_loss: 0.0158, G_A_loss: 0.8424, G_B_loss: 0.4412\n",
      "Epoch [167/200], Step [21/1067], D_A_loss: 0.0240, D_B_loss: 0.0200, G_A_loss: 0.9505, G_B_loss: 0.5475\n",
      "Epoch [167/200], Step [31/1067], D_A_loss: 0.3017, D_B_loss: 0.0169, G_A_loss: 0.9435, G_B_loss: 0.2633\n",
      "Epoch [167/200], Step [41/1067], D_A_loss: 0.0710, D_B_loss: 0.0155, G_A_loss: 0.6634, G_B_loss: 0.5139\n",
      "Epoch [167/200], Step [51/1067], D_A_loss: 0.0880, D_B_loss: 0.0348, G_A_loss: 0.4939, G_B_loss: 0.6755\n",
      "Epoch [167/200], Step [61/1067], D_A_loss: 0.0924, D_B_loss: 0.0296, G_A_loss: 0.8519, G_B_loss: 0.5358\n",
      "Epoch [167/200], Step [71/1067], D_A_loss: 0.0550, D_B_loss: 0.0191, G_A_loss: 0.8696, G_B_loss: 0.4005\n",
      "Epoch [167/200], Step [81/1067], D_A_loss: 0.1723, D_B_loss: 0.0439, G_A_loss: 0.5891, G_B_loss: 0.6039\n",
      "Epoch [167/200], Step [91/1067], D_A_loss: 0.0263, D_B_loss: 0.1267, G_A_loss: 0.3247, G_B_loss: 0.8026\n",
      "Epoch [167/200], Step [101/1067], D_A_loss: 0.0839, D_B_loss: 0.0259, G_A_loss: 0.6887, G_B_loss: 0.7297\n",
      "Epoch [167/200], Step [111/1067], D_A_loss: 0.0683, D_B_loss: 0.0139, G_A_loss: 1.0022, G_B_loss: 0.2995\n",
      "Epoch [167/200], Step [121/1067], D_A_loss: 0.0596, D_B_loss: 0.0406, G_A_loss: 0.6059, G_B_loss: 0.5601\n",
      "Epoch [167/200], Step [131/1067], D_A_loss: 0.2349, D_B_loss: 0.0192, G_A_loss: 0.6515, G_B_loss: 0.1619\n",
      "Epoch [167/200], Step [141/1067], D_A_loss: 0.0683, D_B_loss: 0.0215, G_A_loss: 0.7799, G_B_loss: 0.5336\n",
      "Epoch [167/200], Step [151/1067], D_A_loss: 0.0676, D_B_loss: 0.0730, G_A_loss: 0.7110, G_B_loss: 0.7397\n",
      "Epoch [167/200], Step [161/1067], D_A_loss: 0.0480, D_B_loss: 0.0238, G_A_loss: 0.7173, G_B_loss: 0.6625\n",
      "Epoch [167/200], Step [171/1067], D_A_loss: 0.0510, D_B_loss: 0.0130, G_A_loss: 0.7894, G_B_loss: 0.8272\n",
      "Epoch [167/200], Step [181/1067], D_A_loss: 0.0999, D_B_loss: 0.0114, G_A_loss: 0.9062, G_B_loss: 0.4056\n",
      "Epoch [167/200], Step [191/1067], D_A_loss: 0.0335, D_B_loss: 0.0866, G_A_loss: 0.8793, G_B_loss: 0.7313\n",
      "Epoch [167/200], Step [201/1067], D_A_loss: 0.0537, D_B_loss: 0.0099, G_A_loss: 0.3600, G_B_loss: 0.6089\n",
      "Epoch [167/200], Step [211/1067], D_A_loss: 0.0269, D_B_loss: 0.0547, G_A_loss: 0.5549, G_B_loss: 0.8164\n",
      "Epoch [167/200], Step [221/1067], D_A_loss: 0.0446, D_B_loss: 0.0436, G_A_loss: 1.0965, G_B_loss: 0.6198\n",
      "Epoch [167/200], Step [231/1067], D_A_loss: 0.0561, D_B_loss: 0.0437, G_A_loss: 1.4086, G_B_loss: 0.7178\n",
      "Epoch [167/200], Step [241/1067], D_A_loss: 0.2468, D_B_loss: 0.0219, G_A_loss: 0.7452, G_B_loss: 0.9233\n",
      "Epoch [167/200], Step [251/1067], D_A_loss: 0.1124, D_B_loss: 0.0091, G_A_loss: 0.8699, G_B_loss: 0.4398\n",
      "Epoch [167/200], Step [261/1067], D_A_loss: 0.0686, D_B_loss: 0.0176, G_A_loss: 0.9966, G_B_loss: 0.5219\n",
      "Epoch [167/200], Step [271/1067], D_A_loss: 0.1128, D_B_loss: 0.0461, G_A_loss: 0.5516, G_B_loss: 0.7619\n",
      "Epoch [167/200], Step [281/1067], D_A_loss: 0.0357, D_B_loss: 0.0175, G_A_loss: 0.8226, G_B_loss: 0.5838\n",
      "Epoch [167/200], Step [291/1067], D_A_loss: 0.0967, D_B_loss: 0.0554, G_A_loss: 0.6978, G_B_loss: 0.3966\n",
      "Epoch [167/200], Step [301/1067], D_A_loss: 0.0421, D_B_loss: 0.0233, G_A_loss: 1.3286, G_B_loss: 0.7020\n",
      "Epoch [167/200], Step [311/1067], D_A_loss: 0.0345, D_B_loss: 0.0351, G_A_loss: 0.6043, G_B_loss: 0.7112\n",
      "Epoch [167/200], Step [321/1067], D_A_loss: 0.1315, D_B_loss: 0.0436, G_A_loss: 0.6110, G_B_loss: 0.9688\n",
      "Epoch [167/200], Step [331/1067], D_A_loss: 0.0379, D_B_loss: 0.0452, G_A_loss: 0.5613, G_B_loss: 0.7514\n",
      "Epoch [167/200], Step [341/1067], D_A_loss: 0.0237, D_B_loss: 0.0108, G_A_loss: 0.8895, G_B_loss: 1.2936\n",
      "Epoch [167/200], Step [351/1067], D_A_loss: 0.0301, D_B_loss: 0.0436, G_A_loss: 0.5461, G_B_loss: 0.7282\n",
      "Epoch [167/200], Step [361/1067], D_A_loss: 0.1698, D_B_loss: 0.0249, G_A_loss: 0.7045, G_B_loss: 0.8407\n",
      "Epoch [167/200], Step [371/1067], D_A_loss: 0.0835, D_B_loss: 0.0198, G_A_loss: 0.9179, G_B_loss: 0.5122\n",
      "Epoch [167/200], Step [381/1067], D_A_loss: 0.0481, D_B_loss: 0.0656, G_A_loss: 1.0585, G_B_loss: 0.4078\n",
      "Epoch [167/200], Step [391/1067], D_A_loss: 0.0799, D_B_loss: 0.0337, G_A_loss: 1.0589, G_B_loss: 0.5343\n",
      "Epoch [167/200], Step [401/1067], D_A_loss: 0.1810, D_B_loss: 0.0608, G_A_loss: 0.8770, G_B_loss: 0.2435\n",
      "Epoch [167/200], Step [411/1067], D_A_loss: 0.0377, D_B_loss: 0.0399, G_A_loss: 0.8374, G_B_loss: 0.7093\n",
      "Epoch [167/200], Step [421/1067], D_A_loss: 0.0518, D_B_loss: 0.0348, G_A_loss: 0.7499, G_B_loss: 0.8752\n",
      "Epoch [167/200], Step [431/1067], D_A_loss: 0.0866, D_B_loss: 0.0270, G_A_loss: 0.9927, G_B_loss: 0.4799\n",
      "Epoch [167/200], Step [441/1067], D_A_loss: 0.0372, D_B_loss: 0.0176, G_A_loss: 0.7756, G_B_loss: 0.4910\n",
      "Epoch [167/200], Step [451/1067], D_A_loss: 0.0438, D_B_loss: 0.0167, G_A_loss: 1.0287, G_B_loss: 0.4191\n",
      "Epoch [167/200], Step [461/1067], D_A_loss: 0.0552, D_B_loss: 0.0445, G_A_loss: 0.5747, G_B_loss: 0.6355\n",
      "Epoch [167/200], Step [471/1067], D_A_loss: 0.0272, D_B_loss: 0.0109, G_A_loss: 0.9678, G_B_loss: 0.5306\n",
      "Epoch [167/200], Step [481/1067], D_A_loss: 0.1150, D_B_loss: 0.0276, G_A_loss: 1.1017, G_B_loss: 0.3674\n",
      "Epoch [167/200], Step [491/1067], D_A_loss: 0.0268, D_B_loss: 0.0106, G_A_loss: 0.9363, G_B_loss: 0.7260\n",
      "Epoch [167/200], Step [501/1067], D_A_loss: 0.0817, D_B_loss: 0.0748, G_A_loss: 0.5462, G_B_loss: 0.5155\n",
      "Epoch [167/200], Step [511/1067], D_A_loss: 0.1121, D_B_loss: 0.0293, G_A_loss: 0.6372, G_B_loss: 0.6799\n",
      "Epoch [167/200], Step [521/1067], D_A_loss: 0.0204, D_B_loss: 0.0352, G_A_loss: 0.5982, G_B_loss: 0.9711\n",
      "Epoch [167/200], Step [531/1067], D_A_loss: 0.0692, D_B_loss: 0.0213, G_A_loss: 0.9314, G_B_loss: 0.9043\n",
      "Epoch [167/200], Step [541/1067], D_A_loss: 0.0305, D_B_loss: 0.0226, G_A_loss: 0.7865, G_B_loss: 0.7437\n",
      "Epoch [167/200], Step [551/1067], D_A_loss: 0.0280, D_B_loss: 0.0271, G_A_loss: 0.7119, G_B_loss: 0.9262\n",
      "Epoch [167/200], Step [561/1067], D_A_loss: 0.0295, D_B_loss: 0.0234, G_A_loss: 0.7295, G_B_loss: 0.7914\n",
      "Epoch [167/200], Step [571/1067], D_A_loss: 0.0582, D_B_loss: 0.0132, G_A_loss: 0.8237, G_B_loss: 0.6885\n",
      "Epoch [167/200], Step [581/1067], D_A_loss: 0.0238, D_B_loss: 0.0102, G_A_loss: 0.8406, G_B_loss: 0.8395\n",
      "Epoch [167/200], Step [591/1067], D_A_loss: 0.0593, D_B_loss: 0.0158, G_A_loss: 1.1443, G_B_loss: 0.4515\n",
      "Epoch [167/200], Step [601/1067], D_A_loss: 0.0645, D_B_loss: 0.0211, G_A_loss: 0.7596, G_B_loss: 0.5948\n",
      "Epoch [167/200], Step [611/1067], D_A_loss: 0.1325, D_B_loss: 0.0293, G_A_loss: 1.0368, G_B_loss: 0.5436\n",
      "Epoch [167/200], Step [621/1067], D_A_loss: 0.1006, D_B_loss: 0.0550, G_A_loss: 1.0175, G_B_loss: 0.6870\n",
      "Epoch [167/200], Step [631/1067], D_A_loss: 0.1578, D_B_loss: 0.0205, G_A_loss: 0.7944, G_B_loss: 0.4966\n",
      "Epoch [167/200], Step [641/1067], D_A_loss: 0.0355, D_B_loss: 0.0095, G_A_loss: 0.7911, G_B_loss: 0.6534\n",
      "Epoch [167/200], Step [651/1067], D_A_loss: 0.0254, D_B_loss: 0.0226, G_A_loss: 0.8983, G_B_loss: 0.3286\n",
      "Epoch [167/200], Step [661/1067], D_A_loss: 0.1184, D_B_loss: 0.0483, G_A_loss: 0.5624, G_B_loss: 0.8392\n",
      "Epoch [167/200], Step [671/1067], D_A_loss: 0.0621, D_B_loss: 0.0506, G_A_loss: 0.5531, G_B_loss: 0.8509\n",
      "Epoch [167/200], Step [681/1067], D_A_loss: 0.0300, D_B_loss: 0.0112, G_A_loss: 0.7986, G_B_loss: 0.4672\n",
      "Epoch [167/200], Step [691/1067], D_A_loss: 0.1248, D_B_loss: 0.0329, G_A_loss: 0.6429, G_B_loss: 0.3264\n",
      "Epoch [167/200], Step [701/1067], D_A_loss: 0.0282, D_B_loss: 0.0279, G_A_loss: 0.5122, G_B_loss: 0.6436\n",
      "Epoch [167/200], Step [711/1067], D_A_loss: 0.0250, D_B_loss: 0.0122, G_A_loss: 0.9305, G_B_loss: 1.1620\n",
      "Epoch [167/200], Step [721/1067], D_A_loss: 0.1545, D_B_loss: 0.0392, G_A_loss: 0.6152, G_B_loss: 0.2553\n",
      "Epoch [167/200], Step [731/1067], D_A_loss: 0.0886, D_B_loss: 0.0237, G_A_loss: 0.6626, G_B_loss: 0.8112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [167/200], Step [741/1067], D_A_loss: 0.0280, D_B_loss: 0.0300, G_A_loss: 1.0840, G_B_loss: 0.8060\n",
      "Epoch [167/200], Step [751/1067], D_A_loss: 0.0302, D_B_loss: 0.0267, G_A_loss: 1.1667, G_B_loss: 0.4742\n",
      "Epoch [167/200], Step [761/1067], D_A_loss: 0.0666, D_B_loss: 0.0086, G_A_loss: 0.8920, G_B_loss: 0.6722\n",
      "Epoch [167/200], Step [771/1067], D_A_loss: 0.0333, D_B_loss: 0.0208, G_A_loss: 0.7183, G_B_loss: 0.7838\n",
      "Epoch [167/200], Step [781/1067], D_A_loss: 0.0753, D_B_loss: 0.0220, G_A_loss: 0.7317, G_B_loss: 0.6473\n",
      "Epoch [167/200], Step [791/1067], D_A_loss: 0.1629, D_B_loss: 0.0411, G_A_loss: 0.7190, G_B_loss: 0.5431\n",
      "Epoch [167/200], Step [801/1067], D_A_loss: 0.0413, D_B_loss: 0.0224, G_A_loss: 1.4294, G_B_loss: 0.6700\n",
      "Epoch [167/200], Step [811/1067], D_A_loss: 0.1053, D_B_loss: 0.1134, G_A_loss: 0.8621, G_B_loss: 0.3512\n",
      "Epoch [167/200], Step [821/1067], D_A_loss: 0.0955, D_B_loss: 0.0453, G_A_loss: 0.5944, G_B_loss: 0.4172\n",
      "Epoch [167/200], Step [831/1067], D_A_loss: 0.1013, D_B_loss: 0.0258, G_A_loss: 0.7463, G_B_loss: 0.3733\n",
      "Epoch [167/200], Step [841/1067], D_A_loss: 0.1654, D_B_loss: 0.0092, G_A_loss: 0.5000, G_B_loss: 0.2476\n",
      "Epoch [167/200], Step [851/1067], D_A_loss: 0.0423, D_B_loss: 0.0142, G_A_loss: 0.8917, G_B_loss: 0.6115\n",
      "Epoch [167/200], Step [861/1067], D_A_loss: 0.0364, D_B_loss: 0.0398, G_A_loss: 0.5920, G_B_loss: 0.3973\n",
      "Epoch [167/200], Step [871/1067], D_A_loss: 0.0241, D_B_loss: 0.0244, G_A_loss: 0.6175, G_B_loss: 0.9790\n",
      "Epoch [167/200], Step [881/1067], D_A_loss: 0.0450, D_B_loss: 0.0393, G_A_loss: 0.7379, G_B_loss: 0.7623\n",
      "Epoch [167/200], Step [891/1067], D_A_loss: 0.0583, D_B_loss: 0.0179, G_A_loss: 0.8901, G_B_loss: 0.6211\n",
      "Epoch [167/200], Step [901/1067], D_A_loss: 0.0654, D_B_loss: 0.0411, G_A_loss: 0.6533, G_B_loss: 0.9787\n",
      "Epoch [167/200], Step [911/1067], D_A_loss: 0.1122, D_B_loss: 0.0119, G_A_loss: 0.8986, G_B_loss: 0.3404\n",
      "Epoch [167/200], Step [921/1067], D_A_loss: 0.0973, D_B_loss: 0.0233, G_A_loss: 1.2678, G_B_loss: 0.4207\n",
      "Epoch [167/200], Step [931/1067], D_A_loss: 0.0594, D_B_loss: 0.0332, G_A_loss: 0.7421, G_B_loss: 0.8211\n",
      "Epoch [167/200], Step [941/1067], D_A_loss: 0.1240, D_B_loss: 0.0375, G_A_loss: 0.6846, G_B_loss: 0.5040\n",
      "Epoch [167/200], Step [951/1067], D_A_loss: 0.0307, D_B_loss: 0.0138, G_A_loss: 0.4389, G_B_loss: 0.7709\n",
      "Epoch [167/200], Step [961/1067], D_A_loss: 0.0478, D_B_loss: 0.0088, G_A_loss: 0.7806, G_B_loss: 0.9838\n",
      "Epoch [167/200], Step [971/1067], D_A_loss: 0.0389, D_B_loss: 0.0289, G_A_loss: 1.1741, G_B_loss: 0.7215\n",
      "Epoch [167/200], Step [981/1067], D_A_loss: 0.0300, D_B_loss: 0.0116, G_A_loss: 1.0937, G_B_loss: 0.5269\n",
      "Epoch [167/200], Step [991/1067], D_A_loss: 0.0345, D_B_loss: 0.0300, G_A_loss: 0.4091, G_B_loss: 0.7855\n",
      "Epoch [167/200], Step [1001/1067], D_A_loss: 0.0418, D_B_loss: 0.0084, G_A_loss: 1.0648, G_B_loss: 0.8217\n",
      "Epoch [167/200], Step [1011/1067], D_A_loss: 0.0674, D_B_loss: 0.0099, G_A_loss: 0.9066, G_B_loss: 0.4392\n",
      "Epoch [167/200], Step [1021/1067], D_A_loss: 0.0178, D_B_loss: 0.0229, G_A_loss: 0.9043, G_B_loss: 1.0282\n",
      "Epoch [167/200], Step [1031/1067], D_A_loss: 0.1207, D_B_loss: 0.0158, G_A_loss: 0.7764, G_B_loss: 0.5966\n",
      "Epoch [167/200], Step [1041/1067], D_A_loss: 0.1552, D_B_loss: 0.0323, G_A_loss: 0.7199, G_B_loss: 0.2754\n",
      "Epoch [167/200], Step [1051/1067], D_A_loss: 0.0955, D_B_loss: 0.0295, G_A_loss: 0.8887, G_B_loss: 0.7510\n",
      "Epoch [167/200], Step [1061/1067], D_A_loss: 0.0512, D_B_loss: 0.0367, G_A_loss: 0.6906, G_B_loss: 0.9702\n",
      "Epoch [168/200], Step [1/1067], D_A_loss: 0.0349, D_B_loss: 0.0973, G_A_loss: 1.3906, G_B_loss: 0.4434\n",
      "Epoch [168/200], Step [11/1067], D_A_loss: 0.0322, D_B_loss: 0.0106, G_A_loss: 1.3524, G_B_loss: 0.8120\n",
      "Epoch [168/200], Step [21/1067], D_A_loss: 0.0497, D_B_loss: 0.0214, G_A_loss: 0.7153, G_B_loss: 0.7820\n",
      "Epoch [168/200], Step [31/1067], D_A_loss: 0.0274, D_B_loss: 0.0449, G_A_loss: 0.5454, G_B_loss: 0.8651\n",
      "Epoch [168/200], Step [41/1067], D_A_loss: 0.1363, D_B_loss: 0.0394, G_A_loss: 1.1989, G_B_loss: 0.3200\n",
      "Epoch [168/200], Step [51/1067], D_A_loss: 0.0297, D_B_loss: 0.0201, G_A_loss: 0.7281, G_B_loss: 0.4896\n",
      "Epoch [168/200], Step [61/1067], D_A_loss: 0.1077, D_B_loss: 0.0094, G_A_loss: 0.8408, G_B_loss: 0.6240\n",
      "Epoch [168/200], Step [71/1067], D_A_loss: 0.0233, D_B_loss: 0.0889, G_A_loss: 0.7882, G_B_loss: 0.4898\n",
      "Epoch [168/200], Step [81/1067], D_A_loss: 0.1226, D_B_loss: 0.0152, G_A_loss: 1.0468, G_B_loss: 0.6760\n",
      "Epoch [168/200], Step [91/1067], D_A_loss: 0.0747, D_B_loss: 0.0102, G_A_loss: 0.8044, G_B_loss: 1.2141\n",
      "Epoch [168/200], Step [101/1067], D_A_loss: 0.0251, D_B_loss: 0.0572, G_A_loss: 1.0727, G_B_loss: 0.3083\n",
      "Epoch [168/200], Step [111/1067], D_A_loss: 0.1019, D_B_loss: 0.0247, G_A_loss: 0.7208, G_B_loss: 0.6562\n",
      "Epoch [168/200], Step [121/1067], D_A_loss: 0.0649, D_B_loss: 0.0560, G_A_loss: 0.5710, G_B_loss: 0.9311\n",
      "Epoch [168/200], Step [131/1067], D_A_loss: 0.0352, D_B_loss: 0.0117, G_A_loss: 0.9810, G_B_loss: 0.7720\n",
      "Epoch [168/200], Step [141/1067], D_A_loss: 0.2148, D_B_loss: 0.0138, G_A_loss: 0.8210, G_B_loss: 0.2678\n",
      "Epoch [168/200], Step [151/1067], D_A_loss: 0.0845, D_B_loss: 0.0400, G_A_loss: 0.8634, G_B_loss: 0.4646\n",
      "Epoch [168/200], Step [161/1067], D_A_loss: 0.0194, D_B_loss: 0.0619, G_A_loss: 0.8228, G_B_loss: 0.4887\n",
      "Epoch [168/200], Step [171/1067], D_A_loss: 0.1276, D_B_loss: 0.0105, G_A_loss: 1.0486, G_B_loss: 0.4016\n",
      "Epoch [168/200], Step [181/1067], D_A_loss: 0.0423, D_B_loss: 0.0110, G_A_loss: 0.8686, G_B_loss: 0.6402\n",
      "Epoch [168/200], Step [191/1067], D_A_loss: 0.0259, D_B_loss: 0.0223, G_A_loss: 1.0326, G_B_loss: 0.5899\n",
      "Epoch [168/200], Step [201/1067], D_A_loss: 0.1028, D_B_loss: 0.0082, G_A_loss: 0.5260, G_B_loss: 0.3648\n",
      "Epoch [168/200], Step [211/1067], D_A_loss: 0.0175, D_B_loss: 0.0236, G_A_loss: 1.2324, G_B_loss: 0.9786\n",
      "Epoch [168/200], Step [221/1067], D_A_loss: 0.0386, D_B_loss: 0.0126, G_A_loss: 0.9488, G_B_loss: 0.7257\n",
      "Epoch [168/200], Step [231/1067], D_A_loss: 0.0496, D_B_loss: 0.0253, G_A_loss: 0.4165, G_B_loss: 0.7899\n",
      "Epoch [168/200], Step [241/1067], D_A_loss: 0.0494, D_B_loss: 0.0104, G_A_loss: 0.7839, G_B_loss: 0.9945\n",
      "Epoch [168/200], Step [251/1067], D_A_loss: 0.1270, D_B_loss: 0.0189, G_A_loss: 0.8643, G_B_loss: 0.2559\n",
      "Epoch [168/200], Step [261/1067], D_A_loss: 0.0544, D_B_loss: 0.0236, G_A_loss: 0.6758, G_B_loss: 0.6364\n",
      "Epoch [168/200], Step [271/1067], D_A_loss: 0.0583, D_B_loss: 0.0091, G_A_loss: 1.0573, G_B_loss: 0.5878\n",
      "Epoch [168/200], Step [281/1067], D_A_loss: 0.2021, D_B_loss: 0.0324, G_A_loss: 0.6695, G_B_loss: 0.8027\n",
      "Epoch [168/200], Step [291/1067], D_A_loss: 0.0581, D_B_loss: 0.0144, G_A_loss: 0.6261, G_B_loss: 0.7794\n",
      "Epoch [168/200], Step [301/1067], D_A_loss: 0.0236, D_B_loss: 0.0155, G_A_loss: 0.8293, G_B_loss: 0.8410\n",
      "Epoch [168/200], Step [311/1067], D_A_loss: 0.0248, D_B_loss: 0.0204, G_A_loss: 0.9772, G_B_loss: 0.5283\n",
      "Epoch [168/200], Step [321/1067], D_A_loss: 0.1114, D_B_loss: 0.0172, G_A_loss: 1.1389, G_B_loss: 0.5773\n",
      "Epoch [168/200], Step [331/1067], D_A_loss: 0.0920, D_B_loss: 0.0149, G_A_loss: 0.8394, G_B_loss: 0.8119\n",
      "Epoch [168/200], Step [341/1067], D_A_loss: 0.1072, D_B_loss: 0.0101, G_A_loss: 0.5285, G_B_loss: 0.7605\n",
      "Epoch [168/200], Step [351/1067], D_A_loss: 0.1421, D_B_loss: 0.0174, G_A_loss: 0.8184, G_B_loss: 0.5283\n",
      "Epoch [168/200], Step [361/1067], D_A_loss: 0.0422, D_B_loss: 0.0634, G_A_loss: 0.6044, G_B_loss: 0.4168\n",
      "Epoch [168/200], Step [371/1067], D_A_loss: 0.0763, D_B_loss: 0.0207, G_A_loss: 1.0928, G_B_loss: 0.6848\n",
      "Epoch [168/200], Step [381/1067], D_A_loss: 0.0909, D_B_loss: 0.0672, G_A_loss: 0.7502, G_B_loss: 0.4188\n",
      "Epoch [168/200], Step [391/1067], D_A_loss: 0.1027, D_B_loss: 0.0535, G_A_loss: 0.7139, G_B_loss: 0.4551\n",
      "Epoch [168/200], Step [401/1067], D_A_loss: 0.0270, D_B_loss: 0.0205, G_A_loss: 1.0762, G_B_loss: 1.0243\n",
      "Epoch [168/200], Step [411/1067], D_A_loss: 0.0234, D_B_loss: 0.0081, G_A_loss: 0.6974, G_B_loss: 0.5792\n",
      "Epoch [168/200], Step [421/1067], D_A_loss: 0.0335, D_B_loss: 0.0154, G_A_loss: 0.5504, G_B_loss: 0.8508\n",
      "Epoch [168/200], Step [431/1067], D_A_loss: 0.0487, D_B_loss: 0.0094, G_A_loss: 0.9895, G_B_loss: 1.0980\n",
      "Epoch [168/200], Step [441/1067], D_A_loss: 0.1452, D_B_loss: 0.0267, G_A_loss: 0.7885, G_B_loss: 0.5553\n",
      "Epoch [168/200], Step [451/1067], D_A_loss: 0.0593, D_B_loss: 0.0759, G_A_loss: 0.4967, G_B_loss: 0.6436\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [168/200], Step [461/1067], D_A_loss: 0.0668, D_B_loss: 0.0271, G_A_loss: 0.9225, G_B_loss: 0.5196\n",
      "Epoch [168/200], Step [471/1067], D_A_loss: 0.1341, D_B_loss: 0.0094, G_A_loss: 0.9531, G_B_loss: 0.2056\n",
      "Epoch [168/200], Step [481/1067], D_A_loss: 0.1626, D_B_loss: 0.0723, G_A_loss: 0.4348, G_B_loss: 1.0652\n",
      "Epoch [168/200], Step [491/1067], D_A_loss: 0.1074, D_B_loss: 0.0103, G_A_loss: 0.8893, G_B_loss: 0.7905\n",
      "Epoch [168/200], Step [501/1067], D_A_loss: 0.1202, D_B_loss: 0.0135, G_A_loss: 0.9227, G_B_loss: 0.5245\n",
      "Epoch [168/200], Step [511/1067], D_A_loss: 0.0299, D_B_loss: 0.0348, G_A_loss: 0.7608, G_B_loss: 1.0374\n",
      "Epoch [168/200], Step [521/1067], D_A_loss: 0.1085, D_B_loss: 0.0328, G_A_loss: 1.2753, G_B_loss: 0.3317\n",
      "Epoch [168/200], Step [531/1067], D_A_loss: 0.0328, D_B_loss: 0.0132, G_A_loss: 0.8862, G_B_loss: 0.7940\n",
      "Epoch [168/200], Step [541/1067], D_A_loss: 0.0966, D_B_loss: 0.0143, G_A_loss: 0.8379, G_B_loss: 0.7662\n",
      "Epoch [168/200], Step [551/1067], D_A_loss: 0.0468, D_B_loss: 0.0224, G_A_loss: 0.3686, G_B_loss: 0.6956\n",
      "Epoch [168/200], Step [561/1067], D_A_loss: 0.0909, D_B_loss: 0.0287, G_A_loss: 0.9443, G_B_loss: 0.4801\n",
      "Epoch [168/200], Step [571/1067], D_A_loss: 0.0791, D_B_loss: 0.0333, G_A_loss: 0.6663, G_B_loss: 0.6063\n",
      "Epoch [168/200], Step [581/1067], D_A_loss: 0.0802, D_B_loss: 0.0483, G_A_loss: 1.0887, G_B_loss: 0.4635\n",
      "Epoch [168/200], Step [591/1067], D_A_loss: 0.0672, D_B_loss: 0.0414, G_A_loss: 0.6387, G_B_loss: 1.0814\n",
      "Epoch [168/200], Step [601/1067], D_A_loss: 0.1271, D_B_loss: 0.0352, G_A_loss: 0.6107, G_B_loss: 0.6205\n",
      "Epoch [168/200], Step [611/1067], D_A_loss: 0.0438, D_B_loss: 0.0250, G_A_loss: 0.7364, G_B_loss: 0.6571\n",
      "Epoch [168/200], Step [621/1067], D_A_loss: 0.0376, D_B_loss: 0.0225, G_A_loss: 0.7375, G_B_loss: 0.8105\n",
      "Epoch [168/200], Step [631/1067], D_A_loss: 0.0917, D_B_loss: 0.0228, G_A_loss: 1.0646, G_B_loss: 0.6346\n",
      "Epoch [168/200], Step [641/1067], D_A_loss: 0.0692, D_B_loss: 0.0158, G_A_loss: 1.0442, G_B_loss: 0.5173\n",
      "Epoch [168/200], Step [651/1067], D_A_loss: 0.0802, D_B_loss: 0.0295, G_A_loss: 0.7090, G_B_loss: 0.4279\n",
      "Epoch [168/200], Step [661/1067], D_A_loss: 0.0321, D_B_loss: 0.0195, G_A_loss: 0.8231, G_B_loss: 0.9955\n",
      "Epoch [168/200], Step [671/1067], D_A_loss: 0.1141, D_B_loss: 0.0434, G_A_loss: 1.0273, G_B_loss: 0.4161\n",
      "Epoch [168/200], Step [681/1067], D_A_loss: 0.0615, D_B_loss: 0.0157, G_A_loss: 0.8531, G_B_loss: 0.6042\n",
      "Epoch [168/200], Step [691/1067], D_A_loss: 0.0391, D_B_loss: 0.0305, G_A_loss: 0.8921, G_B_loss: 0.7134\n",
      "Epoch [168/200], Step [701/1067], D_A_loss: 0.0655, D_B_loss: 0.0260, G_A_loss: 0.7666, G_B_loss: 0.4387\n",
      "Epoch [168/200], Step [711/1067], D_A_loss: 0.0784, D_B_loss: 0.0086, G_A_loss: 0.9411, G_B_loss: 0.5959\n",
      "Epoch [168/200], Step [721/1067], D_A_loss: 0.1936, D_B_loss: 0.0061, G_A_loss: 1.0045, G_B_loss: 0.4540\n",
      "Epoch [168/200], Step [731/1067], D_A_loss: 0.0652, D_B_loss: 0.0162, G_A_loss: 1.2808, G_B_loss: 0.8109\n",
      "Epoch [168/200], Step [741/1067], D_A_loss: 0.0348, D_B_loss: 0.0204, G_A_loss: 1.0588, G_B_loss: 0.8533\n",
      "Epoch [168/200], Step [751/1067], D_A_loss: 0.0516, D_B_loss: 0.0074, G_A_loss: 0.5986, G_B_loss: 0.6057\n",
      "Epoch [168/200], Step [761/1067], D_A_loss: 0.0642, D_B_loss: 0.0787, G_A_loss: 0.8137, G_B_loss: 0.5401\n",
      "Epoch [168/200], Step [771/1067], D_A_loss: 0.0835, D_B_loss: 0.0710, G_A_loss: 0.4282, G_B_loss: 0.4964\n",
      "Epoch [168/200], Step [781/1067], D_A_loss: 0.0399, D_B_loss: 0.0811, G_A_loss: 0.5571, G_B_loss: 0.6626\n",
      "Epoch [168/200], Step [791/1067], D_A_loss: 0.0954, D_B_loss: 0.0196, G_A_loss: 0.7392, G_B_loss: 0.8051\n",
      "Epoch [168/200], Step [801/1067], D_A_loss: 0.1395, D_B_loss: 0.0126, G_A_loss: 1.1881, G_B_loss: 0.3150\n",
      "Epoch [168/200], Step [811/1067], D_A_loss: 0.0277, D_B_loss: 0.0973, G_A_loss: 0.8005, G_B_loss: 0.3884\n",
      "Epoch [168/200], Step [821/1067], D_A_loss: 0.0489, D_B_loss: 0.1087, G_A_loss: 1.1412, G_B_loss: 0.2914\n",
      "Epoch [168/200], Step [831/1067], D_A_loss: 0.0210, D_B_loss: 0.0444, G_A_loss: 0.5546, G_B_loss: 1.1059\n",
      "Epoch [168/200], Step [841/1067], D_A_loss: 0.0454, D_B_loss: 0.0341, G_A_loss: 0.8239, G_B_loss: 0.7052\n",
      "Epoch [168/200], Step [851/1067], D_A_loss: 0.1318, D_B_loss: 0.0186, G_A_loss: 0.8737, G_B_loss: 0.7146\n",
      "Epoch [168/200], Step [861/1067], D_A_loss: 0.0698, D_B_loss: 0.0166, G_A_loss: 0.8202, G_B_loss: 0.5696\n",
      "Epoch [168/200], Step [871/1067], D_A_loss: 0.0641, D_B_loss: 0.0168, G_A_loss: 0.7228, G_B_loss: 0.5507\n",
      "Epoch [168/200], Step [881/1067], D_A_loss: 0.0554, D_B_loss: 0.0337, G_A_loss: 0.6867, G_B_loss: 0.5605\n",
      "Epoch [168/200], Step [891/1067], D_A_loss: 0.0223, D_B_loss: 0.0751, G_A_loss: 0.9644, G_B_loss: 0.6509\n",
      "Epoch [168/200], Step [901/1067], D_A_loss: 0.0555, D_B_loss: 0.0223, G_A_loss: 0.9233, G_B_loss: 1.2037\n",
      "Epoch [168/200], Step [911/1067], D_A_loss: 0.1285, D_B_loss: 0.0436, G_A_loss: 0.7218, G_B_loss: 0.6919\n",
      "Epoch [168/200], Step [921/1067], D_A_loss: 0.0997, D_B_loss: 0.0114, G_A_loss: 0.8819, G_B_loss: 0.4238\n",
      "Epoch [168/200], Step [931/1067], D_A_loss: 0.0937, D_B_loss: 0.0069, G_A_loss: 0.7282, G_B_loss: 0.5308\n",
      "Epoch [168/200], Step [941/1067], D_A_loss: 0.1852, D_B_loss: 0.0432, G_A_loss: 0.5684, G_B_loss: 0.4548\n",
      "Epoch [168/200], Step [951/1067], D_A_loss: 0.0953, D_B_loss: 0.0197, G_A_loss: 0.7872, G_B_loss: 0.7650\n",
      "Epoch [168/200], Step [961/1067], D_A_loss: 0.1240, D_B_loss: 0.0398, G_A_loss: 0.5919, G_B_loss: 0.6224\n",
      "Epoch [168/200], Step [971/1067], D_A_loss: 0.0485, D_B_loss: 0.0102, G_A_loss: 0.9961, G_B_loss: 0.4651\n",
      "Epoch [168/200], Step [981/1067], D_A_loss: 0.1733, D_B_loss: 0.0222, G_A_loss: 0.5066, G_B_loss: 0.5215\n",
      "Epoch [168/200], Step [991/1067], D_A_loss: 0.0440, D_B_loss: 0.0358, G_A_loss: 0.9028, G_B_loss: 0.7075\n",
      "Epoch [168/200], Step [1001/1067], D_A_loss: 0.0541, D_B_loss: 0.0251, G_A_loss: 0.7784, G_B_loss: 0.7064\n",
      "Epoch [168/200], Step [1011/1067], D_A_loss: 0.0373, D_B_loss: 0.0147, G_A_loss: 0.6479, G_B_loss: 0.7559\n",
      "Epoch [168/200], Step [1021/1067], D_A_loss: 0.0949, D_B_loss: 0.0160, G_A_loss: 0.9102, G_B_loss: 0.6136\n",
      "Epoch [168/200], Step [1031/1067], D_A_loss: 0.0187, D_B_loss: 0.1365, G_A_loss: 0.3896, G_B_loss: 0.8254\n",
      "Epoch [168/200], Step [1041/1067], D_A_loss: 0.0954, D_B_loss: 0.1373, G_A_loss: 1.4466, G_B_loss: 0.7367\n",
      "Epoch [168/200], Step [1051/1067], D_A_loss: 0.0573, D_B_loss: 0.0121, G_A_loss: 0.8952, G_B_loss: 0.8344\n",
      "Epoch [168/200], Step [1061/1067], D_A_loss: 0.0835, D_B_loss: 0.0256, G_A_loss: 0.7961, G_B_loss: 0.8895\n",
      "Epoch [169/200], Step [1/1067], D_A_loss: 0.0348, D_B_loss: 0.0235, G_A_loss: 0.7980, G_B_loss: 0.6380\n",
      "Epoch [169/200], Step [11/1067], D_A_loss: 0.0555, D_B_loss: 0.0126, G_A_loss: 0.8281, G_B_loss: 0.6475\n",
      "Epoch [169/200], Step [21/1067], D_A_loss: 0.0646, D_B_loss: 0.0179, G_A_loss: 0.5863, G_B_loss: 0.6118\n",
      "Epoch [169/200], Step [31/1067], D_A_loss: 0.0529, D_B_loss: 0.0130, G_A_loss: 0.7299, G_B_loss: 0.7332\n",
      "Epoch [169/200], Step [41/1067], D_A_loss: 0.0935, D_B_loss: 0.0135, G_A_loss: 0.7764, G_B_loss: 0.6670\n",
      "Epoch [169/200], Step [51/1067], D_A_loss: 0.0328, D_B_loss: 0.0182, G_A_loss: 0.9656, G_B_loss: 0.8018\n",
      "Epoch [169/200], Step [61/1067], D_A_loss: 0.0676, D_B_loss: 0.0308, G_A_loss: 0.6541, G_B_loss: 0.8410\n",
      "Epoch [169/200], Step [71/1067], D_A_loss: 0.0523, D_B_loss: 0.0143, G_A_loss: 1.1288, G_B_loss: 0.7459\n",
      "Epoch [169/200], Step [81/1067], D_A_loss: 0.0936, D_B_loss: 0.0211, G_A_loss: 1.0896, G_B_loss: 0.3967\n",
      "Epoch [169/200], Step [91/1067], D_A_loss: 0.0206, D_B_loss: 0.0304, G_A_loss: 0.6939, G_B_loss: 0.5160\n",
      "Epoch [169/200], Step [101/1067], D_A_loss: 0.0339, D_B_loss: 0.0079, G_A_loss: 0.9970, G_B_loss: 0.7652\n",
      "Epoch [169/200], Step [111/1067], D_A_loss: 0.0250, D_B_loss: 0.0350, G_A_loss: 0.6006, G_B_loss: 0.9072\n",
      "Epoch [169/200], Step [121/1067], D_A_loss: 0.0178, D_B_loss: 0.0340, G_A_loss: 0.6456, G_B_loss: 1.1297\n",
      "Epoch [169/200], Step [131/1067], D_A_loss: 0.1694, D_B_loss: 0.0761, G_A_loss: 0.6622, G_B_loss: 0.3526\n",
      "Epoch [169/200], Step [141/1067], D_A_loss: 0.0604, D_B_loss: 0.0310, G_A_loss: 1.0540, G_B_loss: 0.7941\n",
      "Epoch [169/200], Step [151/1067], D_A_loss: 0.0814, D_B_loss: 0.0229, G_A_loss: 0.7264, G_B_loss: 0.8743\n",
      "Epoch [169/200], Step [161/1067], D_A_loss: 0.1070, D_B_loss: 0.0219, G_A_loss: 1.4761, G_B_loss: 0.4137\n",
      "Epoch [169/200], Step [171/1067], D_A_loss: 0.0745, D_B_loss: 0.0198, G_A_loss: 1.0581, G_B_loss: 0.5396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [169/200], Step [181/1067], D_A_loss: 0.0296, D_B_loss: 0.0180, G_A_loss: 1.0570, G_B_loss: 0.5483\n",
      "Epoch [169/200], Step [191/1067], D_A_loss: 0.0774, D_B_loss: 0.0206, G_A_loss: 0.8356, G_B_loss: 0.3423\n",
      "Epoch [169/200], Step [201/1067], D_A_loss: 0.0651, D_B_loss: 0.0857, G_A_loss: 0.3998, G_B_loss: 0.5953\n",
      "Epoch [169/200], Step [211/1067], D_A_loss: 0.1958, D_B_loss: 0.0657, G_A_loss: 0.4462, G_B_loss: 0.5506\n",
      "Epoch [169/200], Step [221/1067], D_A_loss: 0.2146, D_B_loss: 0.0214, G_A_loss: 1.3426, G_B_loss: 0.6250\n",
      "Epoch [169/200], Step [231/1067], D_A_loss: 0.0379, D_B_loss: 0.0376, G_A_loss: 0.5769, G_B_loss: 0.6395\n",
      "Epoch [169/200], Step [241/1067], D_A_loss: 0.0366, D_B_loss: 0.0390, G_A_loss: 0.8400, G_B_loss: 0.4578\n",
      "Epoch [169/200], Step [251/1067], D_A_loss: 0.2563, D_B_loss: 0.0118, G_A_loss: 0.8975, G_B_loss: 0.6258\n",
      "Epoch [169/200], Step [261/1067], D_A_loss: 0.1159, D_B_loss: 0.0286, G_A_loss: 0.5306, G_B_loss: 0.6425\n",
      "Epoch [169/200], Step [271/1067], D_A_loss: 0.0471, D_B_loss: 0.0309, G_A_loss: 0.6588, G_B_loss: 0.5409\n",
      "Epoch [169/200], Step [281/1067], D_A_loss: 0.0604, D_B_loss: 0.1717, G_A_loss: 0.8355, G_B_loss: 0.6525\n",
      "Epoch [169/200], Step [291/1067], D_A_loss: 0.0234, D_B_loss: 0.0877, G_A_loss: 0.8524, G_B_loss: 0.5476\n",
      "Epoch [169/200], Step [301/1067], D_A_loss: 0.0633, D_B_loss: 0.0279, G_A_loss: 0.9605, G_B_loss: 0.5092\n",
      "Epoch [169/200], Step [311/1067], D_A_loss: 0.0250, D_B_loss: 0.0183, G_A_loss: 0.4748, G_B_loss: 0.7577\n",
      "Epoch [169/200], Step [321/1067], D_A_loss: 0.0255, D_B_loss: 0.0293, G_A_loss: 1.3034, G_B_loss: 0.3142\n",
      "Epoch [169/200], Step [331/1067], D_A_loss: 0.1176, D_B_loss: 0.0436, G_A_loss: 0.8199, G_B_loss: 0.7711\n",
      "Epoch [169/200], Step [341/1067], D_A_loss: 0.1262, D_B_loss: 0.0155, G_A_loss: 0.9201, G_B_loss: 0.6244\n",
      "Epoch [169/200], Step [351/1067], D_A_loss: 0.0690, D_B_loss: 0.0423, G_A_loss: 0.7439, G_B_loss: 0.4657\n",
      "Epoch [169/200], Step [361/1067], D_A_loss: 0.0363, D_B_loss: 0.0127, G_A_loss: 1.1024, G_B_loss: 0.7151\n",
      "Epoch [169/200], Step [371/1067], D_A_loss: 0.0281, D_B_loss: 0.0127, G_A_loss: 0.8754, G_B_loss: 0.8242\n",
      "Epoch [169/200], Step [381/1067], D_A_loss: 0.0651, D_B_loss: 0.0248, G_A_loss: 0.7009, G_B_loss: 0.5803\n",
      "Epoch [169/200], Step [391/1067], D_A_loss: 0.0621, D_B_loss: 0.0329, G_A_loss: 1.0630, G_B_loss: 0.6464\n",
      "Epoch [169/200], Step [401/1067], D_A_loss: 0.0610, D_B_loss: 0.0190, G_A_loss: 0.9545, G_B_loss: 0.7233\n",
      "Epoch [169/200], Step [411/1067], D_A_loss: 0.0336, D_B_loss: 0.0104, G_A_loss: 0.9237, G_B_loss: 0.4025\n",
      "Epoch [169/200], Step [421/1067], D_A_loss: 0.0791, D_B_loss: 0.0616, G_A_loss: 0.5057, G_B_loss: 0.5703\n",
      "Epoch [169/200], Step [431/1067], D_A_loss: 0.0678, D_B_loss: 0.0345, G_A_loss: 0.6897, G_B_loss: 0.5181\n",
      "Epoch [169/200], Step [441/1067], D_A_loss: 0.1120, D_B_loss: 0.0793, G_A_loss: 0.7505, G_B_loss: 0.5222\n",
      "Epoch [169/200], Step [451/1067], D_A_loss: 0.0365, D_B_loss: 0.0301, G_A_loss: 0.9439, G_B_loss: 0.6068\n",
      "Epoch [169/200], Step [461/1067], D_A_loss: 0.0256, D_B_loss: 0.0641, G_A_loss: 0.4920, G_B_loss: 0.6356\n",
      "Epoch [169/200], Step [471/1067], D_A_loss: 0.0238, D_B_loss: 0.0278, G_A_loss: 0.9264, G_B_loss: 0.8494\n",
      "Epoch [169/200], Step [481/1067], D_A_loss: 0.0689, D_B_loss: 0.0146, G_A_loss: 0.9383, G_B_loss: 0.6628\n",
      "Epoch [169/200], Step [491/1067], D_A_loss: 0.0858, D_B_loss: 0.0104, G_A_loss: 0.9906, G_B_loss: 0.5994\n",
      "Epoch [169/200], Step [501/1067], D_A_loss: 0.1008, D_B_loss: 0.0509, G_A_loss: 0.9524, G_B_loss: 0.6804\n",
      "Epoch [169/200], Step [511/1067], D_A_loss: 0.0731, D_B_loss: 0.0303, G_A_loss: 0.7726, G_B_loss: 0.5165\n",
      "Epoch [169/200], Step [521/1067], D_A_loss: 0.1229, D_B_loss: 0.0122, G_A_loss: 0.9539, G_B_loss: 0.6196\n",
      "Epoch [169/200], Step [531/1067], D_A_loss: 0.0284, D_B_loss: 0.0618, G_A_loss: 0.6043, G_B_loss: 0.8414\n",
      "Epoch [169/200], Step [541/1067], D_A_loss: 0.0287, D_B_loss: 0.0379, G_A_loss: 0.5885, G_B_loss: 0.4537\n",
      "Epoch [169/200], Step [551/1067], D_A_loss: 0.0194, D_B_loss: 0.0229, G_A_loss: 0.8349, G_B_loss: 0.9274\n",
      "Epoch [169/200], Step [561/1067], D_A_loss: 0.0635, D_B_loss: 0.0105, G_A_loss: 0.8708, G_B_loss: 0.5511\n",
      "Epoch [169/200], Step [571/1067], D_A_loss: 0.1470, D_B_loss: 0.0396, G_A_loss: 0.6530, G_B_loss: 0.2902\n",
      "Epoch [169/200], Step [581/1067], D_A_loss: 0.0451, D_B_loss: 0.0245, G_A_loss: 0.5885, G_B_loss: 0.5123\n",
      "Epoch [169/200], Step [591/1067], D_A_loss: 0.1511, D_B_loss: 0.0485, G_A_loss: 0.8596, G_B_loss: 0.4501\n",
      "Epoch [169/200], Step [601/1067], D_A_loss: 0.0322, D_B_loss: 0.0165, G_A_loss: 0.9612, G_B_loss: 0.5238\n",
      "Epoch [169/200], Step [611/1067], D_A_loss: 0.0756, D_B_loss: 0.0110, G_A_loss: 0.5064, G_B_loss: 0.6788\n",
      "Epoch [169/200], Step [621/1067], D_A_loss: 0.0233, D_B_loss: 0.0146, G_A_loss: 0.7896, G_B_loss: 0.3833\n",
      "Epoch [169/200], Step [631/1067], D_A_loss: 0.0474, D_B_loss: 0.0536, G_A_loss: 1.3719, G_B_loss: 0.7080\n",
      "Epoch [169/200], Step [641/1067], D_A_loss: 0.0654, D_B_loss: 0.0105, G_A_loss: 0.9437, G_B_loss: 0.6305\n",
      "Epoch [169/200], Step [651/1067], D_A_loss: 0.0684, D_B_loss: 0.0239, G_A_loss: 0.7891, G_B_loss: 0.5670\n",
      "Epoch [169/200], Step [661/1067], D_A_loss: 0.1558, D_B_loss: 0.0115, G_A_loss: 0.9925, G_B_loss: 0.3585\n",
      "Epoch [169/200], Step [671/1067], D_A_loss: 0.0276, D_B_loss: 0.0113, G_A_loss: 0.9290, G_B_loss: 0.4286\n",
      "Epoch [169/200], Step [681/1067], D_A_loss: 0.2135, D_B_loss: 0.0134, G_A_loss: 0.8781, G_B_loss: 0.8954\n",
      "Epoch [169/200], Step [691/1067], D_A_loss: 0.1056, D_B_loss: 0.0472, G_A_loss: 0.4892, G_B_loss: 0.8189\n",
      "Epoch [169/200], Step [701/1067], D_A_loss: 0.0270, D_B_loss: 0.0131, G_A_loss: 1.2968, G_B_loss: 1.0012\n",
      "Epoch [169/200], Step [711/1067], D_A_loss: 0.2971, D_B_loss: 0.0411, G_A_loss: 0.8738, G_B_loss: 0.8638\n",
      "Epoch [169/200], Step [721/1067], D_A_loss: 0.0536, D_B_loss: 0.0341, G_A_loss: 0.6894, G_B_loss: 0.8565\n",
      "Epoch [169/200], Step [731/1067], D_A_loss: 0.0538, D_B_loss: 0.0471, G_A_loss: 0.9842, G_B_loss: 0.7442\n",
      "Epoch [169/200], Step [741/1067], D_A_loss: 0.1233, D_B_loss: 0.0165, G_A_loss: 0.7943, G_B_loss: 0.5205\n",
      "Epoch [169/200], Step [751/1067], D_A_loss: 0.1619, D_B_loss: 0.0204, G_A_loss: 0.9936, G_B_loss: 0.2581\n",
      "Epoch [169/200], Step [761/1067], D_A_loss: 0.0730, D_B_loss: 0.0221, G_A_loss: 0.7710, G_B_loss: 0.5175\n",
      "Epoch [169/200], Step [771/1067], D_A_loss: 0.0209, D_B_loss: 0.0719, G_A_loss: 1.3339, G_B_loss: 0.9910\n",
      "Epoch [169/200], Step [781/1067], D_A_loss: 0.0792, D_B_loss: 0.0426, G_A_loss: 0.8586, G_B_loss: 0.4492\n",
      "Epoch [169/200], Step [791/1067], D_A_loss: 0.2167, D_B_loss: 0.0229, G_A_loss: 0.9571, G_B_loss: 0.6760\n",
      "Epoch [169/200], Step [801/1067], D_A_loss: 0.0620, D_B_loss: 0.0072, G_A_loss: 0.7355, G_B_loss: 0.8326\n",
      "Epoch [169/200], Step [811/1067], D_A_loss: 0.0387, D_B_loss: 0.0283, G_A_loss: 0.6788, G_B_loss: 0.6870\n",
      "Epoch [169/200], Step [821/1067], D_A_loss: 0.0524, D_B_loss: 0.0391, G_A_loss: 0.5780, G_B_loss: 0.8261\n",
      "Epoch [169/200], Step [831/1067], D_A_loss: 0.1802, D_B_loss: 0.0591, G_A_loss: 0.6133, G_B_loss: 0.4992\n",
      "Epoch [169/200], Step [841/1067], D_A_loss: 0.0580, D_B_loss: 0.0096, G_A_loss: 1.0858, G_B_loss: 1.1807\n",
      "Epoch [169/200], Step [851/1067], D_A_loss: 0.0372, D_B_loss: 0.0407, G_A_loss: 0.6658, G_B_loss: 0.7986\n",
      "Epoch [169/200], Step [861/1067], D_A_loss: 0.1741, D_B_loss: 0.0129, G_A_loss: 0.8471, G_B_loss: 0.7946\n",
      "Epoch [169/200], Step [871/1067], D_A_loss: 0.0508, D_B_loss: 0.0111, G_A_loss: 0.8664, G_B_loss: 0.4927\n",
      "Epoch [169/200], Step [881/1067], D_A_loss: 0.1502, D_B_loss: 0.0197, G_A_loss: 0.7796, G_B_loss: 0.5169\n",
      "Epoch [169/200], Step [891/1067], D_A_loss: 0.1236, D_B_loss: 0.0126, G_A_loss: 0.9741, G_B_loss: 0.6383\n",
      "Epoch [169/200], Step [901/1067], D_A_loss: 0.0543, D_B_loss: 0.1025, G_A_loss: 0.3852, G_B_loss: 1.0527\n",
      "Epoch [169/200], Step [911/1067], D_A_loss: 0.0938, D_B_loss: 0.0691, G_A_loss: 0.9630, G_B_loss: 0.3791\n",
      "Epoch [169/200], Step [921/1067], D_A_loss: 0.0715, D_B_loss: 0.0257, G_A_loss: 0.9428, G_B_loss: 0.8320\n",
      "Epoch [169/200], Step [931/1067], D_A_loss: 0.0374, D_B_loss: 0.0529, G_A_loss: 0.4978, G_B_loss: 0.7873\n",
      "Epoch [169/200], Step [941/1067], D_A_loss: 0.0660, D_B_loss: 0.0197, G_A_loss: 0.7682, G_B_loss: 0.8932\n",
      "Epoch [169/200], Step [951/1067], D_A_loss: 0.0509, D_B_loss: 0.0148, G_A_loss: 0.7776, G_B_loss: 0.5858\n",
      "Epoch [169/200], Step [961/1067], D_A_loss: 0.0651, D_B_loss: 0.0340, G_A_loss: 0.4438, G_B_loss: 0.9520\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [169/200], Step [971/1067], D_A_loss: 0.0623, D_B_loss: 0.0113, G_A_loss: 0.9241, G_B_loss: 0.5432\n",
      "Epoch [169/200], Step [981/1067], D_A_loss: 0.0202, D_B_loss: 0.1121, G_A_loss: 1.0030, G_B_loss: 0.5195\n",
      "Epoch [169/200], Step [991/1067], D_A_loss: 0.0548, D_B_loss: 0.0217, G_A_loss: 0.9250, G_B_loss: 0.5930\n",
      "Epoch [169/200], Step [1001/1067], D_A_loss: 0.0600, D_B_loss: 0.0437, G_A_loss: 1.2653, G_B_loss: 0.3541\n",
      "Epoch [169/200], Step [1011/1067], D_A_loss: 0.0392, D_B_loss: 0.0260, G_A_loss: 1.0244, G_B_loss: 0.6705\n",
      "Epoch [169/200], Step [1021/1067], D_A_loss: 0.0448, D_B_loss: 0.0126, G_A_loss: 0.5333, G_B_loss: 1.0097\n",
      "Epoch [169/200], Step [1031/1067], D_A_loss: 0.1182, D_B_loss: 0.0133, G_A_loss: 0.5650, G_B_loss: 0.4818\n",
      "Epoch [169/200], Step [1041/1067], D_A_loss: 0.0261, D_B_loss: 0.0276, G_A_loss: 0.9093, G_B_loss: 0.6618\n",
      "Epoch [169/200], Step [1051/1067], D_A_loss: 0.0698, D_B_loss: 0.0418, G_A_loss: 0.5706, G_B_loss: 0.8132\n",
      "Epoch [169/200], Step [1061/1067], D_A_loss: 0.1165, D_B_loss: 0.0122, G_A_loss: 0.9655, G_B_loss: 0.4511\n",
      "Epoch [170/200], Step [1/1067], D_A_loss: 0.0798, D_B_loss: 0.0280, G_A_loss: 0.6750, G_B_loss: 0.7380\n",
      "Epoch [170/200], Step [11/1067], D_A_loss: 0.0667, D_B_loss: 0.0280, G_A_loss: 1.1384, G_B_loss: 0.6120\n",
      "Epoch [170/200], Step [21/1067], D_A_loss: 0.0518, D_B_loss: 0.0138, G_A_loss: 0.8823, G_B_loss: 0.6971\n",
      "Epoch [170/200], Step [31/1067], D_A_loss: 0.0735, D_B_loss: 0.0275, G_A_loss: 0.6537, G_B_loss: 1.0175\n",
      "Epoch [170/200], Step [41/1067], D_A_loss: 0.0557, D_B_loss: 0.0116, G_A_loss: 0.6609, G_B_loss: 0.7137\n",
      "Epoch [170/200], Step [51/1067], D_A_loss: 0.1376, D_B_loss: 0.0228, G_A_loss: 1.2257, G_B_loss: 0.3150\n",
      "Epoch [170/200], Step [61/1067], D_A_loss: 0.1126, D_B_loss: 0.0480, G_A_loss: 0.6061, G_B_loss: 0.4185\n",
      "Epoch [170/200], Step [71/1067], D_A_loss: 0.0293, D_B_loss: 0.0495, G_A_loss: 0.5025, G_B_loss: 0.5369\n",
      "Epoch [170/200], Step [81/1067], D_A_loss: 0.0458, D_B_loss: 0.0320, G_A_loss: 0.8367, G_B_loss: 0.7727\n",
      "Epoch [170/200], Step [91/1067], D_A_loss: 0.0461, D_B_loss: 0.0336, G_A_loss: 0.7607, G_B_loss: 0.2271\n",
      "Epoch [170/200], Step [101/1067], D_A_loss: 0.0651, D_B_loss: 0.0384, G_A_loss: 0.8511, G_B_loss: 1.1255\n",
      "Epoch [170/200], Step [111/1067], D_A_loss: 0.0421, D_B_loss: 0.0121, G_A_loss: 1.1412, G_B_loss: 0.5227\n",
      "Epoch [170/200], Step [121/1067], D_A_loss: 0.1408, D_B_loss: 0.1063, G_A_loss: 1.1729, G_B_loss: 0.4841\n",
      "Epoch [170/200], Step [131/1067], D_A_loss: 0.0346, D_B_loss: 0.0370, G_A_loss: 0.9448, G_B_loss: 0.6832\n",
      "Epoch [170/200], Step [141/1067], D_A_loss: 0.0227, D_B_loss: 0.0137, G_A_loss: 1.0179, G_B_loss: 0.8536\n",
      "Epoch [170/200], Step [151/1067], D_A_loss: 0.0401, D_B_loss: 0.0153, G_A_loss: 1.1762, G_B_loss: 0.6453\n",
      "Epoch [170/200], Step [161/1067], D_A_loss: 0.0545, D_B_loss: 0.0471, G_A_loss: 0.5369, G_B_loss: 0.5693\n",
      "Epoch [170/200], Step [171/1067], D_A_loss: 0.0642, D_B_loss: 0.0188, G_A_loss: 1.1217, G_B_loss: 1.2665\n",
      "Epoch [170/200], Step [181/1067], D_A_loss: 0.0238, D_B_loss: 0.0119, G_A_loss: 0.5731, G_B_loss: 0.2079\n",
      "Epoch [170/200], Step [191/1067], D_A_loss: 0.2472, D_B_loss: 0.0469, G_A_loss: 1.0107, G_B_loss: 0.8731\n",
      "Epoch [170/200], Step [201/1067], D_A_loss: 0.0637, D_B_loss: 0.0508, G_A_loss: 1.1008, G_B_loss: 0.8104\n",
      "Epoch [170/200], Step [211/1067], D_A_loss: 0.0787, D_B_loss: 0.0111, G_A_loss: 0.8408, G_B_loss: 0.4688\n",
      "Epoch [170/200], Step [221/1067], D_A_loss: 0.0897, D_B_loss: 0.0415, G_A_loss: 0.4615, G_B_loss: 0.5916\n",
      "Epoch [170/200], Step [231/1067], D_A_loss: 0.1147, D_B_loss: 0.0520, G_A_loss: 0.5191, G_B_loss: 0.2156\n",
      "Epoch [170/200], Step [241/1067], D_A_loss: 0.0363, D_B_loss: 0.0311, G_A_loss: 0.9017, G_B_loss: 0.5762\n",
      "Epoch [170/200], Step [251/1067], D_A_loss: 0.0588, D_B_loss: 0.0110, G_A_loss: 1.0572, G_B_loss: 0.6206\n",
      "Epoch [170/200], Step [261/1067], D_A_loss: 0.0322, D_B_loss: 0.0486, G_A_loss: 1.3459, G_B_loss: 0.5976\n",
      "Epoch [170/200], Step [271/1067], D_A_loss: 0.0230, D_B_loss: 0.0190, G_A_loss: 0.7587, G_B_loss: 0.8110\n",
      "Epoch [170/200], Step [281/1067], D_A_loss: 0.0341, D_B_loss: 0.0348, G_A_loss: 1.1021, G_B_loss: 0.5611\n",
      "Epoch [170/200], Step [291/1067], D_A_loss: 0.0333, D_B_loss: 0.0081, G_A_loss: 0.5739, G_B_loss: 1.2242\n",
      "Epoch [170/200], Step [301/1067], D_A_loss: 0.0247, D_B_loss: 0.0513, G_A_loss: 0.7364, G_B_loss: 0.4866\n",
      "Epoch [170/200], Step [311/1067], D_A_loss: 0.0622, D_B_loss: 0.0428, G_A_loss: 1.0247, G_B_loss: 0.3386\n",
      "Epoch [170/200], Step [321/1067], D_A_loss: 0.1150, D_B_loss: 0.0248, G_A_loss: 0.8386, G_B_loss: 0.5813\n",
      "Epoch [170/200], Step [331/1067], D_A_loss: 0.0221, D_B_loss: 0.0691, G_A_loss: 1.0815, G_B_loss: 0.6109\n",
      "Epoch [170/200], Step [341/1067], D_A_loss: 0.0337, D_B_loss: 0.0657, G_A_loss: 1.2873, G_B_loss: 0.8110\n",
      "Epoch [170/200], Step [351/1067], D_A_loss: 0.1596, D_B_loss: 0.0216, G_A_loss: 0.6674, G_B_loss: 0.3157\n",
      "Epoch [170/200], Step [361/1067], D_A_loss: 0.0786, D_B_loss: 0.0270, G_A_loss: 0.7684, G_B_loss: 0.6993\n",
      "Epoch [170/200], Step [371/1067], D_A_loss: 0.0329, D_B_loss: 0.0114, G_A_loss: 0.7766, G_B_loss: 0.7072\n",
      "Epoch [170/200], Step [381/1067], D_A_loss: 0.0436, D_B_loss: 0.0106, G_A_loss: 1.2114, G_B_loss: 0.6653\n",
      "Epoch [170/200], Step [391/1067], D_A_loss: 0.0693, D_B_loss: 0.0200, G_A_loss: 0.9057, G_B_loss: 0.5450\n",
      "Epoch [170/200], Step [401/1067], D_A_loss: 0.1302, D_B_loss: 0.0104, G_A_loss: 0.9510, G_B_loss: 0.3479\n",
      "Epoch [170/200], Step [411/1067], D_A_loss: 0.1669, D_B_loss: 0.0139, G_A_loss: 0.9292, G_B_loss: 0.8629\n",
      "Epoch [170/200], Step [421/1067], D_A_loss: 0.0566, D_B_loss: 0.0128, G_A_loss: 0.8759, G_B_loss: 0.4256\n",
      "Epoch [170/200], Step [431/1067], D_A_loss: 0.2492, D_B_loss: 0.0216, G_A_loss: 0.7785, G_B_loss: 0.4371\n",
      "Epoch [170/200], Step [441/1067], D_A_loss: 0.0260, D_B_loss: 0.0306, G_A_loss: 0.7205, G_B_loss: 0.7491\n",
      "Epoch [170/200], Step [451/1067], D_A_loss: 0.1300, D_B_loss: 0.0178, G_A_loss: 0.9215, G_B_loss: 0.8254\n",
      "Epoch [170/200], Step [461/1067], D_A_loss: 0.0321, D_B_loss: 0.0236, G_A_loss: 0.8000, G_B_loss: 0.9369\n",
      "Epoch [170/200], Step [471/1067], D_A_loss: 0.2657, D_B_loss: 0.0094, G_A_loss: 0.7634, G_B_loss: 0.3815\n",
      "Epoch [170/200], Step [481/1067], D_A_loss: 0.0367, D_B_loss: 0.0202, G_A_loss: 0.8840, G_B_loss: 0.5461\n",
      "Epoch [170/200], Step [491/1067], D_A_loss: 0.0422, D_B_loss: 0.0078, G_A_loss: 0.9270, G_B_loss: 0.8528\n",
      "Epoch [170/200], Step [501/1067], D_A_loss: 0.0307, D_B_loss: 0.0126, G_A_loss: 0.5084, G_B_loss: 0.8905\n",
      "Epoch [170/200], Step [511/1067], D_A_loss: 0.0527, D_B_loss: 0.0231, G_A_loss: 0.9781, G_B_loss: 0.7090\n",
      "Epoch [170/200], Step [521/1067], D_A_loss: 0.0681, D_B_loss: 0.0136, G_A_loss: 0.7685, G_B_loss: 1.0034\n",
      "Epoch [170/200], Step [531/1067], D_A_loss: 0.1163, D_B_loss: 0.0123, G_A_loss: 0.8913, G_B_loss: 0.6533\n",
      "Epoch [170/200], Step [541/1067], D_A_loss: 0.0948, D_B_loss: 0.0170, G_A_loss: 0.7493, G_B_loss: 0.5302\n",
      "Epoch [170/200], Step [551/1067], D_A_loss: 0.0260, D_B_loss: 0.0155, G_A_loss: 0.7861, G_B_loss: 0.8643\n",
      "Epoch [170/200], Step [561/1067], D_A_loss: 0.0757, D_B_loss: 0.0242, G_A_loss: 0.6895, G_B_loss: 0.7366\n",
      "Epoch [170/200], Step [571/1067], D_A_loss: 0.1304, D_B_loss: 0.0295, G_A_loss: 1.0577, G_B_loss: 0.3015\n",
      "Epoch [170/200], Step [581/1067], D_A_loss: 0.0428, D_B_loss: 0.0122, G_A_loss: 0.7963, G_B_loss: 0.6215\n",
      "Epoch [170/200], Step [591/1067], D_A_loss: 0.0507, D_B_loss: 0.0337, G_A_loss: 0.6399, G_B_loss: 0.6478\n",
      "Epoch [170/200], Step [601/1067], D_A_loss: 0.0512, D_B_loss: 0.0109, G_A_loss: 0.5699, G_B_loss: 0.7804\n",
      "Epoch [170/200], Step [611/1067], D_A_loss: 0.0650, D_B_loss: 0.0789, G_A_loss: 0.3947, G_B_loss: 0.7588\n",
      "Epoch [170/200], Step [621/1067], D_A_loss: 0.1300, D_B_loss: 0.0115, G_A_loss: 0.9222, G_B_loss: 0.3036\n",
      "Epoch [170/200], Step [631/1067], D_A_loss: 0.0652, D_B_loss: 0.0068, G_A_loss: 1.0415, G_B_loss: 0.4474\n",
      "Epoch [170/200], Step [641/1067], D_A_loss: 0.0657, D_B_loss: 0.0219, G_A_loss: 0.7688, G_B_loss: 0.5519\n",
      "Epoch [170/200], Step [651/1067], D_A_loss: 0.0294, D_B_loss: 0.0125, G_A_loss: 0.9822, G_B_loss: 0.4052\n",
      "Epoch [170/200], Step [661/1067], D_A_loss: 0.0640, D_B_loss: 0.0179, G_A_loss: 0.8528, G_B_loss: 0.7474\n",
      "Epoch [170/200], Step [671/1067], D_A_loss: 0.1160, D_B_loss: 0.0257, G_A_loss: 0.6664, G_B_loss: 0.8020\n",
      "Epoch [170/200], Step [681/1067], D_A_loss: 0.1762, D_B_loss: 0.0190, G_A_loss: 1.0584, G_B_loss: 1.3879\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [170/200], Step [691/1067], D_A_loss: 0.0389, D_B_loss: 0.0483, G_A_loss: 1.4568, G_B_loss: 0.5807\n",
      "Epoch [170/200], Step [701/1067], D_A_loss: 0.0897, D_B_loss: 0.0376, G_A_loss: 0.7425, G_B_loss: 0.6811\n",
      "Epoch [170/200], Step [711/1067], D_A_loss: 0.0381, D_B_loss: 0.0244, G_A_loss: 0.5295, G_B_loss: 0.7065\n",
      "Epoch [170/200], Step [721/1067], D_A_loss: 0.0330, D_B_loss: 0.0446, G_A_loss: 0.3680, G_B_loss: 0.4754\n",
      "Epoch [170/200], Step [731/1067], D_A_loss: 0.1312, D_B_loss: 0.0128, G_A_loss: 0.6683, G_B_loss: 0.3850\n",
      "Epoch [170/200], Step [741/1067], D_A_loss: 0.0957, D_B_loss: 0.0250, G_A_loss: 0.8597, G_B_loss: 0.4092\n",
      "Epoch [170/200], Step [751/1067], D_A_loss: 0.1679, D_B_loss: 0.0215, G_A_loss: 0.7205, G_B_loss: 0.6969\n",
      "Epoch [170/200], Step [761/1067], D_A_loss: 0.1153, D_B_loss: 0.0804, G_A_loss: 0.4380, G_B_loss: 0.4580\n",
      "Epoch [170/200], Step [771/1067], D_A_loss: 0.0425, D_B_loss: 0.0298, G_A_loss: 0.9613, G_B_loss: 0.6729\n",
      "Epoch [170/200], Step [781/1067], D_A_loss: 0.0488, D_B_loss: 0.0475, G_A_loss: 0.5276, G_B_loss: 0.3619\n",
      "Epoch [170/200], Step [791/1067], D_A_loss: 0.0856, D_B_loss: 0.0345, G_A_loss: 0.8740, G_B_loss: 0.5763\n",
      "Epoch [170/200], Step [801/1067], D_A_loss: 0.0456, D_B_loss: 0.0291, G_A_loss: 1.1670, G_B_loss: 0.7018\n",
      "Epoch [170/200], Step [811/1067], D_A_loss: 0.1390, D_B_loss: 0.0090, G_A_loss: 1.0931, G_B_loss: 0.3653\n",
      "Epoch [170/200], Step [821/1067], D_A_loss: 0.0714, D_B_loss: 0.0219, G_A_loss: 0.6467, G_B_loss: 0.5060\n",
      "Epoch [170/200], Step [831/1067], D_A_loss: 0.1016, D_B_loss: 0.0252, G_A_loss: 0.9859, G_B_loss: 0.4384\n",
      "Epoch [170/200], Step [841/1067], D_A_loss: 0.0614, D_B_loss: 0.0259, G_A_loss: 0.6720, G_B_loss: 0.9326\n",
      "Epoch [170/200], Step [851/1067], D_A_loss: 0.0610, D_B_loss: 0.0287, G_A_loss: 1.2022, G_B_loss: 0.4995\n",
      "Epoch [170/200], Step [861/1067], D_A_loss: 0.1089, D_B_loss: 0.0119, G_A_loss: 1.0666, G_B_loss: 0.7593\n",
      "Epoch [170/200], Step [871/1067], D_A_loss: 0.0456, D_B_loss: 0.0616, G_A_loss: 1.0622, G_B_loss: 0.3693\n",
      "Epoch [170/200], Step [881/1067], D_A_loss: 0.1146, D_B_loss: 0.0192, G_A_loss: 0.7801, G_B_loss: 0.4848\n",
      "Epoch [170/200], Step [891/1067], D_A_loss: 0.0511, D_B_loss: 0.0263, G_A_loss: 1.1480, G_B_loss: 0.7009\n",
      "Epoch [170/200], Step [901/1067], D_A_loss: 0.0590, D_B_loss: 0.0214, G_A_loss: 0.9316, G_B_loss: 0.5724\n",
      "Epoch [170/200], Step [911/1067], D_A_loss: 0.0306, D_B_loss: 0.0174, G_A_loss: 0.6358, G_B_loss: 0.6180\n",
      "Epoch [170/200], Step [921/1067], D_A_loss: 0.0261, D_B_loss: 0.0112, G_A_loss: 1.0068, G_B_loss: 0.5350\n",
      "Epoch [170/200], Step [931/1067], D_A_loss: 0.0386, D_B_loss: 0.0121, G_A_loss: 0.8721, G_B_loss: 0.6695\n",
      "Epoch [170/200], Step [941/1067], D_A_loss: 0.0466, D_B_loss: 0.0189, G_A_loss: 1.0128, G_B_loss: 0.8781\n",
      "Epoch [170/200], Step [951/1067], D_A_loss: 0.1788, D_B_loss: 0.0095, G_A_loss: 0.9737, G_B_loss: 0.7047\n",
      "Epoch [170/200], Step [961/1067], D_A_loss: 0.0980, D_B_loss: 0.0691, G_A_loss: 0.9495, G_B_loss: 0.9115\n",
      "Epoch [170/200], Step [971/1067], D_A_loss: 0.1145, D_B_loss: 0.0158, G_A_loss: 0.7257, G_B_loss: 1.0077\n",
      "Epoch [170/200], Step [981/1067], D_A_loss: 0.0239, D_B_loss: 0.0183, G_A_loss: 0.8973, G_B_loss: 0.8975\n",
      "Epoch [170/200], Step [991/1067], D_A_loss: 0.0772, D_B_loss: 0.0731, G_A_loss: 0.4314, G_B_loss: 0.4954\n",
      "Epoch [170/200], Step [1001/1067], D_A_loss: 0.1503, D_B_loss: 0.0235, G_A_loss: 0.8584, G_B_loss: 0.2824\n",
      "Epoch [170/200], Step [1011/1067], D_A_loss: 0.0474, D_B_loss: 0.0438, G_A_loss: 0.5804, G_B_loss: 0.8959\n",
      "Epoch [170/200], Step [1021/1067], D_A_loss: 0.0802, D_B_loss: 0.0247, G_A_loss: 0.6195, G_B_loss: 0.3018\n",
      "Epoch [170/200], Step [1031/1067], D_A_loss: 0.0296, D_B_loss: 0.0191, G_A_loss: 0.8443, G_B_loss: 0.6447\n",
      "Epoch [170/200], Step [1041/1067], D_A_loss: 0.0868, D_B_loss: 0.0195, G_A_loss: 1.3340, G_B_loss: 0.5203\n",
      "Epoch [170/200], Step [1051/1067], D_A_loss: 0.0190, D_B_loss: 0.0129, G_A_loss: 1.1012, G_B_loss: 0.9674\n",
      "Epoch [170/200], Step [1061/1067], D_A_loss: 0.1505, D_B_loss: 0.0493, G_A_loss: 0.5088, G_B_loss: 0.6519\n",
      "Epoch [171/200], Step [1/1067], D_A_loss: 0.0560, D_B_loss: 0.0301, G_A_loss: 0.6311, G_B_loss: 0.8294\n",
      "Epoch [171/200], Step [11/1067], D_A_loss: 0.0299, D_B_loss: 0.0305, G_A_loss: 0.8252, G_B_loss: 0.4688\n",
      "Epoch [171/200], Step [21/1067], D_A_loss: 0.0657, D_B_loss: 0.0589, G_A_loss: 0.8238, G_B_loss: 0.5375\n",
      "Epoch [171/200], Step [31/1067], D_A_loss: 0.1512, D_B_loss: 0.0137, G_A_loss: 0.8430, G_B_loss: 0.7404\n",
      "Epoch [171/200], Step [41/1067], D_A_loss: 0.0638, D_B_loss: 0.0138, G_A_loss: 0.7841, G_B_loss: 0.3351\n",
      "Epoch [171/200], Step [51/1067], D_A_loss: 0.0556, D_B_loss: 0.0383, G_A_loss: 1.3313, G_B_loss: 0.7330\n",
      "Epoch [171/200], Step [61/1067], D_A_loss: 0.0319, D_B_loss: 0.0205, G_A_loss: 0.7350, G_B_loss: 0.4809\n",
      "Epoch [171/200], Step [71/1067], D_A_loss: 0.0267, D_B_loss: 0.0305, G_A_loss: 0.8707, G_B_loss: 0.8514\n",
      "Epoch [171/200], Step [81/1067], D_A_loss: 0.0625, D_B_loss: 0.0122, G_A_loss: 1.1221, G_B_loss: 0.6997\n",
      "Epoch [171/200], Step [91/1067], D_A_loss: 0.0688, D_B_loss: 0.0625, G_A_loss: 1.1417, G_B_loss: 0.8690\n",
      "Epoch [171/200], Step [101/1067], D_A_loss: 0.0484, D_B_loss: 0.0352, G_A_loss: 1.2507, G_B_loss: 0.8558\n",
      "Epoch [171/200], Step [111/1067], D_A_loss: 0.0405, D_B_loss: 0.0246, G_A_loss: 0.6781, G_B_loss: 0.9747\n",
      "Epoch [171/200], Step [121/1067], D_A_loss: 0.0200, D_B_loss: 0.0133, G_A_loss: 0.6084, G_B_loss: 0.9950\n",
      "Epoch [171/200], Step [131/1067], D_A_loss: 0.0607, D_B_loss: 0.0317, G_A_loss: 0.7752, G_B_loss: 0.6897\n",
      "Epoch [171/200], Step [141/1067], D_A_loss: 0.0541, D_B_loss: 0.0353, G_A_loss: 0.9429, G_B_loss: 0.6156\n",
      "Epoch [171/200], Step [151/1067], D_A_loss: 0.1213, D_B_loss: 0.0353, G_A_loss: 0.9402, G_B_loss: 0.3896\n",
      "Epoch [171/200], Step [161/1067], D_A_loss: 0.0624, D_B_loss: 0.0197, G_A_loss: 0.6914, G_B_loss: 0.0464\n",
      "Epoch [171/200], Step [171/1067], D_A_loss: 0.0597, D_B_loss: 0.0552, G_A_loss: 0.6770, G_B_loss: 0.8349\n",
      "Epoch [171/200], Step [181/1067], D_A_loss: 0.0530, D_B_loss: 0.0218, G_A_loss: 0.7894, G_B_loss: 0.5711\n",
      "Epoch [171/200], Step [191/1067], D_A_loss: 0.0288, D_B_loss: 0.0200, G_A_loss: 0.9531, G_B_loss: 0.9271\n",
      "Epoch [171/200], Step [201/1067], D_A_loss: 0.0268, D_B_loss: 0.0268, G_A_loss: 1.1914, G_B_loss: 0.7811\n",
      "Epoch [171/200], Step [211/1067], D_A_loss: 0.0692, D_B_loss: 0.0470, G_A_loss: 0.5376, G_B_loss: 0.4911\n",
      "Epoch [171/200], Step [221/1067], D_A_loss: 0.1385, D_B_loss: 0.0230, G_A_loss: 0.6927, G_B_loss: 0.3741\n",
      "Epoch [171/200], Step [231/1067], D_A_loss: 0.0637, D_B_loss: 0.0449, G_A_loss: 0.5782, G_B_loss: 0.6330\n",
      "Epoch [171/200], Step [241/1067], D_A_loss: 0.0303, D_B_loss: 0.0107, G_A_loss: 0.6897, G_B_loss: 1.0077\n",
      "Epoch [171/200], Step [251/1067], D_A_loss: 0.0692, D_B_loss: 0.0137, G_A_loss: 0.7199, G_B_loss: 0.8331\n",
      "Epoch [171/200], Step [261/1067], D_A_loss: 0.0328, D_B_loss: 0.0585, G_A_loss: 1.0993, G_B_loss: 0.8596\n",
      "Epoch [171/200], Step [271/1067], D_A_loss: 0.0262, D_B_loss: 0.0364, G_A_loss: 0.8427, G_B_loss: 0.4195\n",
      "Epoch [171/200], Step [281/1067], D_A_loss: 0.0839, D_B_loss: 0.0391, G_A_loss: 0.8330, G_B_loss: 0.6048\n",
      "Epoch [171/200], Step [291/1067], D_A_loss: 0.0809, D_B_loss: 0.0387, G_A_loss: 0.8418, G_B_loss: 0.6597\n",
      "Epoch [171/200], Step [301/1067], D_A_loss: 0.0630, D_B_loss: 0.0250, G_A_loss: 0.9316, G_B_loss: 0.4843\n",
      "Epoch [171/200], Step [311/1067], D_A_loss: 0.0501, D_B_loss: 0.0939, G_A_loss: 0.4115, G_B_loss: 0.6685\n",
      "Epoch [171/200], Step [321/1067], D_A_loss: 0.0289, D_B_loss: 0.0128, G_A_loss: 1.1361, G_B_loss: 0.2773\n",
      "Epoch [171/200], Step [331/1067], D_A_loss: 0.1204, D_B_loss: 0.0181, G_A_loss: 0.7561, G_B_loss: 0.3353\n",
      "Epoch [171/200], Step [341/1067], D_A_loss: 0.0418, D_B_loss: 0.0221, G_A_loss: 0.6878, G_B_loss: 0.6360\n",
      "Epoch [171/200], Step [351/1067], D_A_loss: 0.2254, D_B_loss: 0.0198, G_A_loss: 0.6945, G_B_loss: 1.2192\n",
      "Epoch [171/200], Step [361/1067], D_A_loss: 0.0729, D_B_loss: 0.0083, G_A_loss: 0.9683, G_B_loss: 0.4914\n",
      "Epoch [171/200], Step [371/1067], D_A_loss: 0.0464, D_B_loss: 0.0234, G_A_loss: 0.6762, G_B_loss: 0.8414\n",
      "Epoch [171/200], Step [381/1067], D_A_loss: 0.0772, D_B_loss: 0.0155, G_A_loss: 0.4304, G_B_loss: 0.7921\n",
      "Epoch [171/200], Step [391/1067], D_A_loss: 0.1615, D_B_loss: 0.0111, G_A_loss: 0.7059, G_B_loss: 0.8255\n",
      "Epoch [171/200], Step [401/1067], D_A_loss: 0.0825, D_B_loss: 0.0128, G_A_loss: 1.1181, G_B_loss: 0.6404\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [171/200], Step [411/1067], D_A_loss: 0.0401, D_B_loss: 0.0109, G_A_loss: 0.7689, G_B_loss: 0.8267\n",
      "Epoch [171/200], Step [421/1067], D_A_loss: 0.0982, D_B_loss: 0.0536, G_A_loss: 0.5647, G_B_loss: 0.4955\n",
      "Epoch [171/200], Step [431/1067], D_A_loss: 0.0229, D_B_loss: 0.0087, G_A_loss: 0.8779, G_B_loss: 0.8763\n",
      "Epoch [171/200], Step [441/1067], D_A_loss: 0.0414, D_B_loss: 0.0439, G_A_loss: 1.2188, G_B_loss: 0.3810\n",
      "Epoch [171/200], Step [451/1067], D_A_loss: 0.0252, D_B_loss: 0.0844, G_A_loss: 0.3853, G_B_loss: 0.7630\n",
      "Epoch [171/200], Step [461/1067], D_A_loss: 0.0404, D_B_loss: 0.0794, G_A_loss: 0.7539, G_B_loss: 0.6071\n",
      "Epoch [171/200], Step [471/1067], D_A_loss: 0.0671, D_B_loss: 0.0091, G_A_loss: 0.9221, G_B_loss: 0.6102\n",
      "Epoch [171/200], Step [481/1067], D_A_loss: 0.0191, D_B_loss: 0.0463, G_A_loss: 0.7130, G_B_loss: 0.9307\n",
      "Epoch [171/200], Step [491/1067], D_A_loss: 0.0683, D_B_loss: 0.0327, G_A_loss: 0.6257, G_B_loss: 0.8366\n",
      "Epoch [171/200], Step [501/1067], D_A_loss: 0.0389, D_B_loss: 0.0132, G_A_loss: 0.8996, G_B_loss: 0.5418\n",
      "Epoch [171/200], Step [511/1067], D_A_loss: 0.0241, D_B_loss: 0.0246, G_A_loss: 0.8136, G_B_loss: 0.7843\n",
      "Epoch [171/200], Step [521/1067], D_A_loss: 0.0383, D_B_loss: 0.0136, G_A_loss: 1.2130, G_B_loss: 0.6574\n",
      "Epoch [171/200], Step [531/1067], D_A_loss: 0.0424, D_B_loss: 0.0181, G_A_loss: 0.6969, G_B_loss: 0.3773\n",
      "Epoch [171/200], Step [541/1067], D_A_loss: 0.0986, D_B_loss: 0.1155, G_A_loss: 0.3256, G_B_loss: 0.5362\n",
      "Epoch [171/200], Step [551/1067], D_A_loss: 0.0481, D_B_loss: 0.0083, G_A_loss: 0.8876, G_B_loss: 0.7431\n",
      "Epoch [171/200], Step [561/1067], D_A_loss: 0.0382, D_B_loss: 0.0160, G_A_loss: 0.4809, G_B_loss: 0.5508\n",
      "Epoch [171/200], Step [571/1067], D_A_loss: 0.0570, D_B_loss: 0.0276, G_A_loss: 0.8034, G_B_loss: 0.7585\n",
      "Epoch [171/200], Step [581/1067], D_A_loss: 0.0469, D_B_loss: 0.0119, G_A_loss: 1.0279, G_B_loss: 0.6511\n",
      "Epoch [171/200], Step [591/1067], D_A_loss: 0.0757, D_B_loss: 0.0381, G_A_loss: 0.9061, G_B_loss: 0.6121\n",
      "Epoch [171/200], Step [601/1067], D_A_loss: 0.0806, D_B_loss: 0.0120, G_A_loss: 0.8564, G_B_loss: 0.5660\n",
      "Epoch [171/200], Step [611/1067], D_A_loss: 0.0172, D_B_loss: 0.0390, G_A_loss: 0.5880, G_B_loss: 0.5335\n",
      "Epoch [171/200], Step [621/1067], D_A_loss: 0.0220, D_B_loss: 0.0482, G_A_loss: 0.8510, G_B_loss: 0.8504\n",
      "Epoch [171/200], Step [631/1067], D_A_loss: 0.1217, D_B_loss: 0.0410, G_A_loss: 0.9588, G_B_loss: 0.4078\n",
      "Epoch [171/200], Step [641/1067], D_A_loss: 0.1031, D_B_loss: 0.0129, G_A_loss: 0.6860, G_B_loss: 0.4001\n",
      "Epoch [171/200], Step [651/1067], D_A_loss: 0.0249, D_B_loss: 0.0476, G_A_loss: 0.5836, G_B_loss: 0.9262\n",
      "Epoch [171/200], Step [661/1067], D_A_loss: 0.0869, D_B_loss: 0.0092, G_A_loss: 0.7978, G_B_loss: 0.5961\n",
      "Epoch [171/200], Step [671/1067], D_A_loss: 0.0678, D_B_loss: 0.0245, G_A_loss: 0.9965, G_B_loss: 0.5704\n",
      "Epoch [171/200], Step [681/1067], D_A_loss: 0.0676, D_B_loss: 0.0241, G_A_loss: 0.7727, G_B_loss: 0.3892\n",
      "Epoch [171/200], Step [691/1067], D_A_loss: 0.0402, D_B_loss: 0.0196, G_A_loss: 0.8014, G_B_loss: 0.7361\n",
      "Epoch [171/200], Step [701/1067], D_A_loss: 0.0416, D_B_loss: 0.0248, G_A_loss: 0.9312, G_B_loss: 0.8887\n",
      "Epoch [171/200], Step [711/1067], D_A_loss: 0.0525, D_B_loss: 0.0099, G_A_loss: 0.9614, G_B_loss: 1.0259\n",
      "Epoch [171/200], Step [721/1067], D_A_loss: 0.0400, D_B_loss: 0.0122, G_A_loss: 1.1174, G_B_loss: 0.9297\n",
      "Epoch [171/200], Step [731/1067], D_A_loss: 0.0518, D_B_loss: 0.0123, G_A_loss: 0.8319, G_B_loss: 0.4518\n",
      "Epoch [171/200], Step [741/1067], D_A_loss: 0.0809, D_B_loss: 0.0114, G_A_loss: 1.0333, G_B_loss: 0.7907\n",
      "Epoch [171/200], Step [751/1067], D_A_loss: 0.0614, D_B_loss: 0.0750, G_A_loss: 0.6035, G_B_loss: 0.6225\n",
      "Epoch [171/200], Step [761/1067], D_A_loss: 0.0824, D_B_loss: 0.0126, G_A_loss: 0.8128, G_B_loss: 0.7946\n",
      "Epoch [171/200], Step [771/1067], D_A_loss: 0.0703, D_B_loss: 0.0280, G_A_loss: 0.6298, G_B_loss: 0.5086\n",
      "Epoch [171/200], Step [781/1067], D_A_loss: 0.1969, D_B_loss: 0.0430, G_A_loss: 1.1161, G_B_loss: 0.3556\n",
      "Epoch [171/200], Step [791/1067], D_A_loss: 0.0250, D_B_loss: 0.0234, G_A_loss: 1.2517, G_B_loss: 0.6262\n",
      "Epoch [171/200], Step [801/1067], D_A_loss: 0.0538, D_B_loss: 0.0106, G_A_loss: 1.0499, G_B_loss: 0.6389\n",
      "Epoch [171/200], Step [811/1067], D_A_loss: 0.1282, D_B_loss: 0.0213, G_A_loss: 0.7136, G_B_loss: 0.3728\n",
      "Epoch [171/200], Step [821/1067], D_A_loss: 0.0247, D_B_loss: 0.0182, G_A_loss: 0.7620, G_B_loss: 0.5147\n",
      "Epoch [171/200], Step [831/1067], D_A_loss: 0.0233, D_B_loss: 0.0207, G_A_loss: 0.6619, G_B_loss: 0.5885\n",
      "Epoch [171/200], Step [841/1067], D_A_loss: 0.0872, D_B_loss: 0.0121, G_A_loss: 1.0046, G_B_loss: 0.8708\n",
      "Epoch [171/200], Step [851/1067], D_A_loss: 0.0254, D_B_loss: 0.0218, G_A_loss: 0.3233, G_B_loss: 0.7292\n",
      "Epoch [171/200], Step [861/1067], D_A_loss: 0.1096, D_B_loss: 0.0092, G_A_loss: 1.1889, G_B_loss: 0.3613\n",
      "Epoch [171/200], Step [871/1067], D_A_loss: 0.1312, D_B_loss: 0.0375, G_A_loss: 0.9113, G_B_loss: 0.3153\n",
      "Epoch [171/200], Step [881/1067], D_A_loss: 0.0266, D_B_loss: 0.0214, G_A_loss: 0.7136, G_B_loss: 0.4432\n",
      "Epoch [171/200], Step [891/1067], D_A_loss: 0.0681, D_B_loss: 0.0106, G_A_loss: 1.2126, G_B_loss: 0.4738\n",
      "Epoch [171/200], Step [901/1067], D_A_loss: 0.0253, D_B_loss: 0.0298, G_A_loss: 0.6400, G_B_loss: 1.0581\n",
      "Epoch [171/200], Step [911/1067], D_A_loss: 0.0193, D_B_loss: 0.1031, G_A_loss: 0.4324, G_B_loss: 0.5942\n",
      "Epoch [171/200], Step [921/1067], D_A_loss: 0.1411, D_B_loss: 0.1675, G_A_loss: 0.8630, G_B_loss: 0.3403\n",
      "Epoch [171/200], Step [931/1067], D_A_loss: 0.0933, D_B_loss: 0.1024, G_A_loss: 1.1284, G_B_loss: 0.8559\n",
      "Epoch [171/200], Step [941/1067], D_A_loss: 0.0606, D_B_loss: 0.0177, G_A_loss: 0.6472, G_B_loss: 0.6297\n",
      "Epoch [171/200], Step [951/1067], D_A_loss: 0.0980, D_B_loss: 0.0145, G_A_loss: 0.8636, G_B_loss: 0.4447\n",
      "Epoch [171/200], Step [961/1067], D_A_loss: 0.1295, D_B_loss: 0.0155, G_A_loss: 1.2187, G_B_loss: 0.6209\n",
      "Epoch [171/200], Step [971/1067], D_A_loss: 0.0985, D_B_loss: 0.0195, G_A_loss: 0.9203, G_B_loss: 0.4339\n",
      "Epoch [171/200], Step [981/1067], D_A_loss: 0.0432, D_B_loss: 0.0361, G_A_loss: 0.6112, G_B_loss: 0.8235\n",
      "Epoch [171/200], Step [991/1067], D_A_loss: 0.2092, D_B_loss: 0.0353, G_A_loss: 0.6048, G_B_loss: 0.7136\n",
      "Epoch [171/200], Step [1001/1067], D_A_loss: 0.1097, D_B_loss: 0.0208, G_A_loss: 0.7626, G_B_loss: 0.3517\n",
      "Epoch [171/200], Step [1011/1067], D_A_loss: 0.0997, D_B_loss: 0.0187, G_A_loss: 1.0007, G_B_loss: 0.5268\n",
      "Epoch [171/200], Step [1021/1067], D_A_loss: 0.0241, D_B_loss: 0.0190, G_A_loss: 0.7456, G_B_loss: 0.6172\n",
      "Epoch [171/200], Step [1031/1067], D_A_loss: 0.0404, D_B_loss: 0.0262, G_A_loss: 0.9238, G_B_loss: 0.3299\n",
      "Epoch [171/200], Step [1041/1067], D_A_loss: 0.0251, D_B_loss: 0.0567, G_A_loss: 0.8393, G_B_loss: 1.1692\n",
      "Epoch [171/200], Step [1051/1067], D_A_loss: 0.0362, D_B_loss: 0.0759, G_A_loss: 0.9702, G_B_loss: 0.6904\n",
      "Epoch [171/200], Step [1061/1067], D_A_loss: 0.0299, D_B_loss: 0.0164, G_A_loss: 1.1326, G_B_loss: 0.6989\n",
      "Epoch [172/200], Step [1/1067], D_A_loss: 0.0312, D_B_loss: 0.0546, G_A_loss: 0.5096, G_B_loss: 0.5458\n",
      "Epoch [172/200], Step [11/1067], D_A_loss: 0.0314, D_B_loss: 0.0205, G_A_loss: 0.5646, G_B_loss: 0.8141\n",
      "Epoch [172/200], Step [21/1067], D_A_loss: 0.0250, D_B_loss: 0.0159, G_A_loss: 0.6303, G_B_loss: 0.3318\n",
      "Epoch [172/200], Step [31/1067], D_A_loss: 0.1041, D_B_loss: 0.0219, G_A_loss: 0.7399, G_B_loss: 0.9955\n",
      "Epoch [172/200], Step [41/1067], D_A_loss: 0.0818, D_B_loss: 0.0076, G_A_loss: 0.7480, G_B_loss: 0.5296\n",
      "Epoch [172/200], Step [51/1067], D_A_loss: 0.0432, D_B_loss: 0.0352, G_A_loss: 0.7623, G_B_loss: 0.9121\n",
      "Epoch [172/200], Step [61/1067], D_A_loss: 0.0727, D_B_loss: 0.0142, G_A_loss: 0.8518, G_B_loss: 0.7832\n",
      "Epoch [172/200], Step [71/1067], D_A_loss: 0.0562, D_B_loss: 0.0238, G_A_loss: 0.5518, G_B_loss: 0.6283\n",
      "Epoch [172/200], Step [81/1067], D_A_loss: 0.0777, D_B_loss: 0.0125, G_A_loss: 1.1236, G_B_loss: 1.0244\n",
      "Epoch [172/200], Step [91/1067], D_A_loss: 0.0220, D_B_loss: 0.0234, G_A_loss: 0.7121, G_B_loss: 0.9250\n",
      "Epoch [172/200], Step [101/1067], D_A_loss: 0.0442, D_B_loss: 0.0135, G_A_loss: 1.1097, G_B_loss: 0.6987\n",
      "Epoch [172/200], Step [111/1067], D_A_loss: 0.0344, D_B_loss: 0.0187, G_A_loss: 0.8733, G_B_loss: 0.7424\n",
      "Epoch [172/200], Step [121/1067], D_A_loss: 0.0969, D_B_loss: 0.0145, G_A_loss: 0.8903, G_B_loss: 0.4064\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [172/200], Step [131/1067], D_A_loss: 0.0254, D_B_loss: 0.0148, G_A_loss: 0.8771, G_B_loss: 1.0512\n",
      "Epoch [172/200], Step [141/1067], D_A_loss: 0.1081, D_B_loss: 0.0213, G_A_loss: 0.9009, G_B_loss: 0.3878\n",
      "Epoch [172/200], Step [151/1067], D_A_loss: 0.0675, D_B_loss: 0.0177, G_A_loss: 0.6582, G_B_loss: 0.5531\n",
      "Epoch [172/200], Step [161/1067], D_A_loss: 0.0363, D_B_loss: 0.0385, G_A_loss: 0.6014, G_B_loss: 0.9392\n",
      "Epoch [172/200], Step [171/1067], D_A_loss: 0.0376, D_B_loss: 0.0546, G_A_loss: 0.6059, G_B_loss: 0.7536\n",
      "Epoch [172/200], Step [181/1067], D_A_loss: 0.0293, D_B_loss: 0.0173, G_A_loss: 0.7730, G_B_loss: 0.7296\n",
      "Epoch [172/200], Step [191/1067], D_A_loss: 0.0415, D_B_loss: 0.0136, G_A_loss: 0.9868, G_B_loss: 0.7530\n",
      "Epoch [172/200], Step [201/1067], D_A_loss: 0.1074, D_B_loss: 0.0203, G_A_loss: 0.8956, G_B_loss: 0.4124\n",
      "Epoch [172/200], Step [211/1067], D_A_loss: 0.1010, D_B_loss: 0.0102, G_A_loss: 0.8785, G_B_loss: 0.7852\n",
      "Epoch [172/200], Step [221/1067], D_A_loss: 0.0267, D_B_loss: 0.0486, G_A_loss: 0.7409, G_B_loss: 0.3385\n",
      "Epoch [172/200], Step [231/1067], D_A_loss: 0.0561, D_B_loss: 0.0682, G_A_loss: 0.6548, G_B_loss: 0.7672\n",
      "Epoch [172/200], Step [241/1067], D_A_loss: 0.0257, D_B_loss: 0.0251, G_A_loss: 1.1050, G_B_loss: 0.3787\n",
      "Epoch [172/200], Step [251/1067], D_A_loss: 0.0277, D_B_loss: 0.0609, G_A_loss: 0.7813, G_B_loss: 0.8236\n",
      "Epoch [172/200], Step [261/1067], D_A_loss: 0.1332, D_B_loss: 0.0692, G_A_loss: 0.4755, G_B_loss: 0.8720\n",
      "Epoch [172/200], Step [271/1067], D_A_loss: 0.0855, D_B_loss: 0.0108, G_A_loss: 1.1156, G_B_loss: 0.7552\n",
      "Epoch [172/200], Step [281/1067], D_A_loss: 0.0903, D_B_loss: 0.0908, G_A_loss: 0.9958, G_B_loss: 0.4629\n",
      "Epoch [172/200], Step [291/1067], D_A_loss: 0.0548, D_B_loss: 0.0101, G_A_loss: 1.0421, G_B_loss: 0.7640\n",
      "Epoch [172/200], Step [301/1067], D_A_loss: 0.0460, D_B_loss: 0.0264, G_A_loss: 0.7248, G_B_loss: 0.7835\n",
      "Epoch [172/200], Step [311/1067], D_A_loss: 0.0553, D_B_loss: 0.0236, G_A_loss: 1.1124, G_B_loss: 0.4902\n",
      "Epoch [172/200], Step [321/1067], D_A_loss: 0.0747, D_B_loss: 0.0098, G_A_loss: 1.1394, G_B_loss: 0.7012\n",
      "Epoch [172/200], Step [331/1067], D_A_loss: 0.0394, D_B_loss: 0.0470, G_A_loss: 0.5736, G_B_loss: 0.5244\n",
      "Epoch [172/200], Step [341/1067], D_A_loss: 0.0249, D_B_loss: 0.0189, G_A_loss: 0.8490, G_B_loss: 0.6548\n",
      "Epoch [172/200], Step [351/1067], D_A_loss: 0.0370, D_B_loss: 0.0123, G_A_loss: 1.2411, G_B_loss: 0.5413\n",
      "Epoch [172/200], Step [361/1067], D_A_loss: 0.0453, D_B_loss: 0.0242, G_A_loss: 0.5937, G_B_loss: 0.9327\n",
      "Epoch [172/200], Step [371/1067], D_A_loss: 0.2439, D_B_loss: 0.0174, G_A_loss: 0.6831, G_B_loss: 0.5886\n",
      "Epoch [172/200], Step [381/1067], D_A_loss: 0.0768, D_B_loss: 0.0122, G_A_loss: 1.0230, G_B_loss: 0.4934\n",
      "Epoch [172/200], Step [391/1067], D_A_loss: 0.0352, D_B_loss: 0.0109, G_A_loss: 0.7572, G_B_loss: 0.7765\n",
      "Epoch [172/200], Step [401/1067], D_A_loss: 0.0491, D_B_loss: 0.0133, G_A_loss: 0.8500, G_B_loss: 0.3955\n",
      "Epoch [172/200], Step [411/1067], D_A_loss: 0.0616, D_B_loss: 0.0490, G_A_loss: 0.8897, G_B_loss: 0.7252\n",
      "Epoch [172/200], Step [421/1067], D_A_loss: 0.1309, D_B_loss: 0.0103, G_A_loss: 1.1455, G_B_loss: 0.6705\n",
      "Epoch [172/200], Step [431/1067], D_A_loss: 0.0424, D_B_loss: 0.0136, G_A_loss: 0.8909, G_B_loss: 0.7077\n",
      "Epoch [172/200], Step [441/1067], D_A_loss: 0.0841, D_B_loss: 0.0194, G_A_loss: 0.8590, G_B_loss: 0.7315\n",
      "Epoch [172/200], Step [451/1067], D_A_loss: 0.0592, D_B_loss: 0.0913, G_A_loss: 0.3916, G_B_loss: 0.8438\n",
      "Epoch [172/200], Step [461/1067], D_A_loss: 0.0564, D_B_loss: 0.0615, G_A_loss: 0.4923, G_B_loss: 0.9535\n",
      "Epoch [172/200], Step [471/1067], D_A_loss: 0.0720, D_B_loss: 0.0196, G_A_loss: 0.7522, G_B_loss: 0.6629\n",
      "Epoch [172/200], Step [481/1067], D_A_loss: 0.0903, D_B_loss: 0.0386, G_A_loss: 0.7223, G_B_loss: 1.2530\n",
      "Epoch [172/200], Step [491/1067], D_A_loss: 0.0470, D_B_loss: 0.0103, G_A_loss: 1.0236, G_B_loss: 0.5220\n",
      "Epoch [172/200], Step [501/1067], D_A_loss: 0.0224, D_B_loss: 0.0072, G_A_loss: 0.8428, G_B_loss: 0.4641\n",
      "Epoch [172/200], Step [511/1067], D_A_loss: 0.0428, D_B_loss: 0.0366, G_A_loss: 0.7169, G_B_loss: 0.6585\n",
      "Epoch [172/200], Step [521/1067], D_A_loss: 0.1582, D_B_loss: 0.0098, G_A_loss: 0.5881, G_B_loss: 0.2604\n",
      "Epoch [172/200], Step [531/1067], D_A_loss: 0.0147, D_B_loss: 0.0244, G_A_loss: 0.8079, G_B_loss: 0.9680\n",
      "Epoch [172/200], Step [541/1067], D_A_loss: 0.1081, D_B_loss: 0.0125, G_A_loss: 0.9267, G_B_loss: 0.8025\n",
      "Epoch [172/200], Step [551/1067], D_A_loss: 0.0335, D_B_loss: 0.0478, G_A_loss: 1.2326, G_B_loss: 0.3231\n",
      "Epoch [172/200], Step [561/1067], D_A_loss: 0.1704, D_B_loss: 0.0101, G_A_loss: 1.0262, G_B_loss: 0.7242\n",
      "Epoch [172/200], Step [571/1067], D_A_loss: 0.1147, D_B_loss: 0.0443, G_A_loss: 0.7226, G_B_loss: 0.7972\n",
      "Epoch [172/200], Step [581/1067], D_A_loss: 0.0884, D_B_loss: 0.0089, G_A_loss: 1.0626, G_B_loss: 0.6180\n",
      "Epoch [172/200], Step [591/1067], D_A_loss: 0.0686, D_B_loss: 0.0309, G_A_loss: 0.6785, G_B_loss: 0.5131\n",
      "Epoch [172/200], Step [601/1067], D_A_loss: 0.0228, D_B_loss: 0.0083, G_A_loss: 0.9924, G_B_loss: 0.8106\n",
      "Epoch [172/200], Step [611/1067], D_A_loss: 0.0235, D_B_loss: 0.0375, G_A_loss: 0.9628, G_B_loss: 0.5902\n",
      "Epoch [172/200], Step [621/1067], D_A_loss: 0.1175, D_B_loss: 0.0216, G_A_loss: 0.9828, G_B_loss: 0.7957\n",
      "Epoch [172/200], Step [631/1067], D_A_loss: 0.1225, D_B_loss: 0.1284, G_A_loss: 0.6637, G_B_loss: 0.6281\n",
      "Epoch [172/200], Step [641/1067], D_A_loss: 0.0298, D_B_loss: 0.0142, G_A_loss: 0.7885, G_B_loss: 0.9311\n",
      "Epoch [172/200], Step [651/1067], D_A_loss: 0.0410, D_B_loss: 0.0147, G_A_loss: 0.8118, G_B_loss: 0.6365\n",
      "Epoch [172/200], Step [661/1067], D_A_loss: 0.0451, D_B_loss: 0.0143, G_A_loss: 0.8484, G_B_loss: 0.6886\n",
      "Epoch [172/200], Step [671/1067], D_A_loss: 0.1470, D_B_loss: 0.0136, G_A_loss: 1.2903, G_B_loss: 0.8065\n",
      "Epoch [172/200], Step [681/1067], D_A_loss: 0.0310, D_B_loss: 0.0290, G_A_loss: 0.6687, G_B_loss: 0.6234\n",
      "Epoch [172/200], Step [691/1067], D_A_loss: 0.0540, D_B_loss: 0.0347, G_A_loss: 0.6143, G_B_loss: 0.6596\n",
      "Epoch [172/200], Step [701/1067], D_A_loss: 0.0307, D_B_loss: 0.0610, G_A_loss: 0.6194, G_B_loss: 0.9059\n",
      "Epoch [172/200], Step [711/1067], D_A_loss: 0.0460, D_B_loss: 0.0285, G_A_loss: 0.7366, G_B_loss: 0.6452\n",
      "Epoch [172/200], Step [721/1067], D_A_loss: 0.0783, D_B_loss: 0.0309, G_A_loss: 0.6506, G_B_loss: 0.6911\n",
      "Epoch [172/200], Step [731/1067], D_A_loss: 0.0300, D_B_loss: 0.0177, G_A_loss: 0.7824, G_B_loss: 0.8919\n",
      "Epoch [172/200], Step [741/1067], D_A_loss: 0.0346, D_B_loss: 0.0258, G_A_loss: 0.8897, G_B_loss: 0.7531\n",
      "Epoch [172/200], Step [751/1067], D_A_loss: 0.0535, D_B_loss: 0.0102, G_A_loss: 1.0847, G_B_loss: 0.8032\n",
      "Epoch [172/200], Step [761/1067], D_A_loss: 0.0383, D_B_loss: 0.0184, G_A_loss: 0.6780, G_B_loss: 0.4369\n",
      "Epoch [172/200], Step [771/1067], D_A_loss: 0.0446, D_B_loss: 0.0232, G_A_loss: 0.7070, G_B_loss: 0.7055\n",
      "Epoch [172/200], Step [781/1067], D_A_loss: 0.0214, D_B_loss: 0.0322, G_A_loss: 0.9281, G_B_loss: 1.0912\n",
      "Epoch [172/200], Step [791/1067], D_A_loss: 0.0480, D_B_loss: 0.0221, G_A_loss: 0.9949, G_B_loss: 0.6445\n",
      "Epoch [172/200], Step [801/1067], D_A_loss: 0.0976, D_B_loss: 0.0146, G_A_loss: 0.7997, G_B_loss: 0.6888\n",
      "Epoch [172/200], Step [811/1067], D_A_loss: 0.0731, D_B_loss: 0.0239, G_A_loss: 0.9811, G_B_loss: 1.2401\n",
      "Epoch [172/200], Step [821/1067], D_A_loss: 0.1318, D_B_loss: 0.0413, G_A_loss: 0.9803, G_B_loss: 0.4847\n",
      "Epoch [172/200], Step [831/1067], D_A_loss: 0.0827, D_B_loss: 0.0398, G_A_loss: 0.8254, G_B_loss: 0.7222\n",
      "Epoch [172/200], Step [841/1067], D_A_loss: 0.0444, D_B_loss: 0.0165, G_A_loss: 0.9788, G_B_loss: 0.6873\n",
      "Epoch [172/200], Step [851/1067], D_A_loss: 0.0350, D_B_loss: 0.0427, G_A_loss: 0.5523, G_B_loss: 0.7328\n",
      "Epoch [172/200], Step [861/1067], D_A_loss: 0.0403, D_B_loss: 0.0783, G_A_loss: 1.0407, G_B_loss: 0.3920\n",
      "Epoch [172/200], Step [871/1067], D_A_loss: 0.0655, D_B_loss: 0.0154, G_A_loss: 0.8321, G_B_loss: 0.8646\n",
      "Epoch [172/200], Step [881/1067], D_A_loss: 0.0228, D_B_loss: 0.0217, G_A_loss: 0.7100, G_B_loss: 0.6334\n",
      "Epoch [172/200], Step [891/1067], D_A_loss: 0.0731, D_B_loss: 0.0267, G_A_loss: 0.6554, G_B_loss: 0.6224\n",
      "Epoch [172/200], Step [901/1067], D_A_loss: 0.0570, D_B_loss: 0.0111, G_A_loss: 0.8827, G_B_loss: 0.6486\n",
      "Epoch [172/200], Step [911/1067], D_A_loss: 0.0238, D_B_loss: 0.0273, G_A_loss: 1.1433, G_B_loss: 0.6053\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [172/200], Step [921/1067], D_A_loss: 0.0502, D_B_loss: 0.0919, G_A_loss: 0.8123, G_B_loss: 0.6180\n",
      "Epoch [172/200], Step [931/1067], D_A_loss: 0.1254, D_B_loss: 0.0189, G_A_loss: 0.9144, G_B_loss: 0.7893\n",
      "Epoch [172/200], Step [941/1067], D_A_loss: 0.0954, D_B_loss: 0.0283, G_A_loss: 0.7761, G_B_loss: 0.5528\n",
      "Epoch [172/200], Step [951/1067], D_A_loss: 0.0488, D_B_loss: 0.0176, G_A_loss: 1.1822, G_B_loss: 0.6305\n",
      "Epoch [172/200], Step [961/1067], D_A_loss: 0.0341, D_B_loss: 0.0293, G_A_loss: 1.0537, G_B_loss: 0.7469\n",
      "Epoch [172/200], Step [971/1067], D_A_loss: 0.0520, D_B_loss: 0.0111, G_A_loss: 1.0830, G_B_loss: 0.4454\n",
      "Epoch [172/200], Step [981/1067], D_A_loss: 0.0374, D_B_loss: 0.0476, G_A_loss: 0.5644, G_B_loss: 0.7561\n",
      "Epoch [172/200], Step [991/1067], D_A_loss: 0.0638, D_B_loss: 0.0409, G_A_loss: 0.8265, G_B_loss: 0.3616\n",
      "Epoch [172/200], Step [1001/1067], D_A_loss: 0.0256, D_B_loss: 0.0139, G_A_loss: 0.5612, G_B_loss: 0.7232\n",
      "Epoch [172/200], Step [1011/1067], D_A_loss: 0.0823, D_B_loss: 0.0575, G_A_loss: 0.7436, G_B_loss: 0.4627\n",
      "Epoch [172/200], Step [1021/1067], D_A_loss: 0.0375, D_B_loss: 0.0386, G_A_loss: 0.8126, G_B_loss: 0.7428\n",
      "Epoch [172/200], Step [1031/1067], D_A_loss: 0.0369, D_B_loss: 0.0107, G_A_loss: 1.0080, G_B_loss: 0.4932\n",
      "Epoch [172/200], Step [1041/1067], D_A_loss: 0.0547, D_B_loss: 0.0081, G_A_loss: 0.8593, G_B_loss: 0.6669\n",
      "Epoch [172/200], Step [1051/1067], D_A_loss: 0.0976, D_B_loss: 0.0217, G_A_loss: 0.5940, G_B_loss: 0.5916\n",
      "Epoch [172/200], Step [1061/1067], D_A_loss: 0.0984, D_B_loss: 0.0260, G_A_loss: 0.6743, G_B_loss: 0.5166\n",
      "Epoch [173/200], Step [1/1067], D_A_loss: 0.1047, D_B_loss: 0.0134, G_A_loss: 0.8450, G_B_loss: 0.4677\n",
      "Epoch [173/200], Step [11/1067], D_A_loss: 0.0508, D_B_loss: 0.0103, G_A_loss: 0.8666, G_B_loss: 0.6048\n",
      "Epoch [173/200], Step [21/1067], D_A_loss: 0.0190, D_B_loss: 0.0921, G_A_loss: 0.3739, G_B_loss: 0.2484\n",
      "Epoch [173/200], Step [31/1067], D_A_loss: 0.0961, D_B_loss: 0.0566, G_A_loss: 1.3503, G_B_loss: 0.6603\n",
      "Epoch [173/200], Step [41/1067], D_A_loss: 0.0746, D_B_loss: 0.0186, G_A_loss: 1.2800, G_B_loss: 0.9577\n",
      "Epoch [173/200], Step [51/1067], D_A_loss: 0.0434, D_B_loss: 0.0113, G_A_loss: 1.0925, G_B_loss: 0.5722\n",
      "Epoch [173/200], Step [61/1067], D_A_loss: 0.0842, D_B_loss: 0.0387, G_A_loss: 0.5913, G_B_loss: 1.1312\n",
      "Epoch [173/200], Step [71/1067], D_A_loss: 0.1649, D_B_loss: 0.1189, G_A_loss: 1.1225, G_B_loss: 0.4934\n",
      "Epoch [173/200], Step [81/1067], D_A_loss: 0.1327, D_B_loss: 0.0787, G_A_loss: 0.8652, G_B_loss: 0.7114\n",
      "Epoch [173/200], Step [91/1067], D_A_loss: 0.0546, D_B_loss: 0.0126, G_A_loss: 0.8467, G_B_loss: 0.6413\n",
      "Epoch [173/200], Step [101/1067], D_A_loss: 0.0406, D_B_loss: 0.0316, G_A_loss: 0.6573, G_B_loss: 0.7977\n",
      "Epoch [173/200], Step [111/1067], D_A_loss: 0.0490, D_B_loss: 0.0085, G_A_loss: 0.9207, G_B_loss: 0.5874\n",
      "Epoch [173/200], Step [121/1067], D_A_loss: 0.0948, D_B_loss: 0.0227, G_A_loss: 0.8309, G_B_loss: 0.7913\n",
      "Epoch [173/200], Step [131/1067], D_A_loss: 0.0783, D_B_loss: 0.0228, G_A_loss: 0.9990, G_B_loss: 0.4979\n",
      "Epoch [173/200], Step [141/1067], D_A_loss: 0.2011, D_B_loss: 0.1329, G_A_loss: 1.0165, G_B_loss: 0.5584\n",
      "Epoch [173/200], Step [151/1067], D_A_loss: 0.0836, D_B_loss: 0.0170, G_A_loss: 0.8945, G_B_loss: 0.4965\n",
      "Epoch [173/200], Step [161/1067], D_A_loss: 0.0729, D_B_loss: 0.0158, G_A_loss: 0.5459, G_B_loss: 0.9958\n",
      "Epoch [173/200], Step [171/1067], D_A_loss: 0.1522, D_B_loss: 0.0102, G_A_loss: 0.6217, G_B_loss: 0.2735\n",
      "Epoch [173/200], Step [181/1067], D_A_loss: 0.0496, D_B_loss: 0.0308, G_A_loss: 0.6430, G_B_loss: 0.6858\n",
      "Epoch [173/200], Step [191/1067], D_A_loss: 0.1282, D_B_loss: 0.0171, G_A_loss: 0.9843, G_B_loss: 0.8330\n",
      "Epoch [173/200], Step [201/1067], D_A_loss: 0.0502, D_B_loss: 0.0106, G_A_loss: 1.1487, G_B_loss: 0.6337\n",
      "Epoch [173/200], Step [211/1067], D_A_loss: 0.0402, D_B_loss: 0.0122, G_A_loss: 1.1842, G_B_loss: 0.4667\n",
      "Epoch [173/200], Step [221/1067], D_A_loss: 0.0724, D_B_loss: 0.0272, G_A_loss: 0.6503, G_B_loss: 0.8346\n",
      "Epoch [173/200], Step [231/1067], D_A_loss: 0.0349, D_B_loss: 0.0147, G_A_loss: 0.8612, G_B_loss: 0.3704\n",
      "Epoch [173/200], Step [241/1067], D_A_loss: 0.0662, D_B_loss: 0.0123, G_A_loss: 1.0756, G_B_loss: 0.4206\n",
      "Epoch [173/200], Step [251/1067], D_A_loss: 0.0744, D_B_loss: 0.0131, G_A_loss: 0.7788, G_B_loss: 0.4574\n",
      "Epoch [173/200], Step [261/1067], D_A_loss: 0.0438, D_B_loss: 0.0257, G_A_loss: 0.7379, G_B_loss: 0.6625\n",
      "Epoch [173/200], Step [271/1067], D_A_loss: 0.0452, D_B_loss: 0.0884, G_A_loss: 0.3799, G_B_loss: 0.5281\n",
      "Epoch [173/200], Step [281/1067], D_A_loss: 0.1025, D_B_loss: 0.0165, G_A_loss: 0.5897, G_B_loss: 0.7928\n",
      "Epoch [173/200], Step [291/1067], D_A_loss: 0.0169, D_B_loss: 0.0112, G_A_loss: 0.8631, G_B_loss: 0.9803\n",
      "Epoch [173/200], Step [301/1067], D_A_loss: 0.0258, D_B_loss: 0.0389, G_A_loss: 0.6352, G_B_loss: 0.8390\n",
      "Epoch [173/200], Step [311/1067], D_A_loss: 0.0991, D_B_loss: 0.0476, G_A_loss: 0.5413, G_B_loss: 0.5088\n",
      "Epoch [173/200], Step [321/1067], D_A_loss: 0.0760, D_B_loss: 0.1096, G_A_loss: 0.7989, G_B_loss: 0.4615\n",
      "Epoch [173/200], Step [331/1067], D_A_loss: 0.0531, D_B_loss: 0.0175, G_A_loss: 0.7003, G_B_loss: 0.7218\n",
      "Epoch [173/200], Step [341/1067], D_A_loss: 0.1077, D_B_loss: 0.0144, G_A_loss: 1.0720, G_B_loss: 0.5364\n",
      "Epoch [173/200], Step [351/1067], D_A_loss: 0.0444, D_B_loss: 0.0279, G_A_loss: 0.9582, G_B_loss: 0.2971\n",
      "Epoch [173/200], Step [361/1067], D_A_loss: 0.0607, D_B_loss: 0.0152, G_A_loss: 0.9739, G_B_loss: 0.6895\n",
      "Epoch [173/200], Step [371/1067], D_A_loss: 0.1765, D_B_loss: 0.0219, G_A_loss: 0.8580, G_B_loss: 0.2846\n",
      "Epoch [173/200], Step [381/1067], D_A_loss: 0.1128, D_B_loss: 0.0147, G_A_loss: 0.7981, G_B_loss: 0.5378\n",
      "Epoch [173/200], Step [391/1067], D_A_loss: 0.0509, D_B_loss: 0.0350, G_A_loss: 0.6334, G_B_loss: 0.6298\n",
      "Epoch [173/200], Step [401/1067], D_A_loss: 0.0393, D_B_loss: 0.0091, G_A_loss: 0.8659, G_B_loss: 0.6759\n",
      "Epoch [173/200], Step [411/1067], D_A_loss: 0.0802, D_B_loss: 0.0612, G_A_loss: 0.4557, G_B_loss: 0.4427\n",
      "Epoch [173/200], Step [421/1067], D_A_loss: 0.0935, D_B_loss: 0.0693, G_A_loss: 1.4429, G_B_loss: 0.3941\n",
      "Epoch [173/200], Step [431/1067], D_A_loss: 0.1248, D_B_loss: 0.0151, G_A_loss: 0.8092, G_B_loss: 0.3778\n",
      "Epoch [173/200], Step [441/1067], D_A_loss: 0.0211, D_B_loss: 0.0224, G_A_loss: 0.7116, G_B_loss: 0.8798\n",
      "Epoch [173/200], Step [451/1067], D_A_loss: 0.0335, D_B_loss: 0.0249, G_A_loss: 1.0342, G_B_loss: 0.4343\n",
      "Epoch [173/200], Step [461/1067], D_A_loss: 0.2085, D_B_loss: 0.0421, G_A_loss: 0.6757, G_B_loss: 0.6245\n",
      "Epoch [173/200], Step [471/1067], D_A_loss: 0.0464, D_B_loss: 0.0115, G_A_loss: 1.0923, G_B_loss: 0.7135\n",
      "Epoch [173/200], Step [481/1067], D_A_loss: 0.0491, D_B_loss: 0.0403, G_A_loss: 0.6188, G_B_loss: 0.7019\n",
      "Epoch [173/200], Step [491/1067], D_A_loss: 0.0550, D_B_loss: 0.0286, G_A_loss: 0.6885, G_B_loss: 0.7952\n",
      "Epoch [173/200], Step [501/1067], D_A_loss: 0.1545, D_B_loss: 0.0188, G_A_loss: 0.9305, G_B_loss: 0.8263\n",
      "Epoch [173/200], Step [511/1067], D_A_loss: 0.0226, D_B_loss: 0.0237, G_A_loss: 1.1487, G_B_loss: 0.8738\n",
      "Epoch [173/200], Step [521/1067], D_A_loss: 0.1127, D_B_loss: 0.0294, G_A_loss: 0.8396, G_B_loss: 0.6915\n",
      "Epoch [173/200], Step [531/1067], D_A_loss: 0.1761, D_B_loss: 0.0319, G_A_loss: 0.8205, G_B_loss: 0.6350\n",
      "Epoch [173/200], Step [541/1067], D_A_loss: 0.0431, D_B_loss: 0.0170, G_A_loss: 0.7855, G_B_loss: 0.7189\n",
      "Epoch [173/200], Step [551/1067], D_A_loss: 0.0201, D_B_loss: 0.0210, G_A_loss: 1.4690, G_B_loss: 0.6818\n",
      "Epoch [173/200], Step [561/1067], D_A_loss: 0.0257, D_B_loss: 0.0136, G_A_loss: 0.8133, G_B_loss: 1.0062\n",
      "Epoch [173/200], Step [571/1067], D_A_loss: 0.0293, D_B_loss: 0.0164, G_A_loss: 0.9417, G_B_loss: 0.6064\n",
      "Epoch [173/200], Step [581/1067], D_A_loss: 0.0633, D_B_loss: 0.0414, G_A_loss: 1.0568, G_B_loss: 0.5098\n",
      "Epoch [173/200], Step [591/1067], D_A_loss: 0.0433, D_B_loss: 0.0106, G_A_loss: 1.0260, G_B_loss: 0.6831\n",
      "Epoch [173/200], Step [601/1067], D_A_loss: 0.1565, D_B_loss: 0.0256, G_A_loss: 0.6555, G_B_loss: 0.5660\n",
      "Epoch [173/200], Step [611/1067], D_A_loss: 0.0404, D_B_loss: 0.0211, G_A_loss: 0.7783, G_B_loss: 0.5096\n",
      "Epoch [173/200], Step [621/1067], D_A_loss: 0.0399, D_B_loss: 0.0274, G_A_loss: 0.7631, G_B_loss: 0.7223\n",
      "Epoch [173/200], Step [631/1067], D_A_loss: 0.0652, D_B_loss: 0.0756, G_A_loss: 0.8221, G_B_loss: 0.5280\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [173/200], Step [641/1067], D_A_loss: 0.0899, D_B_loss: 0.0161, G_A_loss: 1.0366, G_B_loss: 0.6655\n",
      "Epoch [173/200], Step [651/1067], D_A_loss: 0.0594, D_B_loss: 0.0091, G_A_loss: 1.0675, G_B_loss: 0.3517\n",
      "Epoch [173/200], Step [661/1067], D_A_loss: 0.0692, D_B_loss: 0.0129, G_A_loss: 0.5421, G_B_loss: 0.5106\n",
      "Epoch [173/200], Step [671/1067], D_A_loss: 0.1348, D_B_loss: 0.0270, G_A_loss: 0.7647, G_B_loss: 0.3998\n",
      "Epoch [173/200], Step [681/1067], D_A_loss: 0.1796, D_B_loss: 0.0283, G_A_loss: 1.0200, G_B_loss: 0.5673\n",
      "Epoch [173/200], Step [691/1067], D_A_loss: 0.0397, D_B_loss: 0.0117, G_A_loss: 0.6882, G_B_loss: 0.5195\n",
      "Epoch [173/200], Step [701/1067], D_A_loss: 0.0843, D_B_loss: 0.0536, G_A_loss: 0.9521, G_B_loss: 0.5259\n",
      "Epoch [173/200], Step [711/1067], D_A_loss: 0.0478, D_B_loss: 0.0572, G_A_loss: 0.7353, G_B_loss: 0.7416\n",
      "Epoch [173/200], Step [721/1067], D_A_loss: 0.0318, D_B_loss: 0.0116, G_A_loss: 1.0637, G_B_loss: 0.4754\n",
      "Epoch [173/200], Step [731/1067], D_A_loss: 0.0972, D_B_loss: 0.0123, G_A_loss: 0.7778, G_B_loss: 0.5921\n",
      "Epoch [173/200], Step [741/1067], D_A_loss: 0.0239, D_B_loss: 0.0104, G_A_loss: 0.8177, G_B_loss: 0.6169\n",
      "Epoch [173/200], Step [751/1067], D_A_loss: 0.0456, D_B_loss: 0.0151, G_A_loss: 1.1108, G_B_loss: 0.8719\n",
      "Epoch [173/200], Step [761/1067], D_A_loss: 0.0696, D_B_loss: 0.0204, G_A_loss: 0.8036, G_B_loss: 0.9257\n",
      "Epoch [173/200], Step [771/1067], D_A_loss: 0.1181, D_B_loss: 0.0605, G_A_loss: 1.2371, G_B_loss: 0.4549\n",
      "Epoch [173/200], Step [781/1067], D_A_loss: 0.0177, D_B_loss: 0.0308, G_A_loss: 0.9434, G_B_loss: 0.5029\n",
      "Epoch [173/200], Step [791/1067], D_A_loss: 0.0521, D_B_loss: 0.0348, G_A_loss: 0.7988, G_B_loss: 0.4965\n",
      "Epoch [173/200], Step [801/1067], D_A_loss: 0.1444, D_B_loss: 0.0146, G_A_loss: 0.6888, G_B_loss: 0.6125\n",
      "Epoch [173/200], Step [811/1067], D_A_loss: 0.1878, D_B_loss: 0.0091, G_A_loss: 0.8298, G_B_loss: 0.8734\n",
      "Epoch [173/200], Step [821/1067], D_A_loss: 0.1347, D_B_loss: 0.0836, G_A_loss: 0.6695, G_B_loss: 0.6065\n",
      "Epoch [173/200], Step [831/1067], D_A_loss: 0.0593, D_B_loss: 0.0424, G_A_loss: 0.6405, G_B_loss: 0.5495\n",
      "Epoch [173/200], Step [841/1067], D_A_loss: 0.0326, D_B_loss: 0.0219, G_A_loss: 1.0651, G_B_loss: 0.7851\n",
      "Epoch [173/200], Step [851/1067], D_A_loss: 0.0309, D_B_loss: 0.0089, G_A_loss: 0.7821, G_B_loss: 0.3789\n",
      "Epoch [173/200], Step [861/1067], D_A_loss: 0.0494, D_B_loss: 0.0271, G_A_loss: 0.8679, G_B_loss: 0.4256\n",
      "Epoch [173/200], Step [871/1067], D_A_loss: 0.0962, D_B_loss: 0.0197, G_A_loss: 0.7919, G_B_loss: 0.7753\n",
      "Epoch [173/200], Step [881/1067], D_A_loss: 0.1191, D_B_loss: 0.0160, G_A_loss: 0.7946, G_B_loss: 0.4043\n",
      "Epoch [173/200], Step [891/1067], D_A_loss: 0.0791, D_B_loss: 0.0110, G_A_loss: 0.9057, G_B_loss: 0.9094\n",
      "Epoch [173/200], Step [901/1067], D_A_loss: 0.0406, D_B_loss: 0.0120, G_A_loss: 0.9312, G_B_loss: 0.7175\n",
      "Epoch [173/200], Step [911/1067], D_A_loss: 0.0742, D_B_loss: 0.0599, G_A_loss: 0.4757, G_B_loss: 0.1925\n",
      "Epoch [173/200], Step [921/1067], D_A_loss: 0.0370, D_B_loss: 0.0442, G_A_loss: 1.5583, G_B_loss: 0.5740\n",
      "Epoch [173/200], Step [931/1067], D_A_loss: 0.1575, D_B_loss: 0.0163, G_A_loss: 0.8102, G_B_loss: 0.2499\n",
      "Epoch [173/200], Step [941/1067], D_A_loss: 0.1201, D_B_loss: 0.0101, G_A_loss: 0.5995, G_B_loss: 0.8009\n",
      "Epoch [173/200], Step [951/1067], D_A_loss: 0.0464, D_B_loss: 0.0505, G_A_loss: 0.9925, G_B_loss: 0.8718\n",
      "Epoch [173/200], Step [961/1067], D_A_loss: 0.0281, D_B_loss: 0.0644, G_A_loss: 1.0367, G_B_loss: 0.4576\n",
      "Epoch [173/200], Step [971/1067], D_A_loss: 0.0895, D_B_loss: 0.0086, G_A_loss: 0.9330, G_B_loss: 0.5233\n",
      "Epoch [173/200], Step [981/1067], D_A_loss: 0.0309, D_B_loss: 0.0104, G_A_loss: 1.1215, G_B_loss: 0.7413\n",
      "Epoch [173/200], Step [991/1067], D_A_loss: 0.0956, D_B_loss: 0.0883, G_A_loss: 0.7778, G_B_loss: 0.9334\n",
      "Epoch [173/200], Step [1001/1067], D_A_loss: 0.0912, D_B_loss: 0.0159, G_A_loss: 0.7981, G_B_loss: 0.6300\n",
      "Epoch [173/200], Step [1011/1067], D_A_loss: 0.1021, D_B_loss: 0.0408, G_A_loss: 0.6981, G_B_loss: 1.2185\n",
      "Epoch [173/200], Step [1021/1067], D_A_loss: 0.0211, D_B_loss: 0.0115, G_A_loss: 1.2403, G_B_loss: 0.9266\n",
      "Epoch [173/200], Step [1031/1067], D_A_loss: 0.0511, D_B_loss: 0.0119, G_A_loss: 0.9350, G_B_loss: 0.6294\n",
      "Epoch [173/200], Step [1041/1067], D_A_loss: 0.1173, D_B_loss: 0.0212, G_A_loss: 0.8712, G_B_loss: 0.4967\n",
      "Epoch [173/200], Step [1051/1067], D_A_loss: 0.0797, D_B_loss: 0.1323, G_A_loss: 0.6465, G_B_loss: 0.5615\n",
      "Epoch [173/200], Step [1061/1067], D_A_loss: 0.0936, D_B_loss: 0.0206, G_A_loss: 0.8259, G_B_loss: 0.4026\n",
      "Epoch [174/200], Step [1/1067], D_A_loss: 0.0424, D_B_loss: 0.0603, G_A_loss: 0.6661, G_B_loss: 0.9481\n",
      "Epoch [174/200], Step [11/1067], D_A_loss: 0.0490, D_B_loss: 0.0298, G_A_loss: 0.6522, G_B_loss: 0.7343\n",
      "Epoch [174/200], Step [21/1067], D_A_loss: 0.0243, D_B_loss: 0.0136, G_A_loss: 0.7606, G_B_loss: 0.8263\n",
      "Epoch [174/200], Step [31/1067], D_A_loss: 0.0753, D_B_loss: 0.0268, G_A_loss: 0.8728, G_B_loss: 0.9158\n",
      "Epoch [174/200], Step [41/1067], D_A_loss: 0.0637, D_B_loss: 0.0195, G_A_loss: 1.1318, G_B_loss: 0.5534\n",
      "Epoch [174/200], Step [51/1067], D_A_loss: 0.0680, D_B_loss: 0.0139, G_A_loss: 0.7271, G_B_loss: 0.6237\n",
      "Epoch [174/200], Step [61/1067], D_A_loss: 0.0785, D_B_loss: 0.0173, G_A_loss: 0.7865, G_B_loss: 0.6521\n",
      "Epoch [174/200], Step [71/1067], D_A_loss: 0.0323, D_B_loss: 0.0186, G_A_loss: 1.0033, G_B_loss: 0.8709\n",
      "Epoch [174/200], Step [81/1067], D_A_loss: 0.0558, D_B_loss: 0.0132, G_A_loss: 0.8567, G_B_loss: 0.7130\n",
      "Epoch [174/200], Step [91/1067], D_A_loss: 0.2446, D_B_loss: 0.0244, G_A_loss: 1.1404, G_B_loss: 0.5510\n",
      "Epoch [174/200], Step [101/1067], D_A_loss: 0.1053, D_B_loss: 0.0667, G_A_loss: 0.4506, G_B_loss: 0.5198\n",
      "Epoch [174/200], Step [111/1067], D_A_loss: 0.0328, D_B_loss: 0.0485, G_A_loss: 0.9833, G_B_loss: 0.7667\n",
      "Epoch [174/200], Step [121/1067], D_A_loss: 0.0311, D_B_loss: 0.0115, G_A_loss: 0.6204, G_B_loss: 1.1023\n",
      "Epoch [174/200], Step [131/1067], D_A_loss: 0.1450, D_B_loss: 0.0262, G_A_loss: 0.8330, G_B_loss: 0.2846\n",
      "Epoch [174/200], Step [141/1067], D_A_loss: 0.1278, D_B_loss: 0.0501, G_A_loss: 0.5546, G_B_loss: 0.8075\n",
      "Epoch [174/200], Step [151/1067], D_A_loss: 0.0989, D_B_loss: 0.0177, G_A_loss: 0.8394, G_B_loss: 0.4577\n",
      "Epoch [174/200], Step [161/1067], D_A_loss: 0.0752, D_B_loss: 0.0121, G_A_loss: 0.8789, G_B_loss: 0.9209\n",
      "Epoch [174/200], Step [171/1067], D_A_loss: 0.0479, D_B_loss: 0.0807, G_A_loss: 0.4287, G_B_loss: 0.9947\n",
      "Epoch [174/200], Step [181/1067], D_A_loss: 0.0858, D_B_loss: 0.0365, G_A_loss: 1.0189, G_B_loss: 0.4151\n",
      "Epoch [174/200], Step [191/1067], D_A_loss: 0.0571, D_B_loss: 0.0130, G_A_loss: 0.8102, G_B_loss: 0.6902\n",
      "Epoch [174/200], Step [201/1067], D_A_loss: 0.0744, D_B_loss: 0.0274, G_A_loss: 1.0750, G_B_loss: 0.8172\n",
      "Epoch [174/200], Step [211/1067], D_A_loss: 0.0329, D_B_loss: 0.0427, G_A_loss: 0.6198, G_B_loss: 0.4415\n",
      "Epoch [174/200], Step [221/1067], D_A_loss: 0.0539, D_B_loss: 0.0163, G_A_loss: 0.9606, G_B_loss: 0.5462\n",
      "Epoch [174/200], Step [231/1067], D_A_loss: 0.0376, D_B_loss: 0.0146, G_A_loss: 1.1233, G_B_loss: 0.7051\n",
      "Epoch [174/200], Step [241/1067], D_A_loss: 0.0247, D_B_loss: 0.0177, G_A_loss: 0.8628, G_B_loss: 0.6748\n",
      "Epoch [174/200], Step [251/1067], D_A_loss: 0.0499, D_B_loss: 0.0612, G_A_loss: 0.8862, G_B_loss: 0.5680\n",
      "Epoch [174/200], Step [261/1067], D_A_loss: 0.0273, D_B_loss: 0.0156, G_A_loss: 0.8589, G_B_loss: 0.9211\n",
      "Epoch [174/200], Step [271/1067], D_A_loss: 0.0848, D_B_loss: 0.1480, G_A_loss: 0.5223, G_B_loss: 0.6744\n",
      "Epoch [174/200], Step [281/1067], D_A_loss: 0.0557, D_B_loss: 0.0128, G_A_loss: 1.0005, G_B_loss: 0.6452\n",
      "Epoch [174/200], Step [291/1067], D_A_loss: 0.1227, D_B_loss: 0.1504, G_A_loss: 1.0412, G_B_loss: 0.3822\n",
      "Epoch [174/200], Step [301/1067], D_A_loss: 0.0576, D_B_loss: 0.0132, G_A_loss: 0.7877, G_B_loss: 0.7662\n",
      "Epoch [174/200], Step [311/1067], D_A_loss: 0.0521, D_B_loss: 0.0133, G_A_loss: 1.1013, G_B_loss: 1.1139\n",
      "Epoch [174/200], Step [321/1067], D_A_loss: 0.0428, D_B_loss: 0.0338, G_A_loss: 1.1924, G_B_loss: 0.6527\n",
      "Epoch [174/200], Step [331/1067], D_A_loss: 0.0446, D_B_loss: 0.0165, G_A_loss: 0.8786, G_B_loss: 0.5833\n",
      "Epoch [174/200], Step [341/1067], D_A_loss: 0.0700, D_B_loss: 0.0191, G_A_loss: 0.7881, G_B_loss: 0.2367\n",
      "Epoch [174/200], Step [351/1067], D_A_loss: 0.0394, D_B_loss: 0.0110, G_A_loss: 0.8227, G_B_loss: 0.8138\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [174/200], Step [361/1067], D_A_loss: 0.0279, D_B_loss: 0.0155, G_A_loss: 0.8155, G_B_loss: 0.6251\n",
      "Epoch [174/200], Step [371/1067], D_A_loss: 0.1066, D_B_loss: 0.0143, G_A_loss: 0.8155, G_B_loss: 0.5956\n",
      "Epoch [174/200], Step [381/1067], D_A_loss: 0.0708, D_B_loss: 0.0242, G_A_loss: 0.6964, G_B_loss: 0.6888\n",
      "Epoch [174/200], Step [391/1067], D_A_loss: 0.0571, D_B_loss: 0.0506, G_A_loss: 0.5407, G_B_loss: 0.9094\n",
      "Epoch [174/200], Step [401/1067], D_A_loss: 0.0311, D_B_loss: 0.0142, G_A_loss: 0.8459, G_B_loss: 0.9138\n",
      "Epoch [174/200], Step [411/1067], D_A_loss: 0.0300, D_B_loss: 0.0174, G_A_loss: 0.8377, G_B_loss: 0.7752\n",
      "Epoch [174/200], Step [421/1067], D_A_loss: 0.0537, D_B_loss: 0.0353, G_A_loss: 1.3527, G_B_loss: 0.3501\n",
      "Epoch [174/200], Step [431/1067], D_A_loss: 0.1304, D_B_loss: 0.0076, G_A_loss: 1.0041, G_B_loss: 0.4887\n",
      "Epoch [174/200], Step [441/1067], D_A_loss: 0.0297, D_B_loss: 0.0106, G_A_loss: 0.9325, G_B_loss: 0.9756\n",
      "Epoch [174/200], Step [451/1067], D_A_loss: 0.0313, D_B_loss: 0.0222, G_A_loss: 0.9971, G_B_loss: 0.7237\n",
      "Epoch [174/200], Step [461/1067], D_A_loss: 0.0510, D_B_loss: 0.0498, G_A_loss: 0.9173, G_B_loss: 0.6294\n",
      "Epoch [174/200], Step [471/1067], D_A_loss: 0.0403, D_B_loss: 0.0150, G_A_loss: 1.0838, G_B_loss: 0.7027\n",
      "Epoch [174/200], Step [481/1067], D_A_loss: 0.0167, D_B_loss: 0.0154, G_A_loss: 0.9524, G_B_loss: 0.9150\n",
      "Epoch [174/200], Step [491/1067], D_A_loss: 0.0438, D_B_loss: 0.0849, G_A_loss: 0.7169, G_B_loss: 0.1876\n",
      "Epoch [174/200], Step [501/1067], D_A_loss: 0.0245, D_B_loss: 0.0199, G_A_loss: 1.3291, G_B_loss: 1.0076\n",
      "Epoch [174/200], Step [511/1067], D_A_loss: 0.0359, D_B_loss: 0.0442, G_A_loss: 1.4405, G_B_loss: 0.7320\n",
      "Epoch [174/200], Step [521/1067], D_A_loss: 0.0329, D_B_loss: 0.0105, G_A_loss: 0.6722, G_B_loss: 0.9287\n",
      "Epoch [174/200], Step [531/1067], D_A_loss: 0.1483, D_B_loss: 0.0117, G_A_loss: 0.8628, G_B_loss: 0.6349\n",
      "Epoch [174/200], Step [541/1067], D_A_loss: 0.0781, D_B_loss: 0.0391, G_A_loss: 0.9882, G_B_loss: 0.6538\n",
      "Epoch [174/200], Step [551/1067], D_A_loss: 0.0321, D_B_loss: 0.0580, G_A_loss: 1.4567, G_B_loss: 0.6948\n",
      "Epoch [174/200], Step [561/1067], D_A_loss: 0.0714, D_B_loss: 0.1578, G_A_loss: 1.1879, G_B_loss: 0.5758\n",
      "Epoch [174/200], Step [571/1067], D_A_loss: 0.0737, D_B_loss: 0.0082, G_A_loss: 0.9553, G_B_loss: 0.6841\n",
      "Epoch [174/200], Step [581/1067], D_A_loss: 0.0624, D_B_loss: 0.0333, G_A_loss: 0.8240, G_B_loss: 0.5754\n",
      "Epoch [174/200], Step [591/1067], D_A_loss: 0.1173, D_B_loss: 0.0502, G_A_loss: 0.6501, G_B_loss: 0.7237\n",
      "Epoch [174/200], Step [601/1067], D_A_loss: 0.1226, D_B_loss: 0.0170, G_A_loss: 1.2151, G_B_loss: 1.0548\n",
      "Epoch [174/200], Step [611/1067], D_A_loss: 0.0793, D_B_loss: 0.0160, G_A_loss: 0.7408, G_B_loss: 0.6189\n",
      "Epoch [174/200], Step [621/1067], D_A_loss: 0.0357, D_B_loss: 0.0100, G_A_loss: 0.8003, G_B_loss: 0.9066\n",
      "Epoch [174/200], Step [631/1067], D_A_loss: 0.0199, D_B_loss: 0.0150, G_A_loss: 0.3376, G_B_loss: 0.2741\n",
      "Epoch [174/200], Step [641/1067], D_A_loss: 0.0662, D_B_loss: 0.0240, G_A_loss: 0.9093, G_B_loss: 0.4081\n",
      "Epoch [174/200], Step [651/1067], D_A_loss: 0.0216, D_B_loss: 0.0720, G_A_loss: 0.4316, G_B_loss: 0.6168\n",
      "Epoch [174/200], Step [661/1067], D_A_loss: 0.0551, D_B_loss: 0.0210, G_A_loss: 0.6305, G_B_loss: 0.6645\n",
      "Epoch [174/200], Step [671/1067], D_A_loss: 0.0577, D_B_loss: 0.0483, G_A_loss: 0.5676, G_B_loss: 0.2641\n",
      "Epoch [174/200], Step [681/1067], D_A_loss: 0.0821, D_B_loss: 0.0243, G_A_loss: 0.7313, G_B_loss: 0.7388\n",
      "Epoch [174/200], Step [691/1067], D_A_loss: 0.0623, D_B_loss: 0.0371, G_A_loss: 0.6074, G_B_loss: 0.5696\n",
      "Epoch [174/200], Step [701/1067], D_A_loss: 0.1380, D_B_loss: 0.0489, G_A_loss: 0.7496, G_B_loss: 0.7977\n",
      "Epoch [174/200], Step [711/1067], D_A_loss: 0.0327, D_B_loss: 0.0191, G_A_loss: 0.8139, G_B_loss: 0.7947\n",
      "Epoch [174/200], Step [721/1067], D_A_loss: 0.0727, D_B_loss: 0.0138, G_A_loss: 0.6973, G_B_loss: 0.6054\n",
      "Epoch [174/200], Step [731/1067], D_A_loss: 0.1885, D_B_loss: 0.0386, G_A_loss: 0.8266, G_B_loss: 0.8485\n",
      "Epoch [174/200], Step [741/1067], D_A_loss: 0.1156, D_B_loss: 0.0110, G_A_loss: 1.1138, G_B_loss: 0.8640\n",
      "Epoch [174/200], Step [751/1067], D_A_loss: 0.0638, D_B_loss: 0.0131, G_A_loss: 0.6831, G_B_loss: 0.6988\n",
      "Epoch [174/200], Step [761/1067], D_A_loss: 0.0619, D_B_loss: 0.0100, G_A_loss: 0.9166, G_B_loss: 0.4985\n",
      "Epoch [174/200], Step [771/1067], D_A_loss: 0.1139, D_B_loss: 0.0375, G_A_loss: 0.5970, G_B_loss: 0.6011\n",
      "Epoch [174/200], Step [781/1067], D_A_loss: 0.1829, D_B_loss: 0.0228, G_A_loss: 0.9878, G_B_loss: 1.0238\n",
      "Epoch [174/200], Step [791/1067], D_A_loss: 0.0696, D_B_loss: 0.0631, G_A_loss: 0.7450, G_B_loss: 0.4856\n",
      "Epoch [174/200], Step [801/1067], D_A_loss: 0.0636, D_B_loss: 0.0132, G_A_loss: 0.9608, G_B_loss: 0.4900\n",
      "Epoch [174/200], Step [811/1067], D_A_loss: 0.0748, D_B_loss: 0.0283, G_A_loss: 0.7778, G_B_loss: 0.7895\n",
      "Epoch [174/200], Step [821/1067], D_A_loss: 0.0338, D_B_loss: 0.0123, G_A_loss: 0.9224, G_B_loss: 0.8165\n",
      "Epoch [174/200], Step [831/1067], D_A_loss: 0.0677, D_B_loss: 0.0461, G_A_loss: 0.6840, G_B_loss: 0.4685\n",
      "Epoch [174/200], Step [841/1067], D_A_loss: 0.0391, D_B_loss: 0.0499, G_A_loss: 0.8434, G_B_loss: 0.9460\n",
      "Epoch [174/200], Step [851/1067], D_A_loss: 0.0580, D_B_loss: 0.0080, G_A_loss: 0.9310, G_B_loss: 0.5482\n",
      "Epoch [174/200], Step [861/1067], D_A_loss: 0.1696, D_B_loss: 0.0246, G_A_loss: 0.9641, G_B_loss: 0.5319\n",
      "Epoch [174/200], Step [871/1067], D_A_loss: 0.0354, D_B_loss: 0.0113, G_A_loss: 0.6542, G_B_loss: 0.8058\n",
      "Epoch [174/200], Step [881/1067], D_A_loss: 0.0399, D_B_loss: 0.0301, G_A_loss: 0.6807, G_B_loss: 0.6740\n",
      "Epoch [174/200], Step [891/1067], D_A_loss: 0.0478, D_B_loss: 0.0885, G_A_loss: 1.3240, G_B_loss: 0.5585\n",
      "Epoch [174/200], Step [901/1067], D_A_loss: 0.0709, D_B_loss: 0.0354, G_A_loss: 0.7431, G_B_loss: 0.5481\n",
      "Epoch [174/200], Step [911/1067], D_A_loss: 0.0741, D_B_loss: 0.0327, G_A_loss: 0.6402, G_B_loss: 0.5285\n",
      "Epoch [174/200], Step [921/1067], D_A_loss: 0.0257, D_B_loss: 0.0299, G_A_loss: 0.9445, G_B_loss: 0.9100\n",
      "Epoch [174/200], Step [931/1067], D_A_loss: 0.0417, D_B_loss: 0.0221, G_A_loss: 0.5950, G_B_loss: 0.8030\n",
      "Epoch [174/200], Step [941/1067], D_A_loss: 0.0920, D_B_loss: 0.0154, G_A_loss: 0.9291, G_B_loss: 0.5373\n",
      "Epoch [174/200], Step [951/1067], D_A_loss: 0.0577, D_B_loss: 0.0106, G_A_loss: 0.6633, G_B_loss: 0.5639\n",
      "Epoch [174/200], Step [961/1067], D_A_loss: 0.0553, D_B_loss: 0.0424, G_A_loss: 0.9708, G_B_loss: 0.5805\n",
      "Epoch [174/200], Step [971/1067], D_A_loss: 0.0709, D_B_loss: 0.0104, G_A_loss: 0.9274, G_B_loss: 0.4859\n",
      "Epoch [174/200], Step [981/1067], D_A_loss: 0.0433, D_B_loss: 0.0279, G_A_loss: 1.0343, G_B_loss: 1.1725\n",
      "Epoch [174/200], Step [991/1067], D_A_loss: 0.0757, D_B_loss: 0.2865, G_A_loss: 0.9259, G_B_loss: 0.5654\n",
      "Epoch [174/200], Step [1001/1067], D_A_loss: 0.1418, D_B_loss: 0.0221, G_A_loss: 0.5696, G_B_loss: 0.4232\n",
      "Epoch [174/200], Step [1011/1067], D_A_loss: 0.0579, D_B_loss: 0.0233, G_A_loss: 0.6040, G_B_loss: 0.7874\n",
      "Epoch [174/200], Step [1021/1067], D_A_loss: 0.1814, D_B_loss: 0.0129, G_A_loss: 0.7630, G_B_loss: 0.9205\n",
      "Epoch [174/200], Step [1031/1067], D_A_loss: 0.0885, D_B_loss: 0.0203, G_A_loss: 0.7468, G_B_loss: 0.4266\n",
      "Epoch [174/200], Step [1041/1067], D_A_loss: 0.0784, D_B_loss: 0.0431, G_A_loss: 0.5715, G_B_loss: 0.7582\n",
      "Epoch [174/200], Step [1051/1067], D_A_loss: 0.0576, D_B_loss: 0.0199, G_A_loss: 0.8673, G_B_loss: 0.6399\n",
      "Epoch [174/200], Step [1061/1067], D_A_loss: 0.0355, D_B_loss: 0.0166, G_A_loss: 0.7890, G_B_loss: 0.8565\n",
      "Epoch [175/200], Step [1/1067], D_A_loss: 0.0597, D_B_loss: 0.0716, G_A_loss: 0.4992, G_B_loss: 0.5266\n",
      "Epoch [175/200], Step [11/1067], D_A_loss: 0.0367, D_B_loss: 0.0203, G_A_loss: 0.9283, G_B_loss: 0.5706\n",
      "Epoch [175/200], Step [21/1067], D_A_loss: 0.1514, D_B_loss: 0.0389, G_A_loss: 1.0185, G_B_loss: 0.3339\n",
      "Epoch [175/200], Step [31/1067], D_A_loss: 0.0281, D_B_loss: 0.0255, G_A_loss: 1.0367, G_B_loss: 0.5706\n",
      "Epoch [175/200], Step [41/1067], D_A_loss: 0.0530, D_B_loss: 0.0114, G_A_loss: 1.1177, G_B_loss: 0.9382\n",
      "Epoch [175/200], Step [51/1067], D_A_loss: 0.0465, D_B_loss: 0.0109, G_A_loss: 0.9739, G_B_loss: 0.6035\n",
      "Epoch [175/200], Step [61/1067], D_A_loss: 0.0765, D_B_loss: 0.0310, G_A_loss: 0.9198, G_B_loss: 0.7389\n",
      "Epoch [175/200], Step [71/1067], D_A_loss: 0.0851, D_B_loss: 0.0075, G_A_loss: 1.0484, G_B_loss: 0.4100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [175/200], Step [81/1067], D_A_loss: 0.1177, D_B_loss: 0.0119, G_A_loss: 0.8292, G_B_loss: 0.3368\n",
      "Epoch [175/200], Step [91/1067], D_A_loss: 0.0267, D_B_loss: 0.0151, G_A_loss: 0.8500, G_B_loss: 0.4958\n",
      "Epoch [175/200], Step [101/1067], D_A_loss: 0.0855, D_B_loss: 0.0323, G_A_loss: 0.6226, G_B_loss: 0.5553\n",
      "Epoch [175/200], Step [111/1067], D_A_loss: 0.0899, D_B_loss: 0.0136, G_A_loss: 0.5726, G_B_loss: 0.3962\n",
      "Epoch [175/200], Step [121/1067], D_A_loss: 0.1060, D_B_loss: 0.0357, G_A_loss: 0.7881, G_B_loss: 0.3922\n",
      "Epoch [175/200], Step [131/1067], D_A_loss: 0.0402, D_B_loss: 0.0349, G_A_loss: 0.5939, G_B_loss: 1.1274\n",
      "Epoch [175/200], Step [141/1067], D_A_loss: 0.0644, D_B_loss: 0.0164, G_A_loss: 0.8606, G_B_loss: 0.2864\n",
      "Epoch [175/200], Step [151/1067], D_A_loss: 0.0413, D_B_loss: 0.0109, G_A_loss: 0.9113, G_B_loss: 0.6887\n",
      "Epoch [175/200], Step [161/1067], D_A_loss: 0.0533, D_B_loss: 0.0528, G_A_loss: 0.5191, G_B_loss: 0.8950\n",
      "Epoch [175/200], Step [171/1067], D_A_loss: 0.0699, D_B_loss: 0.0278, G_A_loss: 0.8055, G_B_loss: 0.6432\n",
      "Epoch [175/200], Step [181/1067], D_A_loss: 0.0366, D_B_loss: 0.0566, G_A_loss: 0.8656, G_B_loss: 0.7883\n",
      "Epoch [175/200], Step [191/1067], D_A_loss: 0.1625, D_B_loss: 0.0525, G_A_loss: 1.1723, G_B_loss: 0.4705\n",
      "Epoch [175/200], Step [201/1067], D_A_loss: 0.1731, D_B_loss: 0.0640, G_A_loss: 0.4754, G_B_loss: 0.8503\n",
      "Epoch [175/200], Step [211/1067], D_A_loss: 0.1297, D_B_loss: 0.0374, G_A_loss: 1.1597, G_B_loss: 0.5257\n",
      "Epoch [175/200], Step [221/1067], D_A_loss: 0.0612, D_B_loss: 0.0170, G_A_loss: 1.0248, G_B_loss: 0.1825\n",
      "Epoch [175/200], Step [231/1067], D_A_loss: 0.0344, D_B_loss: 0.0309, G_A_loss: 0.8297, G_B_loss: 0.8523\n",
      "Epoch [175/200], Step [241/1067], D_A_loss: 0.1197, D_B_loss: 0.0274, G_A_loss: 0.6669, G_B_loss: 0.3541\n",
      "Epoch [175/200], Step [251/1067], D_A_loss: 0.0457, D_B_loss: 0.0159, G_A_loss: 1.0942, G_B_loss: 0.4050\n",
      "Epoch [175/200], Step [261/1067], D_A_loss: 0.0239, D_B_loss: 0.0116, G_A_loss: 0.4731, G_B_loss: 0.8973\n",
      "Epoch [175/200], Step [271/1067], D_A_loss: 0.1334, D_B_loss: 0.0247, G_A_loss: 0.6999, G_B_loss: 0.8257\n",
      "Epoch [175/200], Step [281/1067], D_A_loss: 0.1372, D_B_loss: 0.0455, G_A_loss: 0.6727, G_B_loss: 0.3038\n",
      "Epoch [175/200], Step [291/1067], D_A_loss: 0.0414, D_B_loss: 0.0236, G_A_loss: 1.0333, G_B_loss: 0.6447\n",
      "Epoch [175/200], Step [301/1067], D_A_loss: 0.0418, D_B_loss: 0.0400, G_A_loss: 0.5639, G_B_loss: 0.6854\n",
      "Epoch [175/200], Step [311/1067], D_A_loss: 0.1467, D_B_loss: 0.0263, G_A_loss: 0.6582, G_B_loss: 0.8662\n",
      "Epoch [175/200], Step [321/1067], D_A_loss: 0.0628, D_B_loss: 0.0085, G_A_loss: 0.9632, G_B_loss: 0.5544\n",
      "Epoch [175/200], Step [331/1067], D_A_loss: 0.1161, D_B_loss: 0.0140, G_A_loss: 0.7899, G_B_loss: 0.4634\n",
      "Epoch [175/200], Step [341/1067], D_A_loss: 0.0600, D_B_loss: 0.0180, G_A_loss: 0.7720, G_B_loss: 0.5681\n",
      "Epoch [175/200], Step [351/1067], D_A_loss: 0.0400, D_B_loss: 0.0726, G_A_loss: 0.6531, G_B_loss: 0.7438\n",
      "Epoch [175/200], Step [361/1067], D_A_loss: 0.0551, D_B_loss: 0.0156, G_A_loss: 1.0897, G_B_loss: 0.5859\n",
      "Epoch [175/200], Step [371/1067], D_A_loss: 0.1310, D_B_loss: 0.0204, G_A_loss: 0.7101, G_B_loss: 0.7209\n",
      "Epoch [175/200], Step [381/1067], D_A_loss: 0.0317, D_B_loss: 0.0637, G_A_loss: 1.0353, G_B_loss: 0.7084\n",
      "Epoch [175/200], Step [391/1067], D_A_loss: 0.1633, D_B_loss: 0.0101, G_A_loss: 0.9676, G_B_loss: 0.4211\n",
      "Epoch [175/200], Step [401/1067], D_A_loss: 0.0338, D_B_loss: 0.0166, G_A_loss: 0.8297, G_B_loss: 0.7658\n",
      "Epoch [175/200], Step [411/1067], D_A_loss: 0.0182, D_B_loss: 0.0134, G_A_loss: 0.8875, G_B_loss: 0.5816\n",
      "Epoch [175/200], Step [421/1067], D_A_loss: 0.0253, D_B_loss: 0.0109, G_A_loss: 1.0829, G_B_loss: 0.8921\n",
      "Epoch [175/200], Step [431/1067], D_A_loss: 0.0525, D_B_loss: 0.0216, G_A_loss: 0.9740, G_B_loss: 0.5919\n",
      "Epoch [175/200], Step [441/1067], D_A_loss: 0.0653, D_B_loss: 0.0297, G_A_loss: 0.8994, G_B_loss: 0.4500\n",
      "Epoch [175/200], Step [451/1067], D_A_loss: 0.0528, D_B_loss: 0.0240, G_A_loss: 0.7714, G_B_loss: 0.6224\n",
      "Epoch [175/200], Step [461/1067], D_A_loss: 0.0247, D_B_loss: 0.0333, G_A_loss: 0.9036, G_B_loss: 0.5590\n",
      "Epoch [175/200], Step [471/1067], D_A_loss: 0.0624, D_B_loss: 0.0377, G_A_loss: 0.8086, G_B_loss: 0.6162\n",
      "Epoch [175/200], Step [481/1067], D_A_loss: 0.0915, D_B_loss: 0.0283, G_A_loss: 1.0297, G_B_loss: 0.6300\n",
      "Epoch [175/200], Step [491/1067], D_A_loss: 0.0749, D_B_loss: 0.0351, G_A_loss: 0.8525, G_B_loss: 0.5793\n",
      "Epoch [175/200], Step [501/1067], D_A_loss: 0.0568, D_B_loss: 0.0119, G_A_loss: 1.0430, G_B_loss: 0.7077\n",
      "Epoch [175/200], Step [511/1067], D_A_loss: 0.0433, D_B_loss: 0.0126, G_A_loss: 0.9276, G_B_loss: 0.9604\n",
      "Epoch [175/200], Step [521/1067], D_A_loss: 0.0938, D_B_loss: 0.0161, G_A_loss: 0.8320, G_B_loss: 0.3926\n",
      "Epoch [175/200], Step [531/1067], D_A_loss: 0.0297, D_B_loss: 0.0551, G_A_loss: 0.4904, G_B_loss: 0.4888\n",
      "Epoch [175/200], Step [541/1067], D_A_loss: 0.0611, D_B_loss: 0.0093, G_A_loss: 0.6288, G_B_loss: 0.5512\n",
      "Epoch [175/200], Step [551/1067], D_A_loss: 0.0873, D_B_loss: 0.0549, G_A_loss: 0.5224, G_B_loss: 0.7232\n",
      "Epoch [175/200], Step [561/1067], D_A_loss: 0.1271, D_B_loss: 0.0135, G_A_loss: 1.1422, G_B_loss: 0.4531\n",
      "Epoch [175/200], Step [571/1067], D_A_loss: 0.0364, D_B_loss: 0.0174, G_A_loss: 0.8234, G_B_loss: 0.7707\n",
      "Epoch [175/200], Step [581/1067], D_A_loss: 0.0224, D_B_loss: 0.0169, G_A_loss: 1.0063, G_B_loss: 0.5313\n",
      "Epoch [175/200], Step [591/1067], D_A_loss: 0.0799, D_B_loss: 0.0270, G_A_loss: 0.6876, G_B_loss: 0.6194\n",
      "Epoch [175/200], Step [601/1067], D_A_loss: 0.0585, D_B_loss: 0.0125, G_A_loss: 0.7874, G_B_loss: 0.7680\n",
      "Epoch [175/200], Step [611/1067], D_A_loss: 0.0478, D_B_loss: 0.0093, G_A_loss: 0.9525, G_B_loss: 0.6965\n",
      "Epoch [175/200], Step [621/1067], D_A_loss: 0.0670, D_B_loss: 0.0146, G_A_loss: 0.6090, G_B_loss: 0.5232\n",
      "Epoch [175/200], Step [631/1067], D_A_loss: 0.0986, D_B_loss: 0.0219, G_A_loss: 0.7275, G_B_loss: 0.8394\n",
      "Epoch [175/200], Step [641/1067], D_A_loss: 0.0461, D_B_loss: 0.0098, G_A_loss: 0.7413, G_B_loss: 0.6308\n",
      "Epoch [175/200], Step [651/1067], D_A_loss: 0.0268, D_B_loss: 0.0257, G_A_loss: 0.9226, G_B_loss: 0.8439\n",
      "Epoch [175/200], Step [661/1067], D_A_loss: 0.0916, D_B_loss: 0.0776, G_A_loss: 0.8407, G_B_loss: 0.9848\n",
      "Epoch [175/200], Step [671/1067], D_A_loss: 0.0381, D_B_loss: 0.0227, G_A_loss: 0.7020, G_B_loss: 0.6805\n",
      "Epoch [175/200], Step [681/1067], D_A_loss: 0.0829, D_B_loss: 0.0105, G_A_loss: 0.7632, G_B_loss: 0.4218\n",
      "Epoch [175/200], Step [691/1067], D_A_loss: 0.0334, D_B_loss: 0.0121, G_A_loss: 1.1529, G_B_loss: 0.5710\n",
      "Epoch [175/200], Step [701/1067], D_A_loss: 0.1358, D_B_loss: 0.0502, G_A_loss: 1.1021, G_B_loss: 0.2856\n",
      "Epoch [175/200], Step [711/1067], D_A_loss: 0.0404, D_B_loss: 0.0505, G_A_loss: 0.9715, G_B_loss: 0.9412\n",
      "Epoch [175/200], Step [721/1067], D_A_loss: 0.0485, D_B_loss: 0.0134, G_A_loss: 0.9532, G_B_loss: 0.9252\n",
      "Epoch [175/200], Step [731/1067], D_A_loss: 0.0415, D_B_loss: 0.0495, G_A_loss: 0.8250, G_B_loss: 0.7393\n",
      "Epoch [175/200], Step [741/1067], D_A_loss: 0.0537, D_B_loss: 0.0677, G_A_loss: 0.8092, G_B_loss: 0.5564\n",
      "Epoch [175/200], Step [751/1067], D_A_loss: 0.1314, D_B_loss: 0.0136, G_A_loss: 0.6876, G_B_loss: 0.4998\n",
      "Epoch [175/200], Step [761/1067], D_A_loss: 0.1996, D_B_loss: 0.0222, G_A_loss: 0.6097, G_B_loss: 0.3633\n",
      "Epoch [175/200], Step [771/1067], D_A_loss: 0.0262, D_B_loss: 0.0217, G_A_loss: 1.3111, G_B_loss: 0.4976\n",
      "Epoch [175/200], Step [781/1067], D_A_loss: 0.1015, D_B_loss: 0.0156, G_A_loss: 0.8134, G_B_loss: 0.8458\n",
      "Epoch [175/200], Step [791/1067], D_A_loss: 0.1321, D_B_loss: 0.0232, G_A_loss: 1.2312, G_B_loss: 0.6458\n",
      "Epoch [175/200], Step [801/1067], D_A_loss: 0.0494, D_B_loss: 0.0236, G_A_loss: 1.0403, G_B_loss: 0.4913\n",
      "Epoch [175/200], Step [811/1067], D_A_loss: 0.0439, D_B_loss: 0.0190, G_A_loss: 1.0344, G_B_loss: 0.6344\n",
      "Epoch [175/200], Step [821/1067], D_A_loss: 0.0980, D_B_loss: 0.0309, G_A_loss: 1.0637, G_B_loss: 0.5172\n",
      "Epoch [175/200], Step [831/1067], D_A_loss: 0.0560, D_B_loss: 0.0277, G_A_loss: 0.6711, G_B_loss: 0.6103\n",
      "Epoch [175/200], Step [841/1067], D_A_loss: 0.1145, D_B_loss: 0.0204, G_A_loss: 0.9511, G_B_loss: 0.4511\n",
      "Epoch [175/200], Step [851/1067], D_A_loss: 0.0590, D_B_loss: 0.0330, G_A_loss: 0.7429, G_B_loss: 0.6303\n",
      "Epoch [175/200], Step [861/1067], D_A_loss: 0.1292, D_B_loss: 0.0315, G_A_loss: 0.7962, G_B_loss: 0.4273\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [175/200], Step [871/1067], D_A_loss: 0.0312, D_B_loss: 0.0672, G_A_loss: 0.7512, G_B_loss: 0.8996\n",
      "Epoch [175/200], Step [881/1067], D_A_loss: 0.0376, D_B_loss: 0.0216, G_A_loss: 0.8636, G_B_loss: 0.7965\n",
      "Epoch [175/200], Step [891/1067], D_A_loss: 0.3060, D_B_loss: 0.0101, G_A_loss: 0.9534, G_B_loss: 0.8310\n",
      "Epoch [175/200], Step [901/1067], D_A_loss: 0.1983, D_B_loss: 0.0288, G_A_loss: 0.9387, G_B_loss: 0.1759\n",
      "Epoch [175/200], Step [911/1067], D_A_loss: 0.0266, D_B_loss: 0.0247, G_A_loss: 0.7214, G_B_loss: 0.8670\n",
      "Epoch [175/200], Step [921/1067], D_A_loss: 0.0267, D_B_loss: 0.0189, G_A_loss: 0.7592, G_B_loss: 1.1796\n",
      "Epoch [175/200], Step [931/1067], D_A_loss: 0.0481, D_B_loss: 0.0138, G_A_loss: 0.8292, G_B_loss: 0.7714\n",
      "Epoch [175/200], Step [941/1067], D_A_loss: 0.0246, D_B_loss: 0.0111, G_A_loss: 0.6416, G_B_loss: 1.1195\n",
      "Epoch [175/200], Step [951/1067], D_A_loss: 0.0234, D_B_loss: 0.0210, G_A_loss: 0.7106, G_B_loss: 0.8531\n",
      "Epoch [175/200], Step [961/1067], D_A_loss: 0.0420, D_B_loss: 0.0275, G_A_loss: 0.6405, G_B_loss: 0.8927\n",
      "Epoch [175/200], Step [971/1067], D_A_loss: 0.0283, D_B_loss: 0.0204, G_A_loss: 0.8900, G_B_loss: 1.0848\n",
      "Epoch [175/200], Step [981/1067], D_A_loss: 0.0393, D_B_loss: 0.0147, G_A_loss: 0.8746, G_B_loss: 0.7245\n",
      "Epoch [175/200], Step [991/1067], D_A_loss: 0.1849, D_B_loss: 0.0536, G_A_loss: 0.5441, G_B_loss: 0.9439\n",
      "Epoch [175/200], Step [1001/1067], D_A_loss: 0.0691, D_B_loss: 0.0227, G_A_loss: 0.7277, G_B_loss: 0.5032\n",
      "Epoch [175/200], Step [1011/1067], D_A_loss: 0.1088, D_B_loss: 0.0130, G_A_loss: 1.0759, G_B_loss: 0.4200\n",
      "Epoch [175/200], Step [1021/1067], D_A_loss: 0.0724, D_B_loss: 0.0066, G_A_loss: 0.6844, G_B_loss: 0.6514\n",
      "Epoch [175/200], Step [1031/1067], D_A_loss: 0.0405, D_B_loss: 0.0151, G_A_loss: 0.7886, G_B_loss: 1.0268\n",
      "Epoch [175/200], Step [1041/1067], D_A_loss: 0.0226, D_B_loss: 0.0341, G_A_loss: 0.6324, G_B_loss: 0.8578\n",
      "Epoch [175/200], Step [1051/1067], D_A_loss: 0.0721, D_B_loss: 0.0357, G_A_loss: 0.5982, G_B_loss: 0.4765\n",
      "Epoch [175/200], Step [1061/1067], D_A_loss: 0.0500, D_B_loss: 0.0239, G_A_loss: 0.7276, G_B_loss: 0.8161\n",
      "Epoch [176/200], Step [1/1067], D_A_loss: 0.0553, D_B_loss: 0.0114, G_A_loss: 0.7295, G_B_loss: 0.6018\n",
      "Epoch [176/200], Step [11/1067], D_A_loss: 0.0327, D_B_loss: 0.0447, G_A_loss: 0.8489, G_B_loss: 0.5159\n",
      "Epoch [176/200], Step [21/1067], D_A_loss: 0.0348, D_B_loss: 0.0151, G_A_loss: 1.1877, G_B_loss: 0.9516\n",
      "Epoch [176/200], Step [31/1067], D_A_loss: 0.0207, D_B_loss: 0.0262, G_A_loss: 0.7053, G_B_loss: 0.5581\n",
      "Epoch [176/200], Step [41/1067], D_A_loss: 0.0416, D_B_loss: 0.0179, G_A_loss: 0.9342, G_B_loss: 0.7104\n",
      "Epoch [176/200], Step [51/1067], D_A_loss: 0.0386, D_B_loss: 0.0095, G_A_loss: 0.6876, G_B_loss: 0.5968\n",
      "Epoch [176/200], Step [61/1067], D_A_loss: 0.0271, D_B_loss: 0.0184, G_A_loss: 1.2058, G_B_loss: 0.9517\n",
      "Epoch [176/200], Step [71/1067], D_A_loss: 0.0402, D_B_loss: 0.0428, G_A_loss: 0.8492, G_B_loss: 0.5089\n",
      "Epoch [176/200], Step [81/1067], D_A_loss: 0.0307, D_B_loss: 0.0235, G_A_loss: 0.9657, G_B_loss: 0.4441\n",
      "Epoch [176/200], Step [91/1067], D_A_loss: 0.2407, D_B_loss: 0.0508, G_A_loss: 0.7977, G_B_loss: 0.1941\n",
      "Epoch [176/200], Step [101/1067], D_A_loss: 0.0258, D_B_loss: 0.0240, G_A_loss: 0.9093, G_B_loss: 0.4114\n",
      "Epoch [176/200], Step [111/1067], D_A_loss: 0.0749, D_B_loss: 0.0115, G_A_loss: 0.8766, G_B_loss: 0.5291\n",
      "Epoch [176/200], Step [121/1067], D_A_loss: 0.0220, D_B_loss: 0.0143, G_A_loss: 1.1140, G_B_loss: 0.8161\n",
      "Epoch [176/200], Step [131/1067], D_A_loss: 0.1250, D_B_loss: 0.0168, G_A_loss: 1.1944, G_B_loss: 0.5301\n",
      "Epoch [176/200], Step [141/1067], D_A_loss: 0.0149, D_B_loss: 0.0258, G_A_loss: 1.0396, G_B_loss: 0.8627\n",
      "Epoch [176/200], Step [151/1067], D_A_loss: 0.0991, D_B_loss: 0.0132, G_A_loss: 0.9571, G_B_loss: 0.4396\n",
      "Epoch [176/200], Step [161/1067], D_A_loss: 0.0535, D_B_loss: 0.0610, G_A_loss: 1.0340, G_B_loss: 0.6655\n",
      "Epoch [176/200], Step [171/1067], D_A_loss: 0.0486, D_B_loss: 0.0184, G_A_loss: 0.8466, G_B_loss: 0.7672\n",
      "Epoch [176/200], Step [181/1067], D_A_loss: 0.0812, D_B_loss: 0.0152, G_A_loss: 1.1917, G_B_loss: 0.6970\n",
      "Epoch [176/200], Step [191/1067], D_A_loss: 0.1223, D_B_loss: 0.0175, G_A_loss: 1.3499, G_B_loss: 1.1209\n",
      "Epoch [176/200], Step [201/1067], D_A_loss: 0.0496, D_B_loss: 0.0434, G_A_loss: 0.8143, G_B_loss: 0.5603\n",
      "Epoch [176/200], Step [211/1067], D_A_loss: 0.0588, D_B_loss: 0.0183, G_A_loss: 1.0033, G_B_loss: 0.6030\n",
      "Epoch [176/200], Step [221/1067], D_A_loss: 0.0369, D_B_loss: 0.0218, G_A_loss: 1.1044, G_B_loss: 0.8681\n",
      "Epoch [176/200], Step [231/1067], D_A_loss: 0.0478, D_B_loss: 0.0453, G_A_loss: 0.7646, G_B_loss: 0.7006\n",
      "Epoch [176/200], Step [241/1067], D_A_loss: 0.0876, D_B_loss: 0.0566, G_A_loss: 0.5649, G_B_loss: 0.7727\n",
      "Epoch [176/200], Step [251/1067], D_A_loss: 0.0441, D_B_loss: 0.0125, G_A_loss: 0.6787, G_B_loss: 0.6354\n",
      "Epoch [176/200], Step [261/1067], D_A_loss: 0.0278, D_B_loss: 0.1005, G_A_loss: 0.3642, G_B_loss: 0.5528\n",
      "Epoch [176/200], Step [271/1067], D_A_loss: 0.1039, D_B_loss: 0.0130, G_A_loss: 0.8070, G_B_loss: 0.6904\n",
      "Epoch [176/200], Step [281/1067], D_A_loss: 0.1165, D_B_loss: 0.0133, G_A_loss: 1.0480, G_B_loss: 0.5454\n",
      "Epoch [176/200], Step [291/1067], D_A_loss: 0.0257, D_B_loss: 0.0131, G_A_loss: 0.9326, G_B_loss: 0.4649\n",
      "Epoch [176/200], Step [301/1067], D_A_loss: 0.0933, D_B_loss: 0.0169, G_A_loss: 0.8406, G_B_loss: 0.6503\n",
      "Epoch [176/200], Step [311/1067], D_A_loss: 0.2002, D_B_loss: 0.0132, G_A_loss: 0.6625, G_B_loss: 0.8120\n",
      "Epoch [176/200], Step [321/1067], D_A_loss: 0.0596, D_B_loss: 0.0124, G_A_loss: 0.6165, G_B_loss: 0.5422\n",
      "Epoch [176/200], Step [331/1067], D_A_loss: 0.0913, D_B_loss: 0.0276, G_A_loss: 1.0743, G_B_loss: 0.5218\n",
      "Epoch [176/200], Step [341/1067], D_A_loss: 0.0177, D_B_loss: 0.0111, G_A_loss: 0.9348, G_B_loss: 0.4859\n",
      "Epoch [176/200], Step [351/1067], D_A_loss: 0.0953, D_B_loss: 0.0631, G_A_loss: 0.7501, G_B_loss: 0.4780\n",
      "Epoch [176/200], Step [361/1067], D_A_loss: 0.0454, D_B_loss: 0.0085, G_A_loss: 0.9711, G_B_loss: 0.6408\n",
      "Epoch [176/200], Step [371/1067], D_A_loss: 0.0650, D_B_loss: 0.0301, G_A_loss: 0.8036, G_B_loss: 0.5675\n",
      "Epoch [176/200], Step [381/1067], D_A_loss: 0.0220, D_B_loss: 0.0201, G_A_loss: 1.0498, G_B_loss: 1.0664\n",
      "Epoch [176/200], Step [391/1067], D_A_loss: 0.0507, D_B_loss: 0.0168, G_A_loss: 1.1668, G_B_loss: 0.8339\n",
      "Epoch [176/200], Step [401/1067], D_A_loss: 0.1920, D_B_loss: 0.0116, G_A_loss: 1.0193, G_B_loss: 0.7082\n",
      "Epoch [176/200], Step [411/1067], D_A_loss: 0.0570, D_B_loss: 0.0086, G_A_loss: 1.1547, G_B_loss: 0.6330\n",
      "Epoch [176/200], Step [421/1067], D_A_loss: 0.0289, D_B_loss: 0.0136, G_A_loss: 0.8879, G_B_loss: 0.7471\n",
      "Epoch [176/200], Step [431/1067], D_A_loss: 0.0376, D_B_loss: 0.0243, G_A_loss: 1.3159, G_B_loss: 0.6592\n",
      "Epoch [176/200], Step [441/1067], D_A_loss: 0.0175, D_B_loss: 0.0210, G_A_loss: 1.3115, G_B_loss: 0.4030\n",
      "Epoch [176/200], Step [451/1067], D_A_loss: 0.1324, D_B_loss: 0.0421, G_A_loss: 0.8993, G_B_loss: 0.6691\n",
      "Epoch [176/200], Step [461/1067], D_A_loss: 0.0787, D_B_loss: 0.0801, G_A_loss: 0.7651, G_B_loss: 0.7872\n",
      "Epoch [176/200], Step [471/1067], D_A_loss: 0.0479, D_B_loss: 0.0258, G_A_loss: 0.8484, G_B_loss: 0.6428\n",
      "Epoch [176/200], Step [481/1067], D_A_loss: 0.2181, D_B_loss: 0.0205, G_A_loss: 0.8293, G_B_loss: 0.8186\n",
      "Epoch [176/200], Step [491/1067], D_A_loss: 0.0384, D_B_loss: 0.0158, G_A_loss: 1.0690, G_B_loss: 0.7653\n",
      "Epoch [176/200], Step [501/1067], D_A_loss: 0.0453, D_B_loss: 0.0083, G_A_loss: 0.9846, G_B_loss: 0.5681\n",
      "Epoch [176/200], Step [511/1067], D_A_loss: 0.0457, D_B_loss: 0.0271, G_A_loss: 1.2672, G_B_loss: 0.6222\n",
      "Epoch [176/200], Step [521/1067], D_A_loss: 0.0400, D_B_loss: 0.0153, G_A_loss: 1.1508, G_B_loss: 0.3014\n",
      "Epoch [176/200], Step [531/1067], D_A_loss: 0.0551, D_B_loss: 0.0108, G_A_loss: 0.9619, G_B_loss: 0.7298\n",
      "Epoch [176/200], Step [541/1067], D_A_loss: 0.0791, D_B_loss: 0.0161, G_A_loss: 1.0736, G_B_loss: 0.8719\n",
      "Epoch [176/200], Step [551/1067], D_A_loss: 0.0586, D_B_loss: 0.0288, G_A_loss: 0.6893, G_B_loss: 0.8546\n",
      "Epoch [176/200], Step [561/1067], D_A_loss: 0.0251, D_B_loss: 0.0099, G_A_loss: 0.8735, G_B_loss: 0.9280\n",
      "Epoch [176/200], Step [571/1067], D_A_loss: 0.0665, D_B_loss: 0.0192, G_A_loss: 0.7768, G_B_loss: 0.5213\n",
      "Epoch [176/200], Step [581/1067], D_A_loss: 0.0371, D_B_loss: 0.0123, G_A_loss: 0.8821, G_B_loss: 0.5077\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [176/200], Step [591/1067], D_A_loss: 0.1319, D_B_loss: 0.0246, G_A_loss: 0.7302, G_B_loss: 0.4137\n",
      "Epoch [176/200], Step [601/1067], D_A_loss: 0.0226, D_B_loss: 0.0185, G_A_loss: 0.7473, G_B_loss: 0.7420\n",
      "Epoch [176/200], Step [611/1067], D_A_loss: 0.0555, D_B_loss: 0.0099, G_A_loss: 0.7230, G_B_loss: 0.7181\n",
      "Epoch [176/200], Step [621/1067], D_A_loss: 0.0908, D_B_loss: 0.0259, G_A_loss: 0.9268, G_B_loss: 0.5216\n",
      "Epoch [176/200], Step [631/1067], D_A_loss: 0.0685, D_B_loss: 0.0305, G_A_loss: 0.6453, G_B_loss: 0.8997\n",
      "Epoch [176/200], Step [641/1067], D_A_loss: 0.0652, D_B_loss: 0.0434, G_A_loss: 0.5676, G_B_loss: 0.6451\n",
      "Epoch [176/200], Step [651/1067], D_A_loss: 0.0226, D_B_loss: 0.0100, G_A_loss: 0.9834, G_B_loss: 0.9694\n",
      "Epoch [176/200], Step [661/1067], D_A_loss: 0.1335, D_B_loss: 0.0666, G_A_loss: 0.5659, G_B_loss: 0.3204\n",
      "Epoch [176/200], Step [671/1067], D_A_loss: 0.0632, D_B_loss: 0.0464, G_A_loss: 0.5618, G_B_loss: 0.6933\n",
      "Epoch [176/200], Step [681/1067], D_A_loss: 0.0717, D_B_loss: 0.0065, G_A_loss: 1.0309, G_B_loss: 0.4562\n",
      "Epoch [176/200], Step [691/1067], D_A_loss: 0.1259, D_B_loss: 0.0312, G_A_loss: 0.6362, G_B_loss: 0.4981\n",
      "Epoch [176/200], Step [701/1067], D_A_loss: 0.0604, D_B_loss: 0.0478, G_A_loss: 0.7856, G_B_loss: 0.7162\n",
      "Epoch [176/200], Step [711/1067], D_A_loss: 0.0611, D_B_loss: 0.0254, G_A_loss: 0.8882, G_B_loss: 0.8090\n",
      "Epoch [176/200], Step [721/1067], D_A_loss: 0.1602, D_B_loss: 0.0158, G_A_loss: 0.7469, G_B_loss: 0.9694\n",
      "Epoch [176/200], Step [731/1067], D_A_loss: 0.0610, D_B_loss: 0.0457, G_A_loss: 0.7678, G_B_loss: 0.4495\n",
      "Epoch [176/200], Step [741/1067], D_A_loss: 0.0351, D_B_loss: 0.0196, G_A_loss: 0.7817, G_B_loss: 0.7387\n",
      "Epoch [176/200], Step [751/1067], D_A_loss: 0.1686, D_B_loss: 0.0250, G_A_loss: 1.3999, G_B_loss: 0.8582\n",
      "Epoch [176/200], Step [761/1067], D_A_loss: 0.0547, D_B_loss: 0.0229, G_A_loss: 1.0824, G_B_loss: 0.8303\n",
      "Epoch [176/200], Step [771/1067], D_A_loss: 0.0294, D_B_loss: 0.0115, G_A_loss: 1.3136, G_B_loss: 0.8737\n",
      "Epoch [176/200], Step [781/1067], D_A_loss: 0.0384, D_B_loss: 0.0132, G_A_loss: 0.9879, G_B_loss: 0.7372\n",
      "Epoch [176/200], Step [791/1067], D_A_loss: 0.1054, D_B_loss: 0.0109, G_A_loss: 0.9087, G_B_loss: 0.4065\n",
      "Epoch [176/200], Step [801/1067], D_A_loss: 0.0365, D_B_loss: 0.0129, G_A_loss: 1.0630, G_B_loss: 0.9188\n",
      "Epoch [176/200], Step [811/1067], D_A_loss: 0.1104, D_B_loss: 0.0440, G_A_loss: 0.7575, G_B_loss: 0.4308\n",
      "Epoch [176/200], Step [821/1067], D_A_loss: 0.0711, D_B_loss: 0.0125, G_A_loss: 0.9851, G_B_loss: 0.3790\n",
      "Epoch [176/200], Step [831/1067], D_A_loss: 0.0286, D_B_loss: 0.0130, G_A_loss: 0.9301, G_B_loss: 0.9734\n",
      "Epoch [176/200], Step [841/1067], D_A_loss: 0.0689, D_B_loss: 0.0168, G_A_loss: 0.7396, G_B_loss: 0.7442\n",
      "Epoch [176/200], Step [851/1067], D_A_loss: 0.0522, D_B_loss: 0.0220, G_A_loss: 1.2260, G_B_loss: 0.6399\n",
      "Epoch [176/200], Step [861/1067], D_A_loss: 0.0412, D_B_loss: 0.0161, G_A_loss: 0.6421, G_B_loss: 0.8211\n",
      "Epoch [176/200], Step [871/1067], D_A_loss: 0.0341, D_B_loss: 0.0218, G_A_loss: 0.9460, G_B_loss: 0.7466\n",
      "Epoch [176/200], Step [881/1067], D_A_loss: 0.0577, D_B_loss: 0.0105, G_A_loss: 0.7744, G_B_loss: 0.8633\n",
      "Epoch [176/200], Step [891/1067], D_A_loss: 0.0529, D_B_loss: 0.0143, G_A_loss: 1.2487, G_B_loss: 0.8239\n",
      "Epoch [176/200], Step [901/1067], D_A_loss: 0.0521, D_B_loss: 0.0479, G_A_loss: 0.6917, G_B_loss: 0.5563\n",
      "Epoch [176/200], Step [911/1067], D_A_loss: 0.1032, D_B_loss: 0.0104, G_A_loss: 0.8474, G_B_loss: 0.3418\n",
      "Epoch [176/200], Step [921/1067], D_A_loss: 0.0422, D_B_loss: 0.0303, G_A_loss: 0.9919, G_B_loss: 0.5285\n",
      "Epoch [176/200], Step [931/1067], D_A_loss: 0.1150, D_B_loss: 0.0146, G_A_loss: 0.8994, G_B_loss: 0.5165\n",
      "Epoch [176/200], Step [941/1067], D_A_loss: 0.0495, D_B_loss: 0.0285, G_A_loss: 1.1445, G_B_loss: 0.6532\n",
      "Epoch [176/200], Step [951/1067], D_A_loss: 0.0267, D_B_loss: 0.0111, G_A_loss: 0.8877, G_B_loss: 0.8170\n",
      "Epoch [176/200], Step [961/1067], D_A_loss: 0.0900, D_B_loss: 0.0627, G_A_loss: 0.4788, G_B_loss: 0.5152\n",
      "Epoch [176/200], Step [971/1067], D_A_loss: 0.0459, D_B_loss: 0.0134, G_A_loss: 0.9284, G_B_loss: 0.4575\n",
      "Epoch [176/200], Step [981/1067], D_A_loss: 0.0446, D_B_loss: 0.0145, G_A_loss: 1.2081, G_B_loss: 0.9937\n",
      "Epoch [176/200], Step [991/1067], D_A_loss: 0.0532, D_B_loss: 0.0289, G_A_loss: 1.1009, G_B_loss: 0.5849\n",
      "Epoch [176/200], Step [1001/1067], D_A_loss: 0.2283, D_B_loss: 0.0362, G_A_loss: 0.6053, G_B_loss: 0.6105\n",
      "Epoch [176/200], Step [1011/1067], D_A_loss: 0.2121, D_B_loss: 0.0267, G_A_loss: 1.0409, G_B_loss: 0.6445\n",
      "Epoch [176/200], Step [1021/1067], D_A_loss: 0.0409, D_B_loss: 0.0127, G_A_loss: 1.0186, G_B_loss: 0.6435\n",
      "Epoch [176/200], Step [1031/1067], D_A_loss: 0.0655, D_B_loss: 0.0122, G_A_loss: 0.9582, G_B_loss: 0.5636\n",
      "Epoch [176/200], Step [1041/1067], D_A_loss: 0.0473, D_B_loss: 0.0328, G_A_loss: 0.6649, G_B_loss: 1.0443\n",
      "Epoch [176/200], Step [1051/1067], D_A_loss: 0.0650, D_B_loss: 0.0579, G_A_loss: 0.5606, G_B_loss: 0.6624\n",
      "Epoch [176/200], Step [1061/1067], D_A_loss: 0.0333, D_B_loss: 0.0109, G_A_loss: 1.0971, G_B_loss: 0.6669\n",
      "Epoch [177/200], Step [1/1067], D_A_loss: 0.1572, D_B_loss: 0.0124, G_A_loss: 0.9345, G_B_loss: 0.9058\n",
      "Epoch [177/200], Step [11/1067], D_A_loss: 0.0620, D_B_loss: 0.0153, G_A_loss: 1.1503, G_B_loss: 0.2180\n",
      "Epoch [177/200], Step [21/1067], D_A_loss: 0.0308, D_B_loss: 0.0252, G_A_loss: 0.6835, G_B_loss: 0.5102\n",
      "Epoch [177/200], Step [31/1067], D_A_loss: 0.0934, D_B_loss: 0.0080, G_A_loss: 0.8080, G_B_loss: 0.9975\n",
      "Epoch [177/200], Step [41/1067], D_A_loss: 0.0781, D_B_loss: 0.0170, G_A_loss: 0.6971, G_B_loss: 0.4603\n",
      "Epoch [177/200], Step [51/1067], D_A_loss: 0.0370, D_B_loss: 0.0107, G_A_loss: 0.9002, G_B_loss: 0.4506\n",
      "Epoch [177/200], Step [61/1067], D_A_loss: 0.0884, D_B_loss: 0.0424, G_A_loss: 0.6254, G_B_loss: 0.8372\n",
      "Epoch [177/200], Step [71/1067], D_A_loss: 0.1721, D_B_loss: 0.0087, G_A_loss: 0.6327, G_B_loss: 0.6390\n",
      "Epoch [177/200], Step [81/1067], D_A_loss: 0.0414, D_B_loss: 0.0176, G_A_loss: 1.1848, G_B_loss: 0.7387\n",
      "Epoch [177/200], Step [91/1067], D_A_loss: 0.0978, D_B_loss: 0.0148, G_A_loss: 0.5915, G_B_loss: 0.8129\n",
      "Epoch [177/200], Step [101/1067], D_A_loss: 0.0338, D_B_loss: 0.0192, G_A_loss: 0.7574, G_B_loss: 0.8944\n",
      "Epoch [177/200], Step [111/1067], D_A_loss: 0.0230, D_B_loss: 0.0334, G_A_loss: 0.6302, G_B_loss: 0.8902\n",
      "Epoch [177/200], Step [121/1067], D_A_loss: 0.0423, D_B_loss: 0.0463, G_A_loss: 0.6252, G_B_loss: 1.1482\n",
      "Epoch [177/200], Step [131/1067], D_A_loss: 0.0472, D_B_loss: 0.0135, G_A_loss: 0.7378, G_B_loss: 0.6707\n",
      "Epoch [177/200], Step [141/1067], D_A_loss: 0.1504, D_B_loss: 0.0674, G_A_loss: 0.6300, G_B_loss: 0.3189\n",
      "Epoch [177/200], Step [151/1067], D_A_loss: 0.1743, D_B_loss: 0.0338, G_A_loss: 0.9126, G_B_loss: 0.6079\n",
      "Epoch [177/200], Step [161/1067], D_A_loss: 0.0316, D_B_loss: 0.0081, G_A_loss: 0.9222, G_B_loss: 0.8278\n",
      "Epoch [177/200], Step [171/1067], D_A_loss: 0.0380, D_B_loss: 0.0124, G_A_loss: 0.9083, G_B_loss: 1.2446\n",
      "Epoch [177/200], Step [181/1067], D_A_loss: 0.0288, D_B_loss: 0.0217, G_A_loss: 0.8840, G_B_loss: 0.6276\n",
      "Epoch [177/200], Step [191/1067], D_A_loss: 0.0548, D_B_loss: 0.0433, G_A_loss: 0.5503, G_B_loss: 0.8120\n",
      "Epoch [177/200], Step [201/1067], D_A_loss: 0.0352, D_B_loss: 0.0115, G_A_loss: 1.1030, G_B_loss: 0.9028\n",
      "Epoch [177/200], Step [211/1067], D_A_loss: 0.0235, D_B_loss: 0.0142, G_A_loss: 1.0652, G_B_loss: 1.0285\n",
      "Epoch [177/200], Step [221/1067], D_A_loss: 0.0237, D_B_loss: 0.0142, G_A_loss: 0.8196, G_B_loss: 0.6920\n",
      "Epoch [177/200], Step [231/1067], D_A_loss: 0.0847, D_B_loss: 0.0481, G_A_loss: 1.2161, G_B_loss: 0.4396\n",
      "Epoch [177/200], Step [241/1067], D_A_loss: 0.1069, D_B_loss: 0.0649, G_A_loss: 0.8788, G_B_loss: 1.0832\n",
      "Epoch [177/200], Step [251/1067], D_A_loss: 0.0549, D_B_loss: 0.0122, G_A_loss: 1.0786, G_B_loss: 0.5942\n",
      "Epoch [177/200], Step [261/1067], D_A_loss: 0.0260, D_B_loss: 0.0104, G_A_loss: 1.0332, G_B_loss: 0.8761\n",
      "Epoch [177/200], Step [271/1067], D_A_loss: 0.0439, D_B_loss: 0.0141, G_A_loss: 0.8792, G_B_loss: 0.4384\n",
      "Epoch [177/200], Step [281/1067], D_A_loss: 0.0848, D_B_loss: 0.0267, G_A_loss: 1.0590, G_B_loss: 0.6676\n",
      "Epoch [177/200], Step [291/1067], D_A_loss: 0.0926, D_B_loss: 0.0300, G_A_loss: 0.7494, G_B_loss: 0.5966\n",
      "Epoch [177/200], Step [301/1067], D_A_loss: 0.0312, D_B_loss: 0.0434, G_A_loss: 1.0858, G_B_loss: 0.5703\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [177/200], Step [311/1067], D_A_loss: 0.0521, D_B_loss: 0.0242, G_A_loss: 0.7540, G_B_loss: 0.6536\n",
      "Epoch [177/200], Step [321/1067], D_A_loss: 0.0965, D_B_loss: 0.1307, G_A_loss: 1.1860, G_B_loss: 0.3027\n",
      "Epoch [177/200], Step [331/1067], D_A_loss: 0.0774, D_B_loss: 0.0115, G_A_loss: 1.1594, G_B_loss: 0.4655\n",
      "Epoch [177/200], Step [341/1067], D_A_loss: 0.0422, D_B_loss: 0.0287, G_A_loss: 0.7434, G_B_loss: 0.6256\n",
      "Epoch [177/200], Step [351/1067], D_A_loss: 0.0445, D_B_loss: 0.0620, G_A_loss: 0.4972, G_B_loss: 0.7404\n",
      "Epoch [177/200], Step [361/1067], D_A_loss: 0.0548, D_B_loss: 0.0080, G_A_loss: 0.8522, G_B_loss: 0.5906\n",
      "Epoch [177/200], Step [371/1067], D_A_loss: 0.0530, D_B_loss: 0.0123, G_A_loss: 0.6305, G_B_loss: 0.7384\n",
      "Epoch [177/200], Step [381/1067], D_A_loss: 0.0725, D_B_loss: 0.0113, G_A_loss: 0.9081, G_B_loss: 0.6640\n",
      "Epoch [177/200], Step [391/1067], D_A_loss: 0.0389, D_B_loss: 0.0138, G_A_loss: 1.3386, G_B_loss: 0.6653\n",
      "Epoch [177/200], Step [401/1067], D_A_loss: 0.0284, D_B_loss: 0.0555, G_A_loss: 0.4867, G_B_loss: 0.5530\n",
      "Epoch [177/200], Step [411/1067], D_A_loss: 0.0806, D_B_loss: 0.0146, G_A_loss: 0.6347, G_B_loss: 0.4750\n",
      "Epoch [177/200], Step [421/1067], D_A_loss: 0.1336, D_B_loss: 0.0257, G_A_loss: 0.6462, G_B_loss: 0.3665\n",
      "Epoch [177/200], Step [431/1067], D_A_loss: 0.0661, D_B_loss: 0.0233, G_A_loss: 0.7412, G_B_loss: 0.7887\n",
      "Epoch [177/200], Step [441/1067], D_A_loss: 0.0747, D_B_loss: 0.0301, G_A_loss: 0.7427, G_B_loss: 0.8216\n",
      "Epoch [177/200], Step [451/1067], D_A_loss: 0.0871, D_B_loss: 0.0338, G_A_loss: 0.5988, G_B_loss: 0.6815\n",
      "Epoch [177/200], Step [461/1067], D_A_loss: 0.0412, D_B_loss: 0.0258, G_A_loss: 1.2269, G_B_loss: 0.6621\n",
      "Epoch [177/200], Step [471/1067], D_A_loss: 0.0772, D_B_loss: 0.0095, G_A_loss: 1.1527, G_B_loss: 0.4741\n",
      "Epoch [177/200], Step [481/1067], D_A_loss: 0.0684, D_B_loss: 0.0114, G_A_loss: 0.7223, G_B_loss: 0.6962\n",
      "Epoch [177/200], Step [491/1067], D_A_loss: 0.1020, D_B_loss: 0.0219, G_A_loss: 0.7897, G_B_loss: 0.6090\n",
      "Epoch [177/200], Step [501/1067], D_A_loss: 0.0499, D_B_loss: 0.0078, G_A_loss: 0.8595, G_B_loss: 0.6380\n",
      "Epoch [177/200], Step [511/1067], D_A_loss: 0.1097, D_B_loss: 0.0841, G_A_loss: 0.8688, G_B_loss: 0.5611\n",
      "Epoch [177/200], Step [521/1067], D_A_loss: 0.0325, D_B_loss: 0.0238, G_A_loss: 0.8725, G_B_loss: 0.7384\n",
      "Epoch [177/200], Step [531/1067], D_A_loss: 0.0640, D_B_loss: 0.0314, G_A_loss: 0.6693, G_B_loss: 1.0131\n",
      "Epoch [177/200], Step [541/1067], D_A_loss: 0.1044, D_B_loss: 0.0473, G_A_loss: 0.8646, G_B_loss: 0.8043\n",
      "Epoch [177/200], Step [551/1067], D_A_loss: 0.1965, D_B_loss: 0.0173, G_A_loss: 0.8274, G_B_loss: 0.6588\n",
      "Epoch [177/200], Step [561/1067], D_A_loss: 0.0690, D_B_loss: 0.0253, G_A_loss: 0.6931, G_B_loss: 0.5166\n",
      "Epoch [177/200], Step [571/1067], D_A_loss: 0.1080, D_B_loss: 0.0138, G_A_loss: 1.2439, G_B_loss: 0.8151\n",
      "Epoch [177/200], Step [581/1067], D_A_loss: 0.0461, D_B_loss: 0.0133, G_A_loss: 0.5881, G_B_loss: 1.1196\n",
      "Epoch [177/200], Step [591/1067], D_A_loss: 0.0792, D_B_loss: 0.0434, G_A_loss: 0.6281, G_B_loss: 0.6988\n",
      "Epoch [177/200], Step [601/1067], D_A_loss: 0.0383, D_B_loss: 0.0169, G_A_loss: 0.7760, G_B_loss: 0.7010\n",
      "Epoch [177/200], Step [611/1067], D_A_loss: 0.0267, D_B_loss: 0.0415, G_A_loss: 0.5619, G_B_loss: 0.5676\n",
      "Epoch [177/200], Step [621/1067], D_A_loss: 0.0708, D_B_loss: 0.0210, G_A_loss: 0.8748, G_B_loss: 0.5170\n",
      "Epoch [177/200], Step [631/1067], D_A_loss: 0.1036, D_B_loss: 0.0194, G_A_loss: 0.9802, G_B_loss: 0.4221\n",
      "Epoch [177/200], Step [641/1067], D_A_loss: 0.0341, D_B_loss: 0.0110, G_A_loss: 0.9617, G_B_loss: 0.6465\n",
      "Epoch [177/200], Step [651/1067], D_A_loss: 0.0489, D_B_loss: 0.0106, G_A_loss: 0.7959, G_B_loss: 0.5605\n",
      "Epoch [177/200], Step [661/1067], D_A_loss: 0.1764, D_B_loss: 0.0271, G_A_loss: 0.6519, G_B_loss: 0.6382\n",
      "Epoch [177/200], Step [671/1067], D_A_loss: 0.0580, D_B_loss: 0.0309, G_A_loss: 0.7396, G_B_loss: 0.5719\n",
      "Epoch [177/200], Step [681/1067], D_A_loss: 0.0641, D_B_loss: 0.0264, G_A_loss: 0.6946, G_B_loss: 0.6761\n",
      "Epoch [177/200], Step [691/1067], D_A_loss: 0.0194, D_B_loss: 0.0191, G_A_loss: 0.7728, G_B_loss: 0.6563\n",
      "Epoch [177/200], Step [701/1067], D_A_loss: 0.1009, D_B_loss: 0.0856, G_A_loss: 0.9840, G_B_loss: 0.2458\n",
      "Epoch [177/200], Step [711/1067], D_A_loss: 0.0275, D_B_loss: 0.0120, G_A_loss: 1.0582, G_B_loss: 0.3524\n",
      "Epoch [177/200], Step [721/1067], D_A_loss: 0.0675, D_B_loss: 0.0512, G_A_loss: 0.8424, G_B_loss: 0.5521\n",
      "Epoch [177/200], Step [731/1067], D_A_loss: 0.1329, D_B_loss: 0.0149, G_A_loss: 0.9674, G_B_loss: 0.3032\n",
      "Epoch [177/200], Step [741/1067], D_A_loss: 0.0886, D_B_loss: 0.0113, G_A_loss: 1.0822, G_B_loss: 0.7700\n",
      "Epoch [177/200], Step [751/1067], D_A_loss: 0.0236, D_B_loss: 0.0278, G_A_loss: 0.9732, G_B_loss: 0.5891\n",
      "Epoch [177/200], Step [761/1067], D_A_loss: 0.0244, D_B_loss: 0.0684, G_A_loss: 1.2082, G_B_loss: 0.9818\n",
      "Epoch [177/200], Step [771/1067], D_A_loss: 0.0462, D_B_loss: 0.0110, G_A_loss: 0.9162, G_B_loss: 0.6703\n",
      "Epoch [177/200], Step [781/1067], D_A_loss: 0.0781, D_B_loss: 0.0226, G_A_loss: 0.7269, G_B_loss: 0.8264\n",
      "Epoch [177/200], Step [791/1067], D_A_loss: 0.1366, D_B_loss: 0.0522, G_A_loss: 0.5214, G_B_loss: 0.4046\n",
      "Epoch [177/200], Step [801/1067], D_A_loss: 0.1430, D_B_loss: 0.0332, G_A_loss: 0.7637, G_B_loss: 0.7874\n",
      "Epoch [177/200], Step [811/1067], D_A_loss: 0.0296, D_B_loss: 0.0705, G_A_loss: 0.5834, G_B_loss: 0.9201\n",
      "Epoch [177/200], Step [821/1067], D_A_loss: 0.0383, D_B_loss: 0.0107, G_A_loss: 0.8810, G_B_loss: 0.8288\n",
      "Epoch [177/200], Step [831/1067], D_A_loss: 0.0558, D_B_loss: 0.0073, G_A_loss: 1.0419, G_B_loss: 0.7443\n",
      "Epoch [177/200], Step [841/1067], D_A_loss: 0.0267, D_B_loss: 0.0107, G_A_loss: 1.2353, G_B_loss: 0.8434\n",
      "Epoch [177/200], Step [851/1067], D_A_loss: 0.0256, D_B_loss: 0.0100, G_A_loss: 0.5931, G_B_loss: 0.5736\n",
      "Epoch [177/200], Step [861/1067], D_A_loss: 0.0394, D_B_loss: 0.0426, G_A_loss: 0.6116, G_B_loss: 0.7040\n",
      "Epoch [177/200], Step [871/1067], D_A_loss: 0.0297, D_B_loss: 0.0092, G_A_loss: 0.8852, G_B_loss: 0.9093\n",
      "Epoch [177/200], Step [881/1067], D_A_loss: 0.0201, D_B_loss: 0.0089, G_A_loss: 1.0065, G_B_loss: 0.9274\n",
      "Epoch [177/200], Step [891/1067], D_A_loss: 0.0300, D_B_loss: 0.0255, G_A_loss: 0.9526, G_B_loss: 1.0030\n",
      "Epoch [177/200], Step [901/1067], D_A_loss: 0.0729, D_B_loss: 0.0158, G_A_loss: 0.7658, G_B_loss: 0.4905\n",
      "Epoch [177/200], Step [911/1067], D_A_loss: 0.0263, D_B_loss: 0.0235, G_A_loss: 0.6444, G_B_loss: 1.1013\n",
      "Epoch [177/200], Step [921/1067], D_A_loss: 0.0363, D_B_loss: 0.0074, G_A_loss: 1.0089, G_B_loss: 0.5626\n",
      "Epoch [177/200], Step [931/1067], D_A_loss: 0.0911, D_B_loss: 0.0673, G_A_loss: 0.6342, G_B_loss: 0.6845\n",
      "Epoch [177/200], Step [941/1067], D_A_loss: 0.1449, D_B_loss: 0.0081, G_A_loss: 0.8653, G_B_loss: 0.5383\n",
      "Epoch [177/200], Step [951/1067], D_A_loss: 0.0284, D_B_loss: 0.0136, G_A_loss: 0.4019, G_B_loss: 0.8755\n",
      "Epoch [177/200], Step [961/1067], D_A_loss: 0.0755, D_B_loss: 0.0262, G_A_loss: 0.8347, G_B_loss: 0.5144\n",
      "Epoch [177/200], Step [971/1067], D_A_loss: 0.0330, D_B_loss: 0.0284, G_A_loss: 0.7086, G_B_loss: 1.0495\n",
      "Epoch [177/200], Step [981/1067], D_A_loss: 0.0462, D_B_loss: 0.0153, G_A_loss: 0.9306, G_B_loss: 0.5955\n",
      "Epoch [177/200], Step [991/1067], D_A_loss: 0.1548, D_B_loss: 0.0377, G_A_loss: 0.8812, G_B_loss: 0.5009\n",
      "Epoch [177/200], Step [1001/1067], D_A_loss: 0.0282, D_B_loss: 0.0385, G_A_loss: 0.8816, G_B_loss: 0.8440\n",
      "Epoch [177/200], Step [1011/1067], D_A_loss: 0.0830, D_B_loss: 0.0104, G_A_loss: 0.9978, G_B_loss: 1.1302\n",
      "Epoch [177/200], Step [1021/1067], D_A_loss: 0.0948, D_B_loss: 0.0277, G_A_loss: 1.1783, G_B_loss: 0.5598\n",
      "Epoch [177/200], Step [1031/1067], D_A_loss: 0.0573, D_B_loss: 0.0496, G_A_loss: 0.9380, G_B_loss: 0.8413\n",
      "Epoch [177/200], Step [1041/1067], D_A_loss: 0.0184, D_B_loss: 0.0111, G_A_loss: 0.8550, G_B_loss: 0.5070\n",
      "Epoch [177/200], Step [1051/1067], D_A_loss: 0.1623, D_B_loss: 0.0213, G_A_loss: 0.7645, G_B_loss: 0.2907\n",
      "Epoch [177/200], Step [1061/1067], D_A_loss: 0.0296, D_B_loss: 0.0169, G_A_loss: 0.8582, G_B_loss: 0.8525\n",
      "Epoch [178/200], Step [1/1067], D_A_loss: 0.0552, D_B_loss: 0.0246, G_A_loss: 0.8148, G_B_loss: 0.3706\n",
      "Epoch [178/200], Step [11/1067], D_A_loss: 0.0314, D_B_loss: 0.0162, G_A_loss: 0.8557, G_B_loss: 0.6566\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [178/200], Step [21/1067], D_A_loss: 0.1413, D_B_loss: 0.0067, G_A_loss: 0.6647, G_B_loss: 0.5626\n",
      "Epoch [178/200], Step [31/1067], D_A_loss: 0.0596, D_B_loss: 0.0160, G_A_loss: 0.7635, G_B_loss: 0.6150\n",
      "Epoch [178/200], Step [41/1067], D_A_loss: 0.0198, D_B_loss: 0.0113, G_A_loss: 0.8681, G_B_loss: 1.0274\n",
      "Epoch [178/200], Step [51/1067], D_A_loss: 0.0506, D_B_loss: 0.0135, G_A_loss: 1.0803, G_B_loss: 0.8776\n",
      "Epoch [178/200], Step [61/1067], D_A_loss: 0.0555, D_B_loss: 0.0314, G_A_loss: 0.6372, G_B_loss: 0.6837\n",
      "Epoch [178/200], Step [71/1067], D_A_loss: 0.0367, D_B_loss: 0.1205, G_A_loss: 0.5292, G_B_loss: 0.4467\n",
      "Epoch [178/200], Step [81/1067], D_A_loss: 0.0476, D_B_loss: 0.0255, G_A_loss: 0.9051, G_B_loss: 1.0843\n",
      "Epoch [178/200], Step [91/1067], D_A_loss: 0.0463, D_B_loss: 0.0245, G_A_loss: 0.8410, G_B_loss: 0.6141\n",
      "Epoch [178/200], Step [101/1067], D_A_loss: 0.0806, D_B_loss: 0.0094, G_A_loss: 0.9670, G_B_loss: 0.6183\n",
      "Epoch [178/200], Step [111/1067], D_A_loss: 0.0554, D_B_loss: 0.0620, G_A_loss: 0.8653, G_B_loss: 0.7309\n",
      "Epoch [178/200], Step [121/1067], D_A_loss: 0.0287, D_B_loss: 0.0201, G_A_loss: 0.8199, G_B_loss: 0.4634\n",
      "Epoch [178/200], Step [131/1067], D_A_loss: 0.2001, D_B_loss: 0.0154, G_A_loss: 0.6330, G_B_loss: 0.2045\n",
      "Epoch [178/200], Step [141/1067], D_A_loss: 0.0982, D_B_loss: 0.0219, G_A_loss: 0.8808, G_B_loss: 0.5810\n",
      "Epoch [178/200], Step [151/1067], D_A_loss: 0.0891, D_B_loss: 0.0355, G_A_loss: 0.7882, G_B_loss: 0.5286\n",
      "Epoch [178/200], Step [161/1067], D_A_loss: 0.0748, D_B_loss: 0.0946, G_A_loss: 0.6713, G_B_loss: 0.6207\n",
      "Epoch [178/200], Step [171/1067], D_A_loss: 0.0484, D_B_loss: 0.0317, G_A_loss: 1.2487, G_B_loss: 0.8532\n",
      "Epoch [178/200], Step [181/1067], D_A_loss: 0.1026, D_B_loss: 0.0116, G_A_loss: 0.8638, G_B_loss: 0.9546\n",
      "Epoch [178/200], Step [191/1067], D_A_loss: 0.0644, D_B_loss: 0.0137, G_A_loss: 0.7896, G_B_loss: 0.6317\n",
      "Epoch [178/200], Step [201/1067], D_A_loss: 0.0712, D_B_loss: 0.0117, G_A_loss: 0.9636, G_B_loss: 0.5141\n",
      "Epoch [178/200], Step [211/1067], D_A_loss: 0.0285, D_B_loss: 0.0881, G_A_loss: 1.1013, G_B_loss: 0.9977\n",
      "Epoch [178/200], Step [221/1067], D_A_loss: 0.0488, D_B_loss: 0.0157, G_A_loss: 0.8621, G_B_loss: 0.4993\n",
      "Epoch [178/200], Step [231/1067], D_A_loss: 0.1169, D_B_loss: 0.0288, G_A_loss: 0.9639, G_B_loss: 0.5581\n",
      "Epoch [178/200], Step [241/1067], D_A_loss: 0.0784, D_B_loss: 0.0378, G_A_loss: 0.8309, G_B_loss: 0.5618\n",
      "Epoch [178/200], Step [251/1067], D_A_loss: 0.0991, D_B_loss: 0.0184, G_A_loss: 0.7558, G_B_loss: 0.7123\n",
      "Epoch [178/200], Step [261/1067], D_A_loss: 0.0457, D_B_loss: 0.0147, G_A_loss: 0.9402, G_B_loss: 0.6357\n",
      "Epoch [178/200], Step [271/1067], D_A_loss: 0.0727, D_B_loss: 0.0729, G_A_loss: 0.8815, G_B_loss: 0.5321\n",
      "Epoch [178/200], Step [281/1067], D_A_loss: 0.0265, D_B_loss: 0.0279, G_A_loss: 1.1121, G_B_loss: 0.8318\n",
      "Epoch [178/200], Step [291/1067], D_A_loss: 0.0478, D_B_loss: 0.0216, G_A_loss: 0.6886, G_B_loss: 0.7476\n",
      "Epoch [178/200], Step [301/1067], D_A_loss: 0.0554, D_B_loss: 0.0356, G_A_loss: 0.6596, G_B_loss: 0.5617\n",
      "Epoch [178/200], Step [311/1067], D_A_loss: 0.0558, D_B_loss: 0.0169, G_A_loss: 0.7704, G_B_loss: 0.1749\n",
      "Epoch [178/200], Step [321/1067], D_A_loss: 0.0577, D_B_loss: 0.0303, G_A_loss: 1.4095, G_B_loss: 0.5734\n",
      "Epoch [178/200], Step [331/1067], D_A_loss: 0.0495, D_B_loss: 0.0192, G_A_loss: 0.7707, G_B_loss: 0.5325\n",
      "Epoch [178/200], Step [341/1067], D_A_loss: 0.0651, D_B_loss: 0.0115, G_A_loss: 0.7306, G_B_loss: 0.5387\n",
      "Epoch [178/200], Step [351/1067], D_A_loss: 0.0830, D_B_loss: 0.0123, G_A_loss: 0.7361, G_B_loss: 0.1956\n",
      "Epoch [178/200], Step [361/1067], D_A_loss: 0.0554, D_B_loss: 0.0533, G_A_loss: 0.5414, G_B_loss: 0.6746\n",
      "Epoch [178/200], Step [371/1067], D_A_loss: 0.0680, D_B_loss: 0.0132, G_A_loss: 0.8856, G_B_loss: 0.5167\n",
      "Epoch [178/200], Step [381/1067], D_A_loss: 0.0240, D_B_loss: 0.0172, G_A_loss: 0.7598, G_B_loss: 1.1244\n",
      "Epoch [178/200], Step [391/1067], D_A_loss: 0.0813, D_B_loss: 0.0175, G_A_loss: 1.4563, G_B_loss: 0.4441\n",
      "Epoch [178/200], Step [401/1067], D_A_loss: 0.0294, D_B_loss: 0.0123, G_A_loss: 0.8084, G_B_loss: 0.7554\n",
      "Epoch [178/200], Step [411/1067], D_A_loss: 0.0757, D_B_loss: 0.0252, G_A_loss: 0.7270, G_B_loss: 0.9405\n",
      "Epoch [178/200], Step [421/1067], D_A_loss: 0.0413, D_B_loss: 0.0208, G_A_loss: 0.7731, G_B_loss: 0.7180\n",
      "Epoch [178/200], Step [431/1067], D_A_loss: 0.0483, D_B_loss: 0.0217, G_A_loss: 0.9815, G_B_loss: 0.4528\n",
      "Epoch [178/200], Step [441/1067], D_A_loss: 0.1078, D_B_loss: 0.0142, G_A_loss: 0.7143, G_B_loss: 0.6866\n",
      "Epoch [178/200], Step [451/1067], D_A_loss: 0.0250, D_B_loss: 0.0089, G_A_loss: 0.6166, G_B_loss: 0.8308\n",
      "Epoch [178/200], Step [461/1067], D_A_loss: 0.0498, D_B_loss: 0.0170, G_A_loss: 0.8444, G_B_loss: 0.9728\n",
      "Epoch [178/200], Step [471/1067], D_A_loss: 0.0920, D_B_loss: 0.0170, G_A_loss: 0.9922, G_B_loss: 0.8514\n",
      "Epoch [178/200], Step [481/1067], D_A_loss: 0.0437, D_B_loss: 0.0096, G_A_loss: 0.9994, G_B_loss: 0.6661\n",
      "Epoch [178/200], Step [491/1067], D_A_loss: 0.1109, D_B_loss: 0.0108, G_A_loss: 0.8778, G_B_loss: 1.2321\n",
      "Epoch [178/200], Step [501/1067], D_A_loss: 0.0486, D_B_loss: 0.0730, G_A_loss: 0.8695, G_B_loss: 0.5531\n",
      "Epoch [178/200], Step [511/1067], D_A_loss: 0.0422, D_B_loss: 0.0341, G_A_loss: 0.6439, G_B_loss: 0.9075\n",
      "Epoch [178/200], Step [521/1067], D_A_loss: 0.0248, D_B_loss: 0.0175, G_A_loss: 1.1097, G_B_loss: 0.8372\n",
      "Epoch [178/200], Step [531/1067], D_A_loss: 0.0450, D_B_loss: 0.0247, G_A_loss: 0.7027, G_B_loss: 0.7378\n",
      "Epoch [178/200], Step [541/1067], D_A_loss: 0.0988, D_B_loss: 0.0271, G_A_loss: 1.2701, G_B_loss: 0.4774\n",
      "Epoch [178/200], Step [551/1067], D_A_loss: 0.0547, D_B_loss: 0.0654, G_A_loss: 0.9199, G_B_loss: 0.6344\n",
      "Epoch [178/200], Step [561/1067], D_A_loss: 0.0248, D_B_loss: 0.0089, G_A_loss: 0.5948, G_B_loss: 0.8713\n",
      "Epoch [178/200], Step [571/1067], D_A_loss: 0.1508, D_B_loss: 0.0314, G_A_loss: 0.6514, G_B_loss: 0.9219\n",
      "Epoch [178/200], Step [581/1067], D_A_loss: 0.0442, D_B_loss: 0.0974, G_A_loss: 0.8066, G_B_loss: 0.3735\n",
      "Epoch [178/200], Step [591/1067], D_A_loss: 0.0669, D_B_loss: 0.0217, G_A_loss: 0.7269, G_B_loss: 0.4448\n",
      "Epoch [178/200], Step [601/1067], D_A_loss: 0.0884, D_B_loss: 0.0143, G_A_loss: 0.8356, G_B_loss: 0.4602\n",
      "Epoch [178/200], Step [611/1067], D_A_loss: 0.0777, D_B_loss: 0.0346, G_A_loss: 0.6023, G_B_loss: 0.4977\n",
      "Epoch [178/200], Step [621/1067], D_A_loss: 0.2122, D_B_loss: 0.0518, G_A_loss: 0.7398, G_B_loss: 0.8611\n",
      "Epoch [178/200], Step [631/1067], D_A_loss: 0.1745, D_B_loss: 0.0128, G_A_loss: 1.0317, G_B_loss: 0.7137\n",
      "Epoch [178/200], Step [641/1067], D_A_loss: 0.0255, D_B_loss: 0.0147, G_A_loss: 0.9024, G_B_loss: 0.6512\n",
      "Epoch [178/200], Step [651/1067], D_A_loss: 0.0774, D_B_loss: 0.0450, G_A_loss: 0.7501, G_B_loss: 0.7605\n",
      "Epoch [178/200], Step [661/1067], D_A_loss: 0.0160, D_B_loss: 0.0632, G_A_loss: 0.8819, G_B_loss: 0.9409\n",
      "Epoch [178/200], Step [671/1067], D_A_loss: 0.0238, D_B_loss: 0.0103, G_A_loss: 0.9766, G_B_loss: 0.9113\n",
      "Epoch [178/200], Step [681/1067], D_A_loss: 0.0496, D_B_loss: 0.0403, G_A_loss: 1.0985, G_B_loss: 0.7136\n",
      "Epoch [178/200], Step [691/1067], D_A_loss: 0.0544, D_B_loss: 0.0152, G_A_loss: 0.8677, G_B_loss: 0.3381\n",
      "Epoch [178/200], Step [701/1067], D_A_loss: 0.0291, D_B_loss: 0.0402, G_A_loss: 1.4165, G_B_loss: 0.9099\n",
      "Epoch [178/200], Step [711/1067], D_A_loss: 0.0315, D_B_loss: 0.0275, G_A_loss: 0.3598, G_B_loss: 1.0897\n",
      "Epoch [178/200], Step [721/1067], D_A_loss: 0.0228, D_B_loss: 0.0352, G_A_loss: 0.8797, G_B_loss: 0.9007\n",
      "Epoch [178/200], Step [731/1067], D_A_loss: 0.0951, D_B_loss: 0.0169, G_A_loss: 0.9488, G_B_loss: 0.4683\n",
      "Epoch [178/200], Step [741/1067], D_A_loss: 0.1894, D_B_loss: 0.0639, G_A_loss: 0.8064, G_B_loss: 0.7756\n",
      "Epoch [178/200], Step [751/1067], D_A_loss: 0.1057, D_B_loss: 0.0224, G_A_loss: 0.9651, G_B_loss: 0.5302\n",
      "Epoch [178/200], Step [761/1067], D_A_loss: 0.1008, D_B_loss: 0.0388, G_A_loss: 0.6919, G_B_loss: 0.9412\n",
      "Epoch [178/200], Step [771/1067], D_A_loss: 0.1103, D_B_loss: 0.0227, G_A_loss: 0.6923, G_B_loss: 0.4438\n",
      "Epoch [178/200], Step [781/1067], D_A_loss: 0.0882, D_B_loss: 0.0256, G_A_loss: 0.7302, G_B_loss: 0.8747\n",
      "Epoch [178/200], Step [791/1067], D_A_loss: 0.1028, D_B_loss: 0.0446, G_A_loss: 0.7291, G_B_loss: 0.4867\n",
      "Epoch [178/200], Step [801/1067], D_A_loss: 0.0494, D_B_loss: 0.0378, G_A_loss: 0.8033, G_B_loss: 0.7507\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [178/200], Step [811/1067], D_A_loss: 0.0235, D_B_loss: 0.0167, G_A_loss: 1.1775, G_B_loss: 0.9170\n",
      "Epoch [178/200], Step [821/1067], D_A_loss: 0.0281, D_B_loss: 0.0551, G_A_loss: 0.8602, G_B_loss: 0.6723\n",
      "Epoch [178/200], Step [831/1067], D_A_loss: 0.0561, D_B_loss: 0.0189, G_A_loss: 0.8553, G_B_loss: 0.5842\n",
      "Epoch [178/200], Step [841/1067], D_A_loss: 0.0778, D_B_loss: 0.0451, G_A_loss: 0.7304, G_B_loss: 0.6963\n",
      "Epoch [178/200], Step [851/1067], D_A_loss: 0.0702, D_B_loss: 0.0327, G_A_loss: 0.7900, G_B_loss: 0.5557\n",
      "Epoch [178/200], Step [861/1067], D_A_loss: 0.0737, D_B_loss: 0.0879, G_A_loss: 0.9070, G_B_loss: 0.8474\n",
      "Epoch [178/200], Step [871/1067], D_A_loss: 0.0768, D_B_loss: 0.0191, G_A_loss: 0.8730, G_B_loss: 0.7368\n",
      "Epoch [178/200], Step [881/1067], D_A_loss: 0.0398, D_B_loss: 0.0207, G_A_loss: 1.0926, G_B_loss: 0.6585\n",
      "Epoch [178/200], Step [891/1067], D_A_loss: 0.1395, D_B_loss: 0.0288, G_A_loss: 0.9161, G_B_loss: 0.5476\n",
      "Epoch [178/200], Step [901/1067], D_A_loss: 0.0400, D_B_loss: 0.0201, G_A_loss: 1.0038, G_B_loss: 1.2581\n",
      "Epoch [178/200], Step [911/1067], D_A_loss: 0.0498, D_B_loss: 0.0185, G_A_loss: 1.0879, G_B_loss: 1.0553\n",
      "Epoch [178/200], Step [921/1067], D_A_loss: 0.0241, D_B_loss: 0.0162, G_A_loss: 0.8011, G_B_loss: 0.9027\n",
      "Epoch [178/200], Step [931/1067], D_A_loss: 0.0232, D_B_loss: 0.0170, G_A_loss: 0.8113, G_B_loss: 0.5845\n",
      "Epoch [178/200], Step [941/1067], D_A_loss: 0.1519, D_B_loss: 0.0589, G_A_loss: 0.7971, G_B_loss: 0.6204\n",
      "Epoch [178/200], Step [951/1067], D_A_loss: 0.0429, D_B_loss: 0.0251, G_A_loss: 0.9975, G_B_loss: 0.6148\n",
      "Epoch [178/200], Step [961/1067], D_A_loss: 0.0530, D_B_loss: 0.0272, G_A_loss: 0.8541, G_B_loss: 1.0256\n",
      "Epoch [178/200], Step [971/1067], D_A_loss: 0.0437, D_B_loss: 0.0227, G_A_loss: 0.6889, G_B_loss: 0.8136\n",
      "Epoch [178/200], Step [981/1067], D_A_loss: 0.0297, D_B_loss: 0.0232, G_A_loss: 0.8688, G_B_loss: 0.8718\n",
      "Epoch [178/200], Step [991/1067], D_A_loss: 0.0497, D_B_loss: 0.0312, G_A_loss: 1.1620, G_B_loss: 0.5804\n",
      "Epoch [178/200], Step [1001/1067], D_A_loss: 0.0599, D_B_loss: 0.1096, G_A_loss: 0.8910, G_B_loss: 0.6517\n",
      "Epoch [178/200], Step [1011/1067], D_A_loss: 0.0315, D_B_loss: 0.1151, G_A_loss: 0.8636, G_B_loss: 0.8107\n",
      "Epoch [178/200], Step [1021/1067], D_A_loss: 0.0410, D_B_loss: 0.0232, G_A_loss: 1.1135, G_B_loss: 1.0508\n",
      "Epoch [178/200], Step [1031/1067], D_A_loss: 0.1391, D_B_loss: 0.0233, G_A_loss: 1.3298, G_B_loss: 0.2807\n",
      "Epoch [178/200], Step [1041/1067], D_A_loss: 0.0376, D_B_loss: 0.0516, G_A_loss: 0.5675, G_B_loss: 0.5541\n",
      "Epoch [178/200], Step [1051/1067], D_A_loss: 0.1015, D_B_loss: 0.0149, G_A_loss: 0.7260, G_B_loss: 0.5645\n",
      "Epoch [178/200], Step [1061/1067], D_A_loss: 0.1589, D_B_loss: 0.0499, G_A_loss: 0.6259, G_B_loss: 0.2617\n",
      "Epoch [179/200], Step [1/1067], D_A_loss: 0.1979, D_B_loss: 0.0243, G_A_loss: 0.8699, G_B_loss: 0.2327\n",
      "Epoch [179/200], Step [11/1067], D_A_loss: 0.0462, D_B_loss: 0.0267, G_A_loss: 0.7629, G_B_loss: 0.9724\n",
      "Epoch [179/200], Step [21/1067], D_A_loss: 0.1816, D_B_loss: 0.0211, G_A_loss: 0.8473, G_B_loss: 0.6881\n",
      "Epoch [179/200], Step [31/1067], D_A_loss: 0.1585, D_B_loss: 0.0164, G_A_loss: 0.5644, G_B_loss: 0.6773\n",
      "Epoch [179/200], Step [41/1067], D_A_loss: 0.0220, D_B_loss: 0.0125, G_A_loss: 0.8670, G_B_loss: 0.4347\n",
      "Epoch [179/200], Step [51/1067], D_A_loss: 0.0309, D_B_loss: 0.0152, G_A_loss: 0.7893, G_B_loss: 0.6829\n",
      "Epoch [179/200], Step [61/1067], D_A_loss: 0.0734, D_B_loss: 0.0232, G_A_loss: 0.7557, G_B_loss: 0.5483\n",
      "Epoch [179/200], Step [71/1067], D_A_loss: 0.0426, D_B_loss: 0.0145, G_A_loss: 0.8020, G_B_loss: 0.5428\n",
      "Epoch [179/200], Step [81/1067], D_A_loss: 0.0677, D_B_loss: 0.0218, G_A_loss: 1.2786, G_B_loss: 0.6251\n",
      "Epoch [179/200], Step [91/1067], D_A_loss: 0.1859, D_B_loss: 0.0181, G_A_loss: 0.5163, G_B_loss: 0.6480\n",
      "Epoch [179/200], Step [101/1067], D_A_loss: 0.1350, D_B_loss: 0.0119, G_A_loss: 0.8703, G_B_loss: 0.6421\n",
      "Epoch [179/200], Step [111/1067], D_A_loss: 0.0544, D_B_loss: 0.0189, G_A_loss: 1.0194, G_B_loss: 0.7420\n",
      "Epoch [179/200], Step [121/1067], D_A_loss: 0.0993, D_B_loss: 0.0400, G_A_loss: 0.9376, G_B_loss: 0.3840\n",
      "Epoch [179/200], Step [131/1067], D_A_loss: 0.0341, D_B_loss: 0.0131, G_A_loss: 0.8641, G_B_loss: 0.7327\n",
      "Epoch [179/200], Step [141/1067], D_A_loss: 0.0317, D_B_loss: 0.0620, G_A_loss: 0.9660, G_B_loss: 0.7169\n",
      "Epoch [179/200], Step [151/1067], D_A_loss: 0.0559, D_B_loss: 0.0425, G_A_loss: 0.6020, G_B_loss: 0.7729\n",
      "Epoch [179/200], Step [161/1067], D_A_loss: 0.0459, D_B_loss: 0.0128, G_A_loss: 0.9093, G_B_loss: 0.8817\n",
      "Epoch [179/200], Step [171/1067], D_A_loss: 0.0361, D_B_loss: 0.0209, G_A_loss: 0.7571, G_B_loss: 0.5855\n",
      "Epoch [179/200], Step [181/1067], D_A_loss: 0.0956, D_B_loss: 0.0714, G_A_loss: 0.8901, G_B_loss: 0.9722\n",
      "Epoch [179/200], Step [191/1067], D_A_loss: 0.0523, D_B_loss: 0.0196, G_A_loss: 1.1025, G_B_loss: 0.8589\n",
      "Epoch [179/200], Step [201/1067], D_A_loss: 0.0403, D_B_loss: 0.0265, G_A_loss: 0.9787, G_B_loss: 0.6529\n",
      "Epoch [179/200], Step [211/1067], D_A_loss: 0.0699, D_B_loss: 0.0247, G_A_loss: 0.6508, G_B_loss: 0.7410\n",
      "Epoch [179/200], Step [221/1067], D_A_loss: 0.1699, D_B_loss: 0.0346, G_A_loss: 0.8720, G_B_loss: 0.6922\n",
      "Epoch [179/200], Step [231/1067], D_A_loss: 0.0534, D_B_loss: 0.0103, G_A_loss: 0.8646, G_B_loss: 0.8735\n",
      "Epoch [179/200], Step [241/1067], D_A_loss: 0.0412, D_B_loss: 0.0427, G_A_loss: 1.0961, G_B_loss: 0.6523\n",
      "Epoch [179/200], Step [251/1067], D_A_loss: 0.0874, D_B_loss: 0.0182, G_A_loss: 0.8645, G_B_loss: 0.7490\n",
      "Epoch [179/200], Step [261/1067], D_A_loss: 0.1468, D_B_loss: 0.0136, G_A_loss: 0.8462, G_B_loss: 0.6486\n",
      "Epoch [179/200], Step [271/1067], D_A_loss: 0.0271, D_B_loss: 0.0085, G_A_loss: 0.9911, G_B_loss: 0.5859\n",
      "Epoch [179/200], Step [281/1067], D_A_loss: 0.2300, D_B_loss: 0.0083, G_A_loss: 0.7587, G_B_loss: 0.7002\n",
      "Epoch [179/200], Step [291/1067], D_A_loss: 0.1485, D_B_loss: 0.0105, G_A_loss: 0.6085, G_B_loss: 0.3025\n",
      "Epoch [179/200], Step [301/1067], D_A_loss: 0.0281, D_B_loss: 0.0732, G_A_loss: 1.1987, G_B_loss: 0.9639\n",
      "Epoch [179/200], Step [311/1067], D_A_loss: 0.0404, D_B_loss: 0.0120, G_A_loss: 0.9549, G_B_loss: 0.6816\n",
      "Epoch [179/200], Step [321/1067], D_A_loss: 0.0886, D_B_loss: 0.0274, G_A_loss: 1.0268, G_B_loss: 0.7813\n",
      "Epoch [179/200], Step [331/1067], D_A_loss: 0.0584, D_B_loss: 0.0173, G_A_loss: 0.9510, G_B_loss: 1.4206\n",
      "Epoch [179/200], Step [341/1067], D_A_loss: 0.0411, D_B_loss: 0.0174, G_A_loss: 1.1651, G_B_loss: 0.9372\n",
      "Epoch [179/200], Step [351/1067], D_A_loss: 0.0376, D_B_loss: 0.0072, G_A_loss: 1.0320, G_B_loss: 1.0207\n",
      "Epoch [179/200], Step [361/1067], D_A_loss: 0.0209, D_B_loss: 0.0238, G_A_loss: 0.7065, G_B_loss: 0.9919\n",
      "Epoch [179/200], Step [371/1067], D_A_loss: 0.0298, D_B_loss: 0.0147, G_A_loss: 0.8347, G_B_loss: 1.0401\n",
      "Epoch [179/200], Step [381/1067], D_A_loss: 0.0243, D_B_loss: 0.0200, G_A_loss: 1.1933, G_B_loss: 1.3019\n",
      "Epoch [179/200], Step [391/1067], D_A_loss: 0.0433, D_B_loss: 0.0105, G_A_loss: 1.1242, G_B_loss: 0.8776\n",
      "Epoch [179/200], Step [401/1067], D_A_loss: 0.1000, D_B_loss: 0.0479, G_A_loss: 1.3107, G_B_loss: 0.6701\n",
      "Epoch [179/200], Step [411/1067], D_A_loss: 0.0422, D_B_loss: 0.0097, G_A_loss: 1.0488, G_B_loss: 0.6891\n",
      "Epoch [179/200], Step [421/1067], D_A_loss: 0.1223, D_B_loss: 0.0182, G_A_loss: 0.8643, G_B_loss: 0.7032\n",
      "Epoch [179/200], Step [431/1067], D_A_loss: 0.0169, D_B_loss: 0.0125, G_A_loss: 1.4747, G_B_loss: 0.9453\n",
      "Epoch [179/200], Step [441/1067], D_A_loss: 0.0517, D_B_loss: 0.0119, G_A_loss: 0.8361, G_B_loss: 1.0518\n",
      "Epoch [179/200], Step [451/1067], D_A_loss: 0.0527, D_B_loss: 0.0077, G_A_loss: 0.9381, G_B_loss: 0.7744\n",
      "Epoch [179/200], Step [461/1067], D_A_loss: 0.0698, D_B_loss: 0.0134, G_A_loss: 0.8872, G_B_loss: 0.6070\n",
      "Epoch [179/200], Step [471/1067], D_A_loss: 0.0727, D_B_loss: 0.0244, G_A_loss: 0.6048, G_B_loss: 0.8828\n",
      "Epoch [179/200], Step [481/1067], D_A_loss: 0.0581, D_B_loss: 0.0100, G_A_loss: 1.1586, G_B_loss: 0.6158\n",
      "Epoch [179/200], Step [491/1067], D_A_loss: 0.0338, D_B_loss: 0.0533, G_A_loss: 0.6702, G_B_loss: 0.7851\n",
      "Epoch [179/200], Step [501/1067], D_A_loss: 0.0616, D_B_loss: 0.0093, G_A_loss: 1.1586, G_B_loss: 0.5877\n",
      "Epoch [179/200], Step [511/1067], D_A_loss: 0.0332, D_B_loss: 0.0089, G_A_loss: 0.6961, G_B_loss: 0.7298\n",
      "Epoch [179/200], Step [521/1067], D_A_loss: 0.0228, D_B_loss: 0.0272, G_A_loss: 0.8520, G_B_loss: 0.7754\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [179/200], Step [531/1067], D_A_loss: 0.0298, D_B_loss: 0.0379, G_A_loss: 0.8430, G_B_loss: 0.3895\n",
      "Epoch [179/200], Step [541/1067], D_A_loss: 0.0764, D_B_loss: 0.0366, G_A_loss: 0.9612, G_B_loss: 0.5725\n",
      "Epoch [179/200], Step [551/1067], D_A_loss: 0.0232, D_B_loss: 0.0230, G_A_loss: 1.1087, G_B_loss: 0.8661\n",
      "Epoch [179/200], Step [561/1067], D_A_loss: 0.1076, D_B_loss: 0.0122, G_A_loss: 1.2005, G_B_loss: 0.3641\n",
      "Epoch [179/200], Step [571/1067], D_A_loss: 0.1398, D_B_loss: 0.0119, G_A_loss: 0.8466, G_B_loss: 0.6080\n",
      "Epoch [179/200], Step [581/1067], D_A_loss: 0.0255, D_B_loss: 0.0238, G_A_loss: 0.7882, G_B_loss: 0.6208\n",
      "Epoch [179/200], Step [591/1067], D_A_loss: 0.0573, D_B_loss: 0.0181, G_A_loss: 1.1957, G_B_loss: 0.2593\n",
      "Epoch [179/200], Step [601/1067], D_A_loss: 0.1228, D_B_loss: 0.0156, G_A_loss: 0.6272, G_B_loss: 0.4165\n",
      "Epoch [179/200], Step [611/1067], D_A_loss: 0.0837, D_B_loss: 0.0228, G_A_loss: 0.7641, G_B_loss: 0.4489\n",
      "Epoch [179/200], Step [621/1067], D_A_loss: 0.1323, D_B_loss: 0.0102, G_A_loss: 0.9675, G_B_loss: 0.3252\n",
      "Epoch [179/200], Step [631/1067], D_A_loss: 0.0339, D_B_loss: 0.0324, G_A_loss: 0.7980, G_B_loss: 0.7815\n",
      "Epoch [179/200], Step [641/1067], D_A_loss: 0.0517, D_B_loss: 0.0201, G_A_loss: 1.1874, G_B_loss: 0.5628\n",
      "Epoch [179/200], Step [651/1067], D_A_loss: 0.1442, D_B_loss: 0.0126, G_A_loss: 0.6828, G_B_loss: 0.8651\n",
      "Epoch [179/200], Step [661/1067], D_A_loss: 0.0298, D_B_loss: 0.0173, G_A_loss: 0.6733, G_B_loss: 0.7183\n",
      "Epoch [179/200], Step [671/1067], D_A_loss: 0.0272, D_B_loss: 0.0084, G_A_loss: 1.1057, G_B_loss: 0.6564\n",
      "Epoch [179/200], Step [681/1067], D_A_loss: 0.0333, D_B_loss: 0.0250, G_A_loss: 0.6531, G_B_loss: 0.4785\n",
      "Epoch [179/200], Step [691/1067], D_A_loss: 0.0330, D_B_loss: 0.0104, G_A_loss: 0.9912, G_B_loss: 0.8072\n",
      "Epoch [179/200], Step [701/1067], D_A_loss: 0.1501, D_B_loss: 0.0132, G_A_loss: 0.8911, G_B_loss: 0.3443\n",
      "Epoch [179/200], Step [711/1067], D_A_loss: 0.0408, D_B_loss: 0.0132, G_A_loss: 0.9128, G_B_loss: 1.0137\n",
      "Epoch [179/200], Step [721/1067], D_A_loss: 0.0806, D_B_loss: 0.0179, G_A_loss: 0.5846, G_B_loss: 0.4311\n",
      "Epoch [179/200], Step [731/1067], D_A_loss: 0.1473, D_B_loss: 0.0151, G_A_loss: 0.7898, G_B_loss: 0.4103\n",
      "Epoch [179/200], Step [741/1067], D_A_loss: 0.0740, D_B_loss: 0.0152, G_A_loss: 1.1348, G_B_loss: 0.5058\n",
      "Epoch [179/200], Step [751/1067], D_A_loss: 0.0459, D_B_loss: 0.0316, G_A_loss: 0.6900, G_B_loss: 0.7110\n",
      "Epoch [179/200], Step [761/1067], D_A_loss: 0.0411, D_B_loss: 0.0322, G_A_loss: 0.7727, G_B_loss: 0.9539\n",
      "Epoch [179/200], Step [771/1067], D_A_loss: 0.0381, D_B_loss: 0.0093, G_A_loss: 1.0753, G_B_loss: 0.7529\n",
      "Epoch [179/200], Step [781/1067], D_A_loss: 0.1370, D_B_loss: 0.0526, G_A_loss: 0.5552, G_B_loss: 0.9704\n",
      "Epoch [179/200], Step [791/1067], D_A_loss: 0.0728, D_B_loss: 0.0258, G_A_loss: 0.6904, G_B_loss: 0.6405\n",
      "Epoch [179/200], Step [801/1067], D_A_loss: 0.0667, D_B_loss: 0.0192, G_A_loss: 0.8754, G_B_loss: 0.8008\n",
      "Epoch [179/200], Step [811/1067], D_A_loss: 0.0821, D_B_loss: 0.0244, G_A_loss: 1.2212, G_B_loss: 0.7088\n",
      "Epoch [179/200], Step [821/1067], D_A_loss: 0.1072, D_B_loss: 0.0346, G_A_loss: 1.1794, G_B_loss: 0.3986\n",
      "Epoch [179/200], Step [831/1067], D_A_loss: 0.1057, D_B_loss: 0.0426, G_A_loss: 1.0714, G_B_loss: 0.3828\n",
      "Epoch [179/200], Step [841/1067], D_A_loss: 0.0250, D_B_loss: 0.0244, G_A_loss: 0.6470, G_B_loss: 0.3387\n",
      "Epoch [179/200], Step [851/1067], D_A_loss: 0.0401, D_B_loss: 0.0186, G_A_loss: 0.6564, G_B_loss: 0.6597\n",
      "Epoch [179/200], Step [861/1067], D_A_loss: 0.0408, D_B_loss: 0.0158, G_A_loss: 0.9846, G_B_loss: 1.2163\n",
      "Epoch [179/200], Step [871/1067], D_A_loss: 0.1134, D_B_loss: 0.0170, G_A_loss: 0.7819, G_B_loss: 0.8116\n",
      "Epoch [179/200], Step [881/1067], D_A_loss: 0.0294, D_B_loss: 0.0094, G_A_loss: 1.0034, G_B_loss: 0.8537\n",
      "Epoch [179/200], Step [891/1067], D_A_loss: 0.0344, D_B_loss: 0.0114, G_A_loss: 0.8487, G_B_loss: 0.9075\n",
      "Epoch [179/200], Step [901/1067], D_A_loss: 0.0837, D_B_loss: 0.0121, G_A_loss: 1.1291, G_B_loss: 0.4375\n",
      "Epoch [179/200], Step [911/1067], D_A_loss: 0.0872, D_B_loss: 0.0186, G_A_loss: 0.8579, G_B_loss: 0.6697\n",
      "Epoch [179/200], Step [921/1067], D_A_loss: 0.0423, D_B_loss: 0.0067, G_A_loss: 0.9363, G_B_loss: 0.5550\n",
      "Epoch [179/200], Step [931/1067], D_A_loss: 0.1579, D_B_loss: 0.0160, G_A_loss: 0.7545, G_B_loss: 0.9002\n",
      "Epoch [179/200], Step [941/1067], D_A_loss: 0.0628, D_B_loss: 0.0122, G_A_loss: 1.0703, G_B_loss: 0.5655\n",
      "Epoch [179/200], Step [951/1067], D_A_loss: 0.0205, D_B_loss: 0.0109, G_A_loss: 0.8686, G_B_loss: 0.4789\n",
      "Epoch [179/200], Step [961/1067], D_A_loss: 0.0714, D_B_loss: 0.0253, G_A_loss: 0.7027, G_B_loss: 0.8873\n",
      "Epoch [179/200], Step [971/1067], D_A_loss: 0.0714, D_B_loss: 0.0164, G_A_loss: 0.7601, G_B_loss: 0.7446\n",
      "Epoch [179/200], Step [981/1067], D_A_loss: 0.0180, D_B_loss: 0.0172, G_A_loss: 0.7410, G_B_loss: 0.3389\n",
      "Epoch [179/200], Step [991/1067], D_A_loss: 0.0262, D_B_loss: 0.0167, G_A_loss: 1.3633, G_B_loss: 1.0317\n",
      "Epoch [179/200], Step [1001/1067], D_A_loss: 0.0867, D_B_loss: 0.0179, G_A_loss: 0.9114, G_B_loss: 0.7385\n",
      "Epoch [179/200], Step [1011/1067], D_A_loss: 0.1664, D_B_loss: 0.0204, G_A_loss: 0.7539, G_B_loss: 0.7702\n",
      "Epoch [179/200], Step [1021/1067], D_A_loss: 0.0177, D_B_loss: 0.0392, G_A_loss: 0.9858, G_B_loss: 0.9375\n",
      "Epoch [179/200], Step [1031/1067], D_A_loss: 0.1277, D_B_loss: 0.0124, G_A_loss: 0.9210, G_B_loss: 1.0123\n",
      "Epoch [179/200], Step [1041/1067], D_A_loss: 0.0347, D_B_loss: 0.0140, G_A_loss: 0.8010, G_B_loss: 0.8766\n",
      "Epoch [179/200], Step [1051/1067], D_A_loss: 0.0364, D_B_loss: 0.0140, G_A_loss: 0.8454, G_B_loss: 0.7380\n",
      "Epoch [179/200], Step [1061/1067], D_A_loss: 0.1064, D_B_loss: 0.0105, G_A_loss: 1.0141, G_B_loss: 0.4441\n",
      "Epoch [180/200], Step [1/1067], D_A_loss: 0.0279, D_B_loss: 0.0158, G_A_loss: 1.4452, G_B_loss: 0.4945\n",
      "Epoch [180/200], Step [11/1067], D_A_loss: 0.0698, D_B_loss: 0.0482, G_A_loss: 0.7466, G_B_loss: 0.6339\n",
      "Epoch [180/200], Step [21/1067], D_A_loss: 0.1344, D_B_loss: 0.0483, G_A_loss: 0.8980, G_B_loss: 1.0489\n",
      "Epoch [180/200], Step [31/1067], D_A_loss: 0.0563, D_B_loss: 0.0121, G_A_loss: 0.8196, G_B_loss: 0.2814\n",
      "Epoch [180/200], Step [41/1067], D_A_loss: 0.0969, D_B_loss: 0.0538, G_A_loss: 0.8734, G_B_loss: 0.4603\n",
      "Epoch [180/200], Step [51/1067], D_A_loss: 0.0588, D_B_loss: 0.0131, G_A_loss: 1.0239, G_B_loss: 0.6124\n",
      "Epoch [180/200], Step [61/1067], D_A_loss: 0.0427, D_B_loss: 0.0264, G_A_loss: 0.8383, G_B_loss: 0.5838\n",
      "Epoch [180/200], Step [71/1067], D_A_loss: 0.0327, D_B_loss: 0.0123, G_A_loss: 0.8585, G_B_loss: 0.4898\n",
      "Epoch [180/200], Step [81/1067], D_A_loss: 0.1139, D_B_loss: 0.0449, G_A_loss: 0.5929, G_B_loss: 0.4237\n",
      "Epoch [180/200], Step [91/1067], D_A_loss: 0.0710, D_B_loss: 0.0176, G_A_loss: 0.9862, G_B_loss: 0.5384\n",
      "Epoch [180/200], Step [101/1067], D_A_loss: 0.0535, D_B_loss: 0.0293, G_A_loss: 0.6980, G_B_loss: 1.0977\n",
      "Epoch [180/200], Step [111/1067], D_A_loss: 0.0708, D_B_loss: 0.0532, G_A_loss: 0.5932, G_B_loss: 0.5010\n",
      "Epoch [180/200], Step [121/1067], D_A_loss: 0.1081, D_B_loss: 0.0155, G_A_loss: 0.9064, G_B_loss: 0.4534\n",
      "Epoch [180/200], Step [131/1067], D_A_loss: 0.0479, D_B_loss: 0.0833, G_A_loss: 0.9188, G_B_loss: 0.7210\n",
      "Epoch [180/200], Step [141/1067], D_A_loss: 0.0466, D_B_loss: 0.0193, G_A_loss: 1.2652, G_B_loss: 0.5916\n",
      "Epoch [180/200], Step [151/1067], D_A_loss: 0.0942, D_B_loss: 0.0239, G_A_loss: 0.7134, G_B_loss: 0.5083\n",
      "Epoch [180/200], Step [161/1067], D_A_loss: 0.1718, D_B_loss: 0.0108, G_A_loss: 0.7689, G_B_loss: 0.6437\n",
      "Epoch [180/200], Step [171/1067], D_A_loss: 0.0804, D_B_loss: 0.0599, G_A_loss: 1.1031, G_B_loss: 0.4501\n",
      "Epoch [180/200], Step [181/1067], D_A_loss: 0.0997, D_B_loss: 0.0171, G_A_loss: 1.0625, G_B_loss: 0.6769\n",
      "Epoch [180/200], Step [191/1067], D_A_loss: 0.1127, D_B_loss: 0.0249, G_A_loss: 0.6856, G_B_loss: 0.3716\n",
      "Epoch [180/200], Step [201/1067], D_A_loss: 0.0220, D_B_loss: 0.0251, G_A_loss: 1.0580, G_B_loss: 0.2888\n",
      "Epoch [180/200], Step [211/1067], D_A_loss: 0.0413, D_B_loss: 0.0455, G_A_loss: 0.5499, G_B_loss: 0.6772\n",
      "Epoch [180/200], Step [221/1067], D_A_loss: 0.0210, D_B_loss: 0.0100, G_A_loss: 1.0319, G_B_loss: 1.0392\n",
      "Epoch [180/200], Step [231/1067], D_A_loss: 0.0688, D_B_loss: 0.0151, G_A_loss: 0.8398, G_B_loss: 0.5708\n",
      "Epoch [180/200], Step [241/1067], D_A_loss: 0.0366, D_B_loss: 0.0092, G_A_loss: 0.8424, G_B_loss: 0.7146\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [180/200], Step [251/1067], D_A_loss: 0.0392, D_B_loss: 0.0336, G_A_loss: 0.6290, G_B_loss: 0.7599\n",
      "Epoch [180/200], Step [261/1067], D_A_loss: 0.0637, D_B_loss: 0.0290, G_A_loss: 0.7603, G_B_loss: 0.7954\n",
      "Epoch [180/200], Step [271/1067], D_A_loss: 0.0238, D_B_loss: 0.0322, G_A_loss: 1.2113, G_B_loss: 0.4739\n",
      "Epoch [180/200], Step [281/1067], D_A_loss: 0.0322, D_B_loss: 0.0430, G_A_loss: 0.8232, G_B_loss: 1.1395\n",
      "Epoch [180/200], Step [291/1067], D_A_loss: 0.0269, D_B_loss: 0.0275, G_A_loss: 1.0934, G_B_loss: 0.7882\n",
      "Epoch [180/200], Step [301/1067], D_A_loss: 0.0176, D_B_loss: 0.0310, G_A_loss: 0.8813, G_B_loss: 0.5730\n",
      "Epoch [180/200], Step [311/1067], D_A_loss: 0.1529, D_B_loss: 0.0110, G_A_loss: 0.9721, G_B_loss: 0.2964\n",
      "Epoch [180/200], Step [321/1067], D_A_loss: 0.0322, D_B_loss: 0.0662, G_A_loss: 1.7592, G_B_loss: 0.4424\n",
      "Epoch [180/200], Step [331/1067], D_A_loss: 0.0284, D_B_loss: 0.0125, G_A_loss: 0.5828, G_B_loss: 0.7427\n",
      "Epoch [180/200], Step [341/1067], D_A_loss: 0.0385, D_B_loss: 0.0106, G_A_loss: 1.0845, G_B_loss: 0.7242\n",
      "Epoch [180/200], Step [351/1067], D_A_loss: 0.0805, D_B_loss: 0.0193, G_A_loss: 1.0582, G_B_loss: 0.5085\n",
      "Epoch [180/200], Step [361/1067], D_A_loss: 0.0631, D_B_loss: 0.0187, G_A_loss: 0.9446, G_B_loss: 0.5912\n",
      "Epoch [180/200], Step [371/1067], D_A_loss: 0.0372, D_B_loss: 0.0300, G_A_loss: 0.7556, G_B_loss: 0.6524\n",
      "Epoch [180/200], Step [381/1067], D_A_loss: 0.0283, D_B_loss: 0.0128, G_A_loss: 0.9666, G_B_loss: 0.9269\n",
      "Epoch [180/200], Step [391/1067], D_A_loss: 0.0815, D_B_loss: 0.0153, G_A_loss: 1.0115, G_B_loss: 0.5289\n",
      "Epoch [180/200], Step [401/1067], D_A_loss: 0.0521, D_B_loss: 0.0487, G_A_loss: 0.8879, G_B_loss: 0.8080\n",
      "Epoch [180/200], Step [411/1067], D_A_loss: 0.0738, D_B_loss: 0.0838, G_A_loss: 0.6598, G_B_loss: 0.6694\n",
      "Epoch [180/200], Step [421/1067], D_A_loss: 0.0603, D_B_loss: 0.0248, G_A_loss: 0.7028, G_B_loss: 0.8391\n",
      "Epoch [180/200], Step [431/1067], D_A_loss: 0.0537, D_B_loss: 0.0174, G_A_loss: 0.8485, G_B_loss: 0.9066\n",
      "Epoch [180/200], Step [441/1067], D_A_loss: 0.0816, D_B_loss: 0.0220, G_A_loss: 0.7446, G_B_loss: 0.4429\n",
      "Epoch [180/200], Step [451/1067], D_A_loss: 0.0590, D_B_loss: 0.0109, G_A_loss: 0.9848, G_B_loss: 0.5827\n",
      "Epoch [180/200], Step [461/1067], D_A_loss: 0.1005, D_B_loss: 0.0399, G_A_loss: 0.6864, G_B_loss: 0.4352\n",
      "Epoch [180/200], Step [471/1067], D_A_loss: 0.0505, D_B_loss: 0.0131, G_A_loss: 0.9102, G_B_loss: 0.7182\n",
      "Epoch [180/200], Step [481/1067], D_A_loss: 0.0358, D_B_loss: 0.0426, G_A_loss: 0.5515, G_B_loss: 0.7490\n",
      "Epoch [180/200], Step [491/1067], D_A_loss: 0.0695, D_B_loss: 0.0254, G_A_loss: 0.7343, G_B_loss: 0.5400\n",
      "Epoch [180/200], Step [501/1067], D_A_loss: 0.0922, D_B_loss: 0.0316, G_A_loss: 1.1556, G_B_loss: 0.6166\n",
      "Epoch [180/200], Step [511/1067], D_A_loss: 0.0860, D_B_loss: 0.0581, G_A_loss: 0.5390, G_B_loss: 0.8209\n",
      "Epoch [180/200], Step [521/1067], D_A_loss: 0.0554, D_B_loss: 0.0144, G_A_loss: 1.0143, G_B_loss: 0.9453\n",
      "Epoch [180/200], Step [531/1067], D_A_loss: 0.0668, D_B_loss: 0.0430, G_A_loss: 1.5905, G_B_loss: 0.5382\n",
      "Epoch [180/200], Step [541/1067], D_A_loss: 0.1008, D_B_loss: 0.0680, G_A_loss: 1.1385, G_B_loss: 0.4957\n",
      "Epoch [180/200], Step [551/1067], D_A_loss: 0.0684, D_B_loss: 0.0182, G_A_loss: 0.7427, G_B_loss: 0.4629\n",
      "Epoch [180/200], Step [561/1067], D_A_loss: 0.0700, D_B_loss: 0.0101, G_A_loss: 0.9829, G_B_loss: 0.7883\n",
      "Epoch [180/200], Step [571/1067], D_A_loss: 0.0866, D_B_loss: 0.0127, G_A_loss: 0.8024, G_B_loss: 1.0024\n",
      "Epoch [180/200], Step [581/1067], D_A_loss: 0.0401, D_B_loss: 0.0600, G_A_loss: 1.5039, G_B_loss: 0.5232\n",
      "Epoch [180/200], Step [591/1067], D_A_loss: 0.0424, D_B_loss: 0.0176, G_A_loss: 0.7513, G_B_loss: 0.6731\n",
      "Epoch [180/200], Step [601/1067], D_A_loss: 0.0586, D_B_loss: 0.0328, G_A_loss: 0.6310, G_B_loss: 0.6057\n",
      "Epoch [180/200], Step [611/1067], D_A_loss: 0.0273, D_B_loss: 0.0274, G_A_loss: 1.4598, G_B_loss: 0.9421\n",
      "Epoch [180/200], Step [621/1067], D_A_loss: 0.1769, D_B_loss: 0.0158, G_A_loss: 0.9806, G_B_loss: 0.9098\n",
      "Epoch [180/200], Step [631/1067], D_A_loss: 0.0730, D_B_loss: 0.0398, G_A_loss: 0.8124, G_B_loss: 0.5137\n",
      "Epoch [180/200], Step [641/1067], D_A_loss: 0.1034, D_B_loss: 0.0512, G_A_loss: 0.9758, G_B_loss: 0.5541\n",
      "Epoch [180/200], Step [651/1067], D_A_loss: 0.2143, D_B_loss: 0.0116, G_A_loss: 1.0950, G_B_loss: 0.3883\n",
      "Epoch [180/200], Step [661/1067], D_A_loss: 0.1782, D_B_loss: 0.0090, G_A_loss: 1.0974, G_B_loss: 0.2265\n",
      "Epoch [180/200], Step [671/1067], D_A_loss: 0.0394, D_B_loss: 0.0625, G_A_loss: 0.5826, G_B_loss: 0.7765\n",
      "Epoch [180/200], Step [681/1067], D_A_loss: 0.0433, D_B_loss: 0.0121, G_A_loss: 1.1479, G_B_loss: 0.7914\n",
      "Epoch [180/200], Step [691/1067], D_A_loss: 0.0404, D_B_loss: 0.0524, G_A_loss: 1.1402, G_B_loss: 0.6025\n",
      "Epoch [180/200], Step [701/1067], D_A_loss: 0.0218, D_B_loss: 0.0090, G_A_loss: 0.9764, G_B_loss: 0.9089\n",
      "Epoch [180/200], Step [711/1067], D_A_loss: 0.0699, D_B_loss: 0.0839, G_A_loss: 0.7134, G_B_loss: 0.5038\n",
      "Epoch [180/200], Step [721/1067], D_A_loss: 0.0294, D_B_loss: 0.0220, G_A_loss: 0.8382, G_B_loss: 0.9329\n",
      "Epoch [180/200], Step [731/1067], D_A_loss: 0.0798, D_B_loss: 0.0099, G_A_loss: 0.9037, G_B_loss: 0.2780\n",
      "Epoch [180/200], Step [741/1067], D_A_loss: 0.1261, D_B_loss: 0.0181, G_A_loss: 0.6323, G_B_loss: 0.5819\n",
      "Epoch [180/200], Step [751/1067], D_A_loss: 0.0718, D_B_loss: 0.0274, G_A_loss: 0.7131, G_B_loss: 0.7572\n",
      "Epoch [180/200], Step [761/1067], D_A_loss: 0.1034, D_B_loss: 0.0341, G_A_loss: 1.1158, G_B_loss: 0.5943\n",
      "Epoch [180/200], Step [771/1067], D_A_loss: 0.0284, D_B_loss: 0.0211, G_A_loss: 1.0011, G_B_loss: 0.5959\n",
      "Epoch [180/200], Step [781/1067], D_A_loss: 0.0276, D_B_loss: 0.0081, G_A_loss: 1.0396, G_B_loss: 0.8121\n",
      "Epoch [180/200], Step [791/1067], D_A_loss: 0.0817, D_B_loss: 0.0152, G_A_loss: 0.6809, G_B_loss: 0.6472\n",
      "Epoch [180/200], Step [801/1067], D_A_loss: 0.1967, D_B_loss: 0.0248, G_A_loss: 1.2509, G_B_loss: 0.2279\n",
      "Epoch [180/200], Step [811/1067], D_A_loss: 0.0968, D_B_loss: 0.0409, G_A_loss: 0.6426, G_B_loss: 0.3897\n",
      "Epoch [180/200], Step [821/1067], D_A_loss: 0.0941, D_B_loss: 0.0218, G_A_loss: 0.8929, G_B_loss: 0.6359\n",
      "Epoch [180/200], Step [831/1067], D_A_loss: 0.0892, D_B_loss: 0.0147, G_A_loss: 0.9193, G_B_loss: 0.7163\n",
      "Epoch [180/200], Step [841/1067], D_A_loss: 0.0415, D_B_loss: 0.0195, G_A_loss: 0.7528, G_B_loss: 0.7546\n",
      "Epoch [180/200], Step [851/1067], D_A_loss: 0.0800, D_B_loss: 0.0265, G_A_loss: 0.7066, G_B_loss: 0.4550\n",
      "Epoch [180/200], Step [861/1067], D_A_loss: 0.0290, D_B_loss: 0.0420, G_A_loss: 0.5750, G_B_loss: 0.6228\n",
      "Epoch [180/200], Step [871/1067], D_A_loss: 0.0255, D_B_loss: 0.1084, G_A_loss: 0.6762, G_B_loss: 0.5820\n",
      "Epoch [180/200], Step [881/1067], D_A_loss: 0.0444, D_B_loss: 0.0099, G_A_loss: 0.8953, G_B_loss: 0.8076\n",
      "Epoch [180/200], Step [891/1067], D_A_loss: 0.0303, D_B_loss: 0.0214, G_A_loss: 0.8863, G_B_loss: 0.5799\n",
      "Epoch [180/200], Step [901/1067], D_A_loss: 0.1276, D_B_loss: 0.0383, G_A_loss: 0.5997, G_B_loss: 0.3097\n",
      "Epoch [180/200], Step [911/1067], D_A_loss: 0.0422, D_B_loss: 0.0171, G_A_loss: 1.2710, G_B_loss: 0.6458\n",
      "Epoch [180/200], Step [921/1067], D_A_loss: 0.0820, D_B_loss: 0.0150, G_A_loss: 0.6327, G_B_loss: 0.7392\n",
      "Epoch [180/200], Step [931/1067], D_A_loss: 0.1666, D_B_loss: 0.0372, G_A_loss: 0.8335, G_B_loss: 0.9642\n",
      "Epoch [180/200], Step [941/1067], D_A_loss: 0.0552, D_B_loss: 0.0192, G_A_loss: 0.7538, G_B_loss: 0.3690\n",
      "Epoch [180/200], Step [951/1067], D_A_loss: 0.0629, D_B_loss: 0.0126, G_A_loss: 0.8126, G_B_loss: 0.8077\n",
      "Epoch [180/200], Step [961/1067], D_A_loss: 0.1688, D_B_loss: 0.0262, G_A_loss: 0.9053, G_B_loss: 0.3523\n",
      "Epoch [180/200], Step [971/1067], D_A_loss: 0.0424, D_B_loss: 0.0085, G_A_loss: 0.9702, G_B_loss: 0.9371\n",
      "Epoch [180/200], Step [981/1067], D_A_loss: 0.0773, D_B_loss: 0.0083, G_A_loss: 0.9236, G_B_loss: 0.5354\n",
      "Epoch [180/200], Step [991/1067], D_A_loss: 0.0334, D_B_loss: 0.0087, G_A_loss: 1.1108, G_B_loss: 0.4361\n",
      "Epoch [180/200], Step [1001/1067], D_A_loss: 0.0394, D_B_loss: 0.0494, G_A_loss: 0.7239, G_B_loss: 0.6288\n",
      "Epoch [180/200], Step [1011/1067], D_A_loss: 0.1437, D_B_loss: 0.0211, G_A_loss: 0.7580, G_B_loss: 0.9395\n",
      "Epoch [180/200], Step [1021/1067], D_A_loss: 0.1509, D_B_loss: 0.0136, G_A_loss: 0.9774, G_B_loss: 0.3520\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [180/200], Step [1031/1067], D_A_loss: 0.0582, D_B_loss: 0.0139, G_A_loss: 0.8755, G_B_loss: 0.7128\n",
      "Epoch [180/200], Step [1041/1067], D_A_loss: 0.0839, D_B_loss: 0.0223, G_A_loss: 1.0217, G_B_loss: 0.6300\n",
      "Epoch [180/200], Step [1051/1067], D_A_loss: 0.0567, D_B_loss: 0.0135, G_A_loss: 1.1088, G_B_loss: 0.6478\n",
      "Epoch [180/200], Step [1061/1067], D_A_loss: 0.1583, D_B_loss: 0.0177, G_A_loss: 0.7305, G_B_loss: 0.2686\n",
      "Epoch [181/200], Step [1/1067], D_A_loss: 0.0588, D_B_loss: 0.0178, G_A_loss: 0.9707, G_B_loss: 0.8256\n",
      "Epoch [181/200], Step [11/1067], D_A_loss: 0.0756, D_B_loss: 0.0271, G_A_loss: 0.8699, G_B_loss: 0.5640\n",
      "Epoch [181/200], Step [21/1067], D_A_loss: 0.0536, D_B_loss: 0.0188, G_A_loss: 0.8871, G_B_loss: 0.3187\n",
      "Epoch [181/200], Step [31/1067], D_A_loss: 0.0997, D_B_loss: 0.0373, G_A_loss: 0.6041, G_B_loss: 0.3854\n",
      "Epoch [181/200], Step [41/1067], D_A_loss: 0.0481, D_B_loss: 0.0263, G_A_loss: 0.6636, G_B_loss: 0.4877\n",
      "Epoch [181/200], Step [51/1067], D_A_loss: 0.0416, D_B_loss: 0.0112, G_A_loss: 0.8482, G_B_loss: 0.9774\n",
      "Epoch [181/200], Step [61/1067], D_A_loss: 0.0639, D_B_loss: 0.0484, G_A_loss: 0.8411, G_B_loss: 0.6326\n",
      "Epoch [181/200], Step [71/1067], D_A_loss: 0.0565, D_B_loss: 0.0317, G_A_loss: 0.6711, G_B_loss: 0.5269\n",
      "Epoch [181/200], Step [81/1067], D_A_loss: 0.1058, D_B_loss: 0.0124, G_A_loss: 0.5103, G_B_loss: 0.6163\n",
      "Epoch [181/200], Step [91/1067], D_A_loss: 0.0756, D_B_loss: 0.1332, G_A_loss: 0.8697, G_B_loss: 0.5696\n",
      "Epoch [181/200], Step [101/1067], D_A_loss: 0.0362, D_B_loss: 0.0154, G_A_loss: 0.8246, G_B_loss: 0.8744\n",
      "Epoch [181/200], Step [111/1067], D_A_loss: 0.0655, D_B_loss: 0.0359, G_A_loss: 0.4968, G_B_loss: 0.4242\n",
      "Epoch [181/200], Step [121/1067], D_A_loss: 0.1042, D_B_loss: 0.0096, G_A_loss: 1.0022, G_B_loss: 0.5929\n",
      "Epoch [181/200], Step [131/1067], D_A_loss: 0.1017, D_B_loss: 0.0115, G_A_loss: 0.9349, G_B_loss: 0.7502\n",
      "Epoch [181/200], Step [141/1067], D_A_loss: 0.0721, D_B_loss: 0.0299, G_A_loss: 0.6277, G_B_loss: 0.5280\n",
      "Epoch [181/200], Step [151/1067], D_A_loss: 0.0439, D_B_loss: 0.0209, G_A_loss: 0.8077, G_B_loss: 0.5113\n",
      "Epoch [181/200], Step [161/1067], D_A_loss: 0.1073, D_B_loss: 0.0342, G_A_loss: 0.6315, G_B_loss: 0.6810\n",
      "Epoch [181/200], Step [171/1067], D_A_loss: 0.1460, D_B_loss: 0.0132, G_A_loss: 0.9740, G_B_loss: 0.6926\n",
      "Epoch [181/200], Step [181/1067], D_A_loss: 0.0594, D_B_loss: 0.0105, G_A_loss: 1.1302, G_B_loss: 0.9610\n",
      "Epoch [181/200], Step [191/1067], D_A_loss: 0.0188, D_B_loss: 0.0293, G_A_loss: 1.0957, G_B_loss: 0.3968\n",
      "Epoch [181/200], Step [201/1067], D_A_loss: 0.0789, D_B_loss: 0.0159, G_A_loss: 1.1266, G_B_loss: 0.6918\n",
      "Epoch [181/200], Step [211/1067], D_A_loss: 0.0689, D_B_loss: 0.0348, G_A_loss: 1.1020, G_B_loss: 0.4088\n",
      "Epoch [181/200], Step [221/1067], D_A_loss: 0.0715, D_B_loss: 0.0137, G_A_loss: 0.8090, G_B_loss: 0.8176\n",
      "Epoch [181/200], Step [231/1067], D_A_loss: 0.0903, D_B_loss: 0.0099, G_A_loss: 0.8673, G_B_loss: 0.6095\n",
      "Epoch [181/200], Step [241/1067], D_A_loss: 0.0824, D_B_loss: 0.0129, G_A_loss: 0.8499, G_B_loss: 0.5654\n",
      "Epoch [181/200], Step [251/1067], D_A_loss: 0.1102, D_B_loss: 0.0101, G_A_loss: 0.9515, G_B_loss: 0.7918\n",
      "Epoch [181/200], Step [261/1067], D_A_loss: 0.0841, D_B_loss: 0.0126, G_A_loss: 0.8317, G_B_loss: 0.5221\n",
      "Epoch [181/200], Step [271/1067], D_A_loss: 0.0342, D_B_loss: 0.0430, G_A_loss: 0.7502, G_B_loss: 0.5983\n",
      "Epoch [181/200], Step [281/1067], D_A_loss: 0.0916, D_B_loss: 0.0321, G_A_loss: 0.7139, G_B_loss: 0.4481\n",
      "Epoch [181/200], Step [291/1067], D_A_loss: 0.0515, D_B_loss: 0.0182, G_A_loss: 1.2475, G_B_loss: 0.5999\n",
      "Epoch [181/200], Step [301/1067], D_A_loss: 0.0677, D_B_loss: 0.0121, G_A_loss: 1.0555, G_B_loss: 0.6210\n",
      "Epoch [181/200], Step [311/1067], D_A_loss: 0.1355, D_B_loss: 0.0203, G_A_loss: 1.0339, G_B_loss: 0.6152\n",
      "Epoch [181/200], Step [321/1067], D_A_loss: 0.0679, D_B_loss: 0.0418, G_A_loss: 0.7297, G_B_loss: 0.8238\n",
      "Epoch [181/200], Step [331/1067], D_A_loss: 0.0228, D_B_loss: 0.0458, G_A_loss: 1.1157, G_B_loss: 0.3745\n",
      "Epoch [181/200], Step [341/1067], D_A_loss: 0.0487, D_B_loss: 0.0392, G_A_loss: 0.5763, G_B_loss: 0.5994\n",
      "Epoch [181/200], Step [351/1067], D_A_loss: 0.0408, D_B_loss: 0.0095, G_A_loss: 1.0462, G_B_loss: 0.3223\n",
      "Epoch [181/200], Step [361/1067], D_A_loss: 0.0694, D_B_loss: 0.0173, G_A_loss: 0.8146, G_B_loss: 0.4464\n",
      "Epoch [181/200], Step [371/1067], D_A_loss: 0.0213, D_B_loss: 0.1206, G_A_loss: 0.3720, G_B_loss: 0.8525\n",
      "Epoch [181/200], Step [381/1067], D_A_loss: 0.0190, D_B_loss: 0.0394, G_A_loss: 0.9472, G_B_loss: 0.8733\n",
      "Epoch [181/200], Step [391/1067], D_A_loss: 0.0347, D_B_loss: 0.0271, G_A_loss: 1.3726, G_B_loss: 0.6972\n",
      "Epoch [181/200], Step [401/1067], D_A_loss: 0.0487, D_B_loss: 0.0193, G_A_loss: 0.7294, G_B_loss: 0.2782\n",
      "Epoch [181/200], Step [411/1067], D_A_loss: 0.0524, D_B_loss: 0.0105, G_A_loss: 0.7914, G_B_loss: 0.6214\n",
      "Epoch [181/200], Step [421/1067], D_A_loss: 0.2017, D_B_loss: 0.0090, G_A_loss: 0.9137, G_B_loss: 0.3814\n",
      "Epoch [181/200], Step [431/1067], D_A_loss: 0.0276, D_B_loss: 0.0110, G_A_loss: 0.9988, G_B_loss: 1.3189\n",
      "Epoch [181/200], Step [441/1067], D_A_loss: 0.0675, D_B_loss: 0.0111, G_A_loss: 1.3501, G_B_loss: 0.7566\n",
      "Epoch [181/200], Step [451/1067], D_A_loss: 0.0998, D_B_loss: 0.0183, G_A_loss: 0.6756, G_B_loss: 0.6514\n",
      "Epoch [181/200], Step [461/1067], D_A_loss: 0.0686, D_B_loss: 0.0251, G_A_loss: 0.6692, G_B_loss: 0.5109\n",
      "Epoch [181/200], Step [471/1067], D_A_loss: 0.0293, D_B_loss: 0.0227, G_A_loss: 0.8400, G_B_loss: 0.6377\n",
      "Epoch [181/200], Step [481/1067], D_A_loss: 0.0411, D_B_loss: 0.0177, G_A_loss: 0.7954, G_B_loss: 0.6356\n",
      "Epoch [181/200], Step [491/1067], D_A_loss: 0.0321, D_B_loss: 0.0392, G_A_loss: 0.6878, G_B_loss: 0.7323\n",
      "Epoch [181/200], Step [501/1067], D_A_loss: 0.0916, D_B_loss: 0.0247, G_A_loss: 0.6987, G_B_loss: 0.4219\n",
      "Epoch [181/200], Step [511/1067], D_A_loss: 0.0434, D_B_loss: 0.0197, G_A_loss: 0.9410, G_B_loss: 0.7478\n",
      "Epoch [181/200], Step [521/1067], D_A_loss: 0.0470, D_B_loss: 0.0586, G_A_loss: 0.8308, G_B_loss: 0.8439\n",
      "Epoch [181/200], Step [531/1067], D_A_loss: 0.0487, D_B_loss: 0.0159, G_A_loss: 0.8075, G_B_loss: 0.6128\n",
      "Epoch [181/200], Step [541/1067], D_A_loss: 0.1230, D_B_loss: 0.0191, G_A_loss: 0.8269, G_B_loss: 0.7205\n",
      "Epoch [181/200], Step [551/1067], D_A_loss: 0.0249, D_B_loss: 0.0886, G_A_loss: 0.5818, G_B_loss: 0.5962\n",
      "Epoch [181/200], Step [561/1067], D_A_loss: 0.0249, D_B_loss: 0.0796, G_A_loss: 0.7489, G_B_loss: 0.6001\n",
      "Epoch [181/200], Step [571/1067], D_A_loss: 0.0511, D_B_loss: 0.0105, G_A_loss: 0.4954, G_B_loss: 0.7147\n",
      "Epoch [181/200], Step [581/1067], D_A_loss: 0.0322, D_B_loss: 0.0232, G_A_loss: 1.3184, G_B_loss: 0.7567\n",
      "Epoch [181/200], Step [591/1067], D_A_loss: 0.0270, D_B_loss: 0.0071, G_A_loss: 0.9436, G_B_loss: 0.7602\n",
      "Epoch [181/200], Step [601/1067], D_A_loss: 0.1195, D_B_loss: 0.0275, G_A_loss: 1.3388, G_B_loss: 0.8830\n",
      "Epoch [181/200], Step [611/1067], D_A_loss: 0.0800, D_B_loss: 0.0097, G_A_loss: 0.6274, G_B_loss: 0.5358\n",
      "Epoch [181/200], Step [621/1067], D_A_loss: 0.0557, D_B_loss: 0.0203, G_A_loss: 0.7614, G_B_loss: 0.6799\n",
      "Epoch [181/200], Step [631/1067], D_A_loss: 0.0664, D_B_loss: 0.0261, G_A_loss: 0.7821, G_B_loss: 0.7706\n",
      "Epoch [181/200], Step [641/1067], D_A_loss: 0.0735, D_B_loss: 0.0208, G_A_loss: 0.7241, G_B_loss: 0.4923\n",
      "Epoch [181/200], Step [651/1067], D_A_loss: 0.0524, D_B_loss: 0.0397, G_A_loss: 0.8151, G_B_loss: 0.5671\n",
      "Epoch [181/200], Step [661/1067], D_A_loss: 0.0735, D_B_loss: 0.0379, G_A_loss: 0.6288, G_B_loss: 0.6341\n",
      "Epoch [181/200], Step [671/1067], D_A_loss: 0.0884, D_B_loss: 0.0231, G_A_loss: 0.8785, G_B_loss: 0.4617\n",
      "Epoch [181/200], Step [681/1067], D_A_loss: 0.1100, D_B_loss: 0.0240, G_A_loss: 0.7240, G_B_loss: 0.2552\n",
      "Epoch [181/200], Step [691/1067], D_A_loss: 0.0893, D_B_loss: 0.0164, G_A_loss: 0.8553, G_B_loss: 0.7420\n",
      "Epoch [181/200], Step [701/1067], D_A_loss: 0.0602, D_B_loss: 0.0319, G_A_loss: 0.9768, G_B_loss: 0.6812\n",
      "Epoch [181/200], Step [711/1067], D_A_loss: 0.0540, D_B_loss: 0.0328, G_A_loss: 0.4620, G_B_loss: 0.8122\n",
      "Epoch [181/200], Step [721/1067], D_A_loss: 0.0263, D_B_loss: 0.0222, G_A_loss: 1.0423, G_B_loss: 0.6698\n",
      "Epoch [181/200], Step [731/1067], D_A_loss: 0.0551, D_B_loss: 0.0175, G_A_loss: 0.9393, G_B_loss: 0.6686\n",
      "Epoch [181/200], Step [741/1067], D_A_loss: 0.1445, D_B_loss: 0.0248, G_A_loss: 0.8578, G_B_loss: 0.8844\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [181/200], Step [751/1067], D_A_loss: 0.0325, D_B_loss: 0.0181, G_A_loss: 0.7545, G_B_loss: 0.9683\n",
      "Epoch [181/200], Step [761/1067], D_A_loss: 0.0914, D_B_loss: 0.0203, G_A_loss: 0.6293, G_B_loss: 0.6457\n",
      "Epoch [181/200], Step [771/1067], D_A_loss: 0.0889, D_B_loss: 0.0092, G_A_loss: 0.9197, G_B_loss: 0.6536\n",
      "Epoch [181/200], Step [781/1067], D_A_loss: 0.0586, D_B_loss: 0.0085, G_A_loss: 1.0960, G_B_loss: 0.6865\n",
      "Epoch [181/200], Step [791/1067], D_A_loss: 0.0711, D_B_loss: 0.0152, G_A_loss: 0.8621, G_B_loss: 1.0271\n",
      "Epoch [181/200], Step [801/1067], D_A_loss: 0.1653, D_B_loss: 0.0191, G_A_loss: 0.8818, G_B_loss: 0.7548\n",
      "Epoch [181/200], Step [811/1067], D_A_loss: 0.0868, D_B_loss: 0.0409, G_A_loss: 0.6454, G_B_loss: 0.4628\n",
      "Epoch [181/200], Step [821/1067], D_A_loss: 0.0445, D_B_loss: 0.0450, G_A_loss: 1.0756, G_B_loss: 0.5512\n",
      "Epoch [181/200], Step [831/1067], D_A_loss: 0.0392, D_B_loss: 0.0125, G_A_loss: 1.1085, G_B_loss: 1.0639\n",
      "Epoch [181/200], Step [841/1067], D_A_loss: 0.0283, D_B_loss: 0.0135, G_A_loss: 0.8111, G_B_loss: 0.8504\n",
      "Epoch [181/200], Step [851/1067], D_A_loss: 0.1219, D_B_loss: 0.0099, G_A_loss: 1.1002, G_B_loss: 0.3973\n",
      "Epoch [181/200], Step [861/1067], D_A_loss: 0.0795, D_B_loss: 0.0160, G_A_loss: 1.1289, G_B_loss: 0.7654\n",
      "Epoch [181/200], Step [871/1067], D_A_loss: 0.0847, D_B_loss: 0.0108, G_A_loss: 0.7071, G_B_loss: 0.9545\n",
      "Epoch [181/200], Step [881/1067], D_A_loss: 0.0601, D_B_loss: 0.0186, G_A_loss: 0.8774, G_B_loss: 0.8256\n",
      "Epoch [181/200], Step [891/1067], D_A_loss: 0.1549, D_B_loss: 0.0103, G_A_loss: 0.9092, G_B_loss: 0.6533\n",
      "Epoch [181/200], Step [901/1067], D_A_loss: 0.0726, D_B_loss: 0.0318, G_A_loss: 0.9520, G_B_loss: 0.4895\n",
      "Epoch [181/200], Step [911/1067], D_A_loss: 0.0701, D_B_loss: 0.0679, G_A_loss: 0.9732, G_B_loss: 0.6377\n",
      "Epoch [181/200], Step [921/1067], D_A_loss: 0.1004, D_B_loss: 0.0116, G_A_loss: 0.8864, G_B_loss: 0.7833\n",
      "Epoch [181/200], Step [931/1067], D_A_loss: 0.0370, D_B_loss: 0.0331, G_A_loss: 0.6189, G_B_loss: 0.7146\n",
      "Epoch [181/200], Step [941/1067], D_A_loss: 0.0905, D_B_loss: 0.0112, G_A_loss: 0.8181, G_B_loss: 0.5911\n",
      "Epoch [181/200], Step [951/1067], D_A_loss: 0.1001, D_B_loss: 0.0126, G_A_loss: 0.5137, G_B_loss: 0.5616\n",
      "Epoch [181/200], Step [961/1067], D_A_loss: 0.0465, D_B_loss: 0.0107, G_A_loss: 1.1189, G_B_loss: 0.6696\n",
      "Epoch [181/200], Step [971/1067], D_A_loss: 0.0341, D_B_loss: 0.0259, G_A_loss: 0.6726, G_B_loss: 0.6296\n",
      "Epoch [181/200], Step [981/1067], D_A_loss: 0.0320, D_B_loss: 0.0124, G_A_loss: 0.6111, G_B_loss: 0.6767\n",
      "Epoch [181/200], Step [991/1067], D_A_loss: 0.0490, D_B_loss: 0.0115, G_A_loss: 0.9954, G_B_loss: 0.7612\n",
      "Epoch [181/200], Step [1001/1067], D_A_loss: 0.0481, D_B_loss: 0.0122, G_A_loss: 1.1234, G_B_loss: 0.3690\n",
      "Epoch [181/200], Step [1011/1067], D_A_loss: 0.0252, D_B_loss: 0.0243, G_A_loss: 0.8341, G_B_loss: 0.4848\n",
      "Epoch [181/200], Step [1021/1067], D_A_loss: 0.2009, D_B_loss: 0.0275, G_A_loss: 0.9211, G_B_loss: 0.4734\n",
      "Epoch [181/200], Step [1031/1067], D_A_loss: 0.1066, D_B_loss: 0.0115, G_A_loss: 0.7371, G_B_loss: 0.9123\n",
      "Epoch [181/200], Step [1041/1067], D_A_loss: 0.0775, D_B_loss: 0.0214, G_A_loss: 0.9176, G_B_loss: 0.7714\n",
      "Epoch [181/200], Step [1051/1067], D_A_loss: 0.0858, D_B_loss: 0.0294, G_A_loss: 0.9563, G_B_loss: 0.6111\n",
      "Epoch [181/200], Step [1061/1067], D_A_loss: 0.1102, D_B_loss: 0.0210, G_A_loss: 1.1640, G_B_loss: 0.4650\n",
      "Epoch [182/200], Step [1/1067], D_A_loss: 0.0904, D_B_loss: 0.0094, G_A_loss: 0.7710, G_B_loss: 0.7770\n",
      "Epoch [182/200], Step [11/1067], D_A_loss: 0.0421, D_B_loss: 0.0282, G_A_loss: 0.6818, G_B_loss: 0.3848\n",
      "Epoch [182/200], Step [21/1067], D_A_loss: 0.1714, D_B_loss: 0.0158, G_A_loss: 0.9338, G_B_loss: 0.7394\n",
      "Epoch [182/200], Step [31/1067], D_A_loss: 0.0355, D_B_loss: 0.0094, G_A_loss: 0.9863, G_B_loss: 0.8179\n",
      "Epoch [182/200], Step [41/1067], D_A_loss: 0.0868, D_B_loss: 0.0145, G_A_loss: 0.8249, G_B_loss: 0.8654\n",
      "Epoch [182/200], Step [51/1067], D_A_loss: 0.0172, D_B_loss: 0.0121, G_A_loss: 0.9502, G_B_loss: 0.8271\n",
      "Epoch [182/200], Step [61/1067], D_A_loss: 0.0333, D_B_loss: 0.0339, G_A_loss: 0.8565, G_B_loss: 1.0421\n",
      "Epoch [182/200], Step [71/1067], D_A_loss: 0.0340, D_B_loss: 0.0476, G_A_loss: 0.6697, G_B_loss: 0.8703\n",
      "Epoch [182/200], Step [81/1067], D_A_loss: 0.0634, D_B_loss: 0.0140, G_A_loss: 0.7950, G_B_loss: 0.6979\n",
      "Epoch [182/200], Step [91/1067], D_A_loss: 0.0274, D_B_loss: 0.0136, G_A_loss: 1.1448, G_B_loss: 0.8088\n",
      "Epoch [182/200], Step [101/1067], D_A_loss: 0.0501, D_B_loss: 0.0217, G_A_loss: 0.7336, G_B_loss: 0.3225\n",
      "Epoch [182/200], Step [111/1067], D_A_loss: 0.0604, D_B_loss: 0.0089, G_A_loss: 1.0190, G_B_loss: 0.6029\n",
      "Epoch [182/200], Step [121/1067], D_A_loss: 0.0314, D_B_loss: 0.0154, G_A_loss: 0.8930, G_B_loss: 0.6839\n",
      "Epoch [182/200], Step [131/1067], D_A_loss: 0.0262, D_B_loss: 0.0237, G_A_loss: 0.5280, G_B_loss: 0.4727\n",
      "Epoch [182/200], Step [141/1067], D_A_loss: 0.0964, D_B_loss: 0.0263, G_A_loss: 0.8927, G_B_loss: 0.5571\n",
      "Epoch [182/200], Step [151/1067], D_A_loss: 0.0545, D_B_loss: 0.0106, G_A_loss: 0.6395, G_B_loss: 0.3852\n",
      "Epoch [182/200], Step [161/1067], D_A_loss: 0.1400, D_B_loss: 0.0741, G_A_loss: 0.6675, G_B_loss: 0.2984\n",
      "Epoch [182/200], Step [171/1067], D_A_loss: 0.0759, D_B_loss: 0.0137, G_A_loss: 0.8298, G_B_loss: 0.8076\n",
      "Epoch [182/200], Step [181/1067], D_A_loss: 0.0508, D_B_loss: 0.0176, G_A_loss: 0.7797, G_B_loss: 0.8008\n",
      "Epoch [182/200], Step [191/1067], D_A_loss: 0.0446, D_B_loss: 0.0115, G_A_loss: 0.9494, G_B_loss: 0.3946\n",
      "Epoch [182/200], Step [201/1067], D_A_loss: 0.1848, D_B_loss: 0.0086, G_A_loss: 0.9036, G_B_loss: 0.4904\n",
      "Epoch [182/200], Step [211/1067], D_A_loss: 0.0432, D_B_loss: 0.0356, G_A_loss: 1.0243, G_B_loss: 0.6572\n",
      "Epoch [182/200], Step [221/1067], D_A_loss: 0.0451, D_B_loss: 0.0174, G_A_loss: 1.2722, G_B_loss: 0.3718\n",
      "Epoch [182/200], Step [231/1067], D_A_loss: 0.0520, D_B_loss: 0.0373, G_A_loss: 1.1466, G_B_loss: 0.6991\n",
      "Epoch [182/200], Step [241/1067], D_A_loss: 0.0934, D_B_loss: 0.0347, G_A_loss: 0.7272, G_B_loss: 0.8208\n",
      "Epoch [182/200], Step [251/1067], D_A_loss: 0.0559, D_B_loss: 0.0090, G_A_loss: 1.2298, G_B_loss: 0.6999\n",
      "Epoch [182/200], Step [261/1067], D_A_loss: 0.0643, D_B_loss: 0.0459, G_A_loss: 0.4765, G_B_loss: 0.6162\n",
      "Epoch [182/200], Step [271/1067], D_A_loss: 0.0669, D_B_loss: 0.0545, G_A_loss: 0.6473, G_B_loss: 0.5053\n",
      "Epoch [182/200], Step [281/1067], D_A_loss: 0.0725, D_B_loss: 0.0185, G_A_loss: 1.0190, G_B_loss: 0.6903\n",
      "Epoch [182/200], Step [291/1067], D_A_loss: 0.0546, D_B_loss: 0.0070, G_A_loss: 0.7903, G_B_loss: 0.6975\n",
      "Epoch [182/200], Step [301/1067], D_A_loss: 0.1318, D_B_loss: 0.0133, G_A_loss: 0.8949, G_B_loss: 0.5556\n",
      "Epoch [182/200], Step [311/1067], D_A_loss: 0.0582, D_B_loss: 0.0144, G_A_loss: 1.1769, G_B_loss: 0.6596\n",
      "Epoch [182/200], Step [321/1067], D_A_loss: 0.0438, D_B_loss: 0.0298, G_A_loss: 1.4410, G_B_loss: 0.7501\n",
      "Epoch [182/200], Step [331/1067], D_A_loss: 0.0701, D_B_loss: 0.0178, G_A_loss: 0.7410, G_B_loss: 0.4864\n",
      "Epoch [182/200], Step [341/1067], D_A_loss: 0.1206, D_B_loss: 0.0164, G_A_loss: 0.9931, G_B_loss: 0.6553\n",
      "Epoch [182/200], Step [351/1067], D_A_loss: 0.0919, D_B_loss: 0.0099, G_A_loss: 0.6547, G_B_loss: 0.9175\n",
      "Epoch [182/200], Step [361/1067], D_A_loss: 0.0465, D_B_loss: 0.0240, G_A_loss: 0.6967, G_B_loss: 0.6747\n",
      "Epoch [182/200], Step [371/1067], D_A_loss: 0.0555, D_B_loss: 0.0450, G_A_loss: 0.7689, G_B_loss: 0.5650\n",
      "Epoch [182/200], Step [381/1067], D_A_loss: 0.0756, D_B_loss: 0.0193, G_A_loss: 0.8984, G_B_loss: 0.6908\n",
      "Epoch [182/200], Step [391/1067], D_A_loss: 0.2483, D_B_loss: 0.0376, G_A_loss: 0.6161, G_B_loss: 0.5192\n",
      "Epoch [182/200], Step [401/1067], D_A_loss: 0.0382, D_B_loss: 0.0220, G_A_loss: 1.0676, G_B_loss: 0.6959\n",
      "Epoch [182/200], Step [411/1067], D_A_loss: 0.1631, D_B_loss: 0.0095, G_A_loss: 1.0511, G_B_loss: 0.2457\n",
      "Epoch [182/200], Step [421/1067], D_A_loss: 0.0372, D_B_loss: 0.0156, G_A_loss: 1.0299, G_B_loss: 0.7133\n",
      "Epoch [182/200], Step [431/1067], D_A_loss: 0.0738, D_B_loss: 0.0146, G_A_loss: 1.2834, G_B_loss: 0.4660\n",
      "Epoch [182/200], Step [441/1067], D_A_loss: 0.0438, D_B_loss: 0.0177, G_A_loss: 1.2077, G_B_loss: 0.6518\n",
      "Epoch [182/200], Step [451/1067], D_A_loss: 0.1203, D_B_loss: 0.0157, G_A_loss: 0.7720, G_B_loss: 0.3808\n",
      "Epoch [182/200], Step [461/1067], D_A_loss: 0.0367, D_B_loss: 0.0350, G_A_loss: 0.5877, G_B_loss: 0.8516\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [182/200], Step [471/1067], D_A_loss: 0.1660, D_B_loss: 0.0114, G_A_loss: 1.0268, G_B_loss: 0.5770\n",
      "Epoch [182/200], Step [481/1067], D_A_loss: 0.0241, D_B_loss: 0.0130, G_A_loss: 1.0793, G_B_loss: 0.8127\n",
      "Epoch [182/200], Step [491/1067], D_A_loss: 0.1305, D_B_loss: 0.0505, G_A_loss: 0.5430, G_B_loss: 0.4629\n",
      "Epoch [182/200], Step [501/1067], D_A_loss: 0.1266, D_B_loss: 0.0108, G_A_loss: 0.9267, G_B_loss: 0.8781\n",
      "Epoch [182/200], Step [511/1067], D_A_loss: 0.0684, D_B_loss: 0.0254, G_A_loss: 0.6869, G_B_loss: 0.6588\n",
      "Epoch [182/200], Step [521/1067], D_A_loss: 0.0499, D_B_loss: 0.0134, G_A_loss: 0.9192, G_B_loss: 0.9084\n",
      "Epoch [182/200], Step [531/1067], D_A_loss: 0.0299, D_B_loss: 0.0191, G_A_loss: 0.7499, G_B_loss: 0.3755\n",
      "Epoch [182/200], Step [541/1067], D_A_loss: 0.0290, D_B_loss: 0.0629, G_A_loss: 1.0914, G_B_loss: 0.9906\n",
      "Epoch [182/200], Step [551/1067], D_A_loss: 0.1037, D_B_loss: 0.0117, G_A_loss: 1.1753, G_B_loss: 0.3992\n",
      "Epoch [182/200], Step [561/1067], D_A_loss: 0.1161, D_B_loss: 0.0481, G_A_loss: 0.6560, G_B_loss: 0.3771\n",
      "Epoch [182/200], Step [571/1067], D_A_loss: 0.0522, D_B_loss: 0.0235, G_A_loss: 0.7187, G_B_loss: 0.6510\n",
      "Epoch [182/200], Step [581/1067], D_A_loss: 0.1624, D_B_loss: 0.0141, G_A_loss: 0.4669, G_B_loss: 0.6801\n",
      "Epoch [182/200], Step [591/1067], D_A_loss: 0.0687, D_B_loss: 0.0205, G_A_loss: 0.7459, G_B_loss: 0.9300\n",
      "Epoch [182/200], Step [601/1067], D_A_loss: 0.0596, D_B_loss: 0.0144, G_A_loss: 1.1774, G_B_loss: 0.5408\n",
      "Epoch [182/200], Step [611/1067], D_A_loss: 0.0418, D_B_loss: 0.0222, G_A_loss: 1.1303, G_B_loss: 0.7080\n",
      "Epoch [182/200], Step [621/1067], D_A_loss: 0.0262, D_B_loss: 0.0288, G_A_loss: 0.9309, G_B_loss: 0.9440\n",
      "Epoch [182/200], Step [631/1067], D_A_loss: 0.0193, D_B_loss: 0.0116, G_A_loss: 0.9109, G_B_loss: 0.9593\n",
      "Epoch [182/200], Step [641/1067], D_A_loss: 0.0290, D_B_loss: 0.0109, G_A_loss: 1.0096, G_B_loss: 0.5265\n",
      "Epoch [182/200], Step [651/1067], D_A_loss: 0.0391, D_B_loss: 0.0113, G_A_loss: 0.8499, G_B_loss: 0.8505\n",
      "Epoch [182/200], Step [661/1067], D_A_loss: 0.0345, D_B_loss: 0.0299, G_A_loss: 0.6863, G_B_loss: 0.7378\n",
      "Epoch [182/200], Step [671/1067], D_A_loss: 0.0339, D_B_loss: 0.0093, G_A_loss: 0.9452, G_B_loss: 0.9520\n",
      "Epoch [182/200], Step [681/1067], D_A_loss: 0.1962, D_B_loss: 0.0095, G_A_loss: 0.9195, G_B_loss: 0.1866\n",
      "Epoch [182/200], Step [691/1067], D_A_loss: 0.0293, D_B_loss: 0.0103, G_A_loss: 0.9473, G_B_loss: 0.4835\n",
      "Epoch [182/200], Step [701/1067], D_A_loss: 0.1060, D_B_loss: 0.0385, G_A_loss: 1.0820, G_B_loss: 0.7695\n",
      "Epoch [182/200], Step [711/1067], D_A_loss: 0.0994, D_B_loss: 0.0480, G_A_loss: 1.1612, G_B_loss: 0.7378\n",
      "Epoch [182/200], Step [721/1067], D_A_loss: 0.1481, D_B_loss: 0.0555, G_A_loss: 0.6857, G_B_loss: 0.5641\n",
      "Epoch [182/200], Step [731/1067], D_A_loss: 0.0259, D_B_loss: 0.0192, G_A_loss: 0.7698, G_B_loss: 1.0230\n",
      "Epoch [182/200], Step [741/1067], D_A_loss: 0.0628, D_B_loss: 0.0203, G_A_loss: 0.6999, G_B_loss: 0.4427\n",
      "Epoch [182/200], Step [751/1067], D_A_loss: 0.1819, D_B_loss: 0.0552, G_A_loss: 1.2440, G_B_loss: 0.6548\n",
      "Epoch [182/200], Step [761/1067], D_A_loss: 0.0453, D_B_loss: 0.0788, G_A_loss: 0.7642, G_B_loss: 0.4160\n",
      "Epoch [182/200], Step [771/1067], D_A_loss: 0.1041, D_B_loss: 0.0213, G_A_loss: 0.9245, G_B_loss: 0.8229\n",
      "Epoch [182/200], Step [781/1067], D_A_loss: 0.0452, D_B_loss: 0.0489, G_A_loss: 0.9490, G_B_loss: 0.7086\n",
      "Epoch [182/200], Step [791/1067], D_A_loss: 0.0268, D_B_loss: 0.0299, G_A_loss: 0.7911, G_B_loss: 0.9139\n",
      "Epoch [182/200], Step [801/1067], D_A_loss: 0.0929, D_B_loss: 0.0107, G_A_loss: 0.6142, G_B_loss: 0.9841\n",
      "Epoch [182/200], Step [811/1067], D_A_loss: 0.0336, D_B_loss: 0.0303, G_A_loss: 0.6324, G_B_loss: 0.6916\n",
      "Epoch [182/200], Step [821/1067], D_A_loss: 0.0308, D_B_loss: 0.0161, G_A_loss: 0.8804, G_B_loss: 0.2561\n",
      "Epoch [182/200], Step [831/1067], D_A_loss: 0.0888, D_B_loss: 0.0096, G_A_loss: 1.1713, G_B_loss: 0.4581\n",
      "Epoch [182/200], Step [841/1067], D_A_loss: 0.0510, D_B_loss: 0.0230, G_A_loss: 0.8023, G_B_loss: 1.0202\n",
      "Epoch [182/200], Step [851/1067], D_A_loss: 0.1614, D_B_loss: 0.0411, G_A_loss: 1.1834, G_B_loss: 0.9002\n",
      "Epoch [182/200], Step [861/1067], D_A_loss: 0.1036, D_B_loss: 0.0237, G_A_loss: 0.6737, G_B_loss: 0.7308\n",
      "Epoch [182/200], Step [871/1067], D_A_loss: 0.0258, D_B_loss: 0.0292, G_A_loss: 0.9142, G_B_loss: 0.5411\n",
      "Epoch [182/200], Step [881/1067], D_A_loss: 0.0888, D_B_loss: 0.0230, G_A_loss: 0.6916, G_B_loss: 0.5233\n",
      "Epoch [182/200], Step [891/1067], D_A_loss: 0.0459, D_B_loss: 0.0206, G_A_loss: 0.8780, G_B_loss: 0.5725\n",
      "Epoch [182/200], Step [901/1067], D_A_loss: 0.0256, D_B_loss: 0.0256, G_A_loss: 0.6862, G_B_loss: 0.8305\n",
      "Epoch [182/200], Step [911/1067], D_A_loss: 0.1165, D_B_loss: 0.0199, G_A_loss: 1.1977, G_B_loss: 0.7048\n",
      "Epoch [182/200], Step [921/1067], D_A_loss: 0.1594, D_B_loss: 0.0126, G_A_loss: 0.8061, G_B_loss: 0.6588\n",
      "Epoch [182/200], Step [931/1067], D_A_loss: 0.0925, D_B_loss: 0.0289, G_A_loss: 0.6154, G_B_loss: 1.0577\n",
      "Epoch [182/200], Step [941/1067], D_A_loss: 0.1945, D_B_loss: 0.0190, G_A_loss: 1.0384, G_B_loss: 0.5336\n",
      "Epoch [182/200], Step [951/1067], D_A_loss: 0.0307, D_B_loss: 0.0164, G_A_loss: 0.8118, G_B_loss: 0.4969\n",
      "Epoch [182/200], Step [961/1067], D_A_loss: 0.0898, D_B_loss: 0.0121, G_A_loss: 0.8967, G_B_loss: 1.1774\n",
      "Epoch [182/200], Step [971/1067], D_A_loss: 0.0541, D_B_loss: 0.0212, G_A_loss: 0.8153, G_B_loss: 0.6919\n",
      "Epoch [182/200], Step [981/1067], D_A_loss: 0.0256, D_B_loss: 0.0107, G_A_loss: 0.5858, G_B_loss: 0.8906\n",
      "Epoch [182/200], Step [991/1067], D_A_loss: 0.0320, D_B_loss: 0.0154, G_A_loss: 0.7747, G_B_loss: 0.7786\n",
      "Epoch [182/200], Step [1001/1067], D_A_loss: 0.0546, D_B_loss: 0.0107, G_A_loss: 0.9178, G_B_loss: 0.5713\n",
      "Epoch [182/200], Step [1011/1067], D_A_loss: 0.0386, D_B_loss: 0.0102, G_A_loss: 1.0204, G_B_loss: 0.8345\n",
      "Epoch [182/200], Step [1021/1067], D_A_loss: 0.0462, D_B_loss: 0.0292, G_A_loss: 0.7448, G_B_loss: 0.7157\n",
      "Epoch [182/200], Step [1031/1067], D_A_loss: 0.1546, D_B_loss: 0.0387, G_A_loss: 0.5805, G_B_loss: 0.6698\n",
      "Epoch [182/200], Step [1041/1067], D_A_loss: 0.0262, D_B_loss: 0.0318, G_A_loss: 0.6336, G_B_loss: 0.5911\n",
      "Epoch [182/200], Step [1051/1067], D_A_loss: 0.0201, D_B_loss: 0.0137, G_A_loss: 0.8579, G_B_loss: 0.9411\n",
      "Epoch [182/200], Step [1061/1067], D_A_loss: 0.0709, D_B_loss: 0.0207, G_A_loss: 0.8293, G_B_loss: 0.6102\n",
      "Epoch [183/200], Step [1/1067], D_A_loss: 0.1807, D_B_loss: 0.0342, G_A_loss: 1.0353, G_B_loss: 1.0006\n",
      "Epoch [183/200], Step [11/1067], D_A_loss: 0.1952, D_B_loss: 0.0224, G_A_loss: 0.8760, G_B_loss: 0.5378\n",
      "Epoch [183/200], Step [21/1067], D_A_loss: 0.2003, D_B_loss: 0.0581, G_A_loss: 0.6204, G_B_loss: 0.9432\n",
      "Epoch [183/200], Step [31/1067], D_A_loss: 0.1168, D_B_loss: 0.0075, G_A_loss: 0.5257, G_B_loss: 0.6010\n",
      "Epoch [183/200], Step [41/1067], D_A_loss: 0.0246, D_B_loss: 0.0304, G_A_loss: 1.0481, G_B_loss: 0.5555\n",
      "Epoch [183/200], Step [51/1067], D_A_loss: 0.0285, D_B_loss: 0.0180, G_A_loss: 1.2086, G_B_loss: 0.7526\n",
      "Epoch [183/200], Step [61/1067], D_A_loss: 0.0642, D_B_loss: 0.0109, G_A_loss: 0.9239, G_B_loss: 0.3873\n",
      "Epoch [183/200], Step [71/1067], D_A_loss: 0.0775, D_B_loss: 0.0122, G_A_loss: 0.9123, G_B_loss: 0.5597\n",
      "Epoch [183/200], Step [81/1067], D_A_loss: 0.1042, D_B_loss: 0.0145, G_A_loss: 0.8722, G_B_loss: 0.3854\n",
      "Epoch [183/200], Step [91/1067], D_A_loss: 0.0681, D_B_loss: 0.0146, G_A_loss: 0.7968, G_B_loss: 0.5325\n",
      "Epoch [183/200], Step [101/1067], D_A_loss: 0.1424, D_B_loss: 0.0140, G_A_loss: 0.8900, G_B_loss: 0.5056\n",
      "Epoch [183/200], Step [111/1067], D_A_loss: 0.1302, D_B_loss: 0.0341, G_A_loss: 0.8125, G_B_loss: 0.5832\n",
      "Epoch [183/200], Step [121/1067], D_A_loss: 0.0601, D_B_loss: 0.0103, G_A_loss: 1.0915, G_B_loss: 0.8763\n",
      "Epoch [183/200], Step [131/1067], D_A_loss: 0.0606, D_B_loss: 0.0098, G_A_loss: 0.8953, G_B_loss: 0.5412\n",
      "Epoch [183/200], Step [141/1067], D_A_loss: 0.0258, D_B_loss: 0.0110, G_A_loss: 0.8510, G_B_loss: 0.8142\n",
      "Epoch [183/200], Step [151/1067], D_A_loss: 0.0798, D_B_loss: 0.0113, G_A_loss: 0.9823, G_B_loss: 0.5015\n",
      "Epoch [183/200], Step [161/1067], D_A_loss: 0.0492, D_B_loss: 0.0235, G_A_loss: 0.9999, G_B_loss: 0.8447\n",
      "Epoch [183/200], Step [171/1067], D_A_loss: 0.0343, D_B_loss: 0.0134, G_A_loss: 0.7518, G_B_loss: 0.7773\n",
      "Epoch [183/200], Step [181/1067], D_A_loss: 0.0961, D_B_loss: 0.0318, G_A_loss: 0.6808, G_B_loss: 0.4071\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [183/200], Step [191/1067], D_A_loss: 0.1443, D_B_loss: 0.0146, G_A_loss: 1.1731, G_B_loss: 0.3118\n",
      "Epoch [183/200], Step [201/1067], D_A_loss: 0.0253, D_B_loss: 0.0197, G_A_loss: 0.7088, G_B_loss: 0.9747\n",
      "Epoch [183/200], Step [211/1067], D_A_loss: 0.0846, D_B_loss: 0.0097, G_A_loss: 0.4885, G_B_loss: 0.7035\n",
      "Epoch [183/200], Step [221/1067], D_A_loss: 0.0397, D_B_loss: 0.0194, G_A_loss: 0.8971, G_B_loss: 0.4874\n",
      "Epoch [183/200], Step [231/1067], D_A_loss: 0.0328, D_B_loss: 0.0134, G_A_loss: 0.9429, G_B_loss: 0.7530\n",
      "Epoch [183/200], Step [241/1067], D_A_loss: 0.0641, D_B_loss: 0.0240, G_A_loss: 1.0802, G_B_loss: 0.7376\n",
      "Epoch [183/200], Step [251/1067], D_A_loss: 0.0443, D_B_loss: 0.0233, G_A_loss: 0.7945, G_B_loss: 1.0138\n",
      "Epoch [183/200], Step [261/1067], D_A_loss: 0.0280, D_B_loss: 0.0093, G_A_loss: 0.9380, G_B_loss: 1.0452\n",
      "Epoch [183/200], Step [271/1067], D_A_loss: 0.0193, D_B_loss: 0.0248, G_A_loss: 0.7972, G_B_loss: 0.6724\n",
      "Epoch [183/200], Step [281/1067], D_A_loss: 0.0679, D_B_loss: 0.0207, G_A_loss: 0.7394, G_B_loss: 0.7479\n",
      "Epoch [183/200], Step [291/1067], D_A_loss: 0.0719, D_B_loss: 0.0138, G_A_loss: 0.8006, G_B_loss: 1.1633\n",
      "Epoch [183/200], Step [301/1067], D_A_loss: 0.0640, D_B_loss: 0.0171, G_A_loss: 0.8667, G_B_loss: 1.1105\n",
      "Epoch [183/200], Step [311/1067], D_A_loss: 0.0302, D_B_loss: 0.0093, G_A_loss: 1.1511, G_B_loss: 0.6659\n",
      "Epoch [183/200], Step [321/1067], D_A_loss: 0.0609, D_B_loss: 0.0332, G_A_loss: 1.0031, G_B_loss: 0.6359\n",
      "Epoch [183/200], Step [331/1067], D_A_loss: 0.0565, D_B_loss: 0.0101, G_A_loss: 0.9850, G_B_loss: 0.8295\n",
      "Epoch [183/200], Step [341/1067], D_A_loss: 0.0410, D_B_loss: 0.0382, G_A_loss: 0.5694, G_B_loss: 0.8510\n",
      "Epoch [183/200], Step [351/1067], D_A_loss: 0.0671, D_B_loss: 0.0338, G_A_loss: 0.7839, G_B_loss: 0.5484\n",
      "Epoch [183/200], Step [361/1067], D_A_loss: 0.0489, D_B_loss: 0.0127, G_A_loss: 0.9529, G_B_loss: 0.9374\n",
      "Epoch [183/200], Step [371/1067], D_A_loss: 0.1269, D_B_loss: 0.0128, G_A_loss: 0.9969, G_B_loss: 0.7999\n",
      "Epoch [183/200], Step [381/1067], D_A_loss: 0.3496, D_B_loss: 0.0110, G_A_loss: 0.9098, G_B_loss: 0.2375\n",
      "Epoch [183/200], Step [391/1067], D_A_loss: 0.0325, D_B_loss: 0.0162, G_A_loss: 0.9959, G_B_loss: 0.4212\n",
      "Epoch [183/200], Step [401/1067], D_A_loss: 0.0384, D_B_loss: 0.0177, G_A_loss: 0.7373, G_B_loss: 0.7741\n",
      "Epoch [183/200], Step [411/1067], D_A_loss: 0.0364, D_B_loss: 0.0237, G_A_loss: 1.2676, G_B_loss: 0.5995\n",
      "Epoch [183/200], Step [421/1067], D_A_loss: 0.0712, D_B_loss: 0.0154, G_A_loss: 0.9952, G_B_loss: 0.6185\n",
      "Epoch [183/200], Step [431/1067], D_A_loss: 0.0264, D_B_loss: 0.0192, G_A_loss: 0.9264, G_B_loss: 0.8436\n",
      "Epoch [183/200], Step [441/1067], D_A_loss: 0.0560, D_B_loss: 0.0475, G_A_loss: 0.9783, G_B_loss: 0.5670\n",
      "Epoch [183/200], Step [451/1067], D_A_loss: 0.0903, D_B_loss: 0.0165, G_A_loss: 0.7929, G_B_loss: 0.3022\n",
      "Epoch [183/200], Step [461/1067], D_A_loss: 0.0667, D_B_loss: 0.0129, G_A_loss: 0.7868, G_B_loss: 0.6172\n",
      "Epoch [183/200], Step [471/1067], D_A_loss: 0.0884, D_B_loss: 0.0184, G_A_loss: 0.7481, G_B_loss: 0.5480\n",
      "Epoch [183/200], Step [481/1067], D_A_loss: 0.0509, D_B_loss: 0.0181, G_A_loss: 0.4922, G_B_loss: 0.5980\n",
      "Epoch [183/200], Step [491/1067], D_A_loss: 0.1409, D_B_loss: 0.0205, G_A_loss: 0.9469, G_B_loss: 0.6489\n",
      "Epoch [183/200], Step [501/1067], D_A_loss: 0.1367, D_B_loss: 0.0439, G_A_loss: 0.6494, G_B_loss: 0.7600\n",
      "Epoch [183/200], Step [511/1067], D_A_loss: 0.1358, D_B_loss: 0.0117, G_A_loss: 0.9267, G_B_loss: 1.1896\n",
      "Epoch [183/200], Step [521/1067], D_A_loss: 0.0415, D_B_loss: 0.0260, G_A_loss: 0.6745, G_B_loss: 0.7710\n",
      "Epoch [183/200], Step [531/1067], D_A_loss: 0.0846, D_B_loss: 0.0243, G_A_loss: 0.7415, G_B_loss: 0.5444\n",
      "Epoch [183/200], Step [541/1067], D_A_loss: 0.0252, D_B_loss: 0.0257, G_A_loss: 0.7324, G_B_loss: 0.9632\n",
      "Epoch [183/200], Step [551/1067], D_A_loss: 0.0230, D_B_loss: 0.0387, G_A_loss: 0.5671, G_B_loss: 0.7124\n",
      "Epoch [183/200], Step [561/1067], D_A_loss: 0.1572, D_B_loss: 0.0120, G_A_loss: 1.0321, G_B_loss: 0.2461\n",
      "Epoch [183/200], Step [571/1067], D_A_loss: 0.0712, D_B_loss: 0.0412, G_A_loss: 0.9179, G_B_loss: 0.6561\n",
      "Epoch [183/200], Step [581/1067], D_A_loss: 0.0494, D_B_loss: 0.0257, G_A_loss: 1.2720, G_B_loss: 0.6803\n",
      "Epoch [183/200], Step [591/1067], D_A_loss: 0.0289, D_B_loss: 0.0137, G_A_loss: 0.8820, G_B_loss: 0.6450\n",
      "Epoch [183/200], Step [601/1067], D_A_loss: 0.0526, D_B_loss: 0.0171, G_A_loss: 0.5344, G_B_loss: 0.9270\n",
      "Epoch [183/200], Step [611/1067], D_A_loss: 0.0419, D_B_loss: 0.0155, G_A_loss: 1.0063, G_B_loss: 0.7999\n",
      "Epoch [183/200], Step [621/1067], D_A_loss: 0.0244, D_B_loss: 0.0132, G_A_loss: 0.9480, G_B_loss: 0.4063\n",
      "Epoch [183/200], Step [631/1067], D_A_loss: 0.0529, D_B_loss: 0.0088, G_A_loss: 0.6047, G_B_loss: 0.7251\n",
      "Epoch [183/200], Step [641/1067], D_A_loss: 0.0380, D_B_loss: 0.0577, G_A_loss: 0.5115, G_B_loss: 1.1239\n",
      "Epoch [183/200], Step [651/1067], D_A_loss: 0.0320, D_B_loss: 0.0072, G_A_loss: 0.9349, G_B_loss: 0.7873\n",
      "Epoch [183/200], Step [661/1067], D_A_loss: 0.0203, D_B_loss: 0.0207, G_A_loss: 0.7560, G_B_loss: 0.8609\n",
      "Epoch [183/200], Step [671/1067], D_A_loss: 0.0483, D_B_loss: 0.0129, G_A_loss: 1.2693, G_B_loss: 0.7774\n",
      "Epoch [183/200], Step [681/1067], D_A_loss: 0.1528, D_B_loss: 0.0253, G_A_loss: 0.7152, G_B_loss: 0.5849\n",
      "Epoch [183/200], Step [691/1067], D_A_loss: 0.0502, D_B_loss: 0.0150, G_A_loss: 0.8921, G_B_loss: 0.3023\n",
      "Epoch [183/200], Step [701/1067], D_A_loss: 0.0441, D_B_loss: 0.0089, G_A_loss: 0.6406, G_B_loss: 0.5724\n",
      "Epoch [183/200], Step [711/1067], D_A_loss: 0.0280, D_B_loss: 0.0338, G_A_loss: 0.9794, G_B_loss: 0.4719\n",
      "Epoch [183/200], Step [721/1067], D_A_loss: 0.0225, D_B_loss: 0.0203, G_A_loss: 1.3184, G_B_loss: 0.6114\n",
      "Epoch [183/200], Step [731/1067], D_A_loss: 0.0322, D_B_loss: 0.0161, G_A_loss: 0.8015, G_B_loss: 0.8470\n",
      "Epoch [183/200], Step [741/1067], D_A_loss: 0.0228, D_B_loss: 0.0819, G_A_loss: 0.9225, G_B_loss: 0.4986\n",
      "Epoch [183/200], Step [751/1067], D_A_loss: 0.1115, D_B_loss: 0.0166, G_A_loss: 1.2113, G_B_loss: 0.7687\n",
      "Epoch [183/200], Step [761/1067], D_A_loss: 0.0364, D_B_loss: 0.0098, G_A_loss: 1.3545, G_B_loss: 0.7402\n",
      "Epoch [183/200], Step [771/1067], D_A_loss: 0.0272, D_B_loss: 0.0149, G_A_loss: 0.9421, G_B_loss: 0.8288\n",
      "Epoch [183/200], Step [781/1067], D_A_loss: 0.0531, D_B_loss: 0.0224, G_A_loss: 0.9961, G_B_loss: 0.7807\n",
      "Epoch [183/200], Step [791/1067], D_A_loss: 0.0567, D_B_loss: 0.0500, G_A_loss: 0.6084, G_B_loss: 0.7288\n",
      "Epoch [183/200], Step [801/1067], D_A_loss: 0.0886, D_B_loss: 0.0160, G_A_loss: 0.8516, G_B_loss: 0.6440\n",
      "Epoch [183/200], Step [811/1067], D_A_loss: 0.0286, D_B_loss: 0.0118, G_A_loss: 0.9759, G_B_loss: 0.7333\n",
      "Epoch [183/200], Step [821/1067], D_A_loss: 0.0518, D_B_loss: 0.0355, G_A_loss: 1.1086, G_B_loss: 0.6081\n",
      "Epoch [183/200], Step [831/1067], D_A_loss: 0.0301, D_B_loss: 0.0161, G_A_loss: 0.8237, G_B_loss: 0.7552\n",
      "Epoch [183/200], Step [841/1067], D_A_loss: 0.0500, D_B_loss: 0.0138, G_A_loss: 0.9618, G_B_loss: 0.6121\n",
      "Epoch [183/200], Step [851/1067], D_A_loss: 0.1183, D_B_loss: 0.0085, G_A_loss: 0.8846, G_B_loss: 0.4913\n",
      "Epoch [183/200], Step [861/1067], D_A_loss: 0.1199, D_B_loss: 0.0080, G_A_loss: 0.9492, G_B_loss: 0.7353\n",
      "Epoch [183/200], Step [871/1067], D_A_loss: 0.1374, D_B_loss: 0.0338, G_A_loss: 0.6115, G_B_loss: 0.4115\n",
      "Epoch [183/200], Step [881/1067], D_A_loss: 0.0337, D_B_loss: 0.0323, G_A_loss: 0.9837, G_B_loss: 1.2514\n",
      "Epoch [183/200], Step [891/1067], D_A_loss: 0.0333, D_B_loss: 0.0153, G_A_loss: 0.6286, G_B_loss: 1.0613\n",
      "Epoch [183/200], Step [901/1067], D_A_loss: 0.0393, D_B_loss: 0.0120, G_A_loss: 0.9868, G_B_loss: 0.6176\n",
      "Epoch [183/200], Step [911/1067], D_A_loss: 0.0283, D_B_loss: 0.0083, G_A_loss: 0.9453, G_B_loss: 0.8908\n",
      "Epoch [183/200], Step [921/1067], D_A_loss: 0.1136, D_B_loss: 0.0211, G_A_loss: 0.7193, G_B_loss: 0.9957\n",
      "Epoch [183/200], Step [931/1067], D_A_loss: 0.0485, D_B_loss: 0.0334, G_A_loss: 1.3590, G_B_loss: 0.5547\n",
      "Epoch [183/200], Step [941/1067], D_A_loss: 0.0189, D_B_loss: 0.0116, G_A_loss: 0.8943, G_B_loss: 0.6609\n",
      "Epoch [183/200], Step [951/1067], D_A_loss: 0.2038, D_B_loss: 0.0185, G_A_loss: 1.2274, G_B_loss: 0.3268\n",
      "Epoch [183/200], Step [961/1067], D_A_loss: 0.0421, D_B_loss: 0.0196, G_A_loss: 0.5412, G_B_loss: 1.0328\n",
      "Epoch [183/200], Step [971/1067], D_A_loss: 0.0402, D_B_loss: 0.0211, G_A_loss: 0.7077, G_B_loss: 0.6771\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [183/200], Step [981/1067], D_A_loss: 0.0564, D_B_loss: 0.0313, G_A_loss: 0.6291, G_B_loss: 0.7540\n",
      "Epoch [183/200], Step [991/1067], D_A_loss: 0.0500, D_B_loss: 0.0291, G_A_loss: 0.6354, G_B_loss: 0.9901\n",
      "Epoch [183/200], Step [1001/1067], D_A_loss: 0.2282, D_B_loss: 0.0530, G_A_loss: 1.0485, G_B_loss: 1.0777\n",
      "Epoch [183/200], Step [1011/1067], D_A_loss: 0.0348, D_B_loss: 0.0228, G_A_loss: 0.7854, G_B_loss: 0.7037\n",
      "Epoch [183/200], Step [1021/1067], D_A_loss: 0.0378, D_B_loss: 0.0350, G_A_loss: 0.4730, G_B_loss: 0.9190\n",
      "Epoch [183/200], Step [1031/1067], D_A_loss: 0.0588, D_B_loss: 0.0730, G_A_loss: 0.9517, G_B_loss: 1.0088\n",
      "Epoch [183/200], Step [1041/1067], D_A_loss: 0.0336, D_B_loss: 0.0134, G_A_loss: 0.7981, G_B_loss: 0.8043\n",
      "Epoch [183/200], Step [1051/1067], D_A_loss: 0.0586, D_B_loss: 0.0461, G_A_loss: 0.8792, G_B_loss: 0.5760\n",
      "Epoch [183/200], Step [1061/1067], D_A_loss: 0.0521, D_B_loss: 0.0082, G_A_loss: 0.9455, G_B_loss: 0.9113\n",
      "Epoch [184/200], Step [1/1067], D_A_loss: 0.0620, D_B_loss: 0.0570, G_A_loss: 0.9583, G_B_loss: 0.7365\n",
      "Epoch [184/200], Step [11/1067], D_A_loss: 0.0880, D_B_loss: 0.0094, G_A_loss: 1.2668, G_B_loss: 0.5229\n",
      "Epoch [184/200], Step [21/1067], D_A_loss: 0.0279, D_B_loss: 0.0586, G_A_loss: 0.8081, G_B_loss: 0.3344\n",
      "Epoch [184/200], Step [31/1067], D_A_loss: 0.0534, D_B_loss: 0.0287, G_A_loss: 0.9608, G_B_loss: 0.6846\n",
      "Epoch [184/200], Step [41/1067], D_A_loss: 0.0522, D_B_loss: 0.0096, G_A_loss: 0.8696, G_B_loss: 1.0611\n",
      "Epoch [184/200], Step [51/1067], D_A_loss: 0.0698, D_B_loss: 0.0129, G_A_loss: 1.0777, G_B_loss: 0.5256\n",
      "Epoch [184/200], Step [61/1067], D_A_loss: 0.0774, D_B_loss: 0.0154, G_A_loss: 0.7582, G_B_loss: 0.5177\n",
      "Epoch [184/200], Step [71/1067], D_A_loss: 0.0472, D_B_loss: 0.0391, G_A_loss: 0.5962, G_B_loss: 0.6940\n",
      "Epoch [184/200], Step [81/1067], D_A_loss: 0.0603, D_B_loss: 0.0156, G_A_loss: 0.8549, G_B_loss: 0.5675\n",
      "Epoch [184/200], Step [91/1067], D_A_loss: 0.0218, D_B_loss: 0.0171, G_A_loss: 0.7584, G_B_loss: 0.8311\n",
      "Epoch [184/200], Step [101/1067], D_A_loss: 0.0922, D_B_loss: 0.0093, G_A_loss: 0.9627, G_B_loss: 0.4103\n",
      "Epoch [184/200], Step [111/1067], D_A_loss: 0.0333, D_B_loss: 0.0094, G_A_loss: 0.9276, G_B_loss: 0.4981\n",
      "Epoch [184/200], Step [121/1067], D_A_loss: 0.0905, D_B_loss: 0.0148, G_A_loss: 0.8074, G_B_loss: 0.5387\n",
      "Epoch [184/200], Step [131/1067], D_A_loss: 0.0497, D_B_loss: 0.0087, G_A_loss: 0.9378, G_B_loss: 0.7081\n",
      "Epoch [184/200], Step [141/1067], D_A_loss: 0.0499, D_B_loss: 0.0378, G_A_loss: 0.8026, G_B_loss: 0.3942\n",
      "Epoch [184/200], Step [151/1067], D_A_loss: 0.0623, D_B_loss: 0.0122, G_A_loss: 0.8625, G_B_loss: 0.6593\n",
      "Epoch [184/200], Step [161/1067], D_A_loss: 0.0685, D_B_loss: 0.0161, G_A_loss: 0.8158, G_B_loss: 0.8813\n",
      "Epoch [184/200], Step [171/1067], D_A_loss: 0.1116, D_B_loss: 0.0150, G_A_loss: 0.8272, G_B_loss: 0.6401\n",
      "Epoch [184/200], Step [181/1067], D_A_loss: 0.0345, D_B_loss: 0.0138, G_A_loss: 0.8900, G_B_loss: 0.6538\n",
      "Epoch [184/200], Step [191/1067], D_A_loss: 0.0419, D_B_loss: 0.0160, G_A_loss: 1.1179, G_B_loss: 0.7872\n",
      "Epoch [184/200], Step [201/1067], D_A_loss: 0.0943, D_B_loss: 0.0522, G_A_loss: 1.1153, G_B_loss: 0.4101\n",
      "Epoch [184/200], Step [211/1067], D_A_loss: 0.0384, D_B_loss: 0.0089, G_A_loss: 0.9658, G_B_loss: 0.7819\n",
      "Epoch [184/200], Step [221/1067], D_A_loss: 0.1242, D_B_loss: 0.0301, G_A_loss: 0.6449, G_B_loss: 0.4393\n",
      "Epoch [184/200], Step [231/1067], D_A_loss: 0.1378, D_B_loss: 0.0153, G_A_loss: 0.9364, G_B_loss: 0.3964\n",
      "Epoch [184/200], Step [241/1067], D_A_loss: 0.0364, D_B_loss: 0.0198, G_A_loss: 0.8168, G_B_loss: 0.4668\n",
      "Epoch [184/200], Step [251/1067], D_A_loss: 0.1065, D_B_loss: 0.0201, G_A_loss: 0.7265, G_B_loss: 0.6273\n",
      "Epoch [184/200], Step [261/1067], D_A_loss: 0.0488, D_B_loss: 0.0187, G_A_loss: 0.8683, G_B_loss: 0.4304\n",
      "Epoch [184/200], Step [271/1067], D_A_loss: 0.0425, D_B_loss: 0.0259, G_A_loss: 0.6582, G_B_loss: 0.7653\n",
      "Epoch [184/200], Step [281/1067], D_A_loss: 0.0735, D_B_loss: 0.0368, G_A_loss: 0.6630, G_B_loss: 0.5568\n",
      "Epoch [184/200], Step [291/1067], D_A_loss: 0.0221, D_B_loss: 0.0402, G_A_loss: 1.0426, G_B_loss: 0.7554\n",
      "Epoch [184/200], Step [301/1067], D_A_loss: 0.1752, D_B_loss: 0.0123, G_A_loss: 0.8381, G_B_loss: 0.9702\n",
      "Epoch [184/200], Step [311/1067], D_A_loss: 0.0731, D_B_loss: 0.0168, G_A_loss: 0.9088, G_B_loss: 0.8179\n",
      "Epoch [184/200], Step [321/1067], D_A_loss: 0.0724, D_B_loss: 0.0170, G_A_loss: 0.7530, G_B_loss: 0.5425\n",
      "Epoch [184/200], Step [331/1067], D_A_loss: 0.1621, D_B_loss: 0.0232, G_A_loss: 0.9307, G_B_loss: 0.3718\n",
      "Epoch [184/200], Step [341/1067], D_A_loss: 0.0414, D_B_loss: 0.0206, G_A_loss: 0.4774, G_B_loss: 0.7058\n",
      "Epoch [184/200], Step [351/1067], D_A_loss: 0.1201, D_B_loss: 0.0116, G_A_loss: 1.2309, G_B_loss: 1.5408\n",
      "Epoch [184/200], Step [361/1067], D_A_loss: 0.0359, D_B_loss: 0.0174, G_A_loss: 0.7563, G_B_loss: 0.9341\n",
      "Epoch [184/200], Step [371/1067], D_A_loss: 0.0445, D_B_loss: 0.0135, G_A_loss: 0.9948, G_B_loss: 0.8051\n",
      "Epoch [184/200], Step [381/1067], D_A_loss: 0.0913, D_B_loss: 0.0248, G_A_loss: 0.7432, G_B_loss: 0.7261\n",
      "Epoch [184/200], Step [391/1067], D_A_loss: 0.0560, D_B_loss: 0.0114, G_A_loss: 0.9713, G_B_loss: 0.6164\n",
      "Epoch [184/200], Step [401/1067], D_A_loss: 0.0673, D_B_loss: 0.0148, G_A_loss: 0.9700, G_B_loss: 0.6032\n",
      "Epoch [184/200], Step [411/1067], D_A_loss: 0.0443, D_B_loss: 0.0145, G_A_loss: 0.9607, G_B_loss: 0.3795\n",
      "Epoch [184/200], Step [421/1067], D_A_loss: 0.0983, D_B_loss: 0.0278, G_A_loss: 0.6588, G_B_loss: 0.6766\n",
      "Epoch [184/200], Step [431/1067], D_A_loss: 0.1916, D_B_loss: 0.0241, G_A_loss: 0.7467, G_B_loss: 0.5690\n",
      "Epoch [184/200], Step [441/1067], D_A_loss: 0.1574, D_B_loss: 0.0427, G_A_loss: 0.5532, G_B_loss: 0.6587\n",
      "Epoch [184/200], Step [451/1067], D_A_loss: 0.0367, D_B_loss: 0.0325, G_A_loss: 0.7501, G_B_loss: 0.7370\n",
      "Epoch [184/200], Step [461/1067], D_A_loss: 0.0528, D_B_loss: 0.0194, G_A_loss: 0.7299, G_B_loss: 0.6676\n",
      "Epoch [184/200], Step [471/1067], D_A_loss: 0.0393, D_B_loss: 0.0116, G_A_loss: 1.0626, G_B_loss: 1.1889\n",
      "Epoch [184/200], Step [481/1067], D_A_loss: 0.0234, D_B_loss: 0.0216, G_A_loss: 0.7219, G_B_loss: 0.4130\n",
      "Epoch [184/200], Step [491/1067], D_A_loss: 0.0723, D_B_loss: 0.0200, G_A_loss: 0.9189, G_B_loss: 0.6773\n",
      "Epoch [184/200], Step [501/1067], D_A_loss: 0.1396, D_B_loss: 0.0324, G_A_loss: 0.7858, G_B_loss: 0.3144\n",
      "Epoch [184/200], Step [511/1067], D_A_loss: 0.0321, D_B_loss: 0.0364, G_A_loss: 1.5230, G_B_loss: 0.8460\n",
      "Epoch [184/200], Step [521/1067], D_A_loss: 0.0198, D_B_loss: 0.0085, G_A_loss: 1.0579, G_B_loss: 0.5460\n",
      "Epoch [184/200], Step [531/1067], D_A_loss: 0.0251, D_B_loss: 0.0136, G_A_loss: 0.9973, G_B_loss: 1.1176\n",
      "Epoch [184/200], Step [541/1067], D_A_loss: 0.1311, D_B_loss: 0.0194, G_A_loss: 0.9044, G_B_loss: 0.9981\n",
      "Epoch [184/200], Step [551/1067], D_A_loss: 0.0215, D_B_loss: 0.0098, G_A_loss: 0.9236, G_B_loss: 0.7221\n",
      "Epoch [184/200], Step [561/1067], D_A_loss: 0.0420, D_B_loss: 0.0133, G_A_loss: 0.8098, G_B_loss: 0.8753\n",
      "Epoch [184/200], Step [571/1067], D_A_loss: 0.0553, D_B_loss: 0.0160, G_A_loss: 0.8286, G_B_loss: 0.6922\n",
      "Epoch [184/200], Step [581/1067], D_A_loss: 0.0449, D_B_loss: 0.0195, G_A_loss: 0.7806, G_B_loss: 0.2906\n",
      "Epoch [184/200], Step [591/1067], D_A_loss: 0.0630, D_B_loss: 0.0370, G_A_loss: 0.6068, G_B_loss: 0.7383\n",
      "Epoch [184/200], Step [601/1067], D_A_loss: 0.0485, D_B_loss: 0.0100, G_A_loss: 0.5786, G_B_loss: 0.5196\n",
      "Epoch [184/200], Step [611/1067], D_A_loss: 0.0548, D_B_loss: 0.0151, G_A_loss: 0.6929, G_B_loss: 1.1009\n",
      "Epoch [184/200], Step [621/1067], D_A_loss: 0.0848, D_B_loss: 0.0206, G_A_loss: 0.8084, G_B_loss: 0.7772\n",
      "Epoch [184/200], Step [631/1067], D_A_loss: 0.0420, D_B_loss: 0.0188, G_A_loss: 1.0415, G_B_loss: 0.4466\n",
      "Epoch [184/200], Step [641/1067], D_A_loss: 0.0802, D_B_loss: 0.0082, G_A_loss: 0.9809, G_B_loss: 0.6075\n",
      "Epoch [184/200], Step [651/1067], D_A_loss: 0.0283, D_B_loss: 0.0138, G_A_loss: 1.1931, G_B_loss: 0.3314\n",
      "Epoch [184/200], Step [661/1067], D_A_loss: 0.0285, D_B_loss: 0.0508, G_A_loss: 0.8094, G_B_loss: 0.4863\n",
      "Epoch [184/200], Step [671/1067], D_A_loss: 0.0299, D_B_loss: 0.0240, G_A_loss: 0.8348, G_B_loss: 0.7869\n",
      "Epoch [184/200], Step [681/1067], D_A_loss: 0.0444, D_B_loss: 0.1115, G_A_loss: 1.1168, G_B_loss: 0.7459\n",
      "Epoch [184/200], Step [691/1067], D_A_loss: 0.0684, D_B_loss: 0.0524, G_A_loss: 0.8409, G_B_loss: 0.9836\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [184/200], Step [701/1067], D_A_loss: 0.0764, D_B_loss: 0.0681, G_A_loss: 0.8211, G_B_loss: 0.8112\n",
      "Epoch [184/200], Step [711/1067], D_A_loss: 0.0621, D_B_loss: 0.0242, G_A_loss: 0.8045, G_B_loss: 0.8369\n",
      "Epoch [184/200], Step [721/1067], D_A_loss: 0.0437, D_B_loss: 0.0248, G_A_loss: 1.1840, G_B_loss: 0.5351\n",
      "Epoch [184/200], Step [731/1067], D_A_loss: 0.1025, D_B_loss: 0.0324, G_A_loss: 0.8256, G_B_loss: 0.6153\n",
      "Epoch [184/200], Step [741/1067], D_A_loss: 0.1082, D_B_loss: 0.0203, G_A_loss: 1.3752, G_B_loss: 0.4273\n",
      "Epoch [184/200], Step [751/1067], D_A_loss: 0.0758, D_B_loss: 0.1173, G_A_loss: 0.3507, G_B_loss: 0.5626\n",
      "Epoch [184/200], Step [761/1067], D_A_loss: 0.2107, D_B_loss: 0.0120, G_A_loss: 1.0798, G_B_loss: 1.3834\n",
      "Epoch [184/200], Step [771/1067], D_A_loss: 0.0640, D_B_loss: 0.0185, G_A_loss: 0.6740, G_B_loss: 0.7263\n",
      "Epoch [184/200], Step [781/1067], D_A_loss: 0.1352, D_B_loss: 0.0333, G_A_loss: 0.7413, G_B_loss: 0.5975\n",
      "Epoch [184/200], Step [791/1067], D_A_loss: 0.1639, D_B_loss: 0.0111, G_A_loss: 0.6534, G_B_loss: 0.9295\n",
      "Epoch [184/200], Step [801/1067], D_A_loss: 0.0482, D_B_loss: 0.0130, G_A_loss: 1.0610, G_B_loss: 0.6214\n",
      "Epoch [184/200], Step [811/1067], D_A_loss: 0.0439, D_B_loss: 0.0104, G_A_loss: 0.7301, G_B_loss: 0.6963\n",
      "Epoch [184/200], Step [821/1067], D_A_loss: 0.0473, D_B_loss: 0.0542, G_A_loss: 0.7573, G_B_loss: 0.7007\n",
      "Epoch [184/200], Step [831/1067], D_A_loss: 0.0306, D_B_loss: 0.0171, G_A_loss: 0.7366, G_B_loss: 0.4401\n",
      "Epoch [184/200], Step [841/1067], D_A_loss: 0.0589, D_B_loss: 0.0101, G_A_loss: 0.9174, G_B_loss: 0.8077\n",
      "Epoch [184/200], Step [851/1067], D_A_loss: 0.0851, D_B_loss: 0.0471, G_A_loss: 0.5764, G_B_loss: 0.6829\n",
      "Epoch [184/200], Step [861/1067], D_A_loss: 0.0406, D_B_loss: 0.0181, G_A_loss: 1.0518, G_B_loss: 0.8066\n",
      "Epoch [184/200], Step [871/1067], D_A_loss: 0.0621, D_B_loss: 0.0662, G_A_loss: 0.6038, G_B_loss: 0.5273\n",
      "Epoch [184/200], Step [881/1067], D_A_loss: 0.0316, D_B_loss: 0.0273, G_A_loss: 0.6193, G_B_loss: 0.7642\n",
      "Epoch [184/200], Step [891/1067], D_A_loss: 0.0368, D_B_loss: 0.0108, G_A_loss: 0.4420, G_B_loss: 0.4132\n",
      "Epoch [184/200], Step [901/1067], D_A_loss: 0.1084, D_B_loss: 0.0125, G_A_loss: 0.7693, G_B_loss: 0.7549\n",
      "Epoch [184/200], Step [911/1067], D_A_loss: 0.0495, D_B_loss: 0.0355, G_A_loss: 0.9140, G_B_loss: 0.4589\n",
      "Epoch [184/200], Step [921/1067], D_A_loss: 0.0700, D_B_loss: 0.0149, G_A_loss: 0.8731, G_B_loss: 0.6157\n",
      "Epoch [184/200], Step [931/1067], D_A_loss: 0.0254, D_B_loss: 0.0148, G_A_loss: 0.9189, G_B_loss: 0.8570\n",
      "Epoch [184/200], Step [941/1067], D_A_loss: 0.0361, D_B_loss: 0.0130, G_A_loss: 1.1965, G_B_loss: 0.5088\n",
      "Epoch [184/200], Step [951/1067], D_A_loss: 0.0590, D_B_loss: 0.0203, G_A_loss: 1.0499, G_B_loss: 0.7786\n",
      "Epoch [184/200], Step [961/1067], D_A_loss: 0.0258, D_B_loss: 0.0223, G_A_loss: 0.4177, G_B_loss: 0.4613\n",
      "Epoch [184/200], Step [971/1067], D_A_loss: 0.0442, D_B_loss: 0.0099, G_A_loss: 0.8958, G_B_loss: 0.5644\n",
      "Epoch [184/200], Step [981/1067], D_A_loss: 0.0718, D_B_loss: 0.0257, G_A_loss: 0.7119, G_B_loss: 1.0867\n",
      "Epoch [184/200], Step [991/1067], D_A_loss: 0.0269, D_B_loss: 0.0132, G_A_loss: 0.5664, G_B_loss: 1.0310\n",
      "Epoch [184/200], Step [1001/1067], D_A_loss: 0.1888, D_B_loss: 0.0293, G_A_loss: 0.9816, G_B_loss: 0.8202\n",
      "Epoch [184/200], Step [1011/1067], D_A_loss: 0.1099, D_B_loss: 0.0114, G_A_loss: 0.8935, G_B_loss: 0.9637\n",
      "Epoch [184/200], Step [1021/1067], D_A_loss: 0.0301, D_B_loss: 0.0092, G_A_loss: 0.9176, G_B_loss: 0.8483\n",
      "Epoch [184/200], Step [1031/1067], D_A_loss: 0.0184, D_B_loss: 0.0168, G_A_loss: 0.8243, G_B_loss: 0.9682\n",
      "Epoch [184/200], Step [1041/1067], D_A_loss: 0.0487, D_B_loss: 0.0222, G_A_loss: 0.9995, G_B_loss: 0.4448\n",
      "Epoch [184/200], Step [1051/1067], D_A_loss: 0.0814, D_B_loss: 0.0148, G_A_loss: 1.1885, G_B_loss: 0.5119\n",
      "Epoch [184/200], Step [1061/1067], D_A_loss: 0.1412, D_B_loss: 0.0247, G_A_loss: 1.1309, G_B_loss: 0.7767\n",
      "Epoch [185/200], Step [1/1067], D_A_loss: 0.0315, D_B_loss: 0.0091, G_A_loss: 0.9686, G_B_loss: 0.5170\n",
      "Epoch [185/200], Step [11/1067], D_A_loss: 0.0806, D_B_loss: 0.0767, G_A_loss: 0.5641, G_B_loss: 0.4610\n",
      "Epoch [185/200], Step [21/1067], D_A_loss: 0.1194, D_B_loss: 0.0862, G_A_loss: 0.6671, G_B_loss: 0.6074\n",
      "Epoch [185/200], Step [31/1067], D_A_loss: 0.0229, D_B_loss: 0.0353, G_A_loss: 1.1583, G_B_loss: 0.8038\n",
      "Epoch [185/200], Step [41/1067], D_A_loss: 0.0260, D_B_loss: 0.0117, G_A_loss: 1.0078, G_B_loss: 0.7726\n",
      "Epoch [185/200], Step [51/1067], D_A_loss: 0.0508, D_B_loss: 0.0149, G_A_loss: 0.6647, G_B_loss: 0.7754\n",
      "Epoch [185/200], Step [61/1067], D_A_loss: 0.0679, D_B_loss: 0.0086, G_A_loss: 0.9239, G_B_loss: 1.0077\n",
      "Epoch [185/200], Step [71/1067], D_A_loss: 0.0234, D_B_loss: 0.0206, G_A_loss: 0.8175, G_B_loss: 0.3827\n",
      "Epoch [185/200], Step [81/1067], D_A_loss: 0.0626, D_B_loss: 0.0274, G_A_loss: 0.8441, G_B_loss: 0.8353\n",
      "Epoch [185/200], Step [91/1067], D_A_loss: 0.0827, D_B_loss: 0.0086, G_A_loss: 0.9590, G_B_loss: 0.7444\n",
      "Epoch [185/200], Step [101/1067], D_A_loss: 0.0551, D_B_loss: 0.0260, G_A_loss: 0.6942, G_B_loss: 0.5715\n",
      "Epoch [185/200], Step [111/1067], D_A_loss: 0.0673, D_B_loss: 0.0128, G_A_loss: 1.0791, G_B_loss: 0.6159\n",
      "Epoch [185/200], Step [121/1067], D_A_loss: 0.0348, D_B_loss: 0.0101, G_A_loss: 1.2211, G_B_loss: 0.8533\n",
      "Epoch [185/200], Step [131/1067], D_A_loss: 0.0266, D_B_loss: 0.0348, G_A_loss: 0.9105, G_B_loss: 0.8298\n",
      "Epoch [185/200], Step [141/1067], D_A_loss: 0.0676, D_B_loss: 0.0088, G_A_loss: 0.9728, G_B_loss: 0.6918\n",
      "Epoch [185/200], Step [151/1067], D_A_loss: 0.0828, D_B_loss: 0.0084, G_A_loss: 1.0681, G_B_loss: 0.5915\n",
      "Epoch [185/200], Step [161/1067], D_A_loss: 0.0728, D_B_loss: 0.0793, G_A_loss: 0.4024, G_B_loss: 0.6122\n",
      "Epoch [185/200], Step [171/1067], D_A_loss: 0.0399, D_B_loss: 0.0369, G_A_loss: 0.5788, G_B_loss: 0.6630\n",
      "Epoch [185/200], Step [181/1067], D_A_loss: 0.0307, D_B_loss: 0.0362, G_A_loss: 0.7856, G_B_loss: 0.5684\n",
      "Epoch [185/200], Step [191/1067], D_A_loss: 0.0391, D_B_loss: 0.0158, G_A_loss: 0.5127, G_B_loss: 0.8214\n",
      "Epoch [185/200], Step [201/1067], D_A_loss: 0.0523, D_B_loss: 0.0189, G_A_loss: 1.1906, G_B_loss: 0.5411\n",
      "Epoch [185/200], Step [211/1067], D_A_loss: 0.2450, D_B_loss: 0.0120, G_A_loss: 0.7360, G_B_loss: 0.3624\n",
      "Epoch [185/200], Step [221/1067], D_A_loss: 0.0901, D_B_loss: 0.0141, G_A_loss: 0.9714, G_B_loss: 0.4344\n",
      "Epoch [185/200], Step [231/1067], D_A_loss: 0.0405, D_B_loss: 0.0076, G_A_loss: 1.0221, G_B_loss: 0.9645\n",
      "Epoch [185/200], Step [241/1067], D_A_loss: 0.0869, D_B_loss: 0.0097, G_A_loss: 0.7135, G_B_loss: 0.4836\n",
      "Epoch [185/200], Step [251/1067], D_A_loss: 0.0297, D_B_loss: 0.0562, G_A_loss: 0.8757, G_B_loss: 0.7955\n",
      "Epoch [185/200], Step [261/1067], D_A_loss: 0.0274, D_B_loss: 0.0072, G_A_loss: 0.9878, G_B_loss: 0.7871\n",
      "Epoch [185/200], Step [271/1067], D_A_loss: 0.0385, D_B_loss: 0.0347, G_A_loss: 1.4437, G_B_loss: 0.6597\n",
      "Epoch [185/200], Step [281/1067], D_A_loss: 0.0933, D_B_loss: 0.0168, G_A_loss: 0.7850, G_B_loss: 0.6467\n",
      "Epoch [185/200], Step [291/1067], D_A_loss: 0.0791, D_B_loss: 0.0274, G_A_loss: 1.0274, G_B_loss: 0.5798\n",
      "Epoch [185/200], Step [301/1067], D_A_loss: 0.0742, D_B_loss: 0.0187, G_A_loss: 0.7886, G_B_loss: 0.9450\n",
      "Epoch [185/200], Step [311/1067], D_A_loss: 0.0535, D_B_loss: 0.0725, G_A_loss: 0.8430, G_B_loss: 0.2634\n",
      "Epoch [185/200], Step [321/1067], D_A_loss: 0.0502, D_B_loss: 0.0269, G_A_loss: 0.8123, G_B_loss: 0.7343\n",
      "Epoch [185/200], Step [331/1067], D_A_loss: 0.0714, D_B_loss: 0.0645, G_A_loss: 1.0765, G_B_loss: 0.6058\n",
      "Epoch [185/200], Step [341/1067], D_A_loss: 0.1656, D_B_loss: 0.0417, G_A_loss: 1.1989, G_B_loss: 0.5451\n",
      "Epoch [185/200], Step [351/1067], D_A_loss: 0.1559, D_B_loss: 0.0091, G_A_loss: 0.6437, G_B_loss: 0.4085\n",
      "Epoch [185/200], Step [361/1067], D_A_loss: 0.0524, D_B_loss: 0.0189, G_A_loss: 0.9732, G_B_loss: 0.5918\n",
      "Epoch [185/200], Step [371/1067], D_A_loss: 0.0287, D_B_loss: 0.0797, G_A_loss: 0.9758, G_B_loss: 0.8402\n",
      "Epoch [185/200], Step [381/1067], D_A_loss: 0.0809, D_B_loss: 0.0230, G_A_loss: 0.7698, G_B_loss: 0.5162\n",
      "Epoch [185/200], Step [391/1067], D_A_loss: 0.1357, D_B_loss: 0.0474, G_A_loss: 0.8979, G_B_loss: 0.3695\n",
      "Epoch [185/200], Step [401/1067], D_A_loss: 0.1463, D_B_loss: 0.0317, G_A_loss: 0.6264, G_B_loss: 0.6563\n",
      "Epoch [185/200], Step [411/1067], D_A_loss: 0.0797, D_B_loss: 0.0098, G_A_loss: 0.9050, G_B_loss: 0.6542\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [185/200], Step [421/1067], D_A_loss: 0.0303, D_B_loss: 0.0234, G_A_loss: 0.5828, G_B_loss: 0.6659\n",
      "Epoch [185/200], Step [431/1067], D_A_loss: 0.0465, D_B_loss: 0.0180, G_A_loss: 1.1703, G_B_loss: 0.8956\n",
      "Epoch [185/200], Step [441/1067], D_A_loss: 0.0283, D_B_loss: 0.0355, G_A_loss: 1.4516, G_B_loss: 0.6096\n",
      "Epoch [185/200], Step [451/1067], D_A_loss: 0.0484, D_B_loss: 0.0272, G_A_loss: 0.9230, G_B_loss: 0.5407\n",
      "Epoch [185/200], Step [461/1067], D_A_loss: 0.0626, D_B_loss: 0.0262, G_A_loss: 0.7575, G_B_loss: 0.6280\n",
      "Epoch [185/200], Step [471/1067], D_A_loss: 0.0802, D_B_loss: 0.0097, G_A_loss: 0.9188, G_B_loss: 0.4775\n",
      "Epoch [185/200], Step [481/1067], D_A_loss: 0.0833, D_B_loss: 0.0245, G_A_loss: 0.6752, G_B_loss: 0.4877\n",
      "Epoch [185/200], Step [491/1067], D_A_loss: 0.0326, D_B_loss: 0.0170, G_A_loss: 0.7581, G_B_loss: 0.7841\n",
      "Epoch [185/200], Step [501/1067], D_A_loss: 0.1178, D_B_loss: 0.0477, G_A_loss: 0.6210, G_B_loss: 0.7548\n",
      "Epoch [185/200], Step [511/1067], D_A_loss: 0.0373, D_B_loss: 0.0488, G_A_loss: 0.7711, G_B_loss: 1.1815\n",
      "Epoch [185/200], Step [521/1067], D_A_loss: 0.0595, D_B_loss: 0.0105, G_A_loss: 1.1585, G_B_loss: 0.6396\n",
      "Epoch [185/200], Step [531/1067], D_A_loss: 0.0710, D_B_loss: 0.0113, G_A_loss: 0.8228, G_B_loss: 0.6677\n",
      "Epoch [185/200], Step [541/1067], D_A_loss: 0.0258, D_B_loss: 0.0320, G_A_loss: 0.8823, G_B_loss: 0.5022\n",
      "Epoch [185/200], Step [551/1067], D_A_loss: 0.0513, D_B_loss: 0.0314, G_A_loss: 0.8833, G_B_loss: 0.6086\n",
      "Epoch [185/200], Step [561/1067], D_A_loss: 0.0820, D_B_loss: 0.0516, G_A_loss: 0.8511, G_B_loss: 0.5649\n",
      "Epoch [185/200], Step [571/1067], D_A_loss: 0.0630, D_B_loss: 0.0134, G_A_loss: 1.1520, G_B_loss: 0.9481\n",
      "Epoch [185/200], Step [581/1067], D_A_loss: 0.0991, D_B_loss: 0.0415, G_A_loss: 0.6832, G_B_loss: 0.4072\n",
      "Epoch [185/200], Step [591/1067], D_A_loss: 0.0246, D_B_loss: 0.0189, G_A_loss: 0.7367, G_B_loss: 0.5481\n",
      "Epoch [185/200], Step [601/1067], D_A_loss: 0.0233, D_B_loss: 0.0311, G_A_loss: 0.5335, G_B_loss: 0.8881\n",
      "Epoch [185/200], Step [611/1067], D_A_loss: 0.1123, D_B_loss: 0.0481, G_A_loss: 0.5562, G_B_loss: 0.9243\n",
      "Epoch [185/200], Step [621/1067], D_A_loss: 0.0672, D_B_loss: 0.0248, G_A_loss: 1.3171, G_B_loss: 0.4300\n",
      "Epoch [185/200], Step [631/1067], D_A_loss: 0.1031, D_B_loss: 0.0218, G_A_loss: 0.9143, G_B_loss: 0.7260\n",
      "Epoch [185/200], Step [641/1067], D_A_loss: 0.0594, D_B_loss: 0.0166, G_A_loss: 1.1262, G_B_loss: 0.9869\n",
      "Epoch [185/200], Step [651/1067], D_A_loss: 0.0239, D_B_loss: 0.0197, G_A_loss: 0.7539, G_B_loss: 0.8418\n",
      "Epoch [185/200], Step [661/1067], D_A_loss: 0.0607, D_B_loss: 0.0278, G_A_loss: 0.6481, G_B_loss: 0.5000\n",
      "Epoch [185/200], Step [671/1067], D_A_loss: 0.1214, D_B_loss: 0.0103, G_A_loss: 0.7897, G_B_loss: 0.8410\n",
      "Epoch [185/200], Step [681/1067], D_A_loss: 0.0500, D_B_loss: 0.0601, G_A_loss: 1.3590, G_B_loss: 0.6657\n",
      "Epoch [185/200], Step [691/1067], D_A_loss: 0.0465, D_B_loss: 0.0316, G_A_loss: 0.7587, G_B_loss: 0.9597\n",
      "Epoch [185/200], Step [701/1067], D_A_loss: 0.0615, D_B_loss: 0.0529, G_A_loss: 1.1559, G_B_loss: 0.7371\n",
      "Epoch [185/200], Step [711/1067], D_A_loss: 0.0687, D_B_loss: 0.0133, G_A_loss: 0.8099, G_B_loss: 0.5307\n",
      "Epoch [185/200], Step [721/1067], D_A_loss: 0.0664, D_B_loss: 0.0551, G_A_loss: 0.8459, G_B_loss: 0.5286\n",
      "Epoch [185/200], Step [731/1067], D_A_loss: 0.0256, D_B_loss: 0.0093, G_A_loss: 0.9764, G_B_loss: 0.7493\n",
      "Epoch [185/200], Step [741/1067], D_A_loss: 0.1091, D_B_loss: 0.0243, G_A_loss: 0.8915, G_B_loss: 0.4687\n",
      "Epoch [185/200], Step [751/1067], D_A_loss: 0.1606, D_B_loss: 0.0237, G_A_loss: 1.0806, G_B_loss: 0.4750\n",
      "Epoch [185/200], Step [761/1067], D_A_loss: 0.0337, D_B_loss: 0.0329, G_A_loss: 0.6307, G_B_loss: 0.6475\n",
      "Epoch [185/200], Step [771/1067], D_A_loss: 0.0435, D_B_loss: 0.0355, G_A_loss: 0.6311, G_B_loss: 0.8571\n",
      "Epoch [185/200], Step [781/1067], D_A_loss: 0.1053, D_B_loss: 0.0326, G_A_loss: 0.6296, G_B_loss: 0.9601\n",
      "Epoch [185/200], Step [791/1067], D_A_loss: 0.0362, D_B_loss: 0.0187, G_A_loss: 0.8571, G_B_loss: 0.8019\n",
      "Epoch [185/200], Step [801/1067], D_A_loss: 0.0308, D_B_loss: 0.0371, G_A_loss: 0.6321, G_B_loss: 0.5874\n",
      "Epoch [185/200], Step [811/1067], D_A_loss: 0.1479, D_B_loss: 0.0188, G_A_loss: 0.7495, G_B_loss: 0.5252\n",
      "Epoch [185/200], Step [821/1067], D_A_loss: 0.0880, D_B_loss: 0.0447, G_A_loss: 0.8325, G_B_loss: 0.4338\n",
      "Epoch [185/200], Step [831/1067], D_A_loss: 0.0391, D_B_loss: 0.0149, G_A_loss: 0.7896, G_B_loss: 0.6342\n",
      "Epoch [185/200], Step [841/1067], D_A_loss: 0.0819, D_B_loss: 0.0097, G_A_loss: 1.2432, G_B_loss: 0.4426\n",
      "Epoch [185/200], Step [851/1067], D_A_loss: 0.0464, D_B_loss: 0.0265, G_A_loss: 0.9139, G_B_loss: 1.2767\n",
      "Epoch [185/200], Step [861/1067], D_A_loss: 0.0352, D_B_loss: 0.0073, G_A_loss: 0.7067, G_B_loss: 0.7966\n",
      "Epoch [185/200], Step [871/1067], D_A_loss: 0.0320, D_B_loss: 0.0140, G_A_loss: 0.7141, G_B_loss: 0.7415\n",
      "Epoch [185/200], Step [881/1067], D_A_loss: 0.0315, D_B_loss: 0.0263, G_A_loss: 0.3902, G_B_loss: 0.4081\n",
      "Epoch [185/200], Step [891/1067], D_A_loss: 0.0288, D_B_loss: 0.0256, G_A_loss: 1.3788, G_B_loss: 0.4269\n",
      "Epoch [185/200], Step [901/1067], D_A_loss: 0.0982, D_B_loss: 0.0418, G_A_loss: 0.5580, G_B_loss: 0.7004\n",
      "Epoch [185/200], Step [911/1067], D_A_loss: 0.1238, D_B_loss: 0.0339, G_A_loss: 0.7219, G_B_loss: 0.7424\n",
      "Epoch [185/200], Step [921/1067], D_A_loss: 0.1892, D_B_loss: 0.0115, G_A_loss: 1.1333, G_B_loss: 0.5178\n",
      "Epoch [185/200], Step [931/1067], D_A_loss: 0.0321, D_B_loss: 0.0166, G_A_loss: 1.1493, G_B_loss: 0.2841\n",
      "Epoch [185/200], Step [941/1067], D_A_loss: 0.0634, D_B_loss: 0.0088, G_A_loss: 1.2323, G_B_loss: 0.8325\n",
      "Epoch [185/200], Step [951/1067], D_A_loss: 0.0678, D_B_loss: 0.0096, G_A_loss: 0.5257, G_B_loss: 0.4795\n",
      "Epoch [185/200], Step [961/1067], D_A_loss: 0.0157, D_B_loss: 0.0850, G_A_loss: 0.6889, G_B_loss: 0.4634\n",
      "Epoch [185/200], Step [971/1067], D_A_loss: 0.0971, D_B_loss: 0.0481, G_A_loss: 1.0780, G_B_loss: 0.7665\n",
      "Epoch [185/200], Step [981/1067], D_A_loss: 0.0274, D_B_loss: 0.0338, G_A_loss: 0.6224, G_B_loss: 0.8584\n",
      "Epoch [185/200], Step [991/1067], D_A_loss: 0.0280, D_B_loss: 0.0457, G_A_loss: 0.5671, G_B_loss: 0.9815\n",
      "Epoch [185/200], Step [1001/1067], D_A_loss: 0.2264, D_B_loss: 0.0212, G_A_loss: 0.9238, G_B_loss: 0.8199\n",
      "Epoch [185/200], Step [1011/1067], D_A_loss: 0.1797, D_B_loss: 0.0548, G_A_loss: 1.0506, G_B_loss: 0.5761\n",
      "Epoch [185/200], Step [1021/1067], D_A_loss: 0.0420, D_B_loss: 0.0211, G_A_loss: 0.8146, G_B_loss: 0.6960\n",
      "Epoch [185/200], Step [1031/1067], D_A_loss: 0.0546, D_B_loss: 0.0160, G_A_loss: 0.7974, G_B_loss: 0.8753\n",
      "Epoch [185/200], Step [1041/1067], D_A_loss: 0.0679, D_B_loss: 0.0739, G_A_loss: 0.4391, G_B_loss: 0.5438\n",
      "Epoch [185/200], Step [1051/1067], D_A_loss: 0.0510, D_B_loss: 0.0197, G_A_loss: 0.7421, G_B_loss: 0.9204\n",
      "Epoch [185/200], Step [1061/1067], D_A_loss: 0.1597, D_B_loss: 0.0162, G_A_loss: 0.8848, G_B_loss: 0.6864\n",
      "Epoch [186/200], Step [1/1067], D_A_loss: 0.1054, D_B_loss: 0.0389, G_A_loss: 1.1143, G_B_loss: 0.4805\n",
      "Epoch [186/200], Step [11/1067], D_A_loss: 0.0719, D_B_loss: 0.0199, G_A_loss: 1.2107, G_B_loss: 0.4831\n",
      "Epoch [186/200], Step [21/1067], D_A_loss: 0.0834, D_B_loss: 0.0101, G_A_loss: 0.7289, G_B_loss: 0.7463\n",
      "Epoch [186/200], Step [31/1067], D_A_loss: 0.0370, D_B_loss: 0.0415, G_A_loss: 0.5533, G_B_loss: 0.9088\n",
      "Epoch [186/200], Step [41/1067], D_A_loss: 0.0234, D_B_loss: 0.0178, G_A_loss: 1.1759, G_B_loss: 0.5481\n",
      "Epoch [186/200], Step [51/1067], D_A_loss: 0.0224, D_B_loss: 0.0099, G_A_loss: 0.8115, G_B_loss: 1.0892\n",
      "Epoch [186/200], Step [61/1067], D_A_loss: 0.1220, D_B_loss: 0.0091, G_A_loss: 1.1998, G_B_loss: 0.5550\n",
      "Epoch [186/200], Step [71/1067], D_A_loss: 0.0632, D_B_loss: 0.0100, G_A_loss: 0.6662, G_B_loss: 0.5347\n",
      "Epoch [186/200], Step [81/1067], D_A_loss: 0.0352, D_B_loss: 0.0098, G_A_loss: 1.0526, G_B_loss: 0.7857\n",
      "Epoch [186/200], Step [91/1067], D_A_loss: 0.1321, D_B_loss: 0.0409, G_A_loss: 0.8305, G_B_loss: 0.7076\n",
      "Epoch [186/200], Step [101/1067], D_A_loss: 0.0360, D_B_loss: 0.0137, G_A_loss: 0.6613, G_B_loss: 0.3709\n",
      "Epoch [186/200], Step [111/1067], D_A_loss: 0.0468, D_B_loss: 0.0084, G_A_loss: 0.9823, G_B_loss: 0.6763\n",
      "Epoch [186/200], Step [121/1067], D_A_loss: 0.0394, D_B_loss: 0.0223, G_A_loss: 0.9109, G_B_loss: 0.7616\n",
      "Epoch [186/200], Step [131/1067], D_A_loss: 0.0303, D_B_loss: 0.0381, G_A_loss: 0.5704, G_B_loss: 0.9606\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [186/200], Step [141/1067], D_A_loss: 0.1064, D_B_loss: 0.0110, G_A_loss: 0.8159, G_B_loss: 0.3922\n",
      "Epoch [186/200], Step [151/1067], D_A_loss: 0.0610, D_B_loss: 0.0170, G_A_loss: 0.7599, G_B_loss: 0.8801\n",
      "Epoch [186/200], Step [161/1067], D_A_loss: 0.0469, D_B_loss: 0.0143, G_A_loss: 0.8253, G_B_loss: 0.5640\n",
      "Epoch [186/200], Step [171/1067], D_A_loss: 0.0565, D_B_loss: 0.0234, G_A_loss: 0.7472, G_B_loss: 0.8772\n",
      "Epoch [186/200], Step [181/1067], D_A_loss: 0.0263, D_B_loss: 0.0304, G_A_loss: 0.7946, G_B_loss: 0.8202\n",
      "Epoch [186/200], Step [191/1067], D_A_loss: 0.0348, D_B_loss: 0.0231, G_A_loss: 1.1489, G_B_loss: 0.6740\n",
      "Epoch [186/200], Step [201/1067], D_A_loss: 0.0507, D_B_loss: 0.0135, G_A_loss: 0.8065, G_B_loss: 0.7669\n",
      "Epoch [186/200], Step [211/1067], D_A_loss: 0.0507, D_B_loss: 0.0743, G_A_loss: 0.8302, G_B_loss: 0.7003\n",
      "Epoch [186/200], Step [221/1067], D_A_loss: 0.0373, D_B_loss: 0.0172, G_A_loss: 0.7724, G_B_loss: 0.8029\n",
      "Epoch [186/200], Step [231/1067], D_A_loss: 0.0358, D_B_loss: 0.0117, G_A_loss: 1.0705, G_B_loss: 0.6880\n",
      "Epoch [186/200], Step [241/1067], D_A_loss: 0.0829, D_B_loss: 0.0160, G_A_loss: 0.7119, G_B_loss: 0.7758\n",
      "Epoch [186/200], Step [251/1067], D_A_loss: 0.0413, D_B_loss: 0.0090, G_A_loss: 0.9630, G_B_loss: 0.8399\n",
      "Epoch [186/200], Step [261/1067], D_A_loss: 0.0311, D_B_loss: 0.0349, G_A_loss: 0.8915, G_B_loss: 1.1744\n",
      "Epoch [186/200], Step [271/1067], D_A_loss: 0.0265, D_B_loss: 0.0339, G_A_loss: 0.7061, G_B_loss: 0.8022\n",
      "Epoch [186/200], Step [281/1067], D_A_loss: 0.1594, D_B_loss: 0.0173, G_A_loss: 0.7592, G_B_loss: 0.9859\n",
      "Epoch [186/200], Step [291/1067], D_A_loss: 0.0202, D_B_loss: 0.0231, G_A_loss: 0.7456, G_B_loss: 0.8530\n",
      "Epoch [186/200], Step [301/1067], D_A_loss: 0.0752, D_B_loss: 0.0127, G_A_loss: 0.9966, G_B_loss: 0.5098\n",
      "Epoch [186/200], Step [311/1067], D_A_loss: 0.1614, D_B_loss: 0.0384, G_A_loss: 0.5795, G_B_loss: 1.0130\n",
      "Epoch [186/200], Step [321/1067], D_A_loss: 0.0372, D_B_loss: 0.0086, G_A_loss: 0.9898, G_B_loss: 1.0956\n",
      "Epoch [186/200], Step [331/1067], D_A_loss: 0.0415, D_B_loss: 0.0215, G_A_loss: 0.7131, G_B_loss: 0.5943\n",
      "Epoch [186/200], Step [341/1067], D_A_loss: 0.0491, D_B_loss: 0.0132, G_A_loss: 0.8191, G_B_loss: 0.6766\n",
      "Epoch [186/200], Step [351/1067], D_A_loss: 0.0428, D_B_loss: 0.0157, G_A_loss: 0.7686, G_B_loss: 0.7077\n",
      "Epoch [186/200], Step [361/1067], D_A_loss: 0.0749, D_B_loss: 0.0104, G_A_loss: 0.9186, G_B_loss: 0.5439\n",
      "Epoch [186/200], Step [371/1067], D_A_loss: 0.0387, D_B_loss: 0.0109, G_A_loss: 0.8973, G_B_loss: 0.6124\n",
      "Epoch [186/200], Step [381/1067], D_A_loss: 0.0741, D_B_loss: 0.0429, G_A_loss: 1.1194, G_B_loss: 0.5647\n",
      "Epoch [186/200], Step [391/1067], D_A_loss: 0.1167, D_B_loss: 0.0091, G_A_loss: 0.6987, G_B_loss: 0.4989\n",
      "Epoch [186/200], Step [401/1067], D_A_loss: 0.0440, D_B_loss: 0.0236, G_A_loss: 0.7125, G_B_loss: 0.7072\n",
      "Epoch [186/200], Step [411/1067], D_A_loss: 0.0296, D_B_loss: 0.0141, G_A_loss: 1.1138, G_B_loss: 0.6625\n",
      "Epoch [186/200], Step [421/1067], D_A_loss: 0.0825, D_B_loss: 0.0085, G_A_loss: 0.9603, G_B_loss: 0.7699\n",
      "Epoch [186/200], Step [431/1067], D_A_loss: 0.0971, D_B_loss: 0.0388, G_A_loss: 0.5835, G_B_loss: 0.7853\n",
      "Epoch [186/200], Step [441/1067], D_A_loss: 0.0909, D_B_loss: 0.0185, G_A_loss: 0.7338, G_B_loss: 0.7384\n",
      "Epoch [186/200], Step [451/1067], D_A_loss: 0.0357, D_B_loss: 0.0173, G_A_loss: 0.8018, G_B_loss: 0.7932\n",
      "Epoch [186/200], Step [461/1067], D_A_loss: 0.0706, D_B_loss: 0.0278, G_A_loss: 0.7502, G_B_loss: 1.0062\n",
      "Epoch [186/200], Step [471/1067], D_A_loss: 0.0481, D_B_loss: 0.0104, G_A_loss: 1.0051, G_B_loss: 0.6647\n",
      "Epoch [186/200], Step [481/1067], D_A_loss: 0.0364, D_B_loss: 0.0219, G_A_loss: 0.8826, G_B_loss: 0.7038\n",
      "Epoch [186/200], Step [491/1067], D_A_loss: 0.0623, D_B_loss: 0.0173, G_A_loss: 1.0694, G_B_loss: 0.5561\n",
      "Epoch [186/200], Step [501/1067], D_A_loss: 0.0210, D_B_loss: 0.0126, G_A_loss: 0.8065, G_B_loss: 0.5943\n",
      "Epoch [186/200], Step [511/1067], D_A_loss: 0.0209, D_B_loss: 0.0116, G_A_loss: 0.6597, G_B_loss: 1.0639\n",
      "Epoch [186/200], Step [521/1067], D_A_loss: 0.0320, D_B_loss: 0.1181, G_A_loss: 0.4592, G_B_loss: 0.7960\n",
      "Epoch [186/200], Step [531/1067], D_A_loss: 0.0274, D_B_loss: 0.0267, G_A_loss: 0.7276, G_B_loss: 0.8754\n",
      "Epoch [186/200], Step [541/1067], D_A_loss: 0.1209, D_B_loss: 0.0186, G_A_loss: 1.0457, G_B_loss: 0.3871\n",
      "Epoch [186/200], Step [551/1067], D_A_loss: 0.1137, D_B_loss: 0.0163, G_A_loss: 0.7907, G_B_loss: 0.4398\n",
      "Epoch [186/200], Step [561/1067], D_A_loss: 0.0732, D_B_loss: 0.0279, G_A_loss: 0.6652, G_B_loss: 0.8597\n",
      "Epoch [186/200], Step [571/1067], D_A_loss: 0.0487, D_B_loss: 0.0656, G_A_loss: 1.0503, G_B_loss: 0.6906\n",
      "Epoch [186/200], Step [581/1067], D_A_loss: 0.0307, D_B_loss: 0.0225, G_A_loss: 0.6948, G_B_loss: 0.5518\n",
      "Epoch [186/200], Step [591/1067], D_A_loss: 0.2039, D_B_loss: 0.0482, G_A_loss: 1.0025, G_B_loss: 0.7119\n",
      "Epoch [186/200], Step [601/1067], D_A_loss: 0.0384, D_B_loss: 0.0177, G_A_loss: 0.8249, G_B_loss: 0.6138\n",
      "Epoch [186/200], Step [611/1067], D_A_loss: 0.0656, D_B_loss: 0.0161, G_A_loss: 0.9146, G_B_loss: 0.4013\n",
      "Epoch [186/200], Step [621/1067], D_A_loss: 0.1103, D_B_loss: 0.0100, G_A_loss: 0.8457, G_B_loss: 0.8265\n",
      "Epoch [186/200], Step [631/1067], D_A_loss: 0.0304, D_B_loss: 0.0168, G_A_loss: 0.7491, G_B_loss: 0.7185\n",
      "Epoch [186/200], Step [641/1067], D_A_loss: 0.0759, D_B_loss: 0.0143, G_A_loss: 0.9835, G_B_loss: 0.6457\n",
      "Epoch [186/200], Step [651/1067], D_A_loss: 0.0399, D_B_loss: 0.0575, G_A_loss: 0.8628, G_B_loss: 0.7256\n",
      "Epoch [186/200], Step [661/1067], D_A_loss: 0.0907, D_B_loss: 0.0153, G_A_loss: 0.6405, G_B_loss: 0.4517\n",
      "Epoch [186/200], Step [671/1067], D_A_loss: 0.0760, D_B_loss: 0.0176, G_A_loss: 1.0028, G_B_loss: 0.4591\n",
      "Epoch [186/200], Step [681/1067], D_A_loss: 0.0319, D_B_loss: 0.0116, G_A_loss: 0.9806, G_B_loss: 0.8678\n",
      "Epoch [186/200], Step [691/1067], D_A_loss: 0.0218, D_B_loss: 0.0712, G_A_loss: 0.6570, G_B_loss: 0.5062\n",
      "Epoch [186/200], Step [701/1067], D_A_loss: 0.1204, D_B_loss: 0.0179, G_A_loss: 0.7661, G_B_loss: 0.5551\n",
      "Epoch [186/200], Step [711/1067], D_A_loss: 0.0570, D_B_loss: 0.0085, G_A_loss: 0.8631, G_B_loss: 0.6115\n",
      "Epoch [186/200], Step [721/1067], D_A_loss: 0.0656, D_B_loss: 0.0191, G_A_loss: 0.9608, G_B_loss: 0.6579\n",
      "Epoch [186/200], Step [731/1067], D_A_loss: 0.1092, D_B_loss: 0.0149, G_A_loss: 0.7000, G_B_loss: 0.4328\n",
      "Epoch [186/200], Step [741/1067], D_A_loss: 0.0586, D_B_loss: 0.0295, G_A_loss: 0.7446, G_B_loss: 0.6861\n",
      "Epoch [186/200], Step [751/1067], D_A_loss: 0.0454, D_B_loss: 0.0146, G_A_loss: 0.9816, G_B_loss: 0.6150\n",
      "Epoch [186/200], Step [761/1067], D_A_loss: 0.0725, D_B_loss: 0.0296, G_A_loss: 0.6454, G_B_loss: 0.4739\n",
      "Epoch [186/200], Step [771/1067], D_A_loss: 0.0614, D_B_loss: 0.0092, G_A_loss: 0.9109, G_B_loss: 0.5201\n",
      "Epoch [186/200], Step [781/1067], D_A_loss: 0.1333, D_B_loss: 0.0171, G_A_loss: 0.9376, G_B_loss: 0.6123\n",
      "Epoch [186/200], Step [791/1067], D_A_loss: 0.0414, D_B_loss: 0.0103, G_A_loss: 0.9907, G_B_loss: 1.0661\n",
      "Epoch [186/200], Step [801/1067], D_A_loss: 0.0190, D_B_loss: 0.0085, G_A_loss: 0.9027, G_B_loss: 0.5995\n",
      "Epoch [186/200], Step [811/1067], D_A_loss: 0.0761, D_B_loss: 0.0835, G_A_loss: 1.3289, G_B_loss: 0.4793\n",
      "Epoch [186/200], Step [821/1067], D_A_loss: 0.0383, D_B_loss: 0.0342, G_A_loss: 0.6377, G_B_loss: 0.6099\n",
      "Epoch [186/200], Step [831/1067], D_A_loss: 0.0598, D_B_loss: 0.0579, G_A_loss: 0.5739, G_B_loss: 0.5096\n",
      "Epoch [186/200], Step [841/1067], D_A_loss: 0.0200, D_B_loss: 0.0315, G_A_loss: 0.9245, G_B_loss: 0.9420\n",
      "Epoch [186/200], Step [851/1067], D_A_loss: 0.0882, D_B_loss: 0.0313, G_A_loss: 0.6526, G_B_loss: 0.4697\n",
      "Epoch [186/200], Step [861/1067], D_A_loss: 0.0678, D_B_loss: 0.0191, G_A_loss: 0.7087, G_B_loss: 0.8164\n",
      "Epoch [186/200], Step [871/1067], D_A_loss: 0.0164, D_B_loss: 0.0353, G_A_loss: 1.0577, G_B_loss: 0.8049\n",
      "Epoch [186/200], Step [881/1067], D_A_loss: 0.0412, D_B_loss: 0.0138, G_A_loss: 1.2230, G_B_loss: 0.4807\n",
      "Epoch [186/200], Step [891/1067], D_A_loss: 0.0356, D_B_loss: 0.0156, G_A_loss: 0.9684, G_B_loss: 0.8993\n",
      "Epoch [186/200], Step [901/1067], D_A_loss: 0.0424, D_B_loss: 0.0354, G_A_loss: 1.1274, G_B_loss: 0.4845\n",
      "Epoch [186/200], Step [911/1067], D_A_loss: 0.0327, D_B_loss: 0.0107, G_A_loss: 1.0477, G_B_loss: 0.8655\n",
      "Epoch [186/200], Step [921/1067], D_A_loss: 0.0316, D_B_loss: 0.0108, G_A_loss: 0.9599, G_B_loss: 0.7065\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [186/200], Step [931/1067], D_A_loss: 0.0252, D_B_loss: 0.0386, G_A_loss: 1.4617, G_B_loss: 0.4611\n",
      "Epoch [186/200], Step [941/1067], D_A_loss: 0.0355, D_B_loss: 0.0153, G_A_loss: 0.8757, G_B_loss: 0.4607\n",
      "Epoch [186/200], Step [951/1067], D_A_loss: 0.1612, D_B_loss: 0.0127, G_A_loss: 1.3026, G_B_loss: 0.5009\n",
      "Epoch [186/200], Step [961/1067], D_A_loss: 0.0484, D_B_loss: 0.0155, G_A_loss: 0.8918, G_B_loss: 0.5429\n",
      "Epoch [186/200], Step [971/1067], D_A_loss: 0.0884, D_B_loss: 0.0081, G_A_loss: 1.1539, G_B_loss: 0.4723\n",
      "Epoch [186/200], Step [981/1067], D_A_loss: 0.1540, D_B_loss: 0.0112, G_A_loss: 0.8355, G_B_loss: 0.5304\n",
      "Epoch [186/200], Step [991/1067], D_A_loss: 0.0556, D_B_loss: 0.0189, G_A_loss: 0.4865, G_B_loss: 0.7837\n",
      "Epoch [186/200], Step [1001/1067], D_A_loss: 0.0356, D_B_loss: 0.0284, G_A_loss: 0.6715, G_B_loss: 0.9149\n",
      "Epoch [186/200], Step [1011/1067], D_A_loss: 0.0416, D_B_loss: 0.0182, G_A_loss: 0.6869, G_B_loss: 0.6702\n",
      "Epoch [186/200], Step [1021/1067], D_A_loss: 0.0302, D_B_loss: 0.0095, G_A_loss: 0.8634, G_B_loss: 0.8743\n",
      "Epoch [186/200], Step [1031/1067], D_A_loss: 0.0862, D_B_loss: 0.0082, G_A_loss: 0.9198, G_B_loss: 0.6235\n",
      "Epoch [186/200], Step [1041/1067], D_A_loss: 0.0495, D_B_loss: 0.0217, G_A_loss: 0.8662, G_B_loss: 0.3989\n",
      "Epoch [186/200], Step [1051/1067], D_A_loss: 0.0374, D_B_loss: 0.0217, G_A_loss: 0.8615, G_B_loss: 0.7402\n",
      "Epoch [186/200], Step [1061/1067], D_A_loss: 0.0297, D_B_loss: 0.0208, G_A_loss: 1.0909, G_B_loss: 0.5111\n",
      "Epoch [187/200], Step [1/1067], D_A_loss: 0.0571, D_B_loss: 0.0202, G_A_loss: 0.7568, G_B_loss: 0.9604\n",
      "Epoch [187/200], Step [11/1067], D_A_loss: 0.0428, D_B_loss: 0.0125, G_A_loss: 0.6199, G_B_loss: 0.8749\n",
      "Epoch [187/200], Step [21/1067], D_A_loss: 0.0253, D_B_loss: 0.0209, G_A_loss: 0.6695, G_B_loss: 0.9729\n",
      "Epoch [187/200], Step [31/1067], D_A_loss: 0.0464, D_B_loss: 0.0069, G_A_loss: 1.0114, G_B_loss: 0.6425\n",
      "Epoch [187/200], Step [41/1067], D_A_loss: 0.0528, D_B_loss: 0.0243, G_A_loss: 0.9256, G_B_loss: 0.6939\n",
      "Epoch [187/200], Step [51/1067], D_A_loss: 0.0737, D_B_loss: 0.0270, G_A_loss: 1.0969, G_B_loss: 0.5111\n",
      "Epoch [187/200], Step [61/1067], D_A_loss: 0.0489, D_B_loss: 0.0385, G_A_loss: 0.5864, G_B_loss: 0.7059\n",
      "Epoch [187/200], Step [71/1067], D_A_loss: 0.0379, D_B_loss: 0.0414, G_A_loss: 0.5508, G_B_loss: 1.0102\n",
      "Epoch [187/200], Step [81/1067], D_A_loss: 0.0403, D_B_loss: 0.0269, G_A_loss: 1.0259, G_B_loss: 0.7069\n",
      "Epoch [187/200], Step [91/1067], D_A_loss: 0.1380, D_B_loss: 0.0340, G_A_loss: 0.6134, G_B_loss: 0.5125\n",
      "Epoch [187/200], Step [101/1067], D_A_loss: 0.0467, D_B_loss: 0.0158, G_A_loss: 0.7494, G_B_loss: 0.4405\n",
      "Epoch [187/200], Step [111/1067], D_A_loss: 0.0256, D_B_loss: 0.0130, G_A_loss: 0.7806, G_B_loss: 0.9617\n",
      "Epoch [187/200], Step [121/1067], D_A_loss: 0.0498, D_B_loss: 0.0251, G_A_loss: 0.8054, G_B_loss: 0.8355\n",
      "Epoch [187/200], Step [131/1067], D_A_loss: 0.0466, D_B_loss: 0.0227, G_A_loss: 0.7070, G_B_loss: 0.4999\n",
      "Epoch [187/200], Step [141/1067], D_A_loss: 0.0664, D_B_loss: 0.0253, G_A_loss: 0.7498, G_B_loss: 0.5093\n",
      "Epoch [187/200], Step [151/1067], D_A_loss: 0.0266, D_B_loss: 0.0103, G_A_loss: 0.9610, G_B_loss: 0.4710\n",
      "Epoch [187/200], Step [161/1067], D_A_loss: 0.1166, D_B_loss: 0.0316, G_A_loss: 0.6781, G_B_loss: 0.3523\n",
      "Epoch [187/200], Step [171/1067], D_A_loss: 0.1158, D_B_loss: 0.0355, G_A_loss: 1.0191, G_B_loss: 0.4999\n",
      "Epoch [187/200], Step [181/1067], D_A_loss: 0.0326, D_B_loss: 0.0396, G_A_loss: 1.1832, G_B_loss: 0.8017\n",
      "Epoch [187/200], Step [191/1067], D_A_loss: 0.1303, D_B_loss: 0.0358, G_A_loss: 0.8745, G_B_loss: 0.5864\n",
      "Epoch [187/200], Step [201/1067], D_A_loss: 0.0821, D_B_loss: 0.0144, G_A_loss: 0.7747, G_B_loss: 0.4525\n",
      "Epoch [187/200], Step [211/1067], D_A_loss: 0.0291, D_B_loss: 0.0100, G_A_loss: 0.5256, G_B_loss: 0.7998\n",
      "Epoch [187/200], Step [221/1067], D_A_loss: 0.0458, D_B_loss: 0.0111, G_A_loss: 0.9152, G_B_loss: 0.7248\n",
      "Epoch [187/200], Step [231/1067], D_A_loss: 0.1055, D_B_loss: 0.0146, G_A_loss: 1.0279, G_B_loss: 0.3901\n",
      "Epoch [187/200], Step [241/1067], D_A_loss: 0.0692, D_B_loss: 0.0398, G_A_loss: 1.0645, G_B_loss: 0.5818\n",
      "Epoch [187/200], Step [251/1067], D_A_loss: 0.1069, D_B_loss: 0.0106, G_A_loss: 1.0650, G_B_loss: 0.6180\n",
      "Epoch [187/200], Step [261/1067], D_A_loss: 0.0251, D_B_loss: 0.0110, G_A_loss: 0.8304, G_B_loss: 0.2716\n",
      "Epoch [187/200], Step [271/1067], D_A_loss: 0.0861, D_B_loss: 0.0368, G_A_loss: 0.5943, G_B_loss: 0.8179\n",
      "Epoch [187/200], Step [281/1067], D_A_loss: 0.0314, D_B_loss: 0.0166, G_A_loss: 0.9038, G_B_loss: 0.7127\n",
      "Epoch [187/200], Step [291/1067], D_A_loss: 0.0756, D_B_loss: 0.0151, G_A_loss: 1.1961, G_B_loss: 0.9413\n",
      "Epoch [187/200], Step [301/1067], D_A_loss: 0.0365, D_B_loss: 0.0268, G_A_loss: 1.0124, G_B_loss: 0.8814\n",
      "Epoch [187/200], Step [311/1067], D_A_loss: 0.0301, D_B_loss: 0.0214, G_A_loss: 0.8261, G_B_loss: 0.8139\n",
      "Epoch [187/200], Step [321/1067], D_A_loss: 0.0199, D_B_loss: 0.0076, G_A_loss: 0.9610, G_B_loss: 0.7072\n",
      "Epoch [187/200], Step [331/1067], D_A_loss: 0.0483, D_B_loss: 0.0509, G_A_loss: 0.5035, G_B_loss: 0.6233\n",
      "Epoch [187/200], Step [341/1067], D_A_loss: 0.0852, D_B_loss: 0.0163, G_A_loss: 0.7808, G_B_loss: 0.8871\n",
      "Epoch [187/200], Step [351/1067], D_A_loss: 0.0691, D_B_loss: 0.0164, G_A_loss: 0.7743, G_B_loss: 0.5768\n",
      "Epoch [187/200], Step [361/1067], D_A_loss: 0.0560, D_B_loss: 0.0221, G_A_loss: 0.6859, G_B_loss: 0.8020\n",
      "Epoch [187/200], Step [371/1067], D_A_loss: 0.0176, D_B_loss: 0.0097, G_A_loss: 0.9367, G_B_loss: 0.8056\n",
      "Epoch [187/200], Step [381/1067], D_A_loss: 0.1643, D_B_loss: 0.0106, G_A_loss: 0.8801, G_B_loss: 0.7851\n",
      "Epoch [187/200], Step [391/1067], D_A_loss: 0.1072, D_B_loss: 0.0156, G_A_loss: 0.7762, G_B_loss: 0.5381\n",
      "Epoch [187/200], Step [401/1067], D_A_loss: 0.1872, D_B_loss: 0.0130, G_A_loss: 1.0054, G_B_loss: 0.7588\n",
      "Epoch [187/200], Step [411/1067], D_A_loss: 0.0704, D_B_loss: 0.0226, G_A_loss: 1.2253, G_B_loss: 0.5839\n",
      "Epoch [187/200], Step [421/1067], D_A_loss: 0.0520, D_B_loss: 0.0205, G_A_loss: 0.9953, G_B_loss: 0.7856\n",
      "Epoch [187/200], Step [431/1067], D_A_loss: 0.0615, D_B_loss: 0.0442, G_A_loss: 1.1651, G_B_loss: 0.5503\n",
      "Epoch [187/200], Step [441/1067], D_A_loss: 0.0368, D_B_loss: 0.0499, G_A_loss: 0.3846, G_B_loss: 0.6165\n",
      "Epoch [187/200], Step [451/1067], D_A_loss: 0.0466, D_B_loss: 0.0643, G_A_loss: 0.5848, G_B_loss: 0.6052\n",
      "Epoch [187/200], Step [461/1067], D_A_loss: 0.0509, D_B_loss: 0.0128, G_A_loss: 1.2291, G_B_loss: 0.6336\n",
      "Epoch [187/200], Step [471/1067], D_A_loss: 0.1104, D_B_loss: 0.0099, G_A_loss: 0.7347, G_B_loss: 0.5373\n",
      "Epoch [187/200], Step [481/1067], D_A_loss: 0.0508, D_B_loss: 0.0095, G_A_loss: 1.0088, G_B_loss: 0.5737\n",
      "Epoch [187/200], Step [491/1067], D_A_loss: 0.1113, D_B_loss: 0.0555, G_A_loss: 0.8791, G_B_loss: 0.3820\n",
      "Epoch [187/200], Step [501/1067], D_A_loss: 0.0261, D_B_loss: 0.0136, G_A_loss: 1.2160, G_B_loss: 1.0878\n",
      "Epoch [187/200], Step [511/1067], D_A_loss: 0.0456, D_B_loss: 0.0697, G_A_loss: 0.6064, G_B_loss: 0.6253\n",
      "Epoch [187/200], Step [521/1067], D_A_loss: 0.0271, D_B_loss: 0.0117, G_A_loss: 0.8455, G_B_loss: 0.8632\n",
      "Epoch [187/200], Step [531/1067], D_A_loss: 0.0769, D_B_loss: 0.0233, G_A_loss: 0.7641, G_B_loss: 0.5151\n",
      "Epoch [187/200], Step [541/1067], D_A_loss: 0.0282, D_B_loss: 0.0157, G_A_loss: 0.7725, G_B_loss: 0.6308\n",
      "Epoch [187/200], Step [551/1067], D_A_loss: 0.0395, D_B_loss: 0.0090, G_A_loss: 0.9255, G_B_loss: 0.9315\n",
      "Epoch [187/200], Step [561/1067], D_A_loss: 0.1942, D_B_loss: 0.0117, G_A_loss: 1.0100, G_B_loss: 0.4327\n",
      "Epoch [187/200], Step [571/1067], D_A_loss: 0.0557, D_B_loss: 0.0085, G_A_loss: 0.8993, G_B_loss: 0.7063\n",
      "Epoch [187/200], Step [581/1067], D_A_loss: 0.0472, D_B_loss: 0.0253, G_A_loss: 0.6918, G_B_loss: 0.6008\n",
      "Epoch [187/200], Step [591/1067], D_A_loss: 0.0274, D_B_loss: 0.0211, G_A_loss: 0.9403, G_B_loss: 0.9311\n",
      "Epoch [187/200], Step [601/1067], D_A_loss: 0.0280, D_B_loss: 0.0087, G_A_loss: 1.1076, G_B_loss: 0.8157\n",
      "Epoch [187/200], Step [611/1067], D_A_loss: 0.0590, D_B_loss: 0.0579, G_A_loss: 0.4796, G_B_loss: 0.8942\n",
      "Epoch [187/200], Step [621/1067], D_A_loss: 0.1076, D_B_loss: 0.0138, G_A_loss: 0.8743, G_B_loss: 0.5277\n",
      "Epoch [187/200], Step [631/1067], D_A_loss: 0.0640, D_B_loss: 0.0492, G_A_loss: 0.7156, G_B_loss: 0.3926\n",
      "Epoch [187/200], Step [641/1067], D_A_loss: 0.2210, D_B_loss: 0.0159, G_A_loss: 0.7751, G_B_loss: 0.7317\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [187/200], Step [651/1067], D_A_loss: 0.0273, D_B_loss: 0.0687, G_A_loss: 0.9155, G_B_loss: 0.8535\n",
      "Epoch [187/200], Step [661/1067], D_A_loss: 0.1296, D_B_loss: 0.0538, G_A_loss: 0.7515, G_B_loss: 0.4622\n",
      "Epoch [187/200], Step [671/1067], D_A_loss: 0.0653, D_B_loss: 0.0145, G_A_loss: 0.8007, G_B_loss: 0.5435\n",
      "Epoch [187/200], Step [681/1067], D_A_loss: 0.0387, D_B_loss: 0.0414, G_A_loss: 0.5947, G_B_loss: 0.6920\n",
      "Epoch [187/200], Step [691/1067], D_A_loss: 0.0414, D_B_loss: 0.0363, G_A_loss: 0.8408, G_B_loss: 0.6624\n",
      "Epoch [187/200], Step [701/1067], D_A_loss: 0.0581, D_B_loss: 0.0316, G_A_loss: 1.1304, G_B_loss: 0.6109\n",
      "Epoch [187/200], Step [711/1067], D_A_loss: 0.1838, D_B_loss: 0.0076, G_A_loss: 1.0546, G_B_loss: 0.5337\n",
      "Epoch [187/200], Step [721/1067], D_A_loss: 0.0236, D_B_loss: 0.0109, G_A_loss: 0.8181, G_B_loss: 1.0418\n",
      "Epoch [187/200], Step [731/1067], D_A_loss: 0.0487, D_B_loss: 0.0219, G_A_loss: 1.1465, G_B_loss: 0.7195\n",
      "Epoch [187/200], Step [741/1067], D_A_loss: 0.0208, D_B_loss: 0.0090, G_A_loss: 1.0036, G_B_loss: 0.8683\n",
      "Epoch [187/200], Step [751/1067], D_A_loss: 0.0554, D_B_loss: 0.0093, G_A_loss: 0.8782, G_B_loss: 0.7343\n",
      "Epoch [187/200], Step [761/1067], D_A_loss: 0.0279, D_B_loss: 0.0070, G_A_loss: 0.9372, G_B_loss: 0.6339\n",
      "Epoch [187/200], Step [771/1067], D_A_loss: 0.0860, D_B_loss: 0.0084, G_A_loss: 0.9213, G_B_loss: 0.6918\n",
      "Epoch [187/200], Step [781/1067], D_A_loss: 0.0628, D_B_loss: 0.0098, G_A_loss: 0.9464, G_B_loss: 0.6458\n",
      "Epoch [187/200], Step [791/1067], D_A_loss: 0.1145, D_B_loss: 0.0662, G_A_loss: 0.5783, G_B_loss: 0.8860\n",
      "Epoch [187/200], Step [801/1067], D_A_loss: 0.0663, D_B_loss: 0.0161, G_A_loss: 0.9554, G_B_loss: 0.8227\n",
      "Epoch [187/200], Step [811/1067], D_A_loss: 0.0572, D_B_loss: 0.0142, G_A_loss: 1.2206, G_B_loss: 0.4909\n",
      "Epoch [187/200], Step [821/1067], D_A_loss: 0.0465, D_B_loss: 0.0127, G_A_loss: 0.7605, G_B_loss: 0.6612\n",
      "Epoch [187/200], Step [831/1067], D_A_loss: 0.0760, D_B_loss: 0.0095, G_A_loss: 1.0771, G_B_loss: 0.4632\n",
      "Epoch [187/200], Step [841/1067], D_A_loss: 0.0244, D_B_loss: 0.0130, G_A_loss: 0.8415, G_B_loss: 1.0233\n",
      "Epoch [187/200], Step [851/1067], D_A_loss: 0.0336, D_B_loss: 0.0098, G_A_loss: 0.6709, G_B_loss: 0.7026\n",
      "Epoch [187/200], Step [861/1067], D_A_loss: 0.1058, D_B_loss: 0.0649, G_A_loss: 0.7294, G_B_loss: 0.7480\n",
      "Epoch [187/200], Step [871/1067], D_A_loss: 0.0477, D_B_loss: 0.0119, G_A_loss: 0.7162, G_B_loss: 0.7249\n",
      "Epoch [187/200], Step [881/1067], D_A_loss: 0.0460, D_B_loss: 0.0129, G_A_loss: 0.8138, G_B_loss: 0.8340\n",
      "Epoch [187/200], Step [891/1067], D_A_loss: 0.0525, D_B_loss: 0.0134, G_A_loss: 0.9530, G_B_loss: 0.7553\n",
      "Epoch [187/200], Step [901/1067], D_A_loss: 0.0398, D_B_loss: 0.0220, G_A_loss: 0.7340, G_B_loss: 0.5289\n",
      "Epoch [187/200], Step [911/1067], D_A_loss: 0.0199, D_B_loss: 0.0123, G_A_loss: 1.0506, G_B_loss: 0.5246\n",
      "Epoch [187/200], Step [921/1067], D_A_loss: 0.0446, D_B_loss: 0.0161, G_A_loss: 1.2805, G_B_loss: 0.7414\n",
      "Epoch [187/200], Step [931/1067], D_A_loss: 0.0272, D_B_loss: 0.0149, G_A_loss: 0.8180, G_B_loss: 0.8085\n",
      "Epoch [187/200], Step [941/1067], D_A_loss: 0.0590, D_B_loss: 0.0240, G_A_loss: 0.5496, G_B_loss: 0.8731\n",
      "Epoch [187/200], Step [951/1067], D_A_loss: 0.0257, D_B_loss: 0.0095, G_A_loss: 1.0748, G_B_loss: 0.9132\n",
      "Epoch [187/200], Step [961/1067], D_A_loss: 0.0688, D_B_loss: 0.0175, G_A_loss: 0.7546, G_B_loss: 0.8281\n",
      "Epoch [187/200], Step [971/1067], D_A_loss: 0.0467, D_B_loss: 0.0272, G_A_loss: 0.6442, G_B_loss: 0.8305\n",
      "Epoch [187/200], Step [981/1067], D_A_loss: 0.0471, D_B_loss: 0.0218, G_A_loss: 1.0962, G_B_loss: 0.8230\n",
      "Epoch [187/200], Step [991/1067], D_A_loss: 0.0463, D_B_loss: 0.0300, G_A_loss: 0.6639, G_B_loss: 0.6667\n",
      "Epoch [187/200], Step [1001/1067], D_A_loss: 0.1315, D_B_loss: 0.0318, G_A_loss: 0.6389, G_B_loss: 1.0125\n",
      "Epoch [187/200], Step [1011/1067], D_A_loss: 0.0711, D_B_loss: 0.0112, G_A_loss: 0.9871, G_B_loss: 0.7888\n",
      "Epoch [187/200], Step [1021/1067], D_A_loss: 0.0305, D_B_loss: 0.0250, G_A_loss: 0.7194, G_B_loss: 0.6421\n",
      "Epoch [187/200], Step [1031/1067], D_A_loss: 0.0244, D_B_loss: 0.0162, G_A_loss: 0.9943, G_B_loss: 0.9211\n",
      "Epoch [187/200], Step [1041/1067], D_A_loss: 0.0436, D_B_loss: 0.0116, G_A_loss: 1.0637, G_B_loss: 0.7408\n",
      "Epoch [187/200], Step [1051/1067], D_A_loss: 0.0516, D_B_loss: 0.0180, G_A_loss: 0.5287, G_B_loss: 0.7538\n",
      "Epoch [187/200], Step [1061/1067], D_A_loss: 0.0915, D_B_loss: 0.0323, G_A_loss: 0.7130, G_B_loss: 0.8699\n",
      "Epoch [188/200], Step [1/1067], D_A_loss: 0.0833, D_B_loss: 0.0348, G_A_loss: 0.9477, G_B_loss: 0.5801\n",
      "Epoch [188/200], Step [11/1067], D_A_loss: 0.0227, D_B_loss: 0.0444, G_A_loss: 0.6309, G_B_loss: 0.9041\n",
      "Epoch [188/200], Step [21/1067], D_A_loss: 0.0237, D_B_loss: 0.0433, G_A_loss: 0.5411, G_B_loss: 0.6684\n",
      "Epoch [188/200], Step [31/1067], D_A_loss: 0.0479, D_B_loss: 0.0202, G_A_loss: 0.7265, G_B_loss: 0.7650\n",
      "Epoch [188/200], Step [41/1067], D_A_loss: 0.0437, D_B_loss: 0.0298, G_A_loss: 0.8414, G_B_loss: 0.5974\n",
      "Epoch [188/200], Step [51/1067], D_A_loss: 0.1093, D_B_loss: 0.0099, G_A_loss: 0.7422, G_B_loss: 0.7686\n",
      "Epoch [188/200], Step [61/1067], D_A_loss: 0.0811, D_B_loss: 0.0374, G_A_loss: 0.6391, G_B_loss: 0.9026\n",
      "Epoch [188/200], Step [71/1067], D_A_loss: 0.0284, D_B_loss: 0.0237, G_A_loss: 1.2473, G_B_loss: 0.6980\n",
      "Epoch [188/200], Step [81/1067], D_A_loss: 0.0756, D_B_loss: 0.0379, G_A_loss: 0.8425, G_B_loss: 0.5377\n",
      "Epoch [188/200], Step [91/1067], D_A_loss: 0.0433, D_B_loss: 0.0348, G_A_loss: 1.2484, G_B_loss: 0.6738\n",
      "Epoch [188/200], Step [101/1067], D_A_loss: 0.0159, D_B_loss: 0.0068, G_A_loss: 0.9560, G_B_loss: 0.9524\n",
      "Epoch [188/200], Step [111/1067], D_A_loss: 0.0653, D_B_loss: 0.0292, G_A_loss: 0.6487, G_B_loss: 0.5377\n",
      "Epoch [188/200], Step [121/1067], D_A_loss: 0.0554, D_B_loss: 0.0101, G_A_loss: 1.0094, G_B_loss: 0.6004\n",
      "Epoch [188/200], Step [131/1067], D_A_loss: 0.0234, D_B_loss: 0.0241, G_A_loss: 1.0711, G_B_loss: 0.7276\n",
      "Epoch [188/200], Step [141/1067], D_A_loss: 0.0277, D_B_loss: 0.0128, G_A_loss: 0.8700, G_B_loss: 0.4522\n",
      "Epoch [188/200], Step [151/1067], D_A_loss: 0.0227, D_B_loss: 0.0206, G_A_loss: 1.2491, G_B_loss: 0.8448\n",
      "Epoch [188/200], Step [161/1067], D_A_loss: 0.0489, D_B_loss: 0.0393, G_A_loss: 1.1383, G_B_loss: 0.5911\n",
      "Epoch [188/200], Step [171/1067], D_A_loss: 0.0939, D_B_loss: 0.0055, G_A_loss: 0.9936, G_B_loss: 0.7104\n",
      "Epoch [188/200], Step [181/1067], D_A_loss: 0.0747, D_B_loss: 0.0141, G_A_loss: 0.6550, G_B_loss: 0.4939\n",
      "Epoch [188/200], Step [191/1067], D_A_loss: 0.1438, D_B_loss: 0.0173, G_A_loss: 1.0368, G_B_loss: 0.2926\n",
      "Epoch [188/200], Step [201/1067], D_A_loss: 0.0676, D_B_loss: 0.0221, G_A_loss: 1.2714, G_B_loss: 0.3393\n",
      "Epoch [188/200], Step [211/1067], D_A_loss: 0.0499, D_B_loss: 0.0081, G_A_loss: 1.0298, G_B_loss: 0.6842\n",
      "Epoch [188/200], Step [221/1067], D_A_loss: 0.0222, D_B_loss: 0.0093, G_A_loss: 0.9452, G_B_loss: 0.9942\n",
      "Epoch [188/200], Step [231/1067], D_A_loss: 0.0466, D_B_loss: 0.0182, G_A_loss: 0.8556, G_B_loss: 0.8566\n",
      "Epoch [188/200], Step [241/1067], D_A_loss: 0.0353, D_B_loss: 0.0367, G_A_loss: 0.6469, G_B_loss: 0.4513\n",
      "Epoch [188/200], Step [251/1067], D_A_loss: 0.0477, D_B_loss: 0.0117, G_A_loss: 1.0819, G_B_loss: 0.5922\n",
      "Epoch [188/200], Step [261/1067], D_A_loss: 0.0362, D_B_loss: 0.0208, G_A_loss: 0.8373, G_B_loss: 0.7479\n",
      "Epoch [188/200], Step [271/1067], D_A_loss: 0.0882, D_B_loss: 0.0325, G_A_loss: 1.4794, G_B_loss: 0.5671\n",
      "Epoch [188/200], Step [281/1067], D_A_loss: 0.1254, D_B_loss: 0.0353, G_A_loss: 0.7965, G_B_loss: 0.8012\n",
      "Epoch [188/200], Step [291/1067], D_A_loss: 0.0330, D_B_loss: 0.0075, G_A_loss: 0.8961, G_B_loss: 0.6244\n",
      "Epoch [188/200], Step [301/1067], D_A_loss: 0.0790, D_B_loss: 0.0105, G_A_loss: 0.6691, G_B_loss: 0.4401\n",
      "Epoch [188/200], Step [311/1067], D_A_loss: 0.0553, D_B_loss: 0.0116, G_A_loss: 0.6491, G_B_loss: 1.1215\n",
      "Epoch [188/200], Step [321/1067], D_A_loss: 0.0715, D_B_loss: 0.0478, G_A_loss: 1.1197, G_B_loss: 0.6312\n",
      "Epoch [188/200], Step [331/1067], D_A_loss: 0.1431, D_B_loss: 0.0252, G_A_loss: 1.0301, G_B_loss: 0.7022\n",
      "Epoch [188/200], Step [341/1067], D_A_loss: 0.1500, D_B_loss: 0.0250, G_A_loss: 0.7705, G_B_loss: 0.5830\n",
      "Epoch [188/200], Step [351/1067], D_A_loss: 0.0910, D_B_loss: 0.0292, G_A_loss: 0.6624, G_B_loss: 0.4624\n",
      "Epoch [188/200], Step [361/1067], D_A_loss: 0.0385, D_B_loss: 0.0586, G_A_loss: 0.4890, G_B_loss: 0.8536\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [188/200], Step [371/1067], D_A_loss: 0.0566, D_B_loss: 0.0130, G_A_loss: 0.8085, G_B_loss: 0.6234\n",
      "Epoch [188/200], Step [381/1067], D_A_loss: 0.0317, D_B_loss: 0.0134, G_A_loss: 0.7676, G_B_loss: 0.7705\n",
      "Epoch [188/200], Step [391/1067], D_A_loss: 0.0745, D_B_loss: 0.0250, G_A_loss: 0.5827, G_B_loss: 0.3304\n",
      "Epoch [188/200], Step [401/1067], D_A_loss: 0.1106, D_B_loss: 0.0206, G_A_loss: 1.0315, G_B_loss: 0.9016\n",
      "Epoch [188/200], Step [411/1067], D_A_loss: 0.0479, D_B_loss: 0.0237, G_A_loss: 0.6942, G_B_loss: 0.8723\n",
      "Epoch [188/200], Step [421/1067], D_A_loss: 0.0306, D_B_loss: 0.0105, G_A_loss: 1.1103, G_B_loss: 0.5817\n",
      "Epoch [188/200], Step [431/1067], D_A_loss: 0.1252, D_B_loss: 0.0093, G_A_loss: 0.7673, G_B_loss: 0.6820\n",
      "Epoch [188/200], Step [441/1067], D_A_loss: 0.1693, D_B_loss: 0.0122, G_A_loss: 0.9201, G_B_loss: 0.5072\n",
      "Epoch [188/200], Step [451/1067], D_A_loss: 0.0257, D_B_loss: 0.0190, G_A_loss: 0.5778, G_B_loss: 0.5807\n",
      "Epoch [188/200], Step [461/1067], D_A_loss: 0.1418, D_B_loss: 0.0101, G_A_loss: 0.9394, G_B_loss: 0.6431\n",
      "Epoch [188/200], Step [471/1067], D_A_loss: 0.0843, D_B_loss: 0.0163, G_A_loss: 1.2309, G_B_loss: 0.5081\n",
      "Epoch [188/200], Step [481/1067], D_A_loss: 0.0331, D_B_loss: 0.0396, G_A_loss: 0.8369, G_B_loss: 0.9061\n",
      "Epoch [188/200], Step [491/1067], D_A_loss: 0.0497, D_B_loss: 0.0427, G_A_loss: 0.7019, G_B_loss: 0.6585\n",
      "Epoch [188/200], Step [501/1067], D_A_loss: 0.0283, D_B_loss: 0.0123, G_A_loss: 0.7618, G_B_loss: 0.6187\n",
      "Epoch [188/200], Step [511/1067], D_A_loss: 0.0785, D_B_loss: 0.0223, G_A_loss: 0.9403, G_B_loss: 0.5471\n",
      "Epoch [188/200], Step [521/1067], D_A_loss: 0.1015, D_B_loss: 0.0849, G_A_loss: 0.9296, G_B_loss: 0.9993\n",
      "Epoch [188/200], Step [531/1067], D_A_loss: 0.0269, D_B_loss: 0.0176, G_A_loss: 0.9423, G_B_loss: 0.7917\n",
      "Epoch [188/200], Step [541/1067], D_A_loss: 0.0678, D_B_loss: 0.0211, G_A_loss: 0.7987, G_B_loss: 1.0604\n",
      "Epoch [188/200], Step [551/1067], D_A_loss: 0.0369, D_B_loss: 0.0145, G_A_loss: 0.9758, G_B_loss: 0.9329\n",
      "Epoch [188/200], Step [561/1067], D_A_loss: 0.0217, D_B_loss: 0.0140, G_A_loss: 0.7551, G_B_loss: 0.8800\n",
      "Epoch [188/200], Step [571/1067], D_A_loss: 0.0472, D_B_loss: 0.0191, G_A_loss: 0.8450, G_B_loss: 1.0807\n",
      "Epoch [188/200], Step [581/1067], D_A_loss: 0.1036, D_B_loss: 0.0111, G_A_loss: 0.7037, G_B_loss: 0.6115\n",
      "Epoch [188/200], Step [591/1067], D_A_loss: 0.0660, D_B_loss: 0.0602, G_A_loss: 0.4793, G_B_loss: 0.6829\n",
      "Epoch [188/200], Step [601/1067], D_A_loss: 0.0484, D_B_loss: 0.0139, G_A_loss: 0.7740, G_B_loss: 0.8971\n",
      "Epoch [188/200], Step [611/1067], D_A_loss: 0.1003, D_B_loss: 0.0454, G_A_loss: 0.8536, G_B_loss: 0.3902\n",
      "Epoch [188/200], Step [621/1067], D_A_loss: 0.2502, D_B_loss: 0.0172, G_A_loss: 0.8465, G_B_loss: 0.9594\n",
      "Epoch [188/200], Step [631/1067], D_A_loss: 0.0540, D_B_loss: 0.0223, G_A_loss: 0.9788, G_B_loss: 0.5324\n",
      "Epoch [188/200], Step [641/1067], D_A_loss: 0.1587, D_B_loss: 0.0313, G_A_loss: 0.6243, G_B_loss: 0.5268\n",
      "Epoch [188/200], Step [651/1067], D_A_loss: 0.0349, D_B_loss: 0.0271, G_A_loss: 1.1297, G_B_loss: 0.6643\n",
      "Epoch [188/200], Step [661/1067], D_A_loss: 0.0269, D_B_loss: 0.0150, G_A_loss: 1.1050, G_B_loss: 0.7123\n",
      "Epoch [188/200], Step [671/1067], D_A_loss: 0.1720, D_B_loss: 0.0106, G_A_loss: 0.9515, G_B_loss: 0.8507\n",
      "Epoch [188/200], Step [681/1067], D_A_loss: 0.0548, D_B_loss: 0.0330, G_A_loss: 1.1013, G_B_loss: 0.6069\n",
      "Epoch [188/200], Step [691/1067], D_A_loss: 0.0410, D_B_loss: 0.0270, G_A_loss: 0.7191, G_B_loss: 0.8071\n",
      "Epoch [188/200], Step [701/1067], D_A_loss: 0.1280, D_B_loss: 0.0080, G_A_loss: 1.0314, G_B_loss: 0.6059\n",
      "Epoch [188/200], Step [711/1067], D_A_loss: 0.0326, D_B_loss: 0.0207, G_A_loss: 0.7395, G_B_loss: 0.6016\n",
      "Epoch [188/200], Step [721/1067], D_A_loss: 0.0935, D_B_loss: 0.0172, G_A_loss: 0.6033, G_B_loss: 0.6728\n",
      "Epoch [188/200], Step [731/1067], D_A_loss: 0.0527, D_B_loss: 0.0198, G_A_loss: 0.7436, G_B_loss: 0.7228\n",
      "Epoch [188/200], Step [741/1067], D_A_loss: 0.0692, D_B_loss: 0.0885, G_A_loss: 0.7554, G_B_loss: 0.4756\n",
      "Epoch [188/200], Step [751/1067], D_A_loss: 0.1797, D_B_loss: 0.0289, G_A_loss: 0.6271, G_B_loss: 0.5870\n",
      "Epoch [188/200], Step [761/1067], D_A_loss: 0.0387, D_B_loss: 0.0108, G_A_loss: 0.4092, G_B_loss: 1.0084\n",
      "Epoch [188/200], Step [771/1067], D_A_loss: 0.0208, D_B_loss: 0.0154, G_A_loss: 1.0888, G_B_loss: 0.4377\n",
      "Epoch [188/200], Step [781/1067], D_A_loss: 0.0780, D_B_loss: 0.0106, G_A_loss: 1.1337, G_B_loss: 0.5349\n",
      "Epoch [188/200], Step [791/1067], D_A_loss: 0.1313, D_B_loss: 0.0364, G_A_loss: 0.6050, G_B_loss: 0.4726\n",
      "Epoch [188/200], Step [801/1067], D_A_loss: 0.1010, D_B_loss: 0.0347, G_A_loss: 0.5876, G_B_loss: 0.8305\n",
      "Epoch [188/200], Step [811/1067], D_A_loss: 0.0521, D_B_loss: 0.0312, G_A_loss: 0.7305, G_B_loss: 0.6318\n",
      "Epoch [188/200], Step [821/1067], D_A_loss: 0.2222, D_B_loss: 0.0088, G_A_loss: 1.0056, G_B_loss: 0.8829\n",
      "Epoch [188/200], Step [831/1067], D_A_loss: 0.1072, D_B_loss: 0.0284, G_A_loss: 0.6433, G_B_loss: 0.7171\n",
      "Epoch [188/200], Step [841/1067], D_A_loss: 0.0475, D_B_loss: 0.0120, G_A_loss: 1.1965, G_B_loss: 0.4541\n",
      "Epoch [188/200], Step [851/1067], D_A_loss: 0.0417, D_B_loss: 0.0143, G_A_loss: 1.0444, G_B_loss: 0.8332\n",
      "Epoch [188/200], Step [861/1067], D_A_loss: 0.0296, D_B_loss: 0.0122, G_A_loss: 0.9076, G_B_loss: 1.1519\n",
      "Epoch [188/200], Step [871/1067], D_A_loss: 0.0422, D_B_loss: 0.0261, G_A_loss: 0.8750, G_B_loss: 0.6921\n",
      "Epoch [188/200], Step [881/1067], D_A_loss: 0.0663, D_B_loss: 0.0142, G_A_loss: 0.9613, G_B_loss: 0.6551\n",
      "Epoch [188/200], Step [891/1067], D_A_loss: 0.0960, D_B_loss: 0.0236, G_A_loss: 0.9898, G_B_loss: 0.3887\n",
      "Epoch [188/200], Step [901/1067], D_A_loss: 0.1792, D_B_loss: 0.0128, G_A_loss: 0.9669, G_B_loss: 1.0119\n",
      "Epoch [188/200], Step [911/1067], D_A_loss: 0.0463, D_B_loss: 0.0143, G_A_loss: 0.9705, G_B_loss: 0.7252\n",
      "Epoch [188/200], Step [921/1067], D_A_loss: 0.0308, D_B_loss: 0.0294, G_A_loss: 0.6395, G_B_loss: 0.6586\n",
      "Epoch [188/200], Step [931/1067], D_A_loss: 0.0492, D_B_loss: 0.0232, G_A_loss: 0.7096, G_B_loss: 0.9778\n",
      "Epoch [188/200], Step [941/1067], D_A_loss: 0.0259, D_B_loss: 0.0245, G_A_loss: 1.0714, G_B_loss: 0.9487\n",
      "Epoch [188/200], Step [951/1067], D_A_loss: 0.0224, D_B_loss: 0.0669, G_A_loss: 0.9354, G_B_loss: 0.6245\n",
      "Epoch [188/200], Step [961/1067], D_A_loss: 0.1740, D_B_loss: 0.0111, G_A_loss: 1.1585, G_B_loss: 0.3038\n",
      "Epoch [188/200], Step [971/1067], D_A_loss: 0.0891, D_B_loss: 0.0376, G_A_loss: 0.6095, G_B_loss: 0.5001\n",
      "Epoch [188/200], Step [981/1067], D_A_loss: 0.0444, D_B_loss: 0.0137, G_A_loss: 0.5470, G_B_loss: 1.2071\n",
      "Epoch [188/200], Step [991/1067], D_A_loss: 0.0426, D_B_loss: 0.0111, G_A_loss: 0.8365, G_B_loss: 0.6606\n",
      "Epoch [188/200], Step [1001/1067], D_A_loss: 0.0316, D_B_loss: 0.0179, G_A_loss: 0.9712, G_B_loss: 0.4285\n",
      "Epoch [188/200], Step [1011/1067], D_A_loss: 0.0345, D_B_loss: 0.0255, G_A_loss: 0.9625, G_B_loss: 1.1084\n",
      "Epoch [188/200], Step [1021/1067], D_A_loss: 0.0321, D_B_loss: 0.0181, G_A_loss: 0.7408, G_B_loss: 1.1591\n",
      "Epoch [188/200], Step [1031/1067], D_A_loss: 0.1076, D_B_loss: 0.0705, G_A_loss: 0.6793, G_B_loss: 0.4001\n",
      "Epoch [188/200], Step [1041/1067], D_A_loss: 0.0208, D_B_loss: 0.0170, G_A_loss: 1.0819, G_B_loss: 0.9672\n",
      "Epoch [188/200], Step [1051/1067], D_A_loss: 0.0694, D_B_loss: 0.0213, G_A_loss: 0.7793, G_B_loss: 0.4838\n",
      "Epoch [188/200], Step [1061/1067], D_A_loss: 0.0747, D_B_loss: 0.0073, G_A_loss: 1.0064, G_B_loss: 0.7956\n",
      "Epoch [189/200], Step [1/1067], D_A_loss: 0.0787, D_B_loss: 0.0088, G_A_loss: 0.9450, G_B_loss: 0.6309\n",
      "Epoch [189/200], Step [11/1067], D_A_loss: 0.1325, D_B_loss: 0.0082, G_A_loss: 1.0236, G_B_loss: 0.8340\n",
      "Epoch [189/200], Step [21/1067], D_A_loss: 0.0592, D_B_loss: 0.0120, G_A_loss: 0.7669, G_B_loss: 0.9240\n",
      "Epoch [189/200], Step [31/1067], D_A_loss: 0.2387, D_B_loss: 0.0148, G_A_loss: 0.6419, G_B_loss: 0.8872\n",
      "Epoch [189/200], Step [41/1067], D_A_loss: 0.1617, D_B_loss: 0.0165, G_A_loss: 1.0243, G_B_loss: 0.9383\n",
      "Epoch [189/200], Step [51/1067], D_A_loss: 0.1154, D_B_loss: 0.0244, G_A_loss: 0.6709, G_B_loss: 0.4358\n",
      "Epoch [189/200], Step [61/1067], D_A_loss: 0.0196, D_B_loss: 0.0106, G_A_loss: 1.1480, G_B_loss: 0.9608\n",
      "Epoch [189/200], Step [71/1067], D_A_loss: 0.1001, D_B_loss: 0.0474, G_A_loss: 0.7391, G_B_loss: 0.5169\n",
      "Epoch [189/200], Step [81/1067], D_A_loss: 0.0691, D_B_loss: 0.0671, G_A_loss: 0.7437, G_B_loss: 0.8269\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [189/200], Step [91/1067], D_A_loss: 0.0477, D_B_loss: 0.0620, G_A_loss: 1.0643, G_B_loss: 0.6107\n",
      "Epoch [189/200], Step [101/1067], D_A_loss: 0.0688, D_B_loss: 0.0575, G_A_loss: 0.4737, G_B_loss: 0.6676\n",
      "Epoch [189/200], Step [111/1067], D_A_loss: 0.0413, D_B_loss: 0.0125, G_A_loss: 1.2300, G_B_loss: 0.6542\n",
      "Epoch [189/200], Step [121/1067], D_A_loss: 0.0555, D_B_loss: 0.0139, G_A_loss: 1.0534, G_B_loss: 0.7736\n",
      "Epoch [189/200], Step [131/1067], D_A_loss: 0.0288, D_B_loss: 0.0177, G_A_loss: 1.0763, G_B_loss: 0.7841\n",
      "Epoch [189/200], Step [141/1067], D_A_loss: 0.1148, D_B_loss: 0.0144, G_A_loss: 0.9514, G_B_loss: 0.8070\n",
      "Epoch [189/200], Step [151/1067], D_A_loss: 0.0649, D_B_loss: 0.0335, G_A_loss: 1.2388, G_B_loss: 0.7271\n",
      "Epoch [189/200], Step [161/1067], D_A_loss: 0.0655, D_B_loss: 0.0356, G_A_loss: 0.8984, G_B_loss: 0.4137\n",
      "Epoch [189/200], Step [171/1067], D_A_loss: 0.0334, D_B_loss: 0.0083, G_A_loss: 0.7332, G_B_loss: 0.8262\n",
      "Epoch [189/200], Step [181/1067], D_A_loss: 0.0440, D_B_loss: 0.0123, G_A_loss: 0.8877, G_B_loss: 0.8923\n",
      "Epoch [189/200], Step [191/1067], D_A_loss: 0.1371, D_B_loss: 0.0145, G_A_loss: 0.7771, G_B_loss: 0.3814\n",
      "Epoch [189/200], Step [201/1067], D_A_loss: 0.1113, D_B_loss: 0.0133, G_A_loss: 0.7953, G_B_loss: 0.4219\n",
      "Epoch [189/200], Step [211/1067], D_A_loss: 0.0228, D_B_loss: 0.0092, G_A_loss: 0.7408, G_B_loss: 1.0631\n",
      "Epoch [189/200], Step [221/1067], D_A_loss: 0.0230, D_B_loss: 0.0225, G_A_loss: 0.8764, G_B_loss: 0.9396\n",
      "Epoch [189/200], Step [231/1067], D_A_loss: 0.0244, D_B_loss: 0.0103, G_A_loss: 1.0475, G_B_loss: 0.8151\n",
      "Epoch [189/200], Step [241/1067], D_A_loss: 0.0827, D_B_loss: 0.0291, G_A_loss: 0.9148, G_B_loss: 0.9235\n",
      "Epoch [189/200], Step [251/1067], D_A_loss: 0.0315, D_B_loss: 0.0331, G_A_loss: 0.9350, G_B_loss: 0.6425\n",
      "Epoch [189/200], Step [261/1067], D_A_loss: 0.0224, D_B_loss: 0.0414, G_A_loss: 0.6943, G_B_loss: 1.0488\n",
      "Epoch [189/200], Step [271/1067], D_A_loss: 0.0622, D_B_loss: 0.0093, G_A_loss: 0.9510, G_B_loss: 0.6920\n",
      "Epoch [189/200], Step [281/1067], D_A_loss: 0.0234, D_B_loss: 0.0081, G_A_loss: 0.9069, G_B_loss: 0.6881\n",
      "Epoch [189/200], Step [291/1067], D_A_loss: 0.0278, D_B_loss: 0.0558, G_A_loss: 0.8739, G_B_loss: 0.9412\n",
      "Epoch [189/200], Step [301/1067], D_A_loss: 0.0299, D_B_loss: 0.0133, G_A_loss: 0.8079, G_B_loss: 0.9464\n",
      "Epoch [189/200], Step [311/1067], D_A_loss: 0.0567, D_B_loss: 0.0146, G_A_loss: 1.1428, G_B_loss: 0.6045\n",
      "Epoch [189/200], Step [321/1067], D_A_loss: 0.0905, D_B_loss: 0.0704, G_A_loss: 1.0928, G_B_loss: 0.5396\n",
      "Epoch [189/200], Step [331/1067], D_A_loss: 0.1237, D_B_loss: 0.0206, G_A_loss: 0.9820, G_B_loss: 0.5170\n",
      "Epoch [189/200], Step [341/1067], D_A_loss: 0.0617, D_B_loss: 0.0673, G_A_loss: 0.7755, G_B_loss: 0.5521\n",
      "Epoch [189/200], Step [351/1067], D_A_loss: 0.0549, D_B_loss: 0.0672, G_A_loss: 1.3957, G_B_loss: 0.5145\n",
      "Epoch [189/200], Step [361/1067], D_A_loss: 0.1409, D_B_loss: 0.0136, G_A_loss: 0.9639, G_B_loss: 0.5991\n",
      "Epoch [189/200], Step [371/1067], D_A_loss: 0.1549, D_B_loss: 0.0128, G_A_loss: 0.7119, G_B_loss: 0.4783\n",
      "Epoch [189/200], Step [381/1067], D_A_loss: 0.0314, D_B_loss: 0.0078, G_A_loss: 0.7083, G_B_loss: 0.5273\n",
      "Epoch [189/200], Step [391/1067], D_A_loss: 0.0591, D_B_loss: 0.0225, G_A_loss: 0.9385, G_B_loss: 0.6892\n",
      "Epoch [189/200], Step [401/1067], D_A_loss: 0.0443, D_B_loss: 0.0344, G_A_loss: 0.9015, G_B_loss: 1.2091\n",
      "Epoch [189/200], Step [411/1067], D_A_loss: 0.1018, D_B_loss: 0.0095, G_A_loss: 0.9164, G_B_loss: 0.4846\n",
      "Epoch [189/200], Step [421/1067], D_A_loss: 0.0563, D_B_loss: 0.0453, G_A_loss: 1.3795, G_B_loss: 0.8022\n",
      "Epoch [189/200], Step [431/1067], D_A_loss: 0.0334, D_B_loss: 0.0274, G_A_loss: 0.9353, G_B_loss: 0.6994\n",
      "Epoch [189/200], Step [441/1067], D_A_loss: 0.1971, D_B_loss: 0.0102, G_A_loss: 0.8857, G_B_loss: 0.5981\n",
      "Epoch [189/200], Step [451/1067], D_A_loss: 0.0644, D_B_loss: 0.0430, G_A_loss: 0.9817, G_B_loss: 1.4189\n",
      "Epoch [189/200], Step [461/1067], D_A_loss: 0.0195, D_B_loss: 0.0072, G_A_loss: 0.7696, G_B_loss: 0.9946\n",
      "Epoch [189/200], Step [471/1067], D_A_loss: 0.1450, D_B_loss: 0.0361, G_A_loss: 0.8299, G_B_loss: 0.8000\n",
      "Epoch [189/200], Step [481/1067], D_A_loss: 0.0692, D_B_loss: 0.0082, G_A_loss: 1.0914, G_B_loss: 0.7781\n",
      "Epoch [189/200], Step [491/1067], D_A_loss: 0.0277, D_B_loss: 0.0168, G_A_loss: 0.7512, G_B_loss: 1.1723\n",
      "Epoch [189/200], Step [501/1067], D_A_loss: 0.0374, D_B_loss: 0.0110, G_A_loss: 0.6042, G_B_loss: 1.0005\n",
      "Epoch [189/200], Step [511/1067], D_A_loss: 0.0551, D_B_loss: 0.0078, G_A_loss: 0.6503, G_B_loss: 0.6970\n",
      "Epoch [189/200], Step [521/1067], D_A_loss: 0.0724, D_B_loss: 0.0204, G_A_loss: 0.6883, G_B_loss: 1.1275\n",
      "Epoch [189/200], Step [531/1067], D_A_loss: 0.0319, D_B_loss: 0.0120, G_A_loss: 1.2725, G_B_loss: 0.5996\n",
      "Epoch [189/200], Step [541/1067], D_A_loss: 0.0900, D_B_loss: 0.0425, G_A_loss: 0.5551, G_B_loss: 0.4886\n",
      "Epoch [189/200], Step [551/1067], D_A_loss: 0.0416, D_B_loss: 0.0125, G_A_loss: 0.8340, G_B_loss: 0.6935\n",
      "Epoch [189/200], Step [561/1067], D_A_loss: 0.0283, D_B_loss: 0.0104, G_A_loss: 1.0695, G_B_loss: 0.7725\n",
      "Epoch [189/200], Step [571/1067], D_A_loss: 0.0537, D_B_loss: 0.0347, G_A_loss: 1.1985, G_B_loss: 0.7489\n",
      "Epoch [189/200], Step [581/1067], D_A_loss: 0.0601, D_B_loss: 0.0532, G_A_loss: 0.5264, G_B_loss: 0.6979\n",
      "Epoch [189/200], Step [591/1067], D_A_loss: 0.0644, D_B_loss: 0.0346, G_A_loss: 0.7394, G_B_loss: 0.5929\n",
      "Epoch [189/200], Step [601/1067], D_A_loss: 0.0185, D_B_loss: 0.0439, G_A_loss: 1.1090, G_B_loss: 0.8022\n",
      "Epoch [189/200], Step [611/1067], D_A_loss: 0.0336, D_B_loss: 0.0094, G_A_loss: 1.1294, G_B_loss: 0.9262\n",
      "Epoch [189/200], Step [621/1067], D_A_loss: 0.0523, D_B_loss: 0.0126, G_A_loss: 0.7091, G_B_loss: 0.7235\n",
      "Epoch [189/200], Step [631/1067], D_A_loss: 0.0855, D_B_loss: 0.0176, G_A_loss: 0.8395, G_B_loss: 0.7378\n",
      "Epoch [189/200], Step [641/1067], D_A_loss: 0.0567, D_B_loss: 0.0119, G_A_loss: 1.0775, G_B_loss: 0.7662\n",
      "Epoch [189/200], Step [651/1067], D_A_loss: 0.0986, D_B_loss: 0.0351, G_A_loss: 0.9758, G_B_loss: 0.7145\n",
      "Epoch [189/200], Step [661/1067], D_A_loss: 0.0389, D_B_loss: 0.0275, G_A_loss: 0.6649, G_B_loss: 0.6725\n",
      "Epoch [189/200], Step [671/1067], D_A_loss: 0.0614, D_B_loss: 0.0494, G_A_loss: 0.5315, G_B_loss: 0.7696\n",
      "Epoch [189/200], Step [681/1067], D_A_loss: 0.0562, D_B_loss: 0.0166, G_A_loss: 0.8558, G_B_loss: 1.0683\n",
      "Epoch [189/200], Step [691/1067], D_A_loss: 0.1458, D_B_loss: 0.0100, G_A_loss: 0.7938, G_B_loss: 0.4875\n",
      "Epoch [189/200], Step [701/1067], D_A_loss: 0.0419, D_B_loss: 0.0191, G_A_loss: 0.6251, G_B_loss: 0.7849\n",
      "Epoch [189/200], Step [711/1067], D_A_loss: 0.1190, D_B_loss: 0.0527, G_A_loss: 0.7939, G_B_loss: 0.7741\n",
      "Epoch [189/200], Step [721/1067], D_A_loss: 0.0436, D_B_loss: 0.0099, G_A_loss: 0.8757, G_B_loss: 0.7380\n",
      "Epoch [189/200], Step [731/1067], D_A_loss: 0.0267, D_B_loss: 0.0216, G_A_loss: 1.0538, G_B_loss: 0.7848\n",
      "Epoch [189/200], Step [741/1067], D_A_loss: 0.0262, D_B_loss: 0.0073, G_A_loss: 0.8702, G_B_loss: 0.9512\n",
      "Epoch [189/200], Step [751/1067], D_A_loss: 0.0714, D_B_loss: 0.0123, G_A_loss: 0.8952, G_B_loss: 0.5800\n",
      "Epoch [189/200], Step [761/1067], D_A_loss: 0.0244, D_B_loss: 0.0123, G_A_loss: 1.0787, G_B_loss: 0.9576\n",
      "Epoch [189/200], Step [771/1067], D_A_loss: 0.1010, D_B_loss: 0.0314, G_A_loss: 1.1430, G_B_loss: 0.5613\n",
      "Epoch [189/200], Step [781/1067], D_A_loss: 0.1204, D_B_loss: 0.0244, G_A_loss: 0.8056, G_B_loss: 0.5497\n",
      "Epoch [189/200], Step [791/1067], D_A_loss: 0.0257, D_B_loss: 0.0610, G_A_loss: 0.8959, G_B_loss: 1.0009\n",
      "Epoch [189/200], Step [801/1067], D_A_loss: 0.0417, D_B_loss: 0.0294, G_A_loss: 0.8914, G_B_loss: 0.9241\n",
      "Epoch [189/200], Step [811/1067], D_A_loss: 0.0771, D_B_loss: 0.0123, G_A_loss: 0.4320, G_B_loss: 0.7067\n",
      "Epoch [189/200], Step [821/1067], D_A_loss: 0.0389, D_B_loss: 0.0169, G_A_loss: 0.9995, G_B_loss: 0.8194\n",
      "Epoch [189/200], Step [831/1067], D_A_loss: 0.1053, D_B_loss: 0.0216, G_A_loss: 1.0333, G_B_loss: 0.5475\n",
      "Epoch [189/200], Step [841/1067], D_A_loss: 0.0248, D_B_loss: 0.0364, G_A_loss: 0.6457, G_B_loss: 0.6713\n",
      "Epoch [189/200], Step [851/1067], D_A_loss: 0.0218, D_B_loss: 0.0141, G_A_loss: 1.1148, G_B_loss: 0.7612\n",
      "Epoch [189/200], Step [861/1067], D_A_loss: 0.0482, D_B_loss: 0.0086, G_A_loss: 0.9814, G_B_loss: 0.9201\n",
      "Epoch [189/200], Step [871/1067], D_A_loss: 0.0204, D_B_loss: 0.1299, G_A_loss: 0.4482, G_B_loss: 0.7729\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [189/200], Step [881/1067], D_A_loss: 0.0418, D_B_loss: 0.0114, G_A_loss: 1.2170, G_B_loss: 0.3943\n",
      "Epoch [189/200], Step [891/1067], D_A_loss: 0.0361, D_B_loss: 0.0226, G_A_loss: 0.7722, G_B_loss: 0.7843\n",
      "Epoch [189/200], Step [901/1067], D_A_loss: 0.0387, D_B_loss: 0.0109, G_A_loss: 1.1605, G_B_loss: 0.4416\n",
      "Epoch [189/200], Step [911/1067], D_A_loss: 0.1698, D_B_loss: 0.0450, G_A_loss: 1.6087, G_B_loss: 0.2392\n",
      "Epoch [189/200], Step [921/1067], D_A_loss: 0.0406, D_B_loss: 0.0104, G_A_loss: 1.1118, G_B_loss: 0.7332\n",
      "Epoch [189/200], Step [931/1067], D_A_loss: 0.1008, D_B_loss: 0.0285, G_A_loss: 1.1200, G_B_loss: 0.6602\n",
      "Epoch [189/200], Step [941/1067], D_A_loss: 0.0426, D_B_loss: 0.0156, G_A_loss: 1.2104, G_B_loss: 0.6909\n",
      "Epoch [189/200], Step [951/1067], D_A_loss: 0.0232, D_B_loss: 0.0114, G_A_loss: 1.0806, G_B_loss: 0.7641\n",
      "Epoch [189/200], Step [961/1067], D_A_loss: 0.2153, D_B_loss: 0.0105, G_A_loss: 0.9019, G_B_loss: 0.4741\n",
      "Epoch [189/200], Step [971/1067], D_A_loss: 0.0821, D_B_loss: 0.0846, G_A_loss: 0.8805, G_B_loss: 0.6491\n",
      "Epoch [189/200], Step [981/1067], D_A_loss: 0.0288, D_B_loss: 0.0475, G_A_loss: 0.5385, G_B_loss: 0.4750\n",
      "Epoch [189/200], Step [991/1067], D_A_loss: 0.1698, D_B_loss: 0.0124, G_A_loss: 0.9788, G_B_loss: 0.9046\n",
      "Epoch [189/200], Step [1001/1067], D_A_loss: 0.0862, D_B_loss: 0.0256, G_A_loss: 0.7236, G_B_loss: 0.5540\n",
      "Epoch [189/200], Step [1011/1067], D_A_loss: 0.0423, D_B_loss: 0.0471, G_A_loss: 0.5418, G_B_loss: 0.8064\n",
      "Epoch [189/200], Step [1021/1067], D_A_loss: 0.0335, D_B_loss: 0.0205, G_A_loss: 0.7694, G_B_loss: 0.8727\n",
      "Epoch [189/200], Step [1031/1067], D_A_loss: 0.0827, D_B_loss: 0.0349, G_A_loss: 0.9582, G_B_loss: 0.9118\n",
      "Epoch [189/200], Step [1041/1067], D_A_loss: 0.0348, D_B_loss: 0.0279, G_A_loss: 0.9579, G_B_loss: 0.7705\n",
      "Epoch [189/200], Step [1051/1067], D_A_loss: 0.0337, D_B_loss: 0.0158, G_A_loss: 0.9335, G_B_loss: 0.5315\n",
      "Epoch [189/200], Step [1061/1067], D_A_loss: 0.0392, D_B_loss: 0.0143, G_A_loss: 1.1845, G_B_loss: 0.6653\n",
      "Epoch [190/200], Step [1/1067], D_A_loss: 0.0290, D_B_loss: 0.0081, G_A_loss: 0.9220, G_B_loss: 0.8635\n",
      "Epoch [190/200], Step [11/1067], D_A_loss: 0.0455, D_B_loss: 0.0113, G_A_loss: 0.9969, G_B_loss: 0.6178\n",
      "Epoch [190/200], Step [21/1067], D_A_loss: 0.1000, D_B_loss: 0.0173, G_A_loss: 0.8322, G_B_loss: 0.6869\n",
      "Epoch [190/200], Step [31/1067], D_A_loss: 0.0508, D_B_loss: 0.0212, G_A_loss: 0.6937, G_B_loss: 0.6395\n",
      "Epoch [190/200], Step [41/1067], D_A_loss: 0.1892, D_B_loss: 0.1496, G_A_loss: 0.9333, G_B_loss: 0.6327\n",
      "Epoch [190/200], Step [51/1067], D_A_loss: 0.0363, D_B_loss: 0.0278, G_A_loss: 0.6910, G_B_loss: 0.6766\n",
      "Epoch [190/200], Step [61/1067], D_A_loss: 0.1103, D_B_loss: 0.0261, G_A_loss: 0.8685, G_B_loss: 0.7850\n",
      "Epoch [190/200], Step [71/1067], D_A_loss: 0.0694, D_B_loss: 0.0236, G_A_loss: 0.7704, G_B_loss: 0.6853\n",
      "Epoch [190/200], Step [81/1067], D_A_loss: 0.0645, D_B_loss: 0.0082, G_A_loss: 0.8041, G_B_loss: 0.7442\n",
      "Epoch [190/200], Step [91/1067], D_A_loss: 0.2431, D_B_loss: 0.0157, G_A_loss: 0.7558, G_B_loss: 0.2607\n",
      "Epoch [190/200], Step [101/1067], D_A_loss: 0.0680, D_B_loss: 0.0095, G_A_loss: 0.9547, G_B_loss: 0.6766\n",
      "Epoch [190/200], Step [111/1067], D_A_loss: 0.0408, D_B_loss: 0.0122, G_A_loss: 1.1761, G_B_loss: 0.6250\n",
      "Epoch [190/200], Step [121/1067], D_A_loss: 0.0983, D_B_loss: 0.0179, G_A_loss: 0.8956, G_B_loss: 0.5438\n",
      "Epoch [190/200], Step [131/1067], D_A_loss: 0.1546, D_B_loss: 0.0193, G_A_loss: 0.9135, G_B_loss: 0.6768\n",
      "Epoch [190/200], Step [141/1067], D_A_loss: 0.0951, D_B_loss: 0.0445, G_A_loss: 0.5302, G_B_loss: 0.4813\n",
      "Epoch [190/200], Step [151/1067], D_A_loss: 0.0433, D_B_loss: 0.0087, G_A_loss: 1.0741, G_B_loss: 0.4902\n",
      "Epoch [190/200], Step [161/1067], D_A_loss: 0.0919, D_B_loss: 0.0136, G_A_loss: 0.8229, G_B_loss: 0.4420\n",
      "Epoch [190/200], Step [171/1067], D_A_loss: 0.0999, D_B_loss: 0.0710, G_A_loss: 0.4711, G_B_loss: 0.7456\n",
      "Epoch [190/200], Step [181/1067], D_A_loss: 0.1287, D_B_loss: 0.0165, G_A_loss: 0.7596, G_B_loss: 0.5470\n",
      "Epoch [190/200], Step [191/1067], D_A_loss: 0.1066, D_B_loss: 0.0174, G_A_loss: 1.0076, G_B_loss: 0.4898\n",
      "Epoch [190/200], Step [201/1067], D_A_loss: 0.0792, D_B_loss: 0.0107, G_A_loss: 0.9289, G_B_loss: 0.7373\n",
      "Epoch [190/200], Step [211/1067], D_A_loss: 0.0326, D_B_loss: 0.0512, G_A_loss: 1.0497, G_B_loss: 0.9260\n",
      "Epoch [190/200], Step [221/1067], D_A_loss: 0.0319, D_B_loss: 0.0184, G_A_loss: 0.7435, G_B_loss: 0.7729\n",
      "Epoch [190/200], Step [231/1067], D_A_loss: 0.0343, D_B_loss: 0.0289, G_A_loss: 0.8231, G_B_loss: 0.7895\n",
      "Epoch [190/200], Step [241/1067], D_A_loss: 0.0212, D_B_loss: 0.0265, G_A_loss: 0.8602, G_B_loss: 0.6676\n",
      "Epoch [190/200], Step [251/1067], D_A_loss: 0.0912, D_B_loss: 0.0311, G_A_loss: 0.6338, G_B_loss: 0.4706\n",
      "Epoch [190/200], Step [261/1067], D_A_loss: 0.0616, D_B_loss: 0.0559, G_A_loss: 0.9748, G_B_loss: 0.5933\n",
      "Epoch [190/200], Step [271/1067], D_A_loss: 0.1141, D_B_loss: 0.0418, G_A_loss: 0.8511, G_B_loss: 0.6560\n",
      "Epoch [190/200], Step [281/1067], D_A_loss: 0.0346, D_B_loss: 0.0233, G_A_loss: 0.6736, G_B_loss: 0.5421\n",
      "Epoch [190/200], Step [291/1067], D_A_loss: 0.0659, D_B_loss: 0.0089, G_A_loss: 0.7458, G_B_loss: 0.5901\n",
      "Epoch [190/200], Step [301/1067], D_A_loss: 0.1743, D_B_loss: 0.0340, G_A_loss: 0.5459, G_B_loss: 0.8393\n",
      "Epoch [190/200], Step [311/1067], D_A_loss: 0.0703, D_B_loss: 0.0260, G_A_loss: 0.7646, G_B_loss: 0.8523\n",
      "Epoch [190/200], Step [321/1067], D_A_loss: 0.1168, D_B_loss: 0.0096, G_A_loss: 0.8426, G_B_loss: 0.6487\n",
      "Epoch [190/200], Step [331/1067], D_A_loss: 0.0287, D_B_loss: 0.0222, G_A_loss: 0.8534, G_B_loss: 1.0023\n",
      "Epoch [190/200], Step [341/1067], D_A_loss: 0.1146, D_B_loss: 0.0258, G_A_loss: 0.9354, G_B_loss: 0.3500\n",
      "Epoch [190/200], Step [351/1067], D_A_loss: 0.2199, D_B_loss: 0.0291, G_A_loss: 0.6854, G_B_loss: 0.6927\n",
      "Epoch [190/200], Step [361/1067], D_A_loss: 0.0704, D_B_loss: 0.0173, G_A_loss: 1.2335, G_B_loss: 0.3566\n",
      "Epoch [190/200], Step [371/1067], D_A_loss: 0.0608, D_B_loss: 0.0702, G_A_loss: 1.0604, G_B_loss: 0.5476\n",
      "Epoch [190/200], Step [381/1067], D_A_loss: 0.0618, D_B_loss: 0.0634, G_A_loss: 0.5077, G_B_loss: 0.9399\n",
      "Epoch [190/200], Step [391/1067], D_A_loss: 0.1106, D_B_loss: 0.0350, G_A_loss: 0.5932, G_B_loss: 0.3799\n",
      "Epoch [190/200], Step [401/1067], D_A_loss: 0.0454, D_B_loss: 0.0194, G_A_loss: 0.7545, G_B_loss: 0.8461\n",
      "Epoch [190/200], Step [411/1067], D_A_loss: 0.0416, D_B_loss: 0.0347, G_A_loss: 0.9373, G_B_loss: 0.9395\n",
      "Epoch [190/200], Step [421/1067], D_A_loss: 0.0611, D_B_loss: 0.0383, G_A_loss: 0.8266, G_B_loss: 0.7791\n",
      "Epoch [190/200], Step [431/1067], D_A_loss: 0.0332, D_B_loss: 0.0093, G_A_loss: 1.4507, G_B_loss: 0.7956\n",
      "Epoch [190/200], Step [441/1067], D_A_loss: 0.0237, D_B_loss: 0.0085, G_A_loss: 0.7378, G_B_loss: 0.9085\n",
      "Epoch [190/200], Step [451/1067], D_A_loss: 0.0526, D_B_loss: 0.0099, G_A_loss: 1.0407, G_B_loss: 0.7548\n",
      "Epoch [190/200], Step [461/1067], D_A_loss: 0.1238, D_B_loss: 0.0268, G_A_loss: 0.9389, G_B_loss: 0.6464\n",
      "Epoch [190/200], Step [471/1067], D_A_loss: 0.0838, D_B_loss: 0.0228, G_A_loss: 0.5319, G_B_loss: 0.9008\n",
      "Epoch [190/200], Step [481/1067], D_A_loss: 0.0633, D_B_loss: 0.0145, G_A_loss: 0.9091, G_B_loss: 0.5693\n",
      "Epoch [190/200], Step [491/1067], D_A_loss: 0.0555, D_B_loss: 0.0180, G_A_loss: 1.0958, G_B_loss: 0.6074\n",
      "Epoch [190/200], Step [501/1067], D_A_loss: 0.0417, D_B_loss: 0.0206, G_A_loss: 0.7610, G_B_loss: 0.8107\n",
      "Epoch [190/200], Step [511/1067], D_A_loss: 0.1077, D_B_loss: 0.0619, G_A_loss: 0.8400, G_B_loss: 0.4739\n",
      "Epoch [190/200], Step [521/1067], D_A_loss: 0.0557, D_B_loss: 0.0105, G_A_loss: 0.5248, G_B_loss: 0.9372\n",
      "Epoch [190/200], Step [531/1067], D_A_loss: 0.0646, D_B_loss: 0.0227, G_A_loss: 1.0355, G_B_loss: 0.7200\n",
      "Epoch [190/200], Step [541/1067], D_A_loss: 0.0339, D_B_loss: 0.0262, G_A_loss: 1.3250, G_B_loss: 0.7230\n",
      "Epoch [190/200], Step [551/1067], D_A_loss: 0.0255, D_B_loss: 0.0255, G_A_loss: 0.6967, G_B_loss: 0.9460\n",
      "Epoch [190/200], Step [561/1067], D_A_loss: 0.2455, D_B_loss: 0.0289, G_A_loss: 0.6538, G_B_loss: 0.5811\n",
      "Epoch [190/200], Step [571/1067], D_A_loss: 0.0494, D_B_loss: 0.0095, G_A_loss: 0.9598, G_B_loss: 0.6778\n",
      "Epoch [190/200], Step [581/1067], D_A_loss: 0.0293, D_B_loss: 0.0122, G_A_loss: 1.0126, G_B_loss: 0.6184\n",
      "Epoch [190/200], Step [591/1067], D_A_loss: 0.0296, D_B_loss: 0.0345, G_A_loss: 1.1309, G_B_loss: 0.8642\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [190/200], Step [601/1067], D_A_loss: 0.0404, D_B_loss: 0.0113, G_A_loss: 1.1366, G_B_loss: 0.9373\n",
      "Epoch [190/200], Step [611/1067], D_A_loss: 0.0436, D_B_loss: 0.0302, G_A_loss: 1.0446, G_B_loss: 0.8177\n",
      "Epoch [190/200], Step [621/1067], D_A_loss: 0.1007, D_B_loss: 0.0265, G_A_loss: 0.8362, G_B_loss: 0.6840\n",
      "Epoch [190/200], Step [631/1067], D_A_loss: 0.0420, D_B_loss: 0.0074, G_A_loss: 0.9685, G_B_loss: 0.7438\n",
      "Epoch [190/200], Step [641/1067], D_A_loss: 0.0268, D_B_loss: 0.0179, G_A_loss: 0.8190, G_B_loss: 1.0723\n",
      "Epoch [190/200], Step [651/1067], D_A_loss: 0.0232, D_B_loss: 0.0139, G_A_loss: 0.8361, G_B_loss: 0.7870\n",
      "Epoch [190/200], Step [661/1067], D_A_loss: 0.0191, D_B_loss: 0.0102, G_A_loss: 0.9454, G_B_loss: 0.4123\n",
      "Epoch [190/200], Step [671/1067], D_A_loss: 0.1512, D_B_loss: 0.0412, G_A_loss: 0.6927, G_B_loss: 0.6478\n",
      "Epoch [190/200], Step [681/1067], D_A_loss: 0.0695, D_B_loss: 0.0338, G_A_loss: 0.6843, G_B_loss: 0.7522\n",
      "Epoch [190/200], Step [691/1067], D_A_loss: 0.0223, D_B_loss: 0.0162, G_A_loss: 1.1062, G_B_loss: 0.9431\n",
      "Epoch [190/200], Step [701/1067], D_A_loss: 0.0669, D_B_loss: 0.0072, G_A_loss: 0.8051, G_B_loss: 0.5113\n",
      "Epoch [190/200], Step [711/1067], D_A_loss: 0.0935, D_B_loss: 0.0368, G_A_loss: 1.1958, G_B_loss: 0.5663\n",
      "Epoch [190/200], Step [721/1067], D_A_loss: 0.0549, D_B_loss: 0.0257, G_A_loss: 1.0798, G_B_loss: 0.6309\n",
      "Epoch [190/200], Step [731/1067], D_A_loss: 0.0682, D_B_loss: 0.0303, G_A_loss: 0.9547, G_B_loss: 0.6988\n",
      "Epoch [190/200], Step [741/1067], D_A_loss: 0.0377, D_B_loss: 0.0256, G_A_loss: 1.2292, G_B_loss: 0.6797\n",
      "Epoch [190/200], Step [751/1067], D_A_loss: 0.0559, D_B_loss: 0.0118, G_A_loss: 0.8184, G_B_loss: 0.6850\n",
      "Epoch [190/200], Step [761/1067], D_A_loss: 0.0567, D_B_loss: 0.0512, G_A_loss: 0.6302, G_B_loss: 0.9431\n",
      "Epoch [190/200], Step [771/1067], D_A_loss: 0.0327, D_B_loss: 0.0240, G_A_loss: 0.7274, G_B_loss: 0.7730\n",
      "Epoch [190/200], Step [781/1067], D_A_loss: 0.0815, D_B_loss: 0.0203, G_A_loss: 0.7083, G_B_loss: 0.8335\n",
      "Epoch [190/200], Step [791/1067], D_A_loss: 0.0510, D_B_loss: 0.0089, G_A_loss: 1.0237, G_B_loss: 0.7172\n",
      "Epoch [190/200], Step [801/1067], D_A_loss: 0.0426, D_B_loss: 0.1562, G_A_loss: 1.2254, G_B_loss: 0.7124\n",
      "Epoch [190/200], Step [811/1067], D_A_loss: 0.0618, D_B_loss: 0.0311, G_A_loss: 0.6864, G_B_loss: 0.8139\n",
      "Epoch [190/200], Step [821/1067], D_A_loss: 0.1284, D_B_loss: 0.0246, G_A_loss: 0.5844, G_B_loss: 0.5123\n",
      "Epoch [190/200], Step [831/1067], D_A_loss: 0.1384, D_B_loss: 0.0127, G_A_loss: 0.8819, G_B_loss: 0.7651\n",
      "Epoch [190/200], Step [841/1067], D_A_loss: 0.2101, D_B_loss: 0.0090, G_A_loss: 1.1308, G_B_loss: 0.6714\n",
      "Epoch [190/200], Step [851/1067], D_A_loss: 0.1491, D_B_loss: 0.0191, G_A_loss: 1.3237, G_B_loss: 0.5706\n",
      "Epoch [190/200], Step [861/1067], D_A_loss: 0.0224, D_B_loss: 0.0275, G_A_loss: 0.6617, G_B_loss: 0.9047\n",
      "Epoch [190/200], Step [871/1067], D_A_loss: 0.0953, D_B_loss: 0.0321, G_A_loss: 1.1055, G_B_loss: 0.7304\n",
      "Epoch [190/200], Step [881/1067], D_A_loss: 0.1382, D_B_loss: 0.0111, G_A_loss: 0.9637, G_B_loss: 0.9000\n",
      "Epoch [190/200], Step [891/1067], D_A_loss: 0.0680, D_B_loss: 0.0135, G_A_loss: 0.9429, G_B_loss: 0.9605\n",
      "Epoch [190/200], Step [901/1067], D_A_loss: 0.0479, D_B_loss: 0.0108, G_A_loss: 0.9101, G_B_loss: 0.8557\n",
      "Epoch [190/200], Step [911/1067], D_A_loss: 0.0296, D_B_loss: 0.0126, G_A_loss: 1.2157, G_B_loss: 0.7462\n",
      "Epoch [190/200], Step [921/1067], D_A_loss: 0.0421, D_B_loss: 0.0239, G_A_loss: 0.8463, G_B_loss: 0.9140\n",
      "Epoch [190/200], Step [931/1067], D_A_loss: 0.0642, D_B_loss: 0.0172, G_A_loss: 0.7887, G_B_loss: 0.5211\n",
      "Epoch [190/200], Step [941/1067], D_A_loss: 0.0848, D_B_loss: 0.0202, G_A_loss: 0.9669, G_B_loss: 0.4238\n",
      "Epoch [190/200], Step [951/1067], D_A_loss: 0.0399, D_B_loss: 0.0190, G_A_loss: 0.8180, G_B_loss: 0.6724\n",
      "Epoch [190/200], Step [961/1067], D_A_loss: 0.0279, D_B_loss: 0.0096, G_A_loss: 1.1037, G_B_loss: 0.4903\n",
      "Epoch [190/200], Step [971/1067], D_A_loss: 0.0377, D_B_loss: 0.0222, G_A_loss: 0.7676, G_B_loss: 0.8685\n",
      "Epoch [190/200], Step [981/1067], D_A_loss: 0.0866, D_B_loss: 0.0081, G_A_loss: 0.9940, G_B_loss: 0.4439\n",
      "Epoch [190/200], Step [991/1067], D_A_loss: 0.1154, D_B_loss: 0.0107, G_A_loss: 0.9471, G_B_loss: 1.0779\n",
      "Epoch [190/200], Step [1001/1067], D_A_loss: 0.0556, D_B_loss: 0.0090, G_A_loss: 0.7117, G_B_loss: 0.8728\n",
      "Epoch [190/200], Step [1011/1067], D_A_loss: 0.1083, D_B_loss: 0.0451, G_A_loss: 1.0463, G_B_loss: 0.7112\n",
      "Epoch [190/200], Step [1021/1067], D_A_loss: 0.0963, D_B_loss: 0.0192, G_A_loss: 1.0018, G_B_loss: 0.3942\n",
      "Epoch [190/200], Step [1031/1067], D_A_loss: 0.0703, D_B_loss: 0.0256, G_A_loss: 0.9181, G_B_loss: 0.7935\n",
      "Epoch [190/200], Step [1041/1067], D_A_loss: 0.0469, D_B_loss: 0.0153, G_A_loss: 0.8017, G_B_loss: 1.1437\n",
      "Epoch [190/200], Step [1051/1067], D_A_loss: 0.0579, D_B_loss: 0.0137, G_A_loss: 1.1249, G_B_loss: 0.9325\n",
      "Epoch [190/200], Step [1061/1067], D_A_loss: 0.0269, D_B_loss: 0.0107, G_A_loss: 0.9441, G_B_loss: 0.6291\n",
      "Epoch [191/200], Step [1/1067], D_A_loss: 0.0222, D_B_loss: 0.0493, G_A_loss: 0.5321, G_B_loss: 0.7821\n",
      "Epoch [191/200], Step [11/1067], D_A_loss: 0.0753, D_B_loss: 0.0075, G_A_loss: 0.7856, G_B_loss: 0.8443\n",
      "Epoch [191/200], Step [21/1067], D_A_loss: 0.1818, D_B_loss: 0.0228, G_A_loss: 0.9462, G_B_loss: 1.0570\n",
      "Epoch [191/200], Step [31/1067], D_A_loss: 0.0499, D_B_loss: 0.0190, G_A_loss: 0.8726, G_B_loss: 0.7460\n",
      "Epoch [191/200], Step [41/1067], D_A_loss: 0.1013, D_B_loss: 0.0130, G_A_loss: 0.5701, G_B_loss: 0.3788\n",
      "Epoch [191/200], Step [51/1067], D_A_loss: 0.0571, D_B_loss: 0.0506, G_A_loss: 0.7506, G_B_loss: 0.8502\n",
      "Epoch [191/200], Step [61/1067], D_A_loss: 0.0279, D_B_loss: 0.0109, G_A_loss: 0.5944, G_B_loss: 0.8332\n",
      "Epoch [191/200], Step [71/1067], D_A_loss: 0.0527, D_B_loss: 0.0112, G_A_loss: 0.9582, G_B_loss: 0.8991\n",
      "Epoch [191/200], Step [81/1067], D_A_loss: 0.0513, D_B_loss: 0.0470, G_A_loss: 0.9070, G_B_loss: 0.9268\n",
      "Epoch [191/200], Step [91/1067], D_A_loss: 0.0361, D_B_loss: 0.0314, G_A_loss: 0.6689, G_B_loss: 0.5348\n",
      "Epoch [191/200], Step [101/1067], D_A_loss: 0.0611, D_B_loss: 0.0427, G_A_loss: 0.7027, G_B_loss: 0.5114\n",
      "Epoch [191/200], Step [111/1067], D_A_loss: 0.0222, D_B_loss: 0.0110, G_A_loss: 0.9406, G_B_loss: 0.9850\n",
      "Epoch [191/200], Step [121/1067], D_A_loss: 0.0322, D_B_loss: 0.0242, G_A_loss: 1.3033, G_B_loss: 0.7609\n",
      "Epoch [191/200], Step [131/1067], D_A_loss: 0.1269, D_B_loss: 0.0085, G_A_loss: 0.6126, G_B_loss: 0.8827\n",
      "Epoch [191/200], Step [141/1067], D_A_loss: 0.0340, D_B_loss: 0.0143, G_A_loss: 0.9846, G_B_loss: 0.7467\n",
      "Epoch [191/200], Step [151/1067], D_A_loss: 0.0462, D_B_loss: 0.0122, G_A_loss: 0.4574, G_B_loss: 0.8424\n",
      "Epoch [191/200], Step [161/1067], D_A_loss: 0.0469, D_B_loss: 0.0127, G_A_loss: 1.1301, G_B_loss: 0.6589\n",
      "Epoch [191/200], Step [171/1067], D_A_loss: 0.0809, D_B_loss: 0.0178, G_A_loss: 0.7904, G_B_loss: 0.3796\n",
      "Epoch [191/200], Step [181/1067], D_A_loss: 0.0604, D_B_loss: 0.0242, G_A_loss: 0.7298, G_B_loss: 0.8130\n",
      "Epoch [191/200], Step [191/1067], D_A_loss: 0.0385, D_B_loss: 0.0076, G_A_loss: 1.0415, G_B_loss: 0.3409\n",
      "Epoch [191/200], Step [201/1067], D_A_loss: 0.1936, D_B_loss: 0.0329, G_A_loss: 0.6851, G_B_loss: 0.9146\n",
      "Epoch [191/200], Step [211/1067], D_A_loss: 0.0446, D_B_loss: 0.0202, G_A_loss: 0.7127, G_B_loss: 0.6443\n",
      "Epoch [191/200], Step [221/1067], D_A_loss: 0.0449, D_B_loss: 0.0117, G_A_loss: 0.9945, G_B_loss: 0.8839\n",
      "Epoch [191/200], Step [231/1067], D_A_loss: 0.1678, D_B_loss: 0.0247, G_A_loss: 0.7098, G_B_loss: 0.7298\n",
      "Epoch [191/200], Step [241/1067], D_A_loss: 0.0793, D_B_loss: 0.0086, G_A_loss: 0.9279, G_B_loss: 0.6570\n",
      "Epoch [191/200], Step [251/1067], D_A_loss: 0.0764, D_B_loss: 0.0164, G_A_loss: 0.7501, G_B_loss: 0.6100\n",
      "Epoch [191/200], Step [261/1067], D_A_loss: 0.0555, D_B_loss: 0.0254, G_A_loss: 0.7203, G_B_loss: 0.7424\n",
      "Epoch [191/200], Step [271/1067], D_A_loss: 0.0399, D_B_loss: 0.0423, G_A_loss: 0.5956, G_B_loss: 0.9673\n",
      "Epoch [191/200], Step [281/1067], D_A_loss: 0.0343, D_B_loss: 0.0201, G_A_loss: 0.7117, G_B_loss: 1.0191\n",
      "Epoch [191/200], Step [291/1067], D_A_loss: 0.0598, D_B_loss: 0.0161, G_A_loss: 0.7445, G_B_loss: 0.3447\n",
      "Epoch [191/200], Step [301/1067], D_A_loss: 0.0497, D_B_loss: 0.0280, G_A_loss: 0.6577, G_B_loss: 0.8131\n",
      "Epoch [191/200], Step [311/1067], D_A_loss: 0.0919, D_B_loss: 0.0132, G_A_loss: 0.8414, G_B_loss: 0.4832\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [191/200], Step [321/1067], D_A_loss: 0.0384, D_B_loss: 0.0199, G_A_loss: 1.1083, G_B_loss: 0.8440\n",
      "Epoch [191/200], Step [331/1067], D_A_loss: 0.0673, D_B_loss: 0.0482, G_A_loss: 0.8218, G_B_loss: 0.8345\n",
      "Epoch [191/200], Step [341/1067], D_A_loss: 0.0859, D_B_loss: 0.0153, G_A_loss: 1.1590, G_B_loss: 0.7462\n",
      "Epoch [191/200], Step [351/1067], D_A_loss: 0.0403, D_B_loss: 0.0098, G_A_loss: 0.8720, G_B_loss: 0.4488\n",
      "Epoch [191/200], Step [361/1067], D_A_loss: 0.0510, D_B_loss: 0.0095, G_A_loss: 0.5640, G_B_loss: 0.5979\n",
      "Epoch [191/200], Step [371/1067], D_A_loss: 0.0367, D_B_loss: 0.0134, G_A_loss: 1.0062, G_B_loss: 0.7719\n",
      "Epoch [191/200], Step [381/1067], D_A_loss: 0.0475, D_B_loss: 0.0124, G_A_loss: 0.8995, G_B_loss: 0.7123\n",
      "Epoch [191/200], Step [391/1067], D_A_loss: 0.0391, D_B_loss: 0.0128, G_A_loss: 0.8396, G_B_loss: 0.5511\n",
      "Epoch [191/200], Step [401/1067], D_A_loss: 0.0787, D_B_loss: 0.0112, G_A_loss: 1.0971, G_B_loss: 0.4860\n",
      "Epoch [191/200], Step [411/1067], D_A_loss: 0.0425, D_B_loss: 0.0147, G_A_loss: 0.8759, G_B_loss: 0.9915\n",
      "Epoch [191/200], Step [421/1067], D_A_loss: 0.1047, D_B_loss: 0.0379, G_A_loss: 0.7035, G_B_loss: 0.4292\n",
      "Epoch [191/200], Step [431/1067], D_A_loss: 0.0837, D_B_loss: 0.0059, G_A_loss: 0.9412, G_B_loss: 0.9366\n",
      "Epoch [191/200], Step [441/1067], D_A_loss: 0.0376, D_B_loss: 0.0806, G_A_loss: 0.7380, G_B_loss: 0.7762\n",
      "Epoch [191/200], Step [451/1067], D_A_loss: 0.0418, D_B_loss: 0.0149, G_A_loss: 0.8555, G_B_loss: 0.5255\n",
      "Epoch [191/200], Step [461/1067], D_A_loss: 0.1348, D_B_loss: 0.0077, G_A_loss: 0.8841, G_B_loss: 0.3418\n",
      "Epoch [191/200], Step [471/1067], D_A_loss: 0.1098, D_B_loss: 0.0204, G_A_loss: 0.7000, G_B_loss: 0.6600\n",
      "Epoch [191/200], Step [481/1067], D_A_loss: 0.0459, D_B_loss: 0.0279, G_A_loss: 0.6835, G_B_loss: 0.6599\n",
      "Epoch [191/200], Step [491/1067], D_A_loss: 0.0644, D_B_loss: 0.0183, G_A_loss: 0.7566, G_B_loss: 0.7024\n",
      "Epoch [191/200], Step [501/1067], D_A_loss: 0.1530, D_B_loss: 0.0475, G_A_loss: 0.9220, G_B_loss: 1.1822\n",
      "Epoch [191/200], Step [511/1067], D_A_loss: 0.0595, D_B_loss: 0.0366, G_A_loss: 0.7479, G_B_loss: 0.6174\n",
      "Epoch [191/200], Step [521/1067], D_A_loss: 0.0272, D_B_loss: 0.0088, G_A_loss: 0.7642, G_B_loss: 0.5339\n",
      "Epoch [191/200], Step [531/1067], D_A_loss: 0.0479, D_B_loss: 0.0140, G_A_loss: 0.7108, G_B_loss: 1.0005\n",
      "Epoch [191/200], Step [541/1067], D_A_loss: 0.0356, D_B_loss: 0.0313, G_A_loss: 0.8165, G_B_loss: 0.7542\n",
      "Epoch [191/200], Step [551/1067], D_A_loss: 0.0808, D_B_loss: 0.0319, G_A_loss: 0.7922, G_B_loss: 0.8935\n",
      "Epoch [191/200], Step [561/1067], D_A_loss: 0.0542, D_B_loss: 0.0260, G_A_loss: 1.0968, G_B_loss: 0.7332\n",
      "Epoch [191/200], Step [571/1067], D_A_loss: 0.1197, D_B_loss: 0.0386, G_A_loss: 0.7901, G_B_loss: 0.7964\n",
      "Epoch [191/200], Step [581/1067], D_A_loss: 0.0449, D_B_loss: 0.0128, G_A_loss: 0.8107, G_B_loss: 0.6724\n",
      "Epoch [191/200], Step [591/1067], D_A_loss: 0.0338, D_B_loss: 0.0599, G_A_loss: 1.0790, G_B_loss: 0.7249\n",
      "Epoch [191/200], Step [601/1067], D_A_loss: 0.0624, D_B_loss: 0.0656, G_A_loss: 0.9170, G_B_loss: 0.5177\n",
      "Epoch [191/200], Step [611/1067], D_A_loss: 0.0923, D_B_loss: 0.0091, G_A_loss: 0.9604, G_B_loss: 0.8572\n",
      "Epoch [191/200], Step [621/1067], D_A_loss: 0.0618, D_B_loss: 0.0177, G_A_loss: 0.8345, G_B_loss: 0.9256\n",
      "Epoch [191/200], Step [631/1067], D_A_loss: 0.1673, D_B_loss: 0.0563, G_A_loss: 0.4949, G_B_loss: 0.6813\n",
      "Epoch [191/200], Step [641/1067], D_A_loss: 0.0923, D_B_loss: 0.0338, G_A_loss: 1.0824, G_B_loss: 0.6982\n",
      "Epoch [191/200], Step [651/1067], D_A_loss: 0.0647, D_B_loss: 0.0097, G_A_loss: 1.0738, G_B_loss: 0.5604\n",
      "Epoch [191/200], Step [661/1067], D_A_loss: 0.1245, D_B_loss: 0.0149, G_A_loss: 0.4277, G_B_loss: 0.6633\n",
      "Epoch [191/200], Step [671/1067], D_A_loss: 0.0731, D_B_loss: 0.0258, G_A_loss: 0.6592, G_B_loss: 0.5046\n",
      "Epoch [191/200], Step [681/1067], D_A_loss: 0.0395, D_B_loss: 0.0279, G_A_loss: 0.8875, G_B_loss: 0.8105\n",
      "Epoch [191/200], Step [691/1067], D_A_loss: 0.0729, D_B_loss: 0.0695, G_A_loss: 0.4326, G_B_loss: 0.5044\n",
      "Epoch [191/200], Step [701/1067], D_A_loss: 0.0791, D_B_loss: 0.0217, G_A_loss: 1.3307, G_B_loss: 0.4795\n",
      "Epoch [191/200], Step [711/1067], D_A_loss: 0.0239, D_B_loss: 0.0166, G_A_loss: 0.7736, G_B_loss: 0.9870\n",
      "Epoch [191/200], Step [721/1067], D_A_loss: 0.0554, D_B_loss: 0.0480, G_A_loss: 0.6446, G_B_loss: 0.6577\n",
      "Epoch [191/200], Step [731/1067], D_A_loss: 0.1023, D_B_loss: 0.0121, G_A_loss: 1.0124, G_B_loss: 0.3762\n",
      "Epoch [191/200], Step [741/1067], D_A_loss: 0.0256, D_B_loss: 0.0363, G_A_loss: 0.8262, G_B_loss: 1.1354\n",
      "Epoch [191/200], Step [751/1067], D_A_loss: 0.0307, D_B_loss: 0.0216, G_A_loss: 0.7267, G_B_loss: 0.7902\n",
      "Epoch [191/200], Step [761/1067], D_A_loss: 0.0635, D_B_loss: 0.0504, G_A_loss: 0.5652, G_B_loss: 0.6808\n",
      "Epoch [191/200], Step [771/1067], D_A_loss: 0.0305, D_B_loss: 0.0083, G_A_loss: 0.9558, G_B_loss: 0.9219\n",
      "Epoch [191/200], Step [781/1067], D_A_loss: 0.0857, D_B_loss: 0.0519, G_A_loss: 1.3170, G_B_loss: 0.6237\n",
      "Epoch [191/200], Step [791/1067], D_A_loss: 0.0495, D_B_loss: 0.0097, G_A_loss: 0.7362, G_B_loss: 0.7253\n",
      "Epoch [191/200], Step [801/1067], D_A_loss: 0.0338, D_B_loss: 0.0126, G_A_loss: 0.8241, G_B_loss: 0.5151\n",
      "Epoch [191/200], Step [811/1067], D_A_loss: 0.0478, D_B_loss: 0.0747, G_A_loss: 0.8001, G_B_loss: 0.6315\n",
      "Epoch [191/200], Step [821/1067], D_A_loss: 0.0366, D_B_loss: 0.0129, G_A_loss: 1.1742, G_B_loss: 0.8449\n",
      "Epoch [191/200], Step [831/1067], D_A_loss: 0.0284, D_B_loss: 0.0563, G_A_loss: 0.6294, G_B_loss: 0.8667\n",
      "Epoch [191/200], Step [841/1067], D_A_loss: 0.0322, D_B_loss: 0.0212, G_A_loss: 1.0814, G_B_loss: 0.7157\n",
      "Epoch [191/200], Step [851/1067], D_A_loss: 0.0207, D_B_loss: 0.0222, G_A_loss: 1.1226, G_B_loss: 0.7595\n",
      "Epoch [191/200], Step [861/1067], D_A_loss: 0.1601, D_B_loss: 0.0607, G_A_loss: 1.0618, G_B_loss: 0.3537\n",
      "Epoch [191/200], Step [871/1067], D_A_loss: 0.1108, D_B_loss: 0.0378, G_A_loss: 1.1635, G_B_loss: 0.3427\n",
      "Epoch [191/200], Step [881/1067], D_A_loss: 0.0694, D_B_loss: 0.0376, G_A_loss: 0.5313, G_B_loss: 0.4826\n",
      "Epoch [191/200], Step [891/1067], D_A_loss: 0.0394, D_B_loss: 0.0441, G_A_loss: 0.8594, G_B_loss: 0.8336\n",
      "Epoch [191/200], Step [901/1067], D_A_loss: 0.1573, D_B_loss: 0.0101, G_A_loss: 1.4203, G_B_loss: 0.6361\n",
      "Epoch [191/200], Step [911/1067], D_A_loss: 0.0308, D_B_loss: 0.0149, G_A_loss: 0.8990, G_B_loss: 0.7558\n",
      "Epoch [191/200], Step [921/1067], D_A_loss: 0.0269, D_B_loss: 0.0244, G_A_loss: 1.0881, G_B_loss: 0.4567\n",
      "Epoch [191/200], Step [931/1067], D_A_loss: 0.0656, D_B_loss: 0.1024, G_A_loss: 0.8948, G_B_loss: 0.5065\n",
      "Epoch [191/200], Step [941/1067], D_A_loss: 0.0279, D_B_loss: 0.0425, G_A_loss: 0.5544, G_B_loss: 0.8695\n",
      "Epoch [191/200], Step [951/1067], D_A_loss: 0.0223, D_B_loss: 0.0845, G_A_loss: 0.6898, G_B_loss: 0.8415\n",
      "Epoch [191/200], Step [961/1067], D_A_loss: 0.0489, D_B_loss: 0.0086, G_A_loss: 0.7227, G_B_loss: 0.8604\n",
      "Epoch [191/200], Step [971/1067], D_A_loss: 0.1525, D_B_loss: 0.0201, G_A_loss: 0.8351, G_B_loss: 0.4162\n",
      "Epoch [191/200], Step [981/1067], D_A_loss: 0.0412, D_B_loss: 0.0328, G_A_loss: 0.6582, G_B_loss: 0.9462\n",
      "Epoch [191/200], Step [991/1067], D_A_loss: 0.0951, D_B_loss: 0.1031, G_A_loss: 0.6603, G_B_loss: 0.5789\n",
      "Epoch [191/200], Step [1001/1067], D_A_loss: 0.1025, D_B_loss: 0.0457, G_A_loss: 0.8463, G_B_loss: 0.3791\n",
      "Epoch [191/200], Step [1011/1067], D_A_loss: 0.0350, D_B_loss: 0.0244, G_A_loss: 1.0531, G_B_loss: 0.8777\n",
      "Epoch [191/200], Step [1021/1067], D_A_loss: 0.0502, D_B_loss: 0.0127, G_A_loss: 1.0365, G_B_loss: 1.0761\n",
      "Epoch [191/200], Step [1031/1067], D_A_loss: 0.0585, D_B_loss: 0.0151, G_A_loss: 1.2389, G_B_loss: 1.0847\n",
      "Epoch [191/200], Step [1041/1067], D_A_loss: 0.0507, D_B_loss: 0.0225, G_A_loss: 1.1039, G_B_loss: 0.9363\n",
      "Epoch [191/200], Step [1051/1067], D_A_loss: 0.0598, D_B_loss: 0.0114, G_A_loss: 0.8456, G_B_loss: 1.0323\n",
      "Epoch [191/200], Step [1061/1067], D_A_loss: 0.0453, D_B_loss: 0.0174, G_A_loss: 1.3154, G_B_loss: 0.8538\n",
      "Epoch [192/200], Step [1/1067], D_A_loss: 0.0253, D_B_loss: 0.0095, G_A_loss: 0.6559, G_B_loss: 0.4612\n",
      "Epoch [192/200], Step [11/1067], D_A_loss: 0.1549, D_B_loss: 0.0685, G_A_loss: 1.1487, G_B_loss: 1.0167\n",
      "Epoch [192/200], Step [21/1067], D_A_loss: 0.0290, D_B_loss: 0.0102, G_A_loss: 1.1286, G_B_loss: 0.7911\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [192/200], Step [31/1067], D_A_loss: 0.0759, D_B_loss: 0.1020, G_A_loss: 0.7996, G_B_loss: 0.9954\n",
      "Epoch [192/200], Step [41/1067], D_A_loss: 0.0302, D_B_loss: 0.0120, G_A_loss: 0.9976, G_B_loss: 0.8978\n",
      "Epoch [192/200], Step [51/1067], D_A_loss: 0.0377, D_B_loss: 0.0341, G_A_loss: 0.7427, G_B_loss: 0.7310\n",
      "Epoch [192/200], Step [61/1067], D_A_loss: 0.0402, D_B_loss: 0.0093, G_A_loss: 0.8085, G_B_loss: 0.7717\n",
      "Epoch [192/200], Step [71/1067], D_A_loss: 0.0529, D_B_loss: 0.0196, G_A_loss: 1.1813, G_B_loss: 0.7428\n",
      "Epoch [192/200], Step [81/1067], D_A_loss: 0.0955, D_B_loss: 0.0311, G_A_loss: 0.7717, G_B_loss: 0.1211\n",
      "Epoch [192/200], Step [91/1067], D_A_loss: 0.1103, D_B_loss: 0.0184, G_A_loss: 0.6928, G_B_loss: 0.5804\n",
      "Epoch [192/200], Step [101/1067], D_A_loss: 0.0682, D_B_loss: 0.0166, G_A_loss: 1.1238, G_B_loss: 0.5339\n",
      "Epoch [192/200], Step [111/1067], D_A_loss: 0.0852, D_B_loss: 0.0094, G_A_loss: 0.6981, G_B_loss: 0.6082\n",
      "Epoch [192/200], Step [121/1067], D_A_loss: 0.0740, D_B_loss: 0.0273, G_A_loss: 0.6786, G_B_loss: 0.6571\n",
      "Epoch [192/200], Step [131/1067], D_A_loss: 0.1184, D_B_loss: 0.0142, G_A_loss: 1.0231, G_B_loss: 0.9291\n",
      "Epoch [192/200], Step [141/1067], D_A_loss: 0.0406, D_B_loss: 0.0409, G_A_loss: 0.7974, G_B_loss: 0.7345\n",
      "Epoch [192/200], Step [151/1067], D_A_loss: 0.0412, D_B_loss: 0.0151, G_A_loss: 0.7719, G_B_loss: 0.7879\n",
      "Epoch [192/200], Step [161/1067], D_A_loss: 0.0240, D_B_loss: 0.0093, G_A_loss: 0.9643, G_B_loss: 1.0024\n",
      "Epoch [192/200], Step [171/1067], D_A_loss: 0.0660, D_B_loss: 0.0255, G_A_loss: 1.2394, G_B_loss: 0.8061\n",
      "Epoch [192/200], Step [181/1067], D_A_loss: 0.0449, D_B_loss: 0.0148, G_A_loss: 0.7771, G_B_loss: 0.6558\n",
      "Epoch [192/200], Step [191/1067], D_A_loss: 0.0253, D_B_loss: 0.0202, G_A_loss: 0.6814, G_B_loss: 0.8538\n",
      "Epoch [192/200], Step [201/1067], D_A_loss: 0.0462, D_B_loss: 0.0261, G_A_loss: 0.6881, G_B_loss: 1.1787\n",
      "Epoch [192/200], Step [211/1067], D_A_loss: 0.0355, D_B_loss: 0.0280, G_A_loss: 0.6870, G_B_loss: 0.8061\n",
      "Epoch [192/200], Step [221/1067], D_A_loss: 0.0616, D_B_loss: 0.0240, G_A_loss: 0.7136, G_B_loss: 0.9450\n",
      "Epoch [192/200], Step [231/1067], D_A_loss: 0.0206, D_B_loss: 0.0332, G_A_loss: 1.4014, G_B_loss: 0.8230\n",
      "Epoch [192/200], Step [241/1067], D_A_loss: 0.0271, D_B_loss: 0.0675, G_A_loss: 1.3841, G_B_loss: 0.5452\n",
      "Epoch [192/200], Step [251/1067], D_A_loss: 0.0387, D_B_loss: 0.0119, G_A_loss: 0.9136, G_B_loss: 1.2113\n",
      "Epoch [192/200], Step [261/1067], D_A_loss: 0.0391, D_B_loss: 0.0207, G_A_loss: 0.6683, G_B_loss: 0.8826\n",
      "Epoch [192/200], Step [271/1067], D_A_loss: 0.0389, D_B_loss: 0.0089, G_A_loss: 0.9598, G_B_loss: 0.7159\n",
      "Epoch [192/200], Step [281/1067], D_A_loss: 0.0430, D_B_loss: 0.0138, G_A_loss: 1.1025, G_B_loss: 0.7721\n",
      "Epoch [192/200], Step [291/1067], D_A_loss: 0.1771, D_B_loss: 0.0553, G_A_loss: 0.9305, G_B_loss: 0.5046\n",
      "Epoch [192/200], Step [301/1067], D_A_loss: 0.1411, D_B_loss: 0.0152, G_A_loss: 0.9810, G_B_loss: 0.2825\n",
      "Epoch [192/200], Step [311/1067], D_A_loss: 0.1198, D_B_loss: 0.0140, G_A_loss: 0.8108, G_B_loss: 0.7186\n",
      "Epoch [192/200], Step [321/1067], D_A_loss: 0.1166, D_B_loss: 0.0126, G_A_loss: 0.9900, G_B_loss: 0.3591\n",
      "Epoch [192/200], Step [331/1067], D_A_loss: 0.0485, D_B_loss: 0.0146, G_A_loss: 0.8327, G_B_loss: 0.6707\n",
      "Epoch [192/200], Step [341/1067], D_A_loss: 0.0283, D_B_loss: 0.0064, G_A_loss: 1.0170, G_B_loss: 0.9504\n",
      "Epoch [192/200], Step [351/1067], D_A_loss: 0.0487, D_B_loss: 0.0307, G_A_loss: 0.6930, G_B_loss: 0.7664\n",
      "Epoch [192/200], Step [361/1067], D_A_loss: 0.0274, D_B_loss: 0.0249, G_A_loss: 0.9844, G_B_loss: 0.9478\n",
      "Epoch [192/200], Step [371/1067], D_A_loss: 0.0323, D_B_loss: 0.0159, G_A_loss: 1.1954, G_B_loss: 1.0144\n",
      "Epoch [192/200], Step [381/1067], D_A_loss: 0.1003, D_B_loss: 0.0576, G_A_loss: 0.9222, G_B_loss: 0.6717\n",
      "Epoch [192/200], Step [391/1067], D_A_loss: 0.0725, D_B_loss: 0.0243, G_A_loss: 0.6992, G_B_loss: 0.6459\n",
      "Epoch [192/200], Step [401/1067], D_A_loss: 0.0298, D_B_loss: 0.0150, G_A_loss: 0.8523, G_B_loss: 0.6807\n",
      "Epoch [192/200], Step [411/1067], D_A_loss: 0.0728, D_B_loss: 0.0113, G_A_loss: 0.8315, G_B_loss: 0.7809\n",
      "Epoch [192/200], Step [421/1067], D_A_loss: 0.0245, D_B_loss: 0.0241, G_A_loss: 0.7873, G_B_loss: 0.6844\n",
      "Epoch [192/200], Step [431/1067], D_A_loss: 0.0264, D_B_loss: 0.0287, G_A_loss: 1.4110, G_B_loss: 0.5837\n",
      "Epoch [192/200], Step [441/1067], D_A_loss: 0.0328, D_B_loss: 0.0167, G_A_loss: 0.8093, G_B_loss: 0.7250\n",
      "Epoch [192/200], Step [451/1067], D_A_loss: 0.0693, D_B_loss: 0.0181, G_A_loss: 0.9007, G_B_loss: 0.5352\n",
      "Epoch [192/200], Step [461/1067], D_A_loss: 0.1719, D_B_loss: 0.0168, G_A_loss: 0.9657, G_B_loss: 0.5158\n",
      "Epoch [192/200], Step [471/1067], D_A_loss: 0.0753, D_B_loss: 0.0479, G_A_loss: 0.5350, G_B_loss: 0.4989\n",
      "Epoch [192/200], Step [481/1067], D_A_loss: 0.0573, D_B_loss: 0.0130, G_A_loss: 1.1612, G_B_loss: 0.9767\n",
      "Epoch [192/200], Step [491/1067], D_A_loss: 0.0319, D_B_loss: 0.0456, G_A_loss: 0.6239, G_B_loss: 0.7639\n",
      "Epoch [192/200], Step [501/1067], D_A_loss: 0.1900, D_B_loss: 0.0137, G_A_loss: 0.8840, G_B_loss: 0.9842\n",
      "Epoch [192/200], Step [511/1067], D_A_loss: 0.1453, D_B_loss: 0.0207, G_A_loss: 1.1223, G_B_loss: 0.8522\n",
      "Epoch [192/200], Step [521/1067], D_A_loss: 0.0329, D_B_loss: 0.0092, G_A_loss: 1.0595, G_B_loss: 0.7506\n",
      "Epoch [192/200], Step [531/1067], D_A_loss: 0.0889, D_B_loss: 0.0096, G_A_loss: 0.9156, G_B_loss: 0.5059\n",
      "Epoch [192/200], Step [541/1067], D_A_loss: 0.0425, D_B_loss: 0.0487, G_A_loss: 0.5634, G_B_loss: 0.7834\n",
      "Epoch [192/200], Step [551/1067], D_A_loss: 0.0837, D_B_loss: 0.0198, G_A_loss: 1.2285, G_B_loss: 0.5066\n",
      "Epoch [192/200], Step [561/1067], D_A_loss: 0.0404, D_B_loss: 0.0438, G_A_loss: 1.0163, G_B_loss: 0.6930\n",
      "Epoch [192/200], Step [571/1067], D_A_loss: 0.0410, D_B_loss: 0.0315, G_A_loss: 0.6288, G_B_loss: 0.7150\n",
      "Epoch [192/200], Step [581/1067], D_A_loss: 0.0526, D_B_loss: 0.0162, G_A_loss: 1.1126, G_B_loss: 0.7484\n",
      "Epoch [192/200], Step [591/1067], D_A_loss: 0.0365, D_B_loss: 0.0100, G_A_loss: 1.1515, G_B_loss: 1.0859\n",
      "Epoch [192/200], Step [601/1067], D_A_loss: 0.0328, D_B_loss: 0.0141, G_A_loss: 0.8797, G_B_loss: 0.8218\n",
      "Epoch [192/200], Step [611/1067], D_A_loss: 0.0849, D_B_loss: 0.0150, G_A_loss: 0.7909, G_B_loss: 0.9205\n",
      "Epoch [192/200], Step [621/1067], D_A_loss: 0.1122, D_B_loss: 0.0173, G_A_loss: 0.7744, G_B_loss: 0.6644\n",
      "Epoch [192/200], Step [631/1067], D_A_loss: 0.0456, D_B_loss: 0.0141, G_A_loss: 0.7967, G_B_loss: 0.8188\n",
      "Epoch [192/200], Step [641/1067], D_A_loss: 0.0686, D_B_loss: 0.0128, G_A_loss: 0.8403, G_B_loss: 0.9333\n",
      "Epoch [192/200], Step [651/1067], D_A_loss: 0.0266, D_B_loss: 0.0303, G_A_loss: 0.6366, G_B_loss: 0.7223\n",
      "Epoch [192/200], Step [661/1067], D_A_loss: 0.0769, D_B_loss: 0.0201, G_A_loss: 1.0405, G_B_loss: 0.6262\n",
      "Epoch [192/200], Step [671/1067], D_A_loss: 0.0330, D_B_loss: 0.0083, G_A_loss: 0.9482, G_B_loss: 0.7666\n",
      "Epoch [192/200], Step [681/1067], D_A_loss: 0.0349, D_B_loss: 0.0317, G_A_loss: 0.7383, G_B_loss: 0.7223\n",
      "Epoch [192/200], Step [691/1067], D_A_loss: 0.0711, D_B_loss: 0.0324, G_A_loss: 0.7556, G_B_loss: 0.9105\n",
      "Epoch [192/200], Step [701/1067], D_A_loss: 0.0448, D_B_loss: 0.0201, G_A_loss: 0.7181, G_B_loss: 0.9857\n",
      "Epoch [192/200], Step [711/1067], D_A_loss: 0.0297, D_B_loss: 0.0154, G_A_loss: 0.8525, G_B_loss: 0.7842\n",
      "Epoch [192/200], Step [721/1067], D_A_loss: 0.0681, D_B_loss: 0.0088, G_A_loss: 1.1137, G_B_loss: 0.8867\n",
      "Epoch [192/200], Step [731/1067], D_A_loss: 0.0854, D_B_loss: 0.0110, G_A_loss: 1.1556, G_B_loss: 0.4454\n",
      "Epoch [192/200], Step [741/1067], D_A_loss: 0.0403, D_B_loss: 0.0199, G_A_loss: 1.0537, G_B_loss: 0.8631\n",
      "Epoch [192/200], Step [751/1067], D_A_loss: 0.0418, D_B_loss: 0.0268, G_A_loss: 0.7383, G_B_loss: 0.7816\n",
      "Epoch [192/200], Step [761/1067], D_A_loss: 0.0792, D_B_loss: 0.0136, G_A_loss: 0.9514, G_B_loss: 0.8064\n",
      "Epoch [192/200], Step [771/1067], D_A_loss: 0.0957, D_B_loss: 0.0091, G_A_loss: 0.8021, G_B_loss: 0.8345\n",
      "Epoch [192/200], Step [781/1067], D_A_loss: 0.0304, D_B_loss: 0.0087, G_A_loss: 0.9057, G_B_loss: 0.7395\n",
      "Epoch [192/200], Step [791/1067], D_A_loss: 0.0657, D_B_loss: 0.0124, G_A_loss: 1.0024, G_B_loss: 0.5437\n",
      "Epoch [192/200], Step [801/1067], D_A_loss: 0.0647, D_B_loss: 0.0091, G_A_loss: 0.9641, G_B_loss: 0.5433\n",
      "Epoch [192/200], Step [811/1067], D_A_loss: 0.0242, D_B_loss: 0.0127, G_A_loss: 0.9904, G_B_loss: 0.9259\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [192/200], Step [821/1067], D_A_loss: 0.1298, D_B_loss: 0.0162, G_A_loss: 0.9537, G_B_loss: 0.6252\n",
      "Epoch [192/200], Step [831/1067], D_A_loss: 0.0232, D_B_loss: 0.0081, G_A_loss: 1.1112, G_B_loss: 1.0620\n",
      "Epoch [192/200], Step [841/1067], D_A_loss: 0.0805, D_B_loss: 0.0875, G_A_loss: 0.6523, G_B_loss: 0.5513\n",
      "Epoch [192/200], Step [851/1067], D_A_loss: 0.1204, D_B_loss: 0.0188, G_A_loss: 0.9049, G_B_loss: 0.3473\n",
      "Epoch [192/200], Step [861/1067], D_A_loss: 0.0189, D_B_loss: 0.0144, G_A_loss: 0.8124, G_B_loss: 0.8680\n",
      "Epoch [192/200], Step [871/1067], D_A_loss: 0.0692, D_B_loss: 0.0131, G_A_loss: 0.9378, G_B_loss: 0.7830\n",
      "Epoch [192/200], Step [881/1067], D_A_loss: 0.0353, D_B_loss: 0.0104, G_A_loss: 0.8159, G_B_loss: 0.7669\n",
      "Epoch [192/200], Step [891/1067], D_A_loss: 0.0231, D_B_loss: 0.0221, G_A_loss: 0.6892, G_B_loss: 0.7821\n",
      "Epoch [192/200], Step [901/1067], D_A_loss: 0.0380, D_B_loss: 0.0082, G_A_loss: 1.0955, G_B_loss: 0.7134\n",
      "Epoch [192/200], Step [911/1067], D_A_loss: 0.0321, D_B_loss: 0.0454, G_A_loss: 1.1095, G_B_loss: 0.4685\n",
      "Epoch [192/200], Step [921/1067], D_A_loss: 0.1328, D_B_loss: 0.0341, G_A_loss: 0.5421, G_B_loss: 0.3561\n",
      "Epoch [192/200], Step [931/1067], D_A_loss: 0.0682, D_B_loss: 0.0178, G_A_loss: 0.7375, G_B_loss: 0.8344\n",
      "Epoch [192/200], Step [941/1067], D_A_loss: 0.0305, D_B_loss: 0.0962, G_A_loss: 0.5199, G_B_loss: 0.8019\n",
      "Epoch [192/200], Step [951/1067], D_A_loss: 0.0692, D_B_loss: 0.0115, G_A_loss: 1.0244, G_B_loss: 0.7267\n",
      "Epoch [192/200], Step [961/1067], D_A_loss: 0.0733, D_B_loss: 0.0128, G_A_loss: 1.0062, G_B_loss: 1.0786\n",
      "Epoch [192/200], Step [971/1067], D_A_loss: 0.0634, D_B_loss: 0.0108, G_A_loss: 1.4063, G_B_loss: 0.8666\n",
      "Epoch [192/200], Step [981/1067], D_A_loss: 0.0244, D_B_loss: 0.0215, G_A_loss: 0.7633, G_B_loss: 0.9110\n",
      "Epoch [192/200], Step [991/1067], D_A_loss: 0.1545, D_B_loss: 0.0080, G_A_loss: 0.9172, G_B_loss: 0.6533\n",
      "Epoch [192/200], Step [1001/1067], D_A_loss: 0.0361, D_B_loss: 0.0112, G_A_loss: 0.5445, G_B_loss: 0.6642\n",
      "Epoch [192/200], Step [1011/1067], D_A_loss: 0.0721, D_B_loss: 0.0101, G_A_loss: 0.8796, G_B_loss: 0.9165\n",
      "Epoch [192/200], Step [1021/1067], D_A_loss: 0.0723, D_B_loss: 0.0085, G_A_loss: 0.9667, G_B_loss: 0.7911\n",
      "Epoch [192/200], Step [1031/1067], D_A_loss: 0.0275, D_B_loss: 0.0285, G_A_loss: 0.6411, G_B_loss: 0.8152\n",
      "Epoch [192/200], Step [1041/1067], D_A_loss: 0.0913, D_B_loss: 0.0240, G_A_loss: 0.7947, G_B_loss: 0.7074\n",
      "Epoch [192/200], Step [1051/1067], D_A_loss: 0.0567, D_B_loss: 0.0166, G_A_loss: 0.9678, G_B_loss: 0.8943\n",
      "Epoch [192/200], Step [1061/1067], D_A_loss: 0.0923, D_B_loss: 0.0453, G_A_loss: 0.8703, G_B_loss: 0.6386\n",
      "Epoch [193/200], Step [1/1067], D_A_loss: 0.0294, D_B_loss: 0.0111, G_A_loss: 1.1391, G_B_loss: 0.7403\n",
      "Epoch [193/200], Step [11/1067], D_A_loss: 0.0354, D_B_loss: 0.0111, G_A_loss: 0.8319, G_B_loss: 0.2115\n",
      "Epoch [193/200], Step [21/1067], D_A_loss: 0.0829, D_B_loss: 0.0796, G_A_loss: 0.4344, G_B_loss: 1.0860\n",
      "Epoch [193/200], Step [31/1067], D_A_loss: 0.0490, D_B_loss: 0.0128, G_A_loss: 0.9121, G_B_loss: 0.7118\n",
      "Epoch [193/200], Step [41/1067], D_A_loss: 0.0635, D_B_loss: 0.0167, G_A_loss: 0.9533, G_B_loss: 0.6372\n",
      "Epoch [193/200], Step [51/1067], D_A_loss: 0.0587, D_B_loss: 0.0563, G_A_loss: 0.6098, G_B_loss: 0.6566\n",
      "Epoch [193/200], Step [61/1067], D_A_loss: 0.0219, D_B_loss: 0.0072, G_A_loss: 1.0293, G_B_loss: 1.0486\n",
      "Epoch [193/200], Step [71/1067], D_A_loss: 0.1155, D_B_loss: 0.0245, G_A_loss: 0.6665, G_B_loss: 0.5342\n",
      "Epoch [193/200], Step [81/1067], D_A_loss: 0.0672, D_B_loss: 0.0239, G_A_loss: 1.2250, G_B_loss: 0.8973\n",
      "Epoch [193/200], Step [91/1067], D_A_loss: 0.0241, D_B_loss: 0.0155, G_A_loss: 0.9066, G_B_loss: 0.3774\n",
      "Epoch [193/200], Step [101/1067], D_A_loss: 0.0299, D_B_loss: 0.0226, G_A_loss: 1.1035, G_B_loss: 0.7967\n",
      "Epoch [193/200], Step [111/1067], D_A_loss: 0.0354, D_B_loss: 0.0167, G_A_loss: 0.7691, G_B_loss: 0.3070\n",
      "Epoch [193/200], Step [121/1067], D_A_loss: 0.2415, D_B_loss: 0.0220, G_A_loss: 0.9611, G_B_loss: 0.7438\n",
      "Epoch [193/200], Step [131/1067], D_A_loss: 0.0624, D_B_loss: 0.0144, G_A_loss: 0.9041, G_B_loss: 0.7819\n",
      "Epoch [193/200], Step [141/1067], D_A_loss: 0.1280, D_B_loss: 0.0069, G_A_loss: 1.0696, G_B_loss: 0.6646\n",
      "Epoch [193/200], Step [151/1067], D_A_loss: 0.0694, D_B_loss: 0.0198, G_A_loss: 1.1755, G_B_loss: 0.7159\n",
      "Epoch [193/200], Step [161/1067], D_A_loss: 0.0455, D_B_loss: 0.0152, G_A_loss: 1.3270, G_B_loss: 0.6180\n",
      "Epoch [193/200], Step [171/1067], D_A_loss: 0.0345, D_B_loss: 0.0116, G_A_loss: 1.1018, G_B_loss: 0.6668\n",
      "Epoch [193/200], Step [181/1067], D_A_loss: 0.0640, D_B_loss: 0.0206, G_A_loss: 1.1972, G_B_loss: 0.5756\n",
      "Epoch [193/200], Step [191/1067], D_A_loss: 0.0816, D_B_loss: 0.0138, G_A_loss: 0.7194, G_B_loss: 0.8179\n",
      "Epoch [193/200], Step [201/1067], D_A_loss: 0.0325, D_B_loss: 0.0219, G_A_loss: 0.8997, G_B_loss: 0.7052\n",
      "Epoch [193/200], Step [211/1067], D_A_loss: 0.0318, D_B_loss: 0.0249, G_A_loss: 0.8068, G_B_loss: 0.8124\n",
      "Epoch [193/200], Step [221/1067], D_A_loss: 0.1248, D_B_loss: 0.0074, G_A_loss: 1.0038, G_B_loss: 0.9447\n",
      "Epoch [193/200], Step [231/1067], D_A_loss: 0.0545, D_B_loss: 0.0145, G_A_loss: 0.8933, G_B_loss: 0.6709\n",
      "Epoch [193/200], Step [241/1067], D_A_loss: 0.0289, D_B_loss: 0.0356, G_A_loss: 1.0266, G_B_loss: 0.8095\n",
      "Epoch [193/200], Step [251/1067], D_A_loss: 0.0512, D_B_loss: 0.0174, G_A_loss: 0.9532, G_B_loss: 0.6190\n",
      "Epoch [193/200], Step [261/1067], D_A_loss: 0.0874, D_B_loss: 0.0893, G_A_loss: 0.9209, G_B_loss: 0.6719\n",
      "Epoch [193/200], Step [271/1067], D_A_loss: 0.1211, D_B_loss: 0.0123, G_A_loss: 0.6239, G_B_loss: 0.7131\n",
      "Epoch [193/200], Step [281/1067], D_A_loss: 0.0273, D_B_loss: 0.0102, G_A_loss: 0.9382, G_B_loss: 1.1027\n",
      "Epoch [193/200], Step [291/1067], D_A_loss: 0.0510, D_B_loss: 0.0080, G_A_loss: 0.9645, G_B_loss: 0.6135\n",
      "Epoch [193/200], Step [301/1067], D_A_loss: 0.0475, D_B_loss: 0.0376, G_A_loss: 0.6471, G_B_loss: 0.4671\n",
      "Epoch [193/200], Step [311/1067], D_A_loss: 0.1088, D_B_loss: 0.0332, G_A_loss: 0.4754, G_B_loss: 0.8683\n",
      "Epoch [193/200], Step [321/1067], D_A_loss: 0.0241, D_B_loss: 0.0203, G_A_loss: 0.9701, G_B_loss: 0.8982\n",
      "Epoch [193/200], Step [331/1067], D_A_loss: 0.1722, D_B_loss: 0.0209, G_A_loss: 1.0722, G_B_loss: 0.8191\n",
      "Epoch [193/200], Step [341/1067], D_A_loss: 0.0772, D_B_loss: 0.0336, G_A_loss: 0.8293, G_B_loss: 0.8899\n",
      "Epoch [193/200], Step [351/1067], D_A_loss: 0.0554, D_B_loss: 0.0082, G_A_loss: 1.0461, G_B_loss: 0.7705\n",
      "Epoch [193/200], Step [361/1067], D_A_loss: 0.0389, D_B_loss: 0.0398, G_A_loss: 1.4470, G_B_loss: 0.6580\n",
      "Epoch [193/200], Step [371/1067], D_A_loss: 0.0280, D_B_loss: 0.0487, G_A_loss: 0.5981, G_B_loss: 1.1089\n",
      "Epoch [193/200], Step [381/1067], D_A_loss: 0.0872, D_B_loss: 0.0415, G_A_loss: 1.1257, G_B_loss: 0.6687\n",
      "Epoch [193/200], Step [391/1067], D_A_loss: 0.0814, D_B_loss: 0.0158, G_A_loss: 0.8423, G_B_loss: 0.7503\n",
      "Epoch [193/200], Step [401/1067], D_A_loss: 0.1175, D_B_loss: 0.0083, G_A_loss: 0.7182, G_B_loss: 0.7715\n",
      "Epoch [193/200], Step [411/1067], D_A_loss: 0.1012, D_B_loss: 0.0213, G_A_loss: 0.6722, G_B_loss: 0.5103\n",
      "Epoch [193/200], Step [421/1067], D_A_loss: 0.0540, D_B_loss: 0.0186, G_A_loss: 0.7380, G_B_loss: 0.6862\n",
      "Epoch [193/200], Step [431/1067], D_A_loss: 0.0210, D_B_loss: 0.0107, G_A_loss: 1.1036, G_B_loss: 0.5644\n",
      "Epoch [193/200], Step [441/1067], D_A_loss: 0.0315, D_B_loss: 0.0144, G_A_loss: 0.8238, G_B_loss: 0.8372\n",
      "Epoch [193/200], Step [451/1067], D_A_loss: 0.0287, D_B_loss: 0.0145, G_A_loss: 0.8318, G_B_loss: 0.6336\n",
      "Epoch [193/200], Step [461/1067], D_A_loss: 0.0608, D_B_loss: 0.0210, G_A_loss: 0.9118, G_B_loss: 0.5735\n",
      "Epoch [193/200], Step [471/1067], D_A_loss: 0.0592, D_B_loss: 0.0409, G_A_loss: 0.6856, G_B_loss: 0.7119\n",
      "Epoch [193/200], Step [481/1067], D_A_loss: 0.0217, D_B_loss: 0.0923, G_A_loss: 1.0977, G_B_loss: 1.0161\n",
      "Epoch [193/200], Step [491/1067], D_A_loss: 0.0246, D_B_loss: 0.0194, G_A_loss: 0.5285, G_B_loss: 0.7078\n",
      "Epoch [193/200], Step [501/1067], D_A_loss: 0.0488, D_B_loss: 0.0492, G_A_loss: 0.5862, G_B_loss: 0.5564\n",
      "Epoch [193/200], Step [511/1067], D_A_loss: 0.0319, D_B_loss: 0.0178, G_A_loss: 1.1638, G_B_loss: 0.6013\n",
      "Epoch [193/200], Step [521/1067], D_A_loss: 0.0471, D_B_loss: 0.0212, G_A_loss: 1.2145, G_B_loss: 0.6705\n",
      "Epoch [193/200], Step [531/1067], D_A_loss: 0.1238, D_B_loss: 0.0298, G_A_loss: 0.9289, G_B_loss: 0.7221\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [193/200], Step [541/1067], D_A_loss: 0.0405, D_B_loss: 0.0066, G_A_loss: 1.0300, G_B_loss: 0.8149\n",
      "Epoch [193/200], Step [551/1067], D_A_loss: 0.0613, D_B_loss: 0.0233, G_A_loss: 1.0689, G_B_loss: 0.9582\n",
      "Epoch [193/200], Step [561/1067], D_A_loss: 0.0293, D_B_loss: 0.0066, G_A_loss: 0.9271, G_B_loss: 1.1884\n",
      "Epoch [193/200], Step [571/1067], D_A_loss: 0.0307, D_B_loss: 0.0239, G_A_loss: 0.9832, G_B_loss: 0.7456\n",
      "Epoch [193/200], Step [581/1067], D_A_loss: 0.0384, D_B_loss: 0.0156, G_A_loss: 1.0202, G_B_loss: 0.9333\n",
      "Epoch [193/200], Step [591/1067], D_A_loss: 0.1698, D_B_loss: 0.0093, G_A_loss: 0.9374, G_B_loss: 0.4055\n",
      "Epoch [193/200], Step [601/1067], D_A_loss: 0.0691, D_B_loss: 0.0647, G_A_loss: 0.9553, G_B_loss: 0.5435\n",
      "Epoch [193/200], Step [611/1067], D_A_loss: 0.0305, D_B_loss: 0.0085, G_A_loss: 0.7673, G_B_loss: 0.8177\n",
      "Epoch [193/200], Step [621/1067], D_A_loss: 0.0248, D_B_loss: 0.0158, G_A_loss: 0.7396, G_B_loss: 0.9544\n",
      "Epoch [193/200], Step [631/1067], D_A_loss: 0.1275, D_B_loss: 0.0119, G_A_loss: 0.9224, G_B_loss: 0.5745\n",
      "Epoch [193/200], Step [641/1067], D_A_loss: 0.0506, D_B_loss: 0.0121, G_A_loss: 0.8195, G_B_loss: 0.7345\n",
      "Epoch [193/200], Step [651/1067], D_A_loss: 0.0381, D_B_loss: 0.0096, G_A_loss: 1.0247, G_B_loss: 0.7851\n",
      "Epoch [193/200], Step [661/1067], D_A_loss: 0.0246, D_B_loss: 0.0156, G_A_loss: 1.0776, G_B_loss: 0.7995\n",
      "Epoch [193/200], Step [671/1067], D_A_loss: 0.0507, D_B_loss: 0.0151, G_A_loss: 0.8042, G_B_loss: 0.5968\n",
      "Epoch [193/200], Step [681/1067], D_A_loss: 0.0354, D_B_loss: 0.0486, G_A_loss: 0.6918, G_B_loss: 0.7770\n",
      "Epoch [193/200], Step [691/1067], D_A_loss: 0.0215, D_B_loss: 0.0139, G_A_loss: 1.0697, G_B_loss: 0.8637\n",
      "Epoch [193/200], Step [701/1067], D_A_loss: 0.1219, D_B_loss: 0.0210, G_A_loss: 1.0059, G_B_loss: 0.6612\n",
      "Epoch [193/200], Step [711/1067], D_A_loss: 0.0276, D_B_loss: 0.0225, G_A_loss: 0.9710, G_B_loss: 0.8784\n",
      "Epoch [193/200], Step [721/1067], D_A_loss: 0.0334, D_B_loss: 0.0087, G_A_loss: 1.0717, G_B_loss: 0.7795\n",
      "Epoch [193/200], Step [731/1067], D_A_loss: 0.0398, D_B_loss: 0.0152, G_A_loss: 0.8139, G_B_loss: 0.6937\n",
      "Epoch [193/200], Step [741/1067], D_A_loss: 0.0691, D_B_loss: 0.0075, G_A_loss: 0.9577, G_B_loss: 0.5672\n",
      "Epoch [193/200], Step [751/1067], D_A_loss: 0.0341, D_B_loss: 0.0117, G_A_loss: 0.7856, G_B_loss: 0.6313\n",
      "Epoch [193/200], Step [761/1067], D_A_loss: 0.0285, D_B_loss: 0.0073, G_A_loss: 0.5669, G_B_loss: 0.8490\n",
      "Epoch [193/200], Step [771/1067], D_A_loss: 0.0359, D_B_loss: 0.0151, G_A_loss: 0.7623, G_B_loss: 0.8270\n",
      "Epoch [193/200], Step [781/1067], D_A_loss: 0.0286, D_B_loss: 0.0613, G_A_loss: 1.1631, G_B_loss: 0.7912\n",
      "Epoch [193/200], Step [791/1067], D_A_loss: 0.2256, D_B_loss: 0.0255, G_A_loss: 0.8504, G_B_loss: 0.7868\n",
      "Epoch [193/200], Step [801/1067], D_A_loss: 0.0345, D_B_loss: 0.0310, G_A_loss: 0.8504, G_B_loss: 0.5681\n",
      "Epoch [193/200], Step [811/1067], D_A_loss: 0.1475, D_B_loss: 0.0844, G_A_loss: 0.9646, G_B_loss: 0.2602\n",
      "Epoch [193/200], Step [821/1067], D_A_loss: 0.1791, D_B_loss: 0.0644, G_A_loss: 1.2804, G_B_loss: 0.6293\n",
      "Epoch [193/200], Step [831/1067], D_A_loss: 0.1003, D_B_loss: 0.0094, G_A_loss: 0.9123, G_B_loss: 0.6659\n",
      "Epoch [193/200], Step [841/1067], D_A_loss: 0.0290, D_B_loss: 0.1037, G_A_loss: 0.7334, G_B_loss: 0.9895\n",
      "Epoch [193/200], Step [851/1067], D_A_loss: 0.0678, D_B_loss: 0.0064, G_A_loss: 1.2813, G_B_loss: 0.5810\n",
      "Epoch [193/200], Step [861/1067], D_A_loss: 0.0393, D_B_loss: 0.0472, G_A_loss: 0.8631, G_B_loss: 0.8132\n",
      "Epoch [193/200], Step [871/1067], D_A_loss: 0.0720, D_B_loss: 0.0228, G_A_loss: 0.6908, G_B_loss: 1.1089\n",
      "Epoch [193/200], Step [881/1067], D_A_loss: 0.0912, D_B_loss: 0.0364, G_A_loss: 0.6393, G_B_loss: 0.8812\n",
      "Epoch [193/200], Step [891/1067], D_A_loss: 0.0625, D_B_loss: 0.0372, G_A_loss: 0.7388, G_B_loss: 0.7884\n",
      "Epoch [193/200], Step [901/1067], D_A_loss: 0.1818, D_B_loss: 0.0171, G_A_loss: 0.9694, G_B_loss: 0.4175\n",
      "Epoch [193/200], Step [911/1067], D_A_loss: 0.0228, D_B_loss: 0.0127, G_A_loss: 0.8806, G_B_loss: 0.6117\n",
      "Epoch [193/200], Step [921/1067], D_A_loss: 0.0274, D_B_loss: 0.0170, G_A_loss: 1.1832, G_B_loss: 0.2706\n",
      "Epoch [193/200], Step [931/1067], D_A_loss: 0.1262, D_B_loss: 0.0341, G_A_loss: 1.2679, G_B_loss: 0.6297\n",
      "Epoch [193/200], Step [941/1067], D_A_loss: 0.0303, D_B_loss: 0.0157, G_A_loss: 1.0767, G_B_loss: 0.7706\n",
      "Epoch [193/200], Step [951/1067], D_A_loss: 0.0389, D_B_loss: 0.0144, G_A_loss: 1.4384, G_B_loss: 1.2393\n",
      "Epoch [193/200], Step [961/1067], D_A_loss: 0.2018, D_B_loss: 0.0242, G_A_loss: 0.7735, G_B_loss: 0.4046\n",
      "Epoch [193/200], Step [971/1067], D_A_loss: 0.0245, D_B_loss: 0.1734, G_A_loss: 0.6643, G_B_loss: 0.8017\n",
      "Epoch [193/200], Step [981/1067], D_A_loss: 0.0555, D_B_loss: 0.0089, G_A_loss: 0.9099, G_B_loss: 0.5851\n",
      "Epoch [193/200], Step [991/1067], D_A_loss: 0.0978, D_B_loss: 0.0271, G_A_loss: 0.9045, G_B_loss: 0.6910\n",
      "Epoch [193/200], Step [1001/1067], D_A_loss: 0.1424, D_B_loss: 0.0102, G_A_loss: 1.1140, G_B_loss: 0.7453\n",
      "Epoch [193/200], Step [1011/1067], D_A_loss: 0.0732, D_B_loss: 0.0096, G_A_loss: 0.8350, G_B_loss: 0.7123\n",
      "Epoch [193/200], Step [1021/1067], D_A_loss: 0.0552, D_B_loss: 0.0094, G_A_loss: 1.0574, G_B_loss: 0.8240\n",
      "Epoch [193/200], Step [1031/1067], D_A_loss: 0.0762, D_B_loss: 0.0204, G_A_loss: 0.9406, G_B_loss: 0.5757\n",
      "Epoch [193/200], Step [1041/1067], D_A_loss: 0.0223, D_B_loss: 0.0092, G_A_loss: 1.0656, G_B_loss: 0.8799\n",
      "Epoch [193/200], Step [1051/1067], D_A_loss: 0.0233, D_B_loss: 0.0087, G_A_loss: 1.0515, G_B_loss: 0.7785\n",
      "Epoch [193/200], Step [1061/1067], D_A_loss: 0.0286, D_B_loss: 0.0233, G_A_loss: 1.3209, G_B_loss: 0.7409\n",
      "Epoch [194/200], Step [1/1067], D_A_loss: 0.0218, D_B_loss: 0.0450, G_A_loss: 0.8281, G_B_loss: 0.9054\n",
      "Epoch [194/200], Step [11/1067], D_A_loss: 0.0433, D_B_loss: 0.0143, G_A_loss: 1.1178, G_B_loss: 0.6761\n",
      "Epoch [194/200], Step [21/1067], D_A_loss: 0.0380, D_B_loss: 0.0134, G_A_loss: 0.8008, G_B_loss: 1.0906\n",
      "Epoch [194/200], Step [31/1067], D_A_loss: 0.0867, D_B_loss: 0.0089, G_A_loss: 0.8608, G_B_loss: 0.4757\n",
      "Epoch [194/200], Step [41/1067], D_A_loss: 0.0656, D_B_loss: 0.0094, G_A_loss: 0.9359, G_B_loss: 0.8112\n",
      "Epoch [194/200], Step [51/1067], D_A_loss: 0.0478, D_B_loss: 0.0104, G_A_loss: 1.0412, G_B_loss: 0.6131\n",
      "Epoch [194/200], Step [61/1067], D_A_loss: 0.0425, D_B_loss: 0.0070, G_A_loss: 0.9411, G_B_loss: 0.8672\n",
      "Epoch [194/200], Step [71/1067], D_A_loss: 0.0557, D_B_loss: 0.0116, G_A_loss: 0.9324, G_B_loss: 1.2074\n",
      "Epoch [194/200], Step [81/1067], D_A_loss: 0.1427, D_B_loss: 0.0131, G_A_loss: 1.4044, G_B_loss: 0.4763\n",
      "Epoch [194/200], Step [91/1067], D_A_loss: 0.0497, D_B_loss: 0.0098, G_A_loss: 0.9652, G_B_loss: 0.7818\n",
      "Epoch [194/200], Step [101/1067], D_A_loss: 0.0282, D_B_loss: 0.0246, G_A_loss: 0.8836, G_B_loss: 0.5536\n",
      "Epoch [194/200], Step [111/1067], D_A_loss: 0.0348, D_B_loss: 0.0388, G_A_loss: 1.1923, G_B_loss: 0.8643\n",
      "Epoch [194/200], Step [121/1067], D_A_loss: 0.0163, D_B_loss: 0.0239, G_A_loss: 0.9161, G_B_loss: 0.9411\n",
      "Epoch [194/200], Step [131/1067], D_A_loss: 0.0643, D_B_loss: 0.0102, G_A_loss: 0.7890, G_B_loss: 0.9382\n",
      "Epoch [194/200], Step [141/1067], D_A_loss: 0.0375, D_B_loss: 0.0364, G_A_loss: 0.5801, G_B_loss: 0.8088\n",
      "Epoch [194/200], Step [151/1067], D_A_loss: 0.1036, D_B_loss: 0.0474, G_A_loss: 0.6516, G_B_loss: 0.4623\n",
      "Epoch [194/200], Step [161/1067], D_A_loss: 0.0350, D_B_loss: 0.0159, G_A_loss: 1.0257, G_B_loss: 0.8290\n",
      "Epoch [194/200], Step [171/1067], D_A_loss: 0.0429, D_B_loss: 0.0181, G_A_loss: 0.7636, G_B_loss: 0.7522\n",
      "Epoch [194/200], Step [181/1067], D_A_loss: 0.0744, D_B_loss: 0.0475, G_A_loss: 0.6208, G_B_loss: 0.8872\n",
      "Epoch [194/200], Step [191/1067], D_A_loss: 0.0450, D_B_loss: 0.0508, G_A_loss: 0.7517, G_B_loss: 0.7175\n",
      "Epoch [194/200], Step [201/1067], D_A_loss: 0.1393, D_B_loss: 0.0371, G_A_loss: 0.5824, G_B_loss: 0.5685\n",
      "Epoch [194/200], Step [211/1067], D_A_loss: 0.0355, D_B_loss: 0.0086, G_A_loss: 1.0474, G_B_loss: 0.6955\n",
      "Epoch [194/200], Step [221/1067], D_A_loss: 0.1395, D_B_loss: 0.0319, G_A_loss: 0.7795, G_B_loss: 1.1924\n",
      "Epoch [194/200], Step [231/1067], D_A_loss: 0.1322, D_B_loss: 0.0371, G_A_loss: 0.7136, G_B_loss: 0.6256\n",
      "Epoch [194/200], Step [241/1067], D_A_loss: 0.0931, D_B_loss: 0.0445, G_A_loss: 0.6347, G_B_loss: 0.4330\n",
      "Epoch [194/200], Step [251/1067], D_A_loss: 0.0340, D_B_loss: 0.0140, G_A_loss: 0.8398, G_B_loss: 0.8287\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [194/200], Step [261/1067], D_A_loss: 0.0246, D_B_loss: 0.0164, G_A_loss: 1.0696, G_B_loss: 0.9128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "step = 0\n",
    "for epoch in range(params.num_epochs):\n",
    "    D_A_losses = []\n",
    "    D_B_losses = []\n",
    "    G_A_losses = []\n",
    "    G_B_losses = []\n",
    "    cycle_A_losses = []\n",
    "    cycle_B_losses = []\n",
    "    \n",
    "    # Learing rate decay 설정 구간\n",
    "    if(epoch + 1) > params.decay_epoch:\n",
    "        D_A_optimizer.param_groups[0]['lr'] -= params.lrD / (params.num_epochs - params.decay_epoch)\n",
    "        D_B_optimizer.param_groups[0]['lr'] -= params.lrD / (params.num_epochs - params.decay_epoch)\n",
    "        G_optimizer.param_groups[0]['lr'] -= params.lrG / (params.num_epochs - params.decay_epoch)\n",
    "        \n",
    "    \n",
    "    # training 구간\n",
    "    for i, (real_A, real_B) in enumerate(zip(train_data_loader_A, train_data_loader_B)):\n",
    "        \n",
    "        # input image data\n",
    "        real_A = Variable(real_A.cuda())\n",
    "        real_B = Variable(real_B.cuda())\n",
    "        \n",
    "        # -------------------------- train generator G --------------------------\n",
    "        # A --> B\n",
    "        fake_B = G_A(real_A)\n",
    "        D_B_fake_decision = D_B(fake_B)\n",
    "        G_A_loss = MSE_Loss(D_B_fake_decision, Variable(torch.ones(D_B_fake_decision.size()).cuda()))\n",
    "        \n",
    "        # forward cycle loss\n",
    "        recon_A = G_B(fake_B)\n",
    "        cycle_A_loss = L1_Loss(recon_A, real_A) * params.lambdaA\n",
    "        \n",
    "        # B --> A\n",
    "        fake_A = G_B(real_B)\n",
    "        D_A_fake_decision = D_A(fake_A)\n",
    "        G_B_loss = MSE_Loss(D_A_fake_decision, Variable(torch.ones(D_A_fake_decision.size()).cuda()))\n",
    "        \n",
    "        # backward cycle loss\n",
    "        recon_B = G_A(fake_A)\n",
    "        cycle_B_loss = L1_Loss(recon_B, real_B) * params.lambdaB\n",
    "        \n",
    "        # Back propagation\n",
    "        G_loss = G_A_loss + G_B_loss + cycle_A_loss + cycle_B_loss\n",
    "        G_optimizer.zero_grad()\n",
    "        G_loss.backward()\n",
    "        G_optimizer.step()\n",
    "        \n",
    "        \n",
    "        # -------------------------- train discriminator D_A --------------------------\n",
    "        D_A_real_decision = D_A(real_A)\n",
    "        D_A_real_loss = MSE_Loss(D_A_real_decision, Variable(torch.ones(D_A_real_decision.size()).cuda()))\n",
    "        \n",
    "        fake_A = fake_A_pool.query(fake_A)\n",
    "        \n",
    "        D_A_fake_decision = D_A(fake_A)\n",
    "        D_A_fake_loss = MSE_Loss(D_A_fake_decision, Variable(torch.zeros(D_A_fake_decision.size()).cuda()))\n",
    "        \n",
    "        # Back propagation\n",
    "        D_A_loss = (D_A_real_loss + D_A_fake_loss) * 0.5\n",
    "        D_A_optimizer.zero_grad()\n",
    "        D_A_loss.backward()\n",
    "        D_A_optimizer.step()\n",
    "        \n",
    "        # -------------------------- train discriminator D_B --------------------------\n",
    "        D_B_real_decision = D_B(real_B)\n",
    "        D_B_real_loss = MSE_Loss(D_B_real_decision, Variable(torch.ones(D_B_fake_decision.size()).cuda()))\n",
    "        \n",
    "        fake_B = fake_B_pool.query(fake_B)\n",
    "        \n",
    "        D_B_fake_decision = D_B(fake_B)\n",
    "        D_B_fake_loss = MSE_Loss(D_B_fake_decision, Variable(torch.zeros(D_B_fake_decision.size()).cuda()))\n",
    "        \n",
    "        # Back propagation\n",
    "        D_B_loss = (D_B_real_loss + D_B_fake_loss) * 0.5\n",
    "        D_B_optimizer.zero_grad()\n",
    "        D_B_loss.backward()\n",
    "        D_B_optimizer.step()\n",
    "        \n",
    "        # ------------------------ Print -----------------------------\n",
    "        # loss values\n",
    "        D_A_losses.append(D_A_loss.data[0])\n",
    "        D_B_losses.append(D_B_loss.data[0])\n",
    "        G_A_losses.append(G_A_loss.data[0])\n",
    "        G_B_losses.append(G_B_loss.data[0])\n",
    "        cycle_A_losses.append(cycle_A_loss.data[0])\n",
    "        cycle_B_losses.append(cycle_B_loss.data[0])\n",
    "\n",
    "        if i%10 == 0:\n",
    "            print('Epoch [%d/%d], Step [%d/%d], D_A_loss: %.4f, D_B_loss: %.4f, G_A_loss: %.4f, G_B_loss: %.4f'\n",
    "                  % (epoch+1, params.num_epochs, i+1, len(train_data_loader_A), D_A_loss.data[0], D_B_loss.data[0], G_A_loss.data[0], G_B_loss.data[0]))\n",
    "            \n",
    "        # ============ TensorBoard logging ============#\n",
    "        D_A_logger.scalar_summary('losses', D_A_loss.data[0], step + 1)\n",
    "        D_B_logger.scalar_summary('losses', D_B_loss.data[0], step + 1)\n",
    "        G_A_logger.scalar_summary('losses', G_A_loss.data[0], step + 1)\n",
    "        G_B_logger.scalar_summary('losses', G_B_loss.data[0], step + 1)\n",
    "        cycle_A_logger.scalar_summary('losses', cycle_A_loss.data[0], step + 1)\n",
    "        cycle_B_logger.scalar_summary('losses', cycle_B_loss.data[0], step + 1)\n",
    "        step += 1\n",
    "        \n",
    "    D_A_avg_loss = torch.mean(torch.FloatTensor(D_A_losses))\n",
    "    D_B_avg_loss = torch.mean(torch.FloatTensor(D_B_losses))\n",
    "    G_A_avg_loss = torch.mean(torch.FloatTensor(G_A_losses))\n",
    "    G_B_avg_loss = torch.mean(torch.FloatTensor(G_B_losses))\n",
    "    cycle_A_avg_loss = torch.mean(torch.FloatTensor(cycle_A_losses))\n",
    "    cycle_B_avg_loss = torch.mean(torch.FloatTensor(cycle_B_losses))\n",
    "\n",
    "    # avg loss values for plot\n",
    "    D_A_avg_losses.append(D_A_avg_loss)\n",
    "    D_B_avg_losses.append(D_B_avg_loss)\n",
    "    G_A_avg_losses.append(G_A_avg_loss)\n",
    "    G_B_avg_losses.append(G_B_avg_loss)\n",
    "    cycle_A_avg_losses.append(cycle_A_avg_loss)\n",
    "    cycle_B_avg_losses.append(cycle_B_avg_loss)\n",
    "\n",
    "    # Show result for test image\n",
    "    test_real_A = Variable(test_real_A_data.cuda())\n",
    "    test_fake_B = G_A(test_real_A)\n",
    "    test_recon_A = G_B(test_fake_B)\n",
    "\n",
    "    test_real_B = Variable(test_real_B_data.cuda())\n",
    "    test_fake_A = G_B(test_real_B)\n",
    "    test_recon_B = G_A(test_fake_A)\n",
    "\n",
    "    utils.plot_train_result([test_real_A, test_real_B], [test_fake_B, test_fake_A], [test_recon_A, test_recon_B],\n",
    "                            epoch, save=True, save_dir=save_dir)\n",
    "\n",
    "    # log the images\n",
    "    result_AtoB = np.concatenate((utils.to_np(test_real_A), utils.to_np(test_fake_B), utils.to_np(test_recon_A)), axis=3)\n",
    "    result_BtoA = np.concatenate((utils.to_np(test_real_B), utils.to_np(test_fake_A), utils.to_np(test_recon_B)), axis=3)\n",
    "\n",
    "    info = { 'result_AtoB': result_AtoB.transpose(0, 2, 3, 1),  # convert to BxHxWxC\n",
    "             'result_BtoA': result_BtoA.transpose(0, 2, 3, 1) }\n",
    "\n",
    "    for tag, images in info.items():\n",
    "        img_logger.image_summary(tag, images, epoch + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot average losses\n",
    "avg_losses = []\n",
    "avg_losses.append(D_A_avg_losses)\n",
    "avg_losses.append(D_B_avg_losses)\n",
    "avg_losses.append(G_A_avg_losses)\n",
    "avg_losses.append(G_B_avg_losses)\n",
    "avg_losses.append(cycle_A_avg_losses)\n",
    "avg_losses.append(cycle_B_avg_losses)\n",
    "utils.plot_loss(avg_losses, params.num_epochs, save=True, save_dir=save_dir)\n",
    "\n",
    "# Make gif\n",
    "utils.make_gif(params.dataset, params.num_epochs, save_dir=save_dir)\n",
    "# Save trained parameters of model\n",
    "torch.save(G_A.state_dict(), model_dir + 'generator_A_param.pkl')\n",
    "torch.save(G_B.state_dict(), model_dir + 'generator_B_param.pkl')\n",
    "torch.save(D_A.state_dict(), model_dir + 'discriminator_A_param.pkl')\n",
    "torch.save(D_B.state_dict(), model_dir + 'discriminator_B_param.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
